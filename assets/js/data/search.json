[ { "title": "nacos杂谈", "url": "/2023/07/nacos.html", "categories": "计算机综合", "tags": "IT-Basic", "date": "2023-07-24 08:07:14 +0800", "snippet": " 本文主要介绍 nacos 相关的一些理论知识、实践经验和验证实验。 架构简介 云原生 负载均衡器 协议架构简介 服务注册中心架构演进 阿里巴巴为什么不用 ZooKeeper 做服务发现？ 【Nacos】一文为你揭露它的强大 保姆级教程教你学会搭建Nginx和Nacos集群 干货|深入理解分布式事务，这一篇就够了！ Zookeeper适合做服务发现吗 阿里为啥不用 Z...", "content": " 本文主要介绍 nacos 相关的一些理论知识、实践经验和验证实验。 架构简介 云原生 负载均衡器 协议架构简介 服务注册中心架构演进 阿里巴巴为什么不用 ZooKeeper 做服务发现？ 【Nacos】一文为你揭露它的强大 保姆级教程教你学会搭建Nginx和Nacos集群 干货|深入理解分布式事务，这一篇就够了！ Zookeeper适合做服务发现吗 阿里为啥不用 ZooKeeper 做服务发现？ 55 张图吃透 Nacos，微服务的灵魂摆渡者强大在哪 转载 全网最火的Nacos监控中心——Prometheus+Grafana nacos看这一篇文章就够了 golang：Go-Micro+nacos实现微服务 go语言操作nacos配置中心 支持 gRPC 长链接，深度解读 Nacos 2.0 架构设计及新模型 go集成nacos配置中心并读取配置信息 go-mciro系列(四)使用nacos作为配置中心 golang 监听consul 配置中心 golang apollo使用 qconfig Golang接入配置中心框架 Apollo 所开发的Golang版本客户端 Apollo 初探 Apollo 远程服务配置中心 【Nacos】一文为你揭露它的强大 Nacos之原理讲解和使用 微服务的灵魂摆渡者——Nacos，来一篇原理全攻略 面试官：Nacos 为什么这么强！讲讲实现原理？我懵了。。 配置中心 – Nacos 实现原理 转载 Nacos 注册中心的设计原理详解 什么是Nacos以及原理（转载） nacos 原理是什么？ 【微服务】Nacos 原理 一文上手Nacos（从原理到实战） Nacos全面解析 你想了解的Nacos原理全在这里 一文详解 Nacos 高可用特性 「源码学习」Nacos配置中心服务端实现原理 「源码学习」Nacos配置中心客户端实现原理 nacos的服务注册以及健康检测机制 Nacos作为服务配置中心 Nacos 配置安全最佳实践 图文解析 Nacos 配置中心的实现 Nacos从入门到放弃 配置中心原理和选型：Disconf、Spring Cloud Config、Apollo 和 Nacos 分布式配置中心–Apollo云原生 从Kubernetes到Cloud Native——云原生应用之路 Go语言十大主流微服务框架 五分钟技术趣谈 | 微服务在Golang开发中的实现方案 不看后悔，一文带你入门Go云原生微服务 Go微服务全链路跟踪详解 jupiter golang工程组件篇：微服务工具集go-kit之请求链路追踪 golang工程组件之分布式链路追踪OpenTelemetry golang 使用 OpenTelemetry 实现跨服务 全链路追踪 基于go-micro微服务的实战-zipkin实现全链路追踪(九) go-kit实践之5：go-kit微服务请求跟踪实现 Go微服务架构实战 下篇：1. gRPC + Opentracing + Zipkin实现分布式链路追踪系统 gomicro v2–04 链路追踪jaeger和监控Prometheus go 链路追踪_go-micro V2 从零开始（八）集成链路追踪工具jaeger golang工程组件之分布式链路追踪OpenTelemetry 解读Go分布式链路追踪实现原理 GO微服务实战第二十九节 如何追踪分布式系统调用链路的问题？ 为什么不应该使用ZooKeeper做服务发现 golang分布式链路追踪 OpenTracing jaeger Go2sky – Golang用skywalking实现全链路追踪 分布式链路追踪 之 Skywalking 设计理念&amp;核心原理 Kubernetes上使用Jaeger分布式追踪基础设施详解 微服务线上问题排查困难？不知道问题出在哪一环？那是你还不会分布式链路追踪 三个开源的分布式追踪工具 GO微服务实战第三十节 OpenTracing 规范介绍与分布式链路追踪组件选型 在知乎学Golang场景化解决方案(分布式日志系统) 在CSDN学Golang工程组件（微服务工具集go-kit） golang工程组件之分布式链路追踪OpenTelemetry 微服务架构设计与实现 微服务入门 最全面的零基础认识微服务教程 颠覆微服务认知：深入思考微服务的七个主流观点 最全的微服务知识科普 微服务全流程分析 实施微服务，我们需要哪些基础框架？ 你以为在做的是微服务？不！你只是做了个比单体还糟糕的分布式单体！ 我们公司放弃了微服务，重回单体架构 浅谈微服务中的熔断,限流,降级 微服务分布式系统熔断实战-为何我们需要API级别熔断？ 限流熔断技术选型：从Hystrix到Sentinel http 网关 熔断和限流 颠覆微服务架构？谷歌最新开源Service Weaver初体验 golang微服务框架对比_微服务全流程各组件对比分析 微服务体系下的服务治理 一篇囊括微服务服务拆分的一切：前提，时机，方法，规范，选型 微服务架构深入剖析拆分，聊一聊单体架构的痛点 golang一键多平台打包 面向开发运维的10款开源工具（面向开发运维的10款开源工具有哪些） 推荐一个：开源自动化运维开发平台(IT Automatic Develop Platform) spug小型自动运维平台 开源运维平台负载均衡器 负载均衡、DNS、F5、反向代理、LVS、四层与七层、CDN 分布式系统的负载均衡 | 架构干货 一篇读懂分布式架构下的负载均衡技术：分类、原理、算法、常见方案等 分布式架构系列: 负载均衡技术详解 三大主流软件负载均衡器对比(LVS、Nginx、HAproxy) 亿级PV系统的负载均衡架构与组件的选型 负载均衡器的原理，类型以及如何选择？ 不懂高性能的负载均衡设计？没关系，架构师带你飞 分布式架构系列: 负载均衡技术详解 全局负载均衡方 负载均衡选型要点 Nginx架构四之七层负载均衡 七层负载均衡——-nginx 微服务之负载均衡组件Ribbon [干货 几种负载均衡的挑选](https://blog.csdn.net/jdcdev_/article/details/90693356) 软负载和硬负载的区别分析 浅谈几种常用负载均衡架构 负载均衡架构方案思考（haproxy、nginx、LVS、array、F5） 负载均衡的原理和架构 分布式架构系列: 负载均衡技术详解 一篇读懂分布式架构下的负载均衡 负载均衡是什么（超级详细） 十张图带你了解负载均衡 负载均衡整体架构知识点介绍 负载均衡的原理和架构 负载均衡在分布式架构中是怎么玩起来的？ 负载均衡由来及架构演变——DNS、nginx、apache、LVS 系统架构——负载均衡整理总结 详解【负载均衡】（负载均衡算法、一致性hash、负载均衡架构分析） 全网最详细的负载均衡原理图解 搭建一个高可用负载均衡的集群架构（一） 全网最详细的负载均衡原理图解 全网最详细的负载均衡原理图解 搞懂“负载均衡”，一篇就够了协议 protobuf http/http2 tcp/udp" }, { "title": "go从bug中学习原理和优化", "url": "/2023/03/go.html", "categories": "编程语言", "tags": "Go", "date": "2023-03-29 10:02:40 +0800", "snippet": " 本文通过讲解或制造bug来学习原理。并得到相应的优化手段。 测试工具 官方原生测试包 testing.T testing.F testing.B testing.M testing.PB testdata 目录和 Golden 文件 ...", "content": " 本文通过讲解或制造bug来学习原理。并得到相应的优化手段。 测试工具 官方原生测试包 testing.T testing.F testing.B testing.M testing.PB testdata 目录和 Golden 文件 帮助函数 示例文件 跳过函数 并发测试 testfy assert 包 require 包 测试套件 suite goconvey mock测试 mock测试的缺陷 不用Mock怎么写（单元）测试 业务测试 gomonkey mock易用工具 其他参考文献 性能检测工具 pprof 使用场景 分析 其他类似工具 trace 引入trace 可视化界面解读 常见优化 优化GC 传统的GC算法 Go GC 算法 三色标记法 GC过程 GC优化 GC分析工具 GC源码导读 源码文件位置 触发GC链路 标记准备 并发标记 标记清扫 逃逸分析 逃逸策略 逃逸场景 逃逸总结 其他优化 性能诊断 优化定时器 类型或数据结构优化 cgo或跨语言调用优化 低级优化 综合优化 原理篇 参考文档 第三方库 常见bug和分析 其他工具测试工具测试在原型开发和实际开发、bug复现和技术学习等中，都至关重要。因此，掌握适当的工具，可以简化测试，提高测试效率，进而使测试起来简单、可复用。也就使开发人员更容易和愿意去做这种保质且划算的测试。以下列举的单元测试工具展示了一个发展流程，对于非mock测试： 简单断言或结果打印，可使用官方原生测试包 含各场景分组测试、可读性强、长期维护的测试用例，复杂断言等，可使用testfy(推荐)这里简单总结一下几个测试框架：个人觉得 GoConvey 的语法 对业务代码侵入有点严重，而且理解它本身也需要一些时间成本，比如 testify 逻辑清晰。单元测试逻辑本身就要求比较简单，综上，还是更推荐用 testify。官方原生测试包在testing包中包含一下结构体: testing.T: 这就是我们平常使用的单元测试 testing.F: 模糊测试, 可以自动生成测试用例 testing.B: 基准测试. 对函数的运行时间进行统计. testing.M: 测试的钩子函数, 可预置测试前后的操作. testing.PB: 测试时并行执行.// 此方法源自 Go 官方文档func Reverse(s string) string { bs := []byte(s) length := len(bs) for i := 0; i &lt; length/2; i++ { bs[i], bs[length-i-1] = bs[length-i-1], bs[i] } return string(bs)}testing.TGo对单元测试函数要求如下 文件名形如: xxx_test.go 函数签名形如: func TestXxx(t *testing.T)func TestReverse(t *testing.T) {\tstr := \"abc\"\trevStr1 := Reverse(str)\trevStr2 := Reverse(revStr1)\tif str != revStr2 {\t\t// error 方法报错后, 会继续向下执行\t\tt.Error(\"error\")\t\t// fatal 方法报错后, 会退出测试\t\t// t.Fatal(\"fatal\")\t\t// 输出调试信息\t\t// t.Log(\"log\")\t\t// 测试中断, 但是测试结果不会十遍\t\t// t.Skip(\"skip\")\t}\t// 可启动多个子测试, 子测试之间并行运行\tfor _, str = range []string{\"abcd\", \"aceb\"} { // 第一个参数为子测试的标识\t\tt.Run(str, func(t *testing.T) {\t\t\trevStr1 := Reverse(str)\t\t\trevStr2 := Reverse(revStr1)\t\t\tif str != revStr2 {\t\t\t\tt.Error(\"error\")\t\t\t}\t\t})\t}}下面将要测试的每种情况列举出来，然后针对每个整数调用ToRoman()函数，比较返回的罗马数字字符串和错误值是否与预期的相符。后续要添加新的测试用例也很方便。表格驱动测试示例如下（表驱动测试中testCases结构中加一个场景描述字段，可以提高可读性）：func TestToRoman(t *testing.T) { testCases := []struct { num int expect string err error }{ {0, \"\", ErrOutOfRange}, {1, \"I\", nil}, {500, \"D\", nil}, {1000, \"M\", nil}, {31, \"XXXI\", nil}, {312, \"CCCXII\", nil}, {4000, \"\", ErrOutOfRange}, } for _, testCase := range testCases { got, err := ToRoman(testCase.num) if got != testCase.expect { t.Errorf(\"ToRoman(%d) expect:%s got:%s\", testCase.num, testCase.expect, got) } if err != testCase.err { t.Errorf(\"ToRoman(%d) expect error:%v got:%v\", testCase.num, testCase.err, err) } }}有时候对同一个函数有不同维度的测试，将这些组合在一起有利于维护。例如上面对ToRoman()函数的测试可以分为非法值，单个罗马字符和普通 3 种情况。使用如下命令运行测试用例(test.run 指定运行某一个函数):go test -test.run TestReversetesting.F用于模糊测试, 会自动生成测试用例。其内部会自动生成各种测试用例, 并自动调用执行。Go对模糊测试的函数要求如下: 文件名形如: xxx_test.go 函数签名形如: func FuzzXxx(f *testing.F)func FuzzReverse(f *testing.F) {\t// 设置测试用例需要随机生成的变量类型\tf.Add(\"Hello, world!\")\t// 生成测试用例并进行测试. 回电函数接收的参数, 与 f.Add 设置的参数类型一致\tf.Fuzz(func(t *testing.T, str string) {\t\trevStr1 := Reverse(str)\t\trevStr2 := Reverse(revStr1)\t\tif revStr2 != str {\t\t\tt.Error(\"error\")\t\t}\t\t// 判断是否是合法的 utf8 编码\t\tif utf8.ValidString(str) &amp;&amp; !utf8.ValidString(revStr1) {\t\t\tt.Error(\"utf8 error\")\t\t}\t})}运行命令开始测试: go test -test.fuzz FuzzReverse -test.run ^$ (其中test.run指定不运行test函数)。模糊测试的难点在于，即使测试用例是随机的，也需要像上面示例那样有办法验证其正确性。testing.B用于基准测试. 对函数的运行时间进行统计, 对函数要求如下: 文件名形如: xxx_test.go 函数签名形如: func BenchmarkXxx(b *testing.B)运行命令: go test -test.bench BenchmarkReverse -test.run ^$结果中指出了运行次数及平均时间. 其中各项值的含义如下: 100000000: 迭代次数 ns/op: 平均每次迭代消耗的时间 B/op: 平均每次迭代消耗的内存 allocs/op: 平均每次迭代内存的分配次数testing.M定义在运行测试的前后执行的操作. 对函数的要求如下: 文件名形如: xxx_test.go 函数签名为: func TestMain(m *testing.M)函数定义如下：func TestMain(m *testing.M) {\t// 测试之前执行的操作\tfmt.Println(\"starting test main\")\t// 运行测试\tcode := m.Run()\t// 测试之后执行的操作\tfmt.Println(\"ending test main\")\tos.Exit(code)}此函数会在运行所有测试时自动调用.testing.PB用于在测试时进行并发测试. 上面的”单元测试/模糊测试/基准测试”都可以使用. 以基准测试为例, 使用如下:// 充分利用 CPU 资源, 并行执行 n 次func BenchmarkReverse2(b *testing.B) {\tb.RunParallel(func(pb *testing.PB) {\t\tfor pb.Next() {\t\t\t// 此循环体总共执行 b.N 次\t\t\tReverse(\"hello\")\t\t}\t})}testdata 目录和 Golden 文件这个也是一个比较特殊的目录，go build 编译时，会自动忽略 testdata 目录，并且在运行 go test 指令时，会将 test 文件所在目录设置为根目录，可以直接使用相对路径 testdata 引入或者存储相关文件。简而言之，testdata 目录的使用场景，就是能够很直观的通过文件内容对比，发现测试结果是否符合预期，适用于输入输出都比较复杂的情况。go 官方标准库 cmd/gofmt/gofmt_test.go 源码中就有用到，可参考。我们可以将期望输出存储在一个名为 .golden 的文件中并提供一个 flag 来更新它。这个技巧使你得以测试复杂的输出而无需硬编码。这里是例子：var update = flag.Bool(\"update\", false, \"update .golden files\")func TestSomething(t *testing.T) { actual := doSomething() Golden := filepath.Join(\"testdata\", tc.Name+ \".golden\" ) if *update { ioutil.WriteFile(golden, actual, 0644) } expected, _ := ioutil.ReadFile(golden) if !bytes.Equal(actual, expected) { // FAIL! }}帮助函数Helper()函数将当前所在的函数标记为测试帮助方法。当打印文件和代码行信息时，该方法会被跳过。Go 语言在 1.9 版本中引入了 t.Helper()，用于标注该函数是帮助函数，报错时将输出帮助函数调用者的信息，而不是帮助函数的内部信息。关于 helper 函数的 2 个建议： 不要返回错误， 帮助函数内部直接使用 t.Error 或 t.Fatal 即可，在用例主逻辑中不会因为太多的错误处理代码，影响可读性。 调用 t.Helper() 让报错信息更准确，有助于定位。示例文件测试工具包还能运行和验证示例代码。示例函数包含一个结论行注释，该注释以Output:开头，然后比较示例函数的标准输出和注释中的内容。func ExampleHello() { fmt.Println(\"hello\") // Output: hello}func ExampleSalutations() { fmt.Println(\"hello, and\") fmt.Println(\"goodbye\") // Output: // hello, and // goodbye}Unordered output的前缀注释将匹配任意的行顺序。func ExamplePerm() { for _, value := range Perm(5) { fmt.Println(value) } // Unordered output: 4 // 2 // 1 // 3 // 0}不包含output注释的示例函数，将不会被执行。跳过函数功能测试或性能测试时可以跳过一些测试函数。func TestTimeConsuming(t *testing.T) { if testing.Short() { t.Skip(\"skipping test in short mode.\") } ...}并发测试对于表驱动测试和子测试等，可以通过函数标记来进行并发测试。var Cash = make(map[string]string)func Add(key,value string){ if _,ok := Cash[key];!ok{ Cash[key] = value }}func TestCanParallelExecAdd(t *testing.T){ var addTests = []struct{ key string value string expected int }{ {\"a\",\"aa\",1}, {\"b\",\"bb\",2}, {\"c\",\"cc\",3}, {\"c\",\"cc\",3}, {\"c\",\"cc\",3}, {\"d\",\"dd\",4}, {\"e\",\"ee\",5}, {\"f\",\"ff\",6}, {\"g\",\"gg\",7}, {\"h\",\"hh\",8}, {\"i\",\"ii\",9}, {\"j\",\"jj\",10}, } t.Parallel() quary := rand.Int() t.Logf(\"[goroutine:%d] start\",quary) for _,v := range addTests{ Add(v.key,v.value) t.Logf(\"[goroutine:%d] add %s:%s\",quary,v.key,v.value) if len(Cash) != v.expected{ t.Errorf(\"add %s:%s len = %d; except %d\",v.key,v.value,len(Cash),v.expected) } } Clean()}func TestParallelAdd(t *testing.T){ for i:=0;i&lt;10;i++{ t.Run(fmt.Sprintf(\"g-%d\",i), func(t *testing.T) { t.Parallel() TestAdd(t) }) }}testfy上节中官方原生测试包简单明了，但缺少很多高效简便的断言。testfy 在兼容官方原生测试包的同时提供了简便的断言，提高了测试编码效率。testify 有三个主要功能： 断言，在 assert 包和 require 包。 Mocking，在 mock 包下。 测试组件，在 suite 包下。mock 简易使用 gomonkey，因此减少testfy时不讲其mock功能。assert 包assert 包提供了一系列很方便的断言方法，简化你的测试代码。如package yoursimport ( \"testing\" \"github.com/stretchr/testify/assert\")func TestSomething(t *testing.T) { // 断言相等 assert.Equal(t, 123, 123, \"they should be equal\") // 断言不等 assert.NotEqual(t, 123, 456, \"they should not be equal\") // 断言为 nil assert.Nil(t, object)}assert 包的函数的第一个参数为 testing.T，用于执行 go test 时输出信息。如果你有很多个断言，可以调用New方法实例化 Assertions 结构体，然后就可以省略testing.T参数了。上面的代码，可以简化成func TestSomething(t *testing.T) { // 实例化 assertion 结构体，下面的断言都不用传入 t 作为第一个参数了。 assert := assert.New(t) // 断言相等 assert.Equal(123, 123, \"they should be equal\") // 断言不等 assert.NotEqual(123, 456, \"they should not be equal\") // 断言为 nil assert.Nil(object)}assert 失败的话，底层调用 t.Errorf 来输出错误信息。也就是说，断言失败并不会中停止测试。assert 包的断言函数，返回值是 bool 类型，表示断言的成功或失败。 我们可以根据返回值，进一步做断言。如// 当 object 不为 nil 的时候，进一步断言 object.Value 的值if assert.NotNil(t, object) { assert.Equal(t, \"Something\", object.Value)}assert 包提供的断言类型非常多，包括对比变量、json、目录、Http 响应等。完整列表见assertrequire 包require 包提供的函数和 assert 包是一样的，区别是： require 包如果断言失败，底层调用 t.FailNow， 会立刻中断当前的测试，所以也不会有返回值。 assert 包如果断言失败，底层调用 t.Errorf，返回 false，不会中断测试。测试套件 suite如果你有别的面向对象语言的经验，用 suite 包写单元测试可能更符合你的习惯。我们可以自定义一个结构体，它依赖 suite.Suite，它所有的以 Test 开头的函数，都是一个测试。详见suiteimport ( \"testing\" \"github.com/stretchr/testify/assert\" \"github.com/stretchr/testify/suite\" \"fmt\")// 依赖 suite.Suitetype ExampleTestSuite struct { suite.Suite VariableThatShouldStartAtFive int}// 每个测试运行前，会执行func (suite *ExampleTestSuite) SetupTest() { suite.VariableThatShouldStartAtFive = 5}// 每个测试运行后，会执行func (suite *ExampleTestSuite) TearDownTest() { fmt.Println(\"next test\")}// 所有以“Test”开头的方法，都是一个测试func (suite *ExampleTestSuite) TestExample() { assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)}// 用于 'go test' 的入口func TestExampleTestSuite(t *testing.T) { suite.Run(t, new(ExampleTestSuite))}suite 中有以下钩子： SetupTest：每个测试运行前，都会执行 TearDownTest： 每个测试之后，都会执行 SetupSuite： Suite 开始之前执行一次，在所有测试之前执行 TearDownSuite： Suite 结束之后执行一次，在所有测试之后执行goconveygoconvey特别适合于BDD（行为驱动开发）。行为驱动开发(Behavior Driven Development，BDD)借鉴了敏捷和精益实践，让敏捷研发团队尽可能理解产品经理或业务人员的产品需求，并在软件研发过程中及时反馈和演示软件产品的研发状态，让产品经理或业务人员根据获得的产品研发信息及时对软件产品特性进行调整。BDD帮助敏捷研发团队把精力集中在识别、理解和构建跟业务目标有关的产品特性上面，并让敏捷研发团队能够确保识别出的产品特性能够被正确设计和实现出来。BDD的产品研发流程如下： 产品经理（业务人员）通过具体的用户故事使用场景来告诉软件需求分析人员他（她）想要什么样的软件产品。使用软件产品的使用场景来描述软件需求可以尽可能的避免相关人员错误理解软件需求或增加自己的主观想象的需求。 软件需求分析人员（BA）和研发团队（研发人员、测试人员）一起对产品经理（业务人员）的用户故事进行分析，并梳理出具体的软件产品使用场景举例，这些场景举例使用结构化的关键字自然语言进行描述，例如中文、英文等。 研发团队使用BDD工具把用户故事场景文件转化为可执行的自动化测试代码，研发人员运行自动化测试用例来验证开发出来的软件产品是否符合用户故事场景的验收要求。 测试人员可以根据自动化测试结果开展手工测试和探索性测试。产品经理（业务人员）可以实时查看软件研发团队的自动化测试结果和BDD工具生成的测试报告，确保软件实现符合产品经理（业务人员）的软件期望。// split.gopackage goconvey_demoimport \"strings\"// Split// @Description: 把字符串s按照给定的分隔符sep进行分割返回字符串切片// @param s// @param sep// @return result//func Split(s, sep string) (result []string) {\tresult = make([]string, 0, strings.Count(s, sep)+1)\ti := strings.Index(s, sep)\tfor i &gt; -1 {\t\tresult = append(result, s[:i])\t\ts = s[i+len(sep):] // 使用len(sep)获取sep的长度\t\ti = strings.Index(s, sep)\t}\tresult = append(result, s)\treturn}普通测试文件如下：// split_test.goimport (\t\"testing\"\tc \"github.com/smartystreets/goconvey/convey\" // 别名导入)func TestSplit(t *testing.T) {\tc.Convey(\"基础用例\", t, func() {\t\tvar (\t\t\ts = \"a:b:c\"\t\t\tsep = \":\"\t\t\texpect = []string{\"a\", \"b\", \"c\"}\t\t)\t\tgot := Split(s, sep)\t\tc.So(got, c.ShouldResemble, expect) // 断言\t})\tc.Convey(\"不包含分隔符用例\", t, func() {\t\tvar (\t\t\ts = \"a:b:c\"\t\t\tsep = \"|\"\t\t\texpect = []string{\"a:b:c\"}\t\t)\t\tgot := Split(s, sep)\t\tc.So(got, c.ShouldResemble, expect) // 断言\t})}goconvey还支持在单元测试中根据需要嵌套调用和表格驱动，比如：//// TestChildrenSplit// @Description: 嵌套调用// @param t//func TestChildrenSplit(t *testing.T) {\t// 只需要在顶层的Convey调用时传入t\tc.Convey(\"分隔符在开头或者结尾用例\", t, func() {\t\ttt := []struct {\t\t\tname string\t\t\ts string\t\t\tsep string\t\t\texpect []string\t\t}{\t\t\t{\"分隔符在开头\", \"1*2*3\", \"*\", []string{\"\", \"1\", \"2\", \"3\"}},\t\t\t{\"分隔符在结尾\", \"1+2+3+\", \"+\", []string{\"1\", \"2\", \"3\", \"\"}},\t\t}\t\tfor _, tc := range tt {\t\t\tc.Convey(tc.name, func() {\t\t\t\t// 嵌套调用Convery\t\t\t\tgot := Split(tc.s, tc.sep)\t\t\t\tc.So(got, c.ShouldResemble, tc.expect)\t\t\t})\t\t}\t})}GoConvey为我们提供了很多种类断言方法在So()函数中使用。 一般相等类 数字数量比较类 包含类 字符串类 panic类 类型检查类 时间和时间间隔类如果上面列出来的断言方法都不能满足你的需要，那么你还可以按照下面的格式自定义一个断言方法。除此之外，你还可以借助比如testfy的asset等第三方包。// 注意：&lt;&gt;中的内容是你需要按照实际需求替换的内容。func should&lt;do-something&gt;(actual interface{}, expected ...interface{}) string { if &lt;some-important-condition-is-met(actual, expected)&gt; { return \"\" // 返回空字符串表示断言通过 } return \"&lt;一些描述性消息详细说明断言失败的原因...&gt;\"}goconvey提供全自动的WebUI，只需要在项目目录下执行以下命令：goconvey。默认就会在本机的8080端口提供WebUI界面，十分清晰地展现当前项目的单元测试数据。mock测试单元测试一般仅限于测试本服务，对于别的服务的调用（比如数据库），我们可以创建 Mock 对象来模拟对其他服务的调用。什么时候适合 mock？ 如果一个对象具有以下特征，比较适合使用 mock 对象： 该对象提供非确定的结果（比如当前的时间或者当前的温度） 对象的某些状态难以创建或者重现（比如网络错误或者文件读写错误） 对象方法上的执行太慢（比如在测试开始之前初始化数据库） 该对象还不存在或者其行为可能发生变化（比如测试驱动开发中驱动创建新的类） 该对象必须包含一些专门为测试准备的数据或者方法（后者不适用于静态类型的语言，流行的 mock 框架不能为对象添加新的方法，stub 是可以的）。因此，不要滥用 mock（stub），当被测方法中调用其他方法函数，第一反应应该走进去串起来，而不是从根部就 mock掉了。mock测试的缺陷 漏测关键逻辑：任何时候都要小心，被mock的对象其行为未必跟我们预期的一致（比如时区等）。 测试不存在的逻辑：mock的时候可能已经满足了某些前提，或者引入了额外的逻辑，而这些前提在实际中可能不存在。 漏测横切特性 掩盖坏味道：需要mock，可能是 依赖过多 依赖过于分散：外部依赖没有恰当的封装和隔离 依赖的传递方式或隔离方式存在优化空间 过长的调用链 掩盖性能缺陷：mock一般是直接返回结果，这很可能掩盖了被mock对象或函数的性能缺陷。 阻碍重构：强依赖mock，不便于测试，说明代码布局或分拆存在问题，应当优化功能划分或代码封装粒度等。 测试实现细节而非功能：应当测试功能或业务逻辑，而不是实现细节。单元测试是测试细节，但是测试的是业务细节，而不是实现细节。从测试的目的看，任何测试都应该是行为测试或者业务逻辑测试。即我们测试的是系统或者组件有没有按照期望的方式返回结果。至于这个结果是怎么产生的不应当是测试负责验证的事情（比如可以借用程序调试）。值得指出的是，业务逻辑是层层下放的，也就是上一层的所有业务细节，一定在下一层有支撑。而一般情况下每一个方法一定是应对一个业务需求（粒度大小不同）。从投入产出比来看，为什么不要测试实现细节呢？ 实现细节变化快于其实现的业务变化频率，测试成本高； 同时，因为测试没有到达“边界”，实际上我们获得的信息是有限的。我们经常会发现测试基本上是在重复已实现的逻辑。不用Mock怎么写（单元）测试 消除『单元』情结： 在很多人看来，单元测试就是测试一个类，甚至是一个方法。所有其他的因素全都应当屏蔽掉。这不仅在原则上是错误的，实践上也几乎是不可能做到的。正确的测试单元应当是一个业务逻辑单元。 你的测试本身，而不仅是测试的方法名，应该是对于非开发人员也尽量是可读的。 对象创建与依赖注入：尽量通过函数参数(可以是结构体)把依赖传入，而不是在函数内部直接调用依赖（比如单例调用）。 考虑其他的间接测试方式： 变换测试粒度，或者间接测试等 文件、网络和数据库 可以尝试内存数据库或者docker容器 网络也有本地可执行的组件等替代手段，或者服务器上真实跑跑和观察更划算 文件也可采用内存文件系统，或者服务器上真实跑跑和观察更划算 MVC和容器 Reactive Programming： 响应式编程孤立尽量避免副作用，这使得一个方法几乎不会对外产生依赖。如果有依赖，也是另一个无副作用的依赖。 对于一个函数来说，一个输入无条件的对应一个确定的输出。所以，我们设计的方法往往很快到达“边界”。在纯粹的Functional Programming中，是不存在面向对象意义上的“对象”的。用户可以定义数据结构，其目的是作为参数或者结果，而不是将操作和被操作的数据放到一起。从面向对象编程转向响应式编程的思维方式是一个非常大的转变。我们也不能针对一个用面向对象思维设计出来的类以响应式编程的方式进行测试。对于中间件的输入和输出可以通过依赖注入（比如mysql的连接通过函数参数或者结构体成员变量注入）和本地docker容器来实施。而中间件所需的输入数据，可以通过数据文件或shell等脚本批量执行（可以不断复用）。单元测试的粒度选择可参考玩转Go单元测试，你只需要掌握这5点业务测试对于业务测试，可以使用类似配置文件的方式进行代码设计与测试： 除了main入口之外，其中所有的业务代码和测试代码都共用 正常的代码和测试代码分开文件夹存放 正常代码和测试代码入口分别是：main.go 和 test_main.go main.go 和 test_main.go 中的主要代码流程也相同，只是参数或配置不同 参数或依赖注入的不同主要表现在： 外部依赖的mock文件放在测试文件夹中 正常代码中要给出可以适配测试的初始化函数，比如文件路径、定时器时间周期等 通过第一步之后，制造适当输入即可覆盖所有正常场景和异常场景 如果输出也有依赖的话(比如输出到mq或数据库)，可以讲输出适配成log，通过log来查看输出 通过前面的步骤，就实现了输入和输出的隔离，不依赖任何外部程序的动态数据（依赖的可编译的第三方静态代码是没有任何问题的），可以达到： 本地编译和无网络运行 测试和正常代码除了输入和输出有mock或不同外，中间的几乎所有的代码逻辑都是共用的 本地测试可代替大部分服务器上的测试，而小部分可通过以下过程实现： 输入源输出目的地以及其他动态依赖可通过集成测试实现 开发之间的协议上的理解、产品与开发之间在业务场景理解上的差异，也是可以通过集成测试交互来识别或协同 这种测试的好处： 可快速确保自身业务代码的测试覆盖率、测试简便性、测试的可复用性 当业务逻辑发生变化时，只要外部依赖没有变化，那么测试代码基本上可复用（相较于每个函数的单元测试而言，测试代码变化的概率要小得多） 节约开发在测试上花费的时间，也大大减少了代码更新后的测试与维护时间 容易做自身业务代码的性能测试，使自身代码最优化后，也更容易发现集成性能瓶颈点 对于特别复杂的函数或算法而言，在尽量拆解复杂性之后，可以通过针对性的单元测试或调试来保证稳健性。gomonkey在不得已用 mock 的情况下，推荐使用 gomonkey 这个 mock 工具。gomonkey 基础特性列表如下： 支持为一个函数打一个桩 支持为一个成员方法打一个桩 支持为一个全局变量打一个桩 支持为一个函数变量打一个桩 支持为一个函数打一个特定的桩序列 支持为一个成员方法打一个特定的桩序列 支持为一个函数变量打一个特定的桩序列具体可参考以下文章： gomonkey源码解读 你该刷新 gomonkey 的惯用法了 Golang Mock使用入门 GoMock快速上手教程 Go语言如何在没有实现功能的情况下写出完善的单元测试代码 如何写出可测试的 Go 代码mock易用工具 dockertest orlangure/gnomock：各种中间件的mock，单元测试或集成测试时不再需要自己写mock了 Redis Memcached MySQL MariaDB PostgreSQL MongoDB RabbitMQ Kafka Elasticsearch alicebob/miniredis：纯go的用于单测的redis服务端代码 cjsaylor/sqlfixture：纯go的用于单测的mysql服务端代码 k1LoW/grpcstub：grpc测试打桩其他参考文献 go test 的使用 Go单元测试实践 Go 测试高级窍门和技巧 Go 全场景测试工具和实践选型推荐 Go 中的进阶测试模式 手把手教你如何进行 Golang 单元测试 GoLang 单元测试打桩和 mock Go单元测试实践 Golang 单元测试：有哪些误区和实践？ Golang 单元测试指引 Go：基于BDD的测试框架 Ginkgo 简介及实践 高效测试框架推荐之Ginkgo Go 写测试必学的三个库：Ginkgo、testify 和 GoMock Ginkgo 测试框架学习笔记 ginkgo 测试库 Golang Testing 概览 - 基本篇 Golang Testing 概览 - 深入篇 Golang Testing 概览 - 补充篇 Go单测从零到溜系列0—单元测试基础 Go单测从零到溜系列1—网络测试 Go单测从零到溜系列2—MySQL和Redis测试 Go单测从零到溜系列3—mock接口测试 Go单测从零到溜系列4—使用monkey打桩 Go单测从零到溜系列5—goconvey的使用 Go单测从零到溜系列6—编写可测试的代码 使用Go做测试（进阶版） 手把手教你如何进行 Golang 单元测试 为 go 遗留代码添加单元测试（零） Go语言如何在没有实现功能的情况下写出完善的单元测试代码 Go：测试库（GoConvey，testify，GoStub，GoMonkey）对比及简介性能检测工具编码和单元测试一般聚焦在功能正确这个角度，但有时我们需要再有限资源下追求高性能（比如尽量减少CPU和内存占用、降低时延等），此时就需要借助性能检测工具，以找出性能瓶颈点，然后重点优化。练习pprof的使用可以点击pprof练习pprofpprof 可以分析golang运行中的程序或者特定函数的性能数据，比如CPU、内存、协程等资源使用情况，以及各函数使用资源的占比等。可通过 go install github.com/google/pprof 来安装 pprof。然后可以通过命令 go tool pprof 进行分析。该命令支持多种数据源和交互模式： 数据源： http 地址 已经采集并下载下来的 profile 文件： pprof -http=:8080 cpu.prof 交互模式： 命令行交互 浏览器模式(-http参数) 如果要用到可视化界面的，需要安装 graphviz使用场景一般的使用场景有以下几个： 服务器程序(不主动退出) 非持续运行的程序(运行短暂时间后会主动退出) 测试代码(go test)已服务器程序为例。通过http采样收集一段时间后，得到相关数据然后就地分析或下载文件后他处分析。要点如下： 代码中引入： import _ “net/http/pprof” 如果程序中没有现有的 http 端口或服务，需启动一个http服务 该包会绑定了URL：http://localhost或ip:端口/debug/pprof/ 数据采集和查看 概览：http://localhost或ip:端口/debug/pprof/ 具体的profiles：http://localhost或ip:端口/debug/pprof/类型 其中类型有（打开上面的概览网址即可看到）： allocs： 内存分配情况的采样信息 blocks： 阻塞操作情况的采样信息 cmdline： 显示程序启动命令参数及其参数 goroutine： 显示当前所有协程的堆栈信息 heap： 堆上的内存分配情况的采样信息 mutex： 锁竞争情况的采样信息 profile： cpu占用情况的采样信息，点击会下载文件 threadcreate：系统线程创建情况的采样信息 trace： 程序运行跟踪信息非持续运行的程序、测试代码这两种场景与服务器程序(上面提到的http引入方式)的不同点如下，其他都相同： 非持续运行的程序 代码中引入包：runtime/pprof 使用的API函数形如：runtime.StartCPUProfile/runtime.StopCPUProfile等 具体示例代码可搜索网络或查阅pprof性能调优 测试代码： go test -bench . -cpuprofile cpu.prof（其中的点号代表目录，也可以指定特定的函数），其他参数如下(替换cpuprofile的位置)： benchmem：打印出申请内存的次数 blockprofile：协程阻塞情况 memprofile： 协程内存申请信息 mutexprofile： 互斥情况 trace：执行调用链情况 不论哪种使用场景，最终都会得到所需的profile文件（比如CPU的、内存的）。而分析就是基于这个文件的，只不过分析的时候交互方式有所区别： 网页可视化 分析源基于http： 以cpu为例，即URL中最后一个词profile：go tool pprof -http=:9000 http://localhost:8000/debug/pprof/profile 其他的分析，把URL中的最后一个词替换就行，比如聂村分配情况，可替换成 allocs 其他参数：采样时间 -seconds=5，例如 go tool pprof -seconds=5 -http=:9000 http://localhost:8000/debug/pprof/profile 数据较详细的文件：curl -o profile.out http://localhost:6060/debug/pprof/profile 分析源基于文件：go tool pprof -http=:9000 你的文件 go 1.8之前，你同时需要可执行二进制文件和数据文件，用go 1.8之后的版本编译的程序，分析时不需要指定二进制文件了 终端交互方式： 命令(不需要-http选项，其他都一样，这里以文件为例)：go tool pprof cpu.prof 输入 web 可以查看到svg图形，其他交互命令，可通过输入 help 获取帮助 分析整个分析的过程分为两步： 导出数据（详情参考本文中的“使用场景”一节） 分析数据 通过 top 等统计信息初步定位 通过可视化精细定位 分析函数代码： 当确定出哪个函数耗时之后，可以用pprof分析函数中的哪一行导致的耗时，使用子命令：list 函数名pprof的目标是生成可视化的检测报告。报告是根据采集的样本数据从一个跟节点位置开始按调用关系生成层次化的结构。每个位置包含两个值： flat：当前位置自身消耗的值（不包含函数内的调用消耗） cum：当前位置及子位置累计的消耗值（即当前函数以及所有调用的函数总消耗）pprof生成报告的形式有两种：文字形式和可视化图形 文字报告pprof的文字报告用文字的格式展示了位置的层次结构。文字报告中有5个指标：Flat、Flat%、Sum%、Cum、Cum% Flat：函数自身运行耗时 Flat%：函数自身耗时比例 Sum%：指的就是每一行的flat%与上面所有行的flat%总和 Cum：当前函数加上它所有调用栈的运行总耗时 Cum%：当前函数加上它所有调用栈的运行总耗时比例举例说明：函数demo由三部分组成：调用函数foo、自己直接处理一些事情、调用函数bar，其中调用函数foo耗时1秒，自己直接处理事情耗时3秒，调用函数bar耗时2秒，那么函数demo的flat耗时就是3秒，cum耗时就是6秒。func demo() { foo() // takes 1s do something directly // takes 3s bar() // takes 2s} 可视化图形报告web页面中经常用到的是 VIEW 菜单系列项： Top：同(pprof)中的top命令 Graph：连线图（展示函数调用线） Flame Graph：火焰图 Peek：同(pprof)中的 text 命令，打印每个调用栈 Source：同(pprof)中的 list 命令如果是内存信息，则 菜单 SAMPLE 中有以下介个项： alloc_objects：已分配的对象总量（不管是否已释放） alloc_space：已分配的内存总量（不管是否已释放） inuse_objects： 已分配但尚未释放的对象数量 inuse_sapce：已分配但尚未释放的内存数量在图形化的包中包含节点、节点之间的边、字体三个元素。而每个元素又具有颜色和大小两个属性。 连线图 每个节点的信息包括了包名、函数名、flat、flat%、cum、cum% 节点的颜色越红，其cum和cum%越大 其颜色越灰白，则cum和cum%越小 线条代表了函数的调用链：线条越粗，代表指向的函数消耗了越多的资源 线条的样式代表了调用关系：实线代表直接调用；虚线代表中间少了几个节点 火焰图：可以将程序的 函数调用堆栈关系和资源占比 两个信息可视化，常用用来做程序的CPU和内存的分析。 可以分析函数执行的频繁程度 可以分析哪些函数经常阻塞（profie分析） 可以分析哪些函数频繁分配内存（heap分析） 火焰图两个作用： 可视化函数调用链关系 可视化资源占比：跨度越大，占比资源（CPU/内存）越大 火焰图解读： 火焰图的横向长度表示cum，相比下面超出的一截代表flat 火焰图可以进行点击，细化调用关系，一层层查看更具体的细节 y 轴表示调用栈：每一层都是一个函数。调用栈越深，火焰就越高 x 轴表示抽样数：如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长 只要有”平顶”（plateaus，即该函数占据宽度独大，没有进一步细化），就表示该函数可能存在性能问题 火焰图互动： 鼠标悬浮：火焰的每一层都会标注函数名，鼠标悬浮时会显示完整的函数名、抽样抽中的次数、占据总抽样次数的百分比 点击放大： 在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息 点击上一层会回到上一层调用关系，点击root则会回到最上层 搜索：按下 Ctrl + F 会显示一个搜索框，用户可以输入关键词或正则表达式，所有符合条件的函数名会高亮显示。 其他类似工具 基准测试 promethus 算法时间复杂度分析大 O表示法 适配操作系统存储层次和缓存策略 使用dlv分析golang进程cpu占用高问题 go程序cpu过高问题排查方法 Go 中的性能分析和执行跟踪trace你是否遇到过：为什么在程序中增加了并发，但并没有给它带来更好的性能？go执行跟踪程序可以帮助回答这些疑问，还有其他和其有关性能的问题，例如延迟、竞争和较低的并行效率。在真实的程序中还包含许多的隐藏动作，例如： Goroutine 在执行时会做哪些操作？ Goroutine 执行/阻塞了多长时间？ Syscall 在什么时候被阻止？在哪里被阻止的？ 谁又锁/解锁了 Goroutine ？ GC 是怎么影响到 Goroutine 的执行的？在引入执行trace程序之前，已经有了pprof内存和CPU分析器，那么为什么它还会被添加到官方的工具链中呢？虽然CPU分析器做了一件很好的工作，告诉你什么函数占用了最多的CPU时间，但它并不能帮助你确定是什么阻止了goroutine运行，或者在可用的OS线程上如何调度goroutines。这正是跟踪器真正起作用的地方。trace设计文档很好地解释了跟踪程序背后的动机以及它是如何被设计和工作的。引入trace分析trace之前需要先得到trace数据文件，才能做进一步分析： 代码中引入trace 可终止的程序中引入方式： 在程序中引入包 runtime/trace，程序退出时会把trace信息输出到控制台 执行命令导出trace数据文件：go run main.go 2&gt; trace.out 服务器程序引入方式： 想要从一个运行的web应用收集trace, 你需要添加 /debug/pprof/trace handler。下面的代码示例展示了如何通过简单地导入 net/http/pprof 包为 http.DefaultServerMux 做到这一点。 curl localhost:8181/debug/pprof/trace?seconds=10 &gt; trace.out 启动可视化界面：go tool trace trace.out// 可终止的程序引入方式package mainimport ( \"os\" \"runtime/trace\")func main() { trace.Start(os.Stderr) defer trace.Stop() // create new channel of type int ch := make(chan int) // start new anonymous goroutine go func() { // send 42 to channel ch &lt;- 42 }() // read from channel &lt;-ch}// 服务器程序引入方式：package mainimport ( \"net/http\" _ \"net/http/pprof\")func main() { http.Handle(\"/hello\", http.HandlerFunc(helloHandler)) http.ListenAndServe(\"localhost:8181\", http.DefaultServeMux)}func helloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world!\"))}可视化界面解读启动可视化界面之后，会出现以下项目： View trace：最复杂、最强大和交互式的可视化显示了整个程序执行的时间轴。这个视图显示了在每个虚拟处理器上运行着什么，以及什么是被阻塞等待运行的。稍后我们将在这篇文章中深入探讨这个视图。注意它只能在chrome上显示。 Goroutine analysis：显示了在整个执行过程中，每种类型的goroutines是如何创建的。在选择一种类型之后就可以看到关于这种类型的goroutine的信息。例如，在试图从mutex获取锁、从网络读取、运行等等每个goroutine被阻塞的时间。 Network/Sync/Syscall blocking profile：这些图表显示了goroutines在这些资源上所花费的时间。它们非常接近pprof上的内存/cpu分析。这是分析锁竞争的最佳选择。 Scheduler latency profiler：为调度器级别的信息提供计时功能，显示调度在哪里最耗费时间。在刚开始查看问题时，除非是很明显的现象，否则不应该一开始就陷入细节。界面分析步骤： 先查看 Scheduler latency profile 了解一些概览信息 看 “Goroutine analysis”： 我们能通过这个功能看到整个运行过程中，每个函数块有多少个有 Goroutine 在跑 观察每个的 Goroutine 的运行开销都花费在哪个阶段 每个 Goroutine 具体做了些什么事情，可通过点击具体细项去观察 这块能够很好的帮助我们对 Goroutine 运行阶段做一个的剖析，可以得知到底慢哪，然后再决定下一步的排查方向 查看 “View trace”： 在对当前程序的 Goroutine 运行分布有了初步了解后，我们再通过 “查看跟踪” 看看之间的关联性 具体细节可参考文章 Go 工程师必学：Go 大杀器之跟踪剖析 trace go的请求追踪神器go tool trace 查出问题之后可以： 修复问题前后比较 trace 数据和可视化情况 把问题抽象成 demo，再用 trace 工具突出分析 如果加强 trace 分析经验，可以： 经常使用 trace：尽量把服务器程序本地化。 即不依赖任何外部动态数据或组件，在本地就可以正常运行起来，并制造输入来像跑在服务器一样执行所有业务逻辑（包括外部依赖的mock）。 尽量不影响线上或测试环境正常运作的情况下，实现trace分析自由（具体实施方法可参考”业务测试”一节） 制造bug或demo程序，练习或观察trace表现。 网络收集分析案例或者整理自己遇到过的案例常见优化优化GC垃圾回收（Garbage Collection，简称 GC）是一种内存管理策略，由垃圾收集器以类似守护协程的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间. 优势： 屏蔽内存分配和释放的细节，开发人员能更好地聚焦业务逻辑实现 手动内存分配在大项目协作时，需要具备指针全局跟踪的视野，很容易出现内存污染或悬空指针等内存问题，导致内存bug剧增。 劣势： 内存自动分配自动回收，但开发人员也失去了自行分配内存的自由：将释放内存的工作委托给垃圾回收模块，研发人员得到了减负，但同时也失去了控制主权. 除了运用有限的GC调优参数外，更多的自由度都被阉割，需要向系统看齐，服从设定. 增加了额外成本：全局的垃圾回收模块化零为整，会需要额外的状态信息用以存储全局的内存使用情况. 且部分时间需要中断整个程序用以支持垃圾回收工作的执行，这些都是GC额外产生的成本. GC 在并发度复杂度高且性能不要求极致的项目中，能很好的提高开发效率。但在性能追求极致的项目中，GC可能会成为性能瓶颈。传统的GC算法GC 一般分为两个大的阶段，不同的 GC 算法只不过是在这两个阶段的实现上采取了不同的策略，同时为了弥补该策略带来的副作用而做了一些优化策略。 标记：识别存活对象和垃圾对象 清扫：回收垃圾对象以下通过表格的形式展示常用传统GC算法。| 算法 | 特点 | 备注 || —- | —- | —- || 标记清除 | 标记存活对象，清扫未标记对象 | 默认是垃圾对象，不做空间压缩或重新编排 || 标记压缩 | 同标记清除，但清扫时会做空间压缩或重新编排 | 可减少内存碎片，但复杂度高，有性能开销 || 半空间复制 | 每轮GC只使用空间的一般，GC 时会把存活对象转移到另一半 | 空间换时间，降低了复杂度，但浪费了一半空间 || 引用计数 | 对象每被引用一次加1，每被删除引用一次减1，为0则被视为垃圾对象 | 很难解决循环引用和自引用问题 |Go GC 算法Go GC 算法有一个较长的进化过程，我们首先从较新的算法开始介绍，然后再简述其历史。目前 Go GC 算法大方向已经确定： 三色标记法 混合写屏障机制 GC 和用户协程最大化并发进行Golang采用 TCMalloc 机制，依据对象的大小将其归属为到事先划分好的spanClass当中，这样能够消解外部碎片的问题，将问题限制在相对可控的内部碎片当中三色标记法对于实时系统而言，垃圾回收系统可能是一个极大的隐患，因为在垃圾回收的时候需要将整个应用程序暂停。所以在我们设计消息总线系统的时候，需要小心地选择我们的语言。Go一直在强调它的低延迟，但是它真的做到了吗？如果是的，它是怎么做到的呢？把所有对象分为三类：白色、灰色、黑色。其定义如下： 对象 特点 备注 白色对象 GC 标记前默认的对象标记，GC 标记完成后则为垃圾对象 所有对象假设默认都不可达，标记完成后，不可达才视为真的不可达 灰色对象 已被访问，但其直接引用的对象还未扫描完成，即至少还有一个直接引用对象未被扫描 表示该对象的直接引用对象还在扫描中 黑色对象 该对象及其直接引用的所有对象都已被访问或标记过 表示已确定为可达对象（一旦灰色对象全部转为黑色，则表示标记阶段完成） 需要指出的是，黑色对象需要包括： 不存在引用外部指针的对象 从 root 区域出发扫描到的对象：root 区域主要是程序运行到当前时刻的栈和全局数据区域。从定义中可以得到以下推论： 黑色对象直接引用的所有对象，要么是黑色，要么是灰色，不可能是白色（否则意味着漏标，将被错误回收，导致致命错误）。这是三色标记算法正确性保障的前提条件。 所有灰色对象在GC标记结束后都会变成黑色对象 灰色对象可以认为是波面，该波面由白色传导到黑色，未被传导的则认为不可达，即为垃圾对象。三色标记过程与用户业务执行过程是并发的，可能需要考虑以下问题： 已被标记为黑色的对象，在三色标记过程中被用户解除引用，造成错标。这个错误会在下一轮GC中得到纠正。可见，这只会延后垃圾对象的回收，对用户程序逻辑无影响。 由于起初默认是白色对象，当某个对象已经被标记为黑色对象(即改对象及其直接子对象已经标记完成)。此时用户新建了一个对象（默认为白色对象），并且该对象是被黑色对象引用的，GC认为该白色对象已标记完成，会错误地把该白色对象认为是垃圾对象，即发生了漏标现象。想要在标记过程中保证安全性，不漏标，我们需要达成以下两种三色不变式（Tri-color invariant）中的任意一种： 强三色不变式：黑色对象不能指向白色对象，只能指向灰色或黑色对象； 弱三色不变式：黑色对象指向的白色对象，必须包含一条从灰色对象经由多个白色对象的可达路径。如何解决上面的漏标问题？满足三色不变式，一般可以考虑以下几种方式： 读写屏障(有多种变形)：在读写操作前后插入一段代码，用于记录一些信息、保存某些数据等，概念类似于AOP。 插入写屏障：实现强三色不变式，保证当一个黑色对象指向一个白色对象前，会先触发屏障将白色对象置为灰色，再建立引用。 删除写屏障：实现弱三色不变式，保证当一个白色对象即将被上游删除引用前，会触发屏障将其置灰，之后再删除上游指向其的引用。 混合写屏障：混合使用了插入写屏障和删除写屏障技术，为了减少对栈上对象的重复扫描（栈对象扫描需要STW）。 GC开始将栈上的对象全部扫描并标记为黑色（之后不再进行第二次重复扫描，无需STW） GC期间，任何在栈上创建的新对象，都标记为黑色 被删除的对象标记为灰色 被添加的对象标记为灰色 增量更新：通过写屏障记录GC标记过程中用户解除引用或新建对象产生的白色对象，等到垃圾清理时，STW（stop the world，指在进行垃圾回收时，会暂停应用程序的运行，以便进行垃圾回收操作。这意味着在进行垃圾回收时，应用程序将无法继续执行）对被记录下的对象再扫描一次。 原始快照：GC 扫描期间直接把新建对象标记为黑色如果一个并行 GC 收集器在处理超大内存堆时能够达到极低的延迟，那么为什么还有人在用 stop-the-world 的 GC 收集器呢？难道 Go 的 GC 收集器还不够优秀吗？这不是绝对的，因为低延迟是有开销的。最主要的开销就是，低延迟削减了吞吐量。并发需要额外的同步和赋值操作,而这些操作将会占用程序的处理逻辑的时间。而 Haskell 的 GHC 则针对吞吐量进行了优化，Go 则专注于延迟，我们在考虑采用哪种语言的时候需要针对我们自己的需求进行选择，对于推送系统这种实时性要求比较高的系统，选择Go语言则是权衡之下得到的选择。GC过程GC 相关的代码在runtime/mgc.go文件下。通过注释介绍我们可以知道 GC 一共分为4个阶段。除了走读代码了解GC过程之外，还可以借助pprof的可视化跟踪过程。 sweep termination（清理终止） 会触发 STW ，所有的 P（处理器） 都会进入 safe-point（安全点）； 清理未被清理的 span（一组连续的Page被称为Span，而page指的是按页分配） the mark phase（标记阶段） 将 _GCoff GC 状态 改成 _GCmark，开启 Write Barrier （写入屏障）、mutator assists（协助线程），将根对象入队； 恢复程序执行，mark workers（标记进程）和 mutator assists（协助线程）会开始并发标记内存中的对象。对于任何指针写入和新的指针值，都会被写屏障覆盖，而所有新创建的对象都会被直接标记成黑色； GC 执行根节点的标记，这包括扫描所有的栈、全局对象以及不在堆中的运行时数据结构。扫描goroutine 栈绘导致 goroutine 停止，并对栈上找到的所有指针加置灰，然后继续执行 goroutine。 GC 在遍历灰色对象队列的时候，会将灰色对象变成黑色，并将该对象指向的对象置灰； GC 会使用分布式终止算法（distributed termination algorithm）来检测何时不再有根标记作业或灰色对象，如果没有了 GC 会转为mark termination（标记终止） mark termination（标记终止） STW，然后将 GC 阶段转为 _GCmarktermination,关闭 GC 工作线程以及 mutator assists（协助线程）； 执行清理，如 flush mcache he sweep phase（清理阶段） 将 GC 状态转变至 _GCoff，初始化清理状态并关闭 Write Barrier（写入屏障）； 恢复程序执行，从此开始新创建的对象都是白色的； 后台并发清理所有的内存管理单元 GC 标记的工作是分配 25% 的 CPU 来进行 GC 操作，所以有可能 GC 的标记工作线程比应用程序的分配内存慢，导致永远标记不完，那么这个时候就需要应用程序的线程来协助完成标记工作。下面这张图显示了 gcStart 过程中状态变化，以及 STW 停顿的方法，写屏障启用的周期：GC优化了解了GC的触发时机和频率之后，才能对GC进行更好的优化。 主动触发：runtime.GC()强制触发GC 申请内存时触发：Go 语言运行时的默认配置会在堆内存达到上一次垃圾收集的 2 倍时，触发新一轮的垃圾回收，这个行为可以通过 GOGC 变量调整。它的默认值为 100，即增长 100% 的堆内存才会触发 GC。再分配内存时，判断当前内存是否达到阈值会触发新一轮GC（比如当前为 4MB，GOGC=100，4MB + 4MB * GOGC / 100） 系统定时触发：上次GC间隔达到了runtime.forcegcperiod（默认2分钟），会启动GC调优方法和总体思路（做减法，不做多余的事情）： 合理化内存分配速度 内存池化，降低并复用已经申请的内存 减少对象数量，合理优化数据结构 减少内存使用总量 减少内存分配动态分配频度 尽可能在栈上分配内存 合理使用空结构体（空结构体不占用内存空间） 调整GOGC：事实上，这个值很难确定，可以采用手段GO 内存 ballast。ballast 的大小可以参考使用该手段之前的虚拟内存和物理内存，预估一个值。另外，可参考文章聊聊两个Go即将过时的GC优化策略GC 作为内存垃圾回收的组件，在检测和执行回收时会占用CPU资源，同时可能会引起业务时延的突然飙升。因此有时在以下两方面进行优化是值得的： GC 检测和标记 GC 执行垃圾回收 减少垃圾回收所用的协程数在Go的运行模型GMP中，每个P会运行一个gcBgMarkWorker用于垃圾回收。是否由于P的数量不正确导致GC过多，从而CPU使用率过高？ Go程序在运行时，会使用查询到的CPU的数量作为默认的P的数量，简单地用一个Go脚本验证一下:func main() { cpu := runtime.NumCPU() procs := runtime.GOMAXPROCS(0) fmt.Println(\"cpu num:\", cpu, \" GOMAXPROCS:\", procs)}对于容器或云主机而言，可能会出现：在程序运行时读取到的CPU的数量是宿主机的CPU数量，而不是容器设置的CPU核心数量。通过环境变量GOMAXPROCS可以设置Go运行时P的数量。由于Go程序本身的特性，在运行时会默认读取系统的CPU核心数作为最大的并行执行线程数。 而在容器内，读取到的是宿主机的CPU核心数。 在容器被分配的CPU核心数远小于宿主机的CPU核心数的情况下，就会发生CPU使用率异常升高的情况。 出现问题的这个服务，其业务特点就是周期性的峰值QPS极高，所以会较为明显地观察出CPU使用率异常的现象。 通过配置环境变量 GOMAXPROCS，指定最大的并行执行线程数，可以解决CPU使用率异常的问题。 由于业务逻辑的不同，达到最佳性能的GOMAXPROCS也不同。《The Way to Go》曾给出过一个经验公式：GOMAXPROCS=CPU数量-1。 在容器中，通常设置成申请的核心数即可。另外，Uber开源了一个自动调整GOMAXPROCS的库：https://github.com/uber-go/automaxprocs。具体细节参考.net runtime占用cpu_Go服务在容器内CPU使用率异常问题排查手记。 减少标记阶段扫描耗时降低标记阶段的耗时，需要深刻了解golang语言垃圾回收的理论和代码实现机制。一般从以下方面入手： 减少申请内存的次数(比如可在用户层重用内存，减少申请次数) 减少申请内存的对象个数(即使申请的内存大小一样，但作为一个整体使用与分割成多块来使用，效果不一样) 减少申请内存的频度(即使在相同时间内申请的次数相同，但时间上的分布不同，效果也不同) 减少GC标记扫描的次数或频度权衡使用指针还是内存拷贝，尽量减少指针的使用，至于优化措施是否过时（GC算法在不断优化中），需要借助”GC分析工具“进行验证。优化的本质：尽最大努力不做多余的事情。如何做到这一点： 对业务逻辑充分理解，去掉多余的逻辑，减少代码堆砌； 对编程语言底层原理有充分的理解，使用更高效的方式实现相同的效果。 使用高效的数据结构，简化逻辑的复杂性GC分析工具GC的分析工具有： go tool pprof：CPU和内存分析 go tool trace go bulid -gcflags = “-m”：逃逸分析 GODEBUG=”gctrace=1”：跟踪GC行为 最常用的是GODEBUG=”gctrace=1”，下图中展示的是采用GODEBUG=”gctrace=1”分析GC的情况用pprof中的cpu profile时，可以使用 top cum命令或直接对这些函数使用list命令，并将注意力集中在累计百分比列上。 runtime.gcBgMarkWorker：专用标记工作goroutine的入口点。这里花费的时间与GC频率以及对象图的复杂性和大小成比例。它表示应用程序标记和扫描所用时间的基准。注意：在一个大部分时间都处于空闲状态的Go应用程序中，Go GC会消耗额外的（空闲的）CPU资源来更快地完成任务。 runtime.mallocgc：堆内存的内存分配器的入口点。此处花费的大量累积时间（&gt; 15%）通常表示分配了大量内存。 runtime.gcAssistAlloc：goroutine进入这个函数是为了腾出一些时间来帮助GC进行扫描和标记。这里花费的大量累积时间（&gt; 5%）表明应用程序在分配速度方面可能超过了GC。它表示GC的影响程度特别高，并且还表示应用程序在标记和扫描上花费的时间。请注意，它包含在runtime.mallocgc调用树中，因此它也会使该调用树累计时间增加。在确定GC是一个巨大开销的来源之后，消除堆分配的下一步是找出它们中的大多数来自哪里。为此，内存profile文件（实际上是堆内存profile文件）非常有用。内存profile文件描述了程序堆中分配的来源，并通过分配时的堆栈跟踪来标识它们。每个内存profile文件可以按四种方式分析： inuse_objects：活动对象的数量 inuse_space：按活动对象使用的内存量（以字节为单位） alloc_objects：自Go程序开始执行以来已经分配的对象数 alloc_space：自Go程序开始执行以来所分配的内存总量在这些不同的堆内存视图之间切换可以通过pprof工具的-sample_index标志来完成，或者在交互式使用该工具时通过sample_index选项来完成。为了降低GC成本，alloc_space通常是最有用的视图，因为它直接对应于分配率。此视图将指示可提供最大益处的分配热点。GC源码导读原理需要被源码论证。go GC 经过了几个大版本的进化，如果需要知晓其优化思路与过程，可以先读最新版的源码，然后再从最老的版本读至最新版。在读历史各个版本时，需要关注其不同点或优化点，并始终抱着以下这些问题进行： 为什么需要这些优化 这些优化会引入什么新的问题 该优化在哪些场景有很好的效果 该优化在哪些场景却会带来更差的效果 还可以怎样进一步优化 用户基于这些优化，用户可以怎么做，从中能得到更大的好处。GC 演化简史： 在Go1.3及之前使用的是标记清除法，其中标记清除也经历了串行处理和并行处理阶段； 在Go1.5实现了三色标记法，大幅的降低了STW的时间； 在Go1.7实现了并行的清理垃圾过程，将垃圾收集的时间大幅降低。 在Go1.8引入了混合写屏障，大幅的降低了标记的时间。 在后续的版本中基于以上算法，优化了内存分配、标记开始结束等继续对GC做了部分优化源码文件位置 环节 文件位置 主干流程 runtime/mgc.go 调步策略 runtime/mgcspacer.go 并发标记 runtime/mgcmark.go 清扫流程 runtime/msweep.go 触发GC链路 定时触发GC 方法 文件 init runtime/proc.go forcegchelper runtime/proc.go main runtime/proc.go sysmon runtime/proc.go injectglist runtime/proc.go gcStart runtime/mgc.go gcTrigger.test runtime/mgc.go 对象分配触发 方法 文件 mallocgc runtime/malloc.go gcTrigger.test runtime/mgc.go gcStart runtime/mgc.go 标记准备 方法 文件 gcStart runtime/mgc.go gcBgMarkStartWorkers runtime/mgc.go gcBgMarkWorker runtime/mgc.go stopTheWorldWithSema runtime/mgc.go gcControllerState.startCycle runtime/mgcspacer.go setGCPhase runtime/mgc.go gcMarkRootPrepare runtime/mgc.go gcMarkTinyAllocs runtime/mgc.go startTheWorldWithSema runtime/mgc.go 并发标记 调度标记协程 方法 文件 schedule runtime/proc.go findRunnable runtime/proc.go gcControllerState.findRunnableGCWorker runtime/mgcspacer.go execute runtime/proc.go 并发标记 方法 文件 gcBgMarkWorker runtime/mgc.go gcDrain runtime/mgcmark.go markroot runtime/mgcmark.go scanobject runtime/mgcmark.go greyobject runtime/mgcmark.go markBits.setMarked runtime/mbitmap.go gcWork.putFast/put runtime/mgcwork.go 标记清扫 方法 文件 gcBgMarkWorker runtime/mgc.go gcMarkDone runtime/mgc.go stopTheWorldWithSema runtime/proc.go gcMarkTermination runtime/mgc.go gcSweep runtime/mgc.go sweepone runtime/mgcsweep.go sweepLocked.sweep runtime/mgcsweep.go startTheWorldWithSema runtime/proc.go 逃逸分析所谓逃逸分析（Escape analysis）是指由编译器决定内存分配的位置，不需要程序员指定。 函数中申请一个新的对象如果分配在栈中，则函数执行结束可自动将内存回收；如果分配在堆中，则函数执行结束可交给GC（垃圾回收）处理;有了逃逸分析，返回函数局部变量将变得可能，除此之外，逃逸分析还跟闭包息息相关，了解哪些场景下对象会逃逸至关重要。逃逸策略每当函数中申请新的对象，编译器会跟据该对象是否被函数外部引用来决定是否逃逸： 如果函数外部没有引用，则优先放到栈中；注意，对于函数外部没有引用的对象，也有可能放到堆中，比如内存过大超过栈的存储能力 如果函数外部存在引用，则必定放到堆中；逃逸场景通过编译参数-gcflag=-m可以查年编译过程中的逃逸分析： 指针逃逸：返回局部变量的指针，这其实是一个典型的变量逃逸案例。package maintype Student struct { Name string Age int}func StudentRegister(name string, age int) *Student { s := new(Student) //局部变量s逃逸到堆 s.Name = name s.Age = age return s}func main() { StudentRegister(\"Jim\", 18)}函数StudentRegister()内部s为局部变量，其值通过函数返回值返回，s本身为一指针，其指向的内存地址不会是栈而是堆，这就是典型的逃逸案例。通过编译参数-gcflag=-m可以查年编译过程中的逃逸分析：D:\\SourceCode\\GoExpert\\src&gt;go build -gcflags=-m# _/D_/SourceCode/GoExpert/src.\\main.go:8: can inline StudentRegister.\\main.go:17: can inline main.\\main.go:18: inlining call to StudentRegister.\\main.go:8: leaking param: name.\\main.go:9: new(Student) escapes to heap.\\main.go:18: main new(Student) does not escape可见在StudentRegister()函数中，也即代码第9行显示”escapes to heap”，代表该行内存分配发生了逃逸现象。 栈空间不足逃逸比如以下代码是否存在逃逸，与所需内存空间有关。可通过修改make参数和执行go build -gcflags=-m进行探究。package mainfunc Slice() { s := make([]int, 1000, 1000) for index, _ := range s { s[index] = index }}func main() { Slice()}实际上当栈空间不足以存放当前对象时或无法判断当前切片长度时会将对象分配到堆中。 动态类型逃逸很多函数参数为interface类型，比如fmt.Println(a …interface{})，编译期间很难确定其参数的具体类型，也会产生逃逸。 闭包引用逃逸某著名的开源框架实现了某个返回Fibonacci数列的函数：func Fibonacci() func() int { a, b := 0, 1 return func() int { a, b = b, a+b return a }}该函数返回一个闭包，闭包引用了函数的局部变量a和b，使用时通过该函数获取该闭包，然后每次执行闭包都会依次输出Fibonacci数列。 完整的示例程序如下所示：package mainimport \"fmt\"func Fibonacci() func() int { a, b := 0, 1 return func() int { a, b = b, a+b return a }}func main() { f := Fibonacci() for i := 0; i &lt; 10; i++ { fmt.Printf(\"Fibonacci: %d\\n\", f()) }}Fibonacci()函数中原本属于局部变量的a和b由于闭包的引用，不得不将二者放到堆上，以致产生逃逸。 指针必然不逃逸的情况 指针被未发生逃逸的变量引用 仅仅在函数内对变量做取址操作，未将指针传出逃逸总结 栈上分配的对象比在堆中分配的有更高的效率 栈上分配的内存不需要GC处理 堆上分配的内存使用完毕后会交给GC处理 逃逸分析目的是决定内存分配地址是栈还是堆 逃逸分析在编译阶段完成思考一下这个问题：函数传递指针真的比传值效率高吗？ 我们知道传递指针可以减少底层值的拷贝，可以提高效率，但是如果拷贝的数据量小，由于指针传递会产生逃逸，可能会使用堆，也可能会增加GC的负担，所以传递指针不一定是高效的。其他优化 Go 性能：你知道的越多，不知道的也就越多 Go性能优化及实践 Go 语言中各式各样的优化手段 go 性能优化 GO项目性能优化大赏 [郑建勋：Go程序性能分层优化 CPU篇](https://zhuanlan.zhihu.com/p/516942933?utm_id=0) 性能诊断 golang性能诊断看这篇就够了 通过 profiling 定位 golang 性能问题 - 内存篇 使用dlv分析golang进程cpu占用高问题 Go 性能调优之 —— 基准测试 Go 云端程序的持续分析 优化你的go代码的几个工具 译文 Go 高性能系列教程之二：性能评估和分析 Go 程序性能分析 Go程序的问题诊断和性能调优指南 GO的花式调优技术 golang-性能分析（原生工具） go程序cpu过高问题排查方法 高cpu进程排查方法 7种 Go 程序性能分析方法 golang性能分析之trace golang性能诊断看这篇就够了 Go程序性能分析方法（一文全解） go 静态检查工具优化定时器 golang timer 性能消耗 超硬核 Go timer 解析 Golang如何应对海量定时、延迟任务？ 转载类型或数据结构优化 Go 泛型使用与性能对比 详解简单高效的Go struct优化 map内存优化 defer滥用 闭包慎用 chan的适用场景 interface滥用 不得不用refect时的优化手段 chan回收 Go语言性能优化- For Range 性能研究cgo或跨语言调用优化 Golang实践录：调用C++函数的优化低级优化 Golang 性能提高技术—-低级优化 go| go 性能优化入门之「Go代码重构：23倍的性能爆增」实践 Go 性能调优之 —— 编译优化 golang 高频服务延时抖动追因-升级go版本综合优化 Go 高性能编程技法 GO高性能编程精华 golang性能优化实践 go语言最全优化技巧总结，值得收藏！ 高德Go生态的服务稳定性建设｜性能优化的实战总结 Go 性能调优之 —— 技巧 Go 性能调优之 —— 总结 Golang号称高并发，但高并发时性能不高解决办法 Golang性能优化技巧（三） go 使用中的一些优化建议和技巧，第一篇『基础结构优化』 性能优化实战：百万级WebSockets和Go语言 优化 Golang 分布式行情推送的性能瓶颈 批处理 大规模Go项目几乎必踏的几个坑 - Dragonboat为例 go 语言实践-goroutine+chan 并不是 CSP 的最佳方式 Go语言的自动内存管理及优化(字节跳动Balanced GC优化方案)(Day5) 最接地气的go服务优化指南原理篇只有理解原理，才能： 养成高性能且可读性强的代码习惯 理解性能工具的指标表征 定位性能问题 提出较为准确和彻底的优化方案参考文档 深入golang runtime的调度 深入理解Go语言与并发编程底层原理 Golang底层原理剖析之闭包 Golang中闭包的实现原理 Golang原理分析：闭包及for range延迟绑定问题原理及解决 Go语言Channel的底层原理详解 Go 内存对齐没有秘密 深入理解 Go 语言的垃圾回收 Golang 垃圾回收原理分析 Go 垃圾回收原理 Go 的垃圾回收机制在实践中有哪些需要注意的地方？ Go的垃圾回收（GC），详细总结 Go的垃圾回收机制 深入Go：垃圾回收的演进 Go 垃圾回收（四）——一次完整的回收 揭秘golang垃圾回收！三色标记法深入剖析 揭秘golang垃圾回收！三色标记法深入剖析 Go语言实时GC - 三色标记算法 两万字长文带你深入Go语言GC源码 可视化Go内存管理 Go 垃圾回收器指南 Golang底层原理剖析之闭包 go select编译期的优化处理逻辑使用场景分析 Golang底层原理剖析专栏汇总 Golang源码探究 —— chan 图文并茂：彻底理解Go中Chan底层同步原理 大厂后台开发基本功修炼路线和经典资料 go-内存管理篇（二） 万字总结-golang内存分配篇 一篇文章讲清Go的内存布局和分配原理 Golang实现带优先级的channel第三方库 新Gopher日报 Golang 开发 常用的第三方库 没有最全只有更全 Awesome gRPC ego微服务框架 evans: 更具表现力的通用gRPC客户端常见bug和分析 Go 泛型的二十一个陷阱 golang runtime.systemstack 泄漏排查 go 定时器泄漏，导致 CPU占用高其他工具 31个！Golang常用工具来啦" }, { "title": "本质思考", "url": "/2023/03/think-hard.html", "categories": "修心", "tags": "Think", "date": "2023-03-18 15:34:08 +0800", "snippet": " 本文主要收集一些对于思维的探讨，比如本质思考、思维缺陷、思维模型等 本质思考 本质思考的习惯 精准性思考 非歧义思考 反馈式思考 多维度思考 整合式思考 适应性思考 循环式思考 本质思考的陷...", "content": " 本文主要收集一些对于思维的探讨，比如本质思考、思维缺陷、思维模型等 本质思考 本质思考的习惯 精准性思考 非歧义思考 反馈式思考 多维度思考 整合式思考 适应性思考 循环式思考 本质思考的陷阱 思维惰性：少思考是大脑的本能 认知扭曲，心理防御机制的副作用 盲区：紧急状态下人的视野会收缩 局限：只基于自己掌控的范围寻找方案 孤立：忽视各问题之间的关联 情绪：“非理性”会彻底扰乱思维过程 偏见：“无意识”会形成很多思维死角 责任感缺失：所有人都很容易放弃思考 思维静态化：看不到时代进步产生的新机会 本质思考的方法 格式化：重新构建底层逻辑的模型和框架 剥离：清理问题背后的利害关系 反复溯因：层层剥开问题的核心 越界：全视角、全方位地构想方法 刷新：反复核验和预判形势变化 内省：平复情绪波动，避免冲动决策 双层思考：在思考问题的同时查验“思考” 对比分析：深度挖掘缺乏责任感的原因 定期升级：根据全新环境重新审视问题 本质思考的训练 假设力：尽可能涵盖所有可能方案 逆向思考力：从未来可能得失败倒推 共情力：不断地站在他人的角度看问题 信息整理力：辨别每种信息的类型和属性 图像化能力：掌握更直观的表达方式 定规则能力：不断推演怎样的制度更合理 知识消化力：搭建自己的知识库 数据力：探索事物之间的量化关系 深度思考：基于底层逻辑思考潜在威胁 训练实施 思考模型 历史演化模型 本质思考本质思考是一个循序渐进的过程，是一个修行和与自我深度交流的逐步深入的进程。 从认识思维陷阱开始 掌握本质思考方法 改变不良思考习惯 日常训练本质思考方法，养成新的思考习惯本质思考的习惯 精准性思考：语言越模糊，思考越难深入 非歧义思考：分岔的表述会使人偏离本质 反馈式思考：反复确认才能锚定问题的本质 多维度思考：克服信息缺损的有效方式 整合式思考：过早地进行简单选择，盲目行事往往会成为习惯 适应性思考：“生搬硬套”通常没有好结果 循环式思考：一步一步逼近问题的本质精准性思考 语言越模糊，思考越难深入切记，天下不可能有两本完全一样的个人“词典”。因此，只要使用语言交流，说话者与听话者之间对其理解就必然存在微秒差别。为了填平思维的这道鸿沟，人们应该： 努力尝试更多的表达方式（比如图表、音视频和打比方等） 尽量提供问题的背景说明或描述 站在听者的角度思考问题，用听者容易听懂的方式表达 引入第三者的视角看待问题，抽象出共性，有助于精准表达。比如遇到这种情况，马云和马化腾等怎么表达或思考非歧义思考 分岔的表述会使人偏离本质存在歧义的问答，也就意味着语义的分岔、表义的分岔。可能会出现以下困境： 提问者以为回答者听懂了自己的意图，但实际上回答者理解的意思和提问者想表达的却不是一回事 回答者以为自己的回答已经被提问者所理解，但实际上提问者理解的和回答者想要表达的不一致 提问者和回答者语言中的关键词存在歧义或者不同的量化标准，导致大致意思是一样的，但厉害程度却大不相同为此，提问者和回答者双方理应： 提问者必须明确自己的提问目的 回答者则要思考提问者的真实意图 如果有不清楚的东西一定要先确认，再回答 回答者一定要有这个意识：对自己来说理所当然的东西，对于提问者不一定是理所当然的。 反馈式思考 反复确认才能锚定问题的本质不清楚问题的具体表意、或者提问的表意含糊不清、或者提问用词有歧义、或者有隐含前提、或有不合理假设等等时，一定要询问清楚，否则会引发严重后果。不懂装懂，会使你的思考偏离问题的本质。先把握住问题的本质，就不会干很多白费功夫的事情。 不要怕麻烦或难以为情，该确认的事情不好好确认，就继续往下做，这可以说是一种“坏的思维习惯”。 不要怕麻烦或难以为情，你必须明白，弄清含糊不清的问题对双方来说都大有好处。 如果下属老提问，而你觉得对方很麻烦。这个时候，米一定要自我反省一下，自己的语言表达是不是有含糊不清的地方。多维度思考 多维度思考是克服信息缺损的有效方式基于以下事实，表达者的真实意图与接收者获得的信息之间避免不了缺损。 每个人对事物的表达至少会经历四层过滤器，每一层都可能损失部分信息。 通过五官获得感觉：每个人的五官能力各异，注意力集中的地方和大小不同，获得的感觉也有差异。 身体内部语言：将五官得到的感觉转换成身体内部语言。而内部语言因人而异，和这个人的阅历、教育背景、思想、潜意识和当时的状态等等都有关。 表达的草案：利用自己的个人词典和以往类似的经历，尝试转换成外在语言。这受限于个人的语言能力、思维和记忆等因素。 外在表达：形成表达草案之后，人们会根据时间地点场合、面对的人、当时的处境和个人的所处的角色定位等进行选择性或婉转地表达 每个人的视角或定位不同，那取舍和选择加工的方式和方向也不同 在语言转换过程中，各种信息会进行简化处理 另外，光靠语言无法完全传达所有信息。能够一起使用语言与语言以外的传达方式，当然是一种高效的思维方式。因此，需要从多维度来补充可能缺损的各种信息，相互印证，方可获得他人更为真实的表达信息。整合式思考整合思维是指 面对相互冲突甚至对立的模式时不是简单地进行选择，而是能够进行建设性的思考，创造性地解决它们之间的冲突，形成一个既包含已有模式的某些成分但又优于已有模式的新模式。 过早地进行简单选择，盲目行事往往会成为习惯 “有一些想法，就赶快行动”的方式好像也能成功解决问题，不过那只是“瞎猫碰上死耗子”。 凭借条件反射本能地行动，很多时候也能保证事情进展顺利 那些看起来已经被成功解决的事情，其实本该有更好的解决办法盲目行动通常情况下也能获得较好的效果，因此很容易形成习惯。为此，从平常开始，就要在每件事情上有意识地训练“本质思考习惯”。以便在遇到需要认真思考的时候，能快速进入全面和深入思考状态。适应性思考 “生搬硬套”通常没有好结果在变化较少的时代，过去经历过的问题可能再次出现。因此可以重复利用以往的答案。曾解决过问题的方式也会行之有效。然而，在瞬息万变的时代，面临完全相同的问题的可能性越来越小。因此，利用以往的答案很难触及问题的本质。 有些现象看起来相似，但本质上完全不同。对于那些非常复杂且绝不允许失误的问题，你必须在理解问题的本质之后，再仔细探讨其解决之策。如果养成喜欢扑向“生搬硬套的答案的习惯”，就无法获得本质思考的习惯，这无疑是一种“坏的思维习惯”。因此，不要养成“只追求答案的本身”的习惯，而是要注重背后的思考过程，强化“本质把握能力”，养成“本质思考习惯”。循环式思考 循环式思考，一步一步逼近问题的本质“把不成熟的想法有形化”是为了获得精确的市场反馈，也是为了下一步“思考”做准备，可以说是一种实验。 “思考”和“行动”并不是一对反义词，而是互反馈网络中相互作用的因子。 为了好好“思考”，“尽快行动以获得正确的输入信息”式很高效的举措。尽早启动项目管理基本周期是非常必要的。本质思考的陷阱人们之所以被阻滞在问题的表面，很大程度是因为各式各样的思维陷阱。这些陷阱： 有的是源自人类的本性 有的是因为理性受到了情绪的浸泡 还有的则可以归咎于认知方式上存在的偏差。面对如此多的陷阱，每个人难免都有深陷其中的时刻，而如果人们意识不到自身的处境，那么就只能像无头苍蝇一样在陷阱中四处碰壁。主要陷阱有： 思维惰性：少思考是大脑的本能 认知扭曲：心理防御机制的副作用 盲区：紧急状态下人的视野会收缩 局限：只基于自己掌控的范围寻找方案 孤立：忽视各问题之间的关联 情绪：“非理性”会彻底扰乱思维过程 偏见：“无意识”会形成很多思维死角 责任感缺失：所有人都很容易放弃思考 思维静态化：看不见时代进步产生的新机会思维惰性：少思考是大脑的本能思维惰性：该陷阱指的是不经过深入思考就断言问题的本质，或者认定眼前的问题与过去经历过的问题一样。该陷阱的症状有： 沉醉于过去的成功，看不到当前问题的背景与前提条件所发生的变化，认定与过去问题一样。这一切将导致人们所使用的方法根本无法触及新问题的本质。 对所谓的通常做法、标准做法不加思考就拿来使用。 自认为透彻地理解了问题的本质，并基于自己的臆想就给问题下定论。或者，基于对自己有利的假设去寻找解决问题的办法。人们希望能以最快的速度处理问题，因此对于现成的方法充满了渴望，很容易忽略匹配性方面的因素。然而，方法是为了实现某个目标而存在的。如果不首先正确认识自己要达成的目标，方法的选择也就无从说起。常见的忠告或案例如下： 思维紧箍咒：警惕那些成功的经验。规模等的不同直接决定了所面临问题的差异。 表面化模仿：有些东西是永远复制不了的。 本末倒置：相关关系不等于因果关系。 因果关系指的是原因和结果之间有着明确的关系。 相关关系指的是当一方发生变化时，另外一方也同时发生了变化。 有人会恶意吧相关关系说成因果关系，混淆两者。 轻率判断：完全依靠自己的主观感受 数据迷信：对于所谓“客观正确”缺乏反思能力 很多时候，人们并不是先看到数据才得出结论，而是先有一个初步的结论才去找数据支撑。 数据不同的呈现方式、不同的选择方式，所能支撑的结论可能是完全对立的。 数据很可能误导人们把相关关系视为因果关系 惯性定律：保持现状往往成了第一选择 对对象本身还没有充分探讨的情况下，就开始讨论应该采用的方法，最终很可能导致方法与实际对象完全脱离 如果讨论聚焦于问题的本质，那么无论外界发生怎样的变化，人们都能直接找到最恰当的应对之道。 如果忽视问题的本质，只是一味地讨论方法，讨论到最后就可能变成“老方法保卫战”。 我们应该注意： 不要迷信过去的成功经验、常识、通论、权威、舆论等 不要不加思索就轻易地下结论 不要被表象迷惑，不加研究就胡乱归结原因，采取错误的方法无法正确解释所获取的信息，仅凭表象就做出判断。这种错误行为也包含在“思维惰性”陷阱中。认知扭曲，心理防御机制的副作用虽然意识到了问题的存在，然而却由于强烈的自我保护心理，而不愿意承认并着手解决，这种情况就是“认知扭曲陷阱”。那为什么不能解决问题呢？ 其原因就在于自我保护心理会扭曲人们对现状的认识。每个人都不太愿意承认自己犯了错误，这是天性。 即使正确理解了目的、目标、计划，然而如果无法正确认识现状，那么就难以找到具体的方式方法 出人意料的是，即使能够得到代表现状的数据，很多时候人们也不愿意老实接受 在某一项工作上，花费的时间与精力越多，人们就越不愿承认现状与其理想状态的差距。 出于自我保护的目的，人们往往会把不满意的结果归咎于外因，把失误归因于客观条件或不可抗因素。 从而他们永远无法直面自己的粗心大意、懈怠、懒惰、嫌麻烦。 如果不能正视这种差距（计划与实际成果之间的差异），那么在之后就无法分析根本原因。 即使大的方向正确，但一旦要采取具体措施时，就会出现疏漏。 为了更加客观地把握现状，每个人必须从各种角度重新对现状进行审视 在日常工作中，每个人都应该明确定量数据与定性数据的使用方式。在确认数据正确之后，还要培养自己使用数据的习惯。数据的核心价值在于对某项事物进行说明，佐证判断正确与否。认知扭曲常见的案例有： 强调特殊性：对抗问题的万能盾牌 试试筛选：只强调有利的各项指标要想选择合适的解决方法与解决手段，我们必须首先理解问题的本质，掌握现状，坦然接受那些让人不太愉快的信息，分析计划与实际成果之间出现差异的原因，然后再考虑应该采取何种对策。盲区：紧急状态下人的视野会收缩在面对那些迫在眉睫的麻烦时，人们的视野会极速缩小。这种机制确实帮着人们通过了许多危险时刻。不过，有的时候，这些迫在眉睫的麻烦其实源于更深层次的原因。如果不解决更深层次的麻烦，迫在眉睫的麻烦就会反复发作。在发现计划与实际成果之间存在差异时，错把这种差异当成了症结所在，这就构成了”盲区陷阱“。有的人在分析问题时所依据的逻辑是正确的，但分析缺乏深度，无法触及问题的核心。如果问题根本原因出在提出问题或给出报告数据的本人身上（或者数据本身的量化方法或思考模型上），那么光听他的报告是不会了解实情的。局限：只基于自己掌控的范围寻找方案如果既理解了问题的本质，又对现状有了把握，同时能发现计划与实际成果之间存在的差异，并分析除了根本原因，那么接下来就该针对问题的根本原因采取行动。然而，这个时候，人们总是很容易自我设限，只是利用自己能掌控的资源来解决问题，因为不用麻烦别人。人们都倾向于选择手头现有的解决办法，当然，这些方法有时候确实就是最佳选择。不过，也有另一种可能，人们手边没有现成的最佳解决办法。在这种情况下，任梦必须扩宽思路，去挖掘更多的可能性。思考解决方案时，不应局限于自己的职位或已有的权利或资源等，也应该想一下，如果你拥有更大的权利或者你就是CEO或老板等，你会怎么去解决问题。一切思考额核心目的是从根本上解决问题，而不是由自己解决所有问题。你的上级或其他人存在的意义，就在于他们能够解决你解决不了的问题（或者具备你没有的视角或思维方式或思考维度），能够改变你改变不了的东西。案例有： 搭便车：免费的东西往往代价更高 换位思考：从更高的角度审视问题的本质，在更高层次调配资源人们在讨论从根本上解决问题的方法时，不要只考虑那些自己能够掌控的选项，还应该基于问题本身来思考。同时，也应该设想一下，拥有更多权限的上级应该怎么处理这个问题。如果能说动上级，那问题的解决途径会变得更清晰，效率也会提高。孤立：忽视各问题之间的关联很多时候，人们紧急满足于找到最合适的方法以及采取行动，而对于问题最终是否获得解决，并没有进行检验或确认。人们只是自己感觉，问题已经成功解决了。经查验，预期效果根本没有达成，需要再次开启本质思考的循环： 确认是否真正找到了问题 认清现状与计划之间的差异 正确分析差异形成的原因 针对问题的根本原因采取相应的措施需要注意的是，人们所采取的措施可能确实解决了最初的问题，然而却同时引发了其他一些问题。因此，对于从根本上解决问题而言，检验和确认工作必不可少。在思考或解决问题时，尽量将问题抽象化或具象化，比如用水流车流等做比拟，堵住了这头是否会把问题导向到另一个方向？为了确认是否引发了其他问题，最行之有效的方式是：我们将问题抽象地分出层次，一层一层地检查问题是否获得了解决。 正反面思考：想方设法堵住思维的漏洞我们很容易拘泥于自身的假设，尤其是那些自己呕心沥血好不容易得出的结论。于是，我们总是断定自己的假设是正确的。只有在特定条件下某事件才会发生，在其他条件下，该事件必定不会发生，这就是假设。然而，当人们绞尽脑汁想证明假设成立时，却很容易忘记假设的另一个侧面，那就是去证明，在其他条件下该事件不会发生。如果不能同时证明这两点，那假设就无法成立。情绪：“非理性”会彻底扰乱思维过程“情绪化”指的是由于情绪波动，人们往往会做出一些长远来看明显“弊大于利”的选择。 冲动是魔鬼：要解决问题，而非借问题发泄切记，在情绪波动时，人都很难做出正常的判断。如果发现自己处于情绪激动的状态，那么你千万别对那些非常重要的事情做出决定。在思考时，人们必须先让自己冷静下来或者先搁置一下，发泄私愤的做法百害而无一利。 非理性迷雾：每个人都要为自己的不冷静买单过去的事情就让它过去吧，人们在做选择时，更应该着眼于现在雨未来的幸福。人们应当优先考虑从根本上解决问题，而不是以问题为借口，来发泄自己的情绪。情绪激动的时候，必须慎重，必须反复用本质思考的方式确定自己的最终目的。偏见：“无意识”会形成很多思维死角从古至今的进化过程中，人类形成了各种各样的视角。对于特定的个人或群体，受家庭和教育背景行业背景、阅历以及思维习惯等作用下，也会形成特殊的视角。这些视角能帮助人类节省大量的判断时间，从而确保人类能够生存下去。从这个意义上来说，特殊视角提高了人类的效率，从而为人类带来巨大的好处。只是，有时候这些视角会妨碍人们从根本上把握问题，让人们无法采用最有效的措施去解决问题。由于视角内嵌在思考的运作模式中，因此很难将其排除。同时，这种运作模式也会与其他陷阱相生相伴。“思维惰性陷阱”就与固定视角有着极强的关联度。话虽如此，人们也可以反复思考自己所下的结论（问题的本质或者选择的解决对策），考虑一下，这些结论是否受到习惯的影响，偏离了原有的轨道。相信很多人都听说过“无意识偏见”这个词。这种偏见由每个人的文化背景、个人经验、所属团体、视角等多种因素形成。另外，大众传媒反复的宣传报道也可能让人们形成“无意识偏见”。无意识偏见在不知不觉中影响人们的判断。所有人都必须认识到这一点。 先入为主：思维定式往往会形成误导 即使心里完全没有“歧视的意识”或者偏见，人们的大脑还是会自动进行主观臆断 人们应当反复审视自己所做的决定，看其是否受到“无意识偏见”的影响。只有这样，才能更精准地把握问题的本质。 感情色彩：思维过程中的语言暗门 大脑其实更加偏好有积极感情色彩的表达（当然这种表达和文化教育背景等有关） 对古怪或负面的表达，人们会产生一种异样的感觉。 大脑对于那些令人不舒服的表达，会自动产生抗拒反应，从而让人们带着怀疑的目光对其进行重新审视。 一旦大脑开始重新审视时，就会非常认真，这将大幅度提高人们做出正确判断的可能性。 由于大脑不会带着华裔的目光去看待那些带有感情色彩的表达，因此会受到欺骗。 每个人都是习惯塑造的动物，因此要注意审视自身的判断是否受到习惯的影响。人类的大脑更加偏好有感情色彩的表达。即使有些表达很容易直接获得认同，但所有人都该对此保持警惕，并检验大脑直接构建的关联性是否符合逻辑。 对其他人带有感情色彩的表达或者误导性的表达，要进行表达式改造，使其降低误导性，有助于大脑客观判断 对自己常用的表达进行审视，看是否有习惯性的误导，有则改之。有助于减少潜意识的错误判断 语言表达通过各种方式的改造，有助于全面多视角看问题，如拆解、调整词序、更换词语、剔除枝叶保留主干、近义词反义词替换等。责任感缺失：所有人都很容易放弃思考有些人其实从一开始就没觉得自己有责任去根本解决问题，这种情况属于“责任感缺失陷阱”。显然，很多人对于把握问题的本质根本没有兴趣。他们对眼前出现的问题或者现象毫不在意，就跟与自己毫无关系一样。这类人认为，眼前的事情应付一下就行了。自己采取的行动会引起何种变化，该变化又是否与预期相符，这都不在他们考虑的范围之内。他们一开始就放弃了思考。与之前的种种陷阱相比，这种陷阱更具危害性。很少有人会在每件事情上都掉入“责任感缺失陷阱”。一般只是对于特定的现象，他们会放弃思考。在陷入了这种状态时，他们其实是把“应付”这种方法当成了最本质的东西。然而，方法其实依附于想要达成的目标，该目标远比方法更本质。掉入“责任感缺失陷阱”的人，往往只在意“做眼前的事情”与“做上级吩咐的事情”。急于摆脱眼前麻烦，这是人之常情。然而，如果当事人一味只是想摆脱眼前的困境，那么实际问题自然无法从根本上得到解决。有想法，问题就有被彻底解决的希望。如果根本不愿承认问题的存在，那就只能坐以待毙了。人们为什么不愿承认问题的存在呢？我认为，这一切都源于两种因素引起的恶性循环： 失败恐惧：逃避会开启恶性循环既往失败的悲痛经历，被上级严厉斥责的记忆，或者曾目睹过失败所造成的毁灭性影响，这些都使人们对于失败怀有极大的恐惧感。为了避免失败，这类人就会选择那些不需要自己负责的选项。于是，他们放弃了自身的思考能力，同时也摆脱了需要承担的责任。这一行为一旦形成习惯，他们的思考以及判断能力就会日益衰退，从而开启了恶性循环的大门。 文化环境：行为模式是塑造出来的如果一个人从小就被教导说“按大人说的去做”，而且其行为还受到了严格限制，那么，他就会认为按别人的命令行事是最正确的方式。工作后，如果上级一直强调“按我说的做”，那么就会完全习惯这种行为模式。如果这种不恰当的工作方式一直持续，长此以往，接受指示的人就彻底沦为了机器。他们丝毫不会关心这项工作究竟会给组织或社会带来何种变化。这样一来，他们就很难保持对工作的热情。为了避免落入这种陷阱： 从个人层面而言，人们必须形成一种习惯，那就是努力理解和阐明手头工作的重要性与意义，把它当做自己的事情。 从文化、制度层面而言，人们应该尊重那些勇敢的失败者，并建立能够接受失败的组织文化和制度。值得注意的是，如果某组织所采取的措施都能顺利实施，所有的活动都能顺利开展，那很可能是由于该组织所有成员都处于舒适圈之内，没有人愿意挑战有难度的问题。其实，任何人、任何组织总会遭遇“失败”，只要能从“失败”中获得教训，个人与组织就能不断成长。思维静态化：看不到时代进步产生的新机会有的时候，在新的情况下，过去所面临的问题其实很容易得到解决，而人们却丝毫没有察觉，并继续在该问题上花费时间与精力，并持续承受巨大的压力。当今社会，事物正处于急速变化的形势中。即使个人没做出任何改变（虽然这点也不太可能），周围环境的变化也有可能让问题轻易解决。或许，当重新审视过去没法做的事情时，人们就会发现，如果运用现代技术，这些事情很容易就迎刃而解了。 在时间维度上，要用发展的眼光看问题。我们应该定期重新审视周边环境，因为在新的情况下，问题很可能可以轻易解决，或者不再是问题了。 从空间或阶层维度上，很多问题可能换一个环境、或者上神或下降一个或多个阶层就可轻易解决。本质思考的方法明确各式各样的陷阱很重要，因为很多时候，人们往往是因为不清楚自己的真实处境，才找不到解决之道。一旦摆脱了“当局者迷”的困境，方法很容易就会清晰化。当然，问题的关键还是运用这些方法的意愿，有时候越简单的方法，往往才是越有效的。对别人有效的方法，对自己不见得一定有效；对过去有效的方法，对现在或未来也不一定有效。只有深刻理解了方法背后的更为根本的思维方式，再结合自身的状况与特质，才能选择出最合适的方法。格式化：重新构建底层逻辑的模型和框架一旦陷入“思维惰性陷阱”，人们就会在没有理解问题本质的情况下，试图解决问题，或者说，在没有理解真正目标的情况下，就盲目行动。显然，在这种情况下，不可能从根本上解决恩替或采取有意义的行动。如果陷入了“思维惰性陷阱”，那么最好的办法是从零开始重新思考问题。 不管是“常识”“权威”，还是自己“过去的成功经验”，一切都归零，彻底割断这些东西与自己所面临的问题的关联。清理完这些过滤层，人们才能对问题的背景或者前提条件进行整理，并明确自己要采取的行动与措施。 有时候，让于该问题不相干的人士参与进来，并提一些问题，说不定会让你产生新的启示。在某个问题上过于纠结，人们肯呢个会陷入某个思维死循环，始终跳不出来，或者会再加入各种不必要的要素，从而使问题变得异常复杂，这都会使得在根本解决问题的路径上南辕北辙。另一方面，局外人不存在上述的障碍，因此反而能接触到问题的核心。 另外，所有的判断都是基于特定的信息，因此人们必须要客观地重新审视这些信息，否则就容易出现偏差或受到误导。这些信息到底是事实，还是意见？信息发送人传递这些信息是否存在特定目的？这些问题都必须加以思考。 客观地重新考虑现有信息，尽量根据事实，从零开始重新对问题进行审视，只有这样人呢才能知道自己是否陷入了“思维惰性陷阱”，并想办法从陷阱中脱身。总结下来，如果陷入了“思维惰性陷阱”，那么： 最好的办法是从零开始重新思考问题 尝试把“常识”“权威”以及自己“过去的成功经历”放到一边。 让局外人参与进来，并提一些问题 重新客观地对现有信息进行审视 化整为零，从头开始，表面上这是在走弯路，但有时这其实是最实际的方法剥离：清理问题背后的利害关系无论人们对于目标的意义理解得多深刻，他都必须脚踏实地，从现实出发。要想真切地把握现状，人们就需要借助各式各样的信息。正确理解这些信息，人们才清楚现实与目标之间的差距，并通过不断地修正措施，逐渐缩小这种差距。对于现状的信息而言，无论它们会让自己觉得有多么不舒服。你都必须接受。漠视现状，目标就会失去根基，成为可望不可即的空中楼阁。不管这些信息是否与自己的怠慢或工作失误有关，人们都没有必要采取防御性的姿态。说到底，这类信息只是展示现状的一个要素而已。因此，人们必须尝试站在局外人的角度上，冷静地对这些信息进行审视。通过隔离自己，从旁观者的角度审视，而不是从利己的角度辩护，你就无法用搪塞与敷衍之辞来保护自己，而直击本质的锐见则穿透阴霾，洞若观火。切记，决策所基于的“事实”一定要是客观的、全面的，而不是被断章取义截取出来的“事实”碎片。另外，在处理信息时，一定要注意区别“事实”与“意见”。如果是一些“意见性”或观点性的信息，那人们要先思考为什么会出现这种意见，然后再对其进行处理。对于所获得的信息，包括计划与实际成果之间存在差异的相关信息，即使听起来不那么让人舒服，人们也必须接受事实，并站在局外人的角度上仔细思考这些信息的含义。反复溯因：层层剥开问题的核心由于对问题的根本原因分析得不充分(RCA，即彻底进行根本原因分析)，往往使得人们把思考的重心放在了问题的现象上，或者说把问题的表面原因当成了问题的根本原因，并对此采取措施。这样一来，表面上问题看起来得到了解决，然而很快它又会再次出现。也就是说，这只是“头痛医头，脚痛医脚”。在使用RCA进行分析的时候，会反复使用追问原因的手法，这时候人们需要注意正确地使用语言。换而言之，在使用语言时，不能省略主语、谓语、宾语，不能模棱两可，使用的概念定义必须非常清楚，无歧义，即要使用精准的表达方式。所有人都应该反复追寻原因（至少重复5次以上），直到总是出现同一个理由。很多时候，找不到根本原因，完全是因为没有刨根问底。越界：全视角、全方位地构想方法即使顺利通过了以下阶段，还有可能掉入“局限陷阱”： 掌握了问题的本质 正确地理解了现状 同时也清楚计划与实际成果之间所存在的差异 在经过RCA分析字后，我们还找到了问题产生的根本原因。当人们顺利绕过了以上陷阱后，他们往往在选择方法时，掉进了“局限陷阱”。一旦掉进了这个陷阱，往往就会在白白浪费成本后，所有事情都从头做起。因此，应当从不同侧面，不同视角去考虑方法。我建议大家在选择方法的时候一定要运用几个原则： 做决策时，你不但要站在自己立场上，还要站在自己的上级（或者说拥有更多权限、决定权和资源的人）的立场上去思考： 如果由他们来解决这个问题，他们会怎么做？ 同时，你也要参考专家、咨询或搜索等途径所收集的意见或参考资料 不但要根据现状做决策，你也应该着眼于更长远一点儿的未来。 除了功能要求以外，我们还应该考虑到其他非功能要求（可靠性、可维护性、性能和安全等）切记，一定要避免独自一人做决策，对于选择正确的方法而言，这一点非常重要。我们应该军团作战而非独自厮杀，这里的军团成员可以为： 行业专家 受决策影响的人或事物 决策路径中的所有节点 同时空或跨时空类似的问题或决策 多维度视角 多利害方视角刷新：反复核验和预判形势变化不管在把握问题的本质，寻找解决方法方面，你做得多么完美，如果最后没有确认结果，那你就掉入了“孤立陷阱”。基本上，只要实施了解决问题的方法，多少都会有一些效果显现，但是这并不代表完全解决了问题。另外，有的时候，原问题虽然得到了部分解决，但同时又产生了其他新问题。应对这种状况的方法十分简单，就是及时确认现状。即使确认晚了，也比完全不确认好得多。在采取措施之后，如果已经经过了一段时间，那么你去确认措施结果的同时，其实也是在进行现状确认。不管怎样，你必须不时地对问题重新思考，因为一段时间过去之后，问题本身可能已发生了变化。在“项目管理的基本周期”图中，把握“实际成果”指的就是把握现状。如果能把握好“计划”与“实际成果”，你就能发现两者之间的差距。通过分析这种差距产生的原因，你就能确定对策或措施。另外，在采取某种对策或措施之后，你必须检查其是否达到了预期效果。如果说效果不太明显，你就必须再次确认预期效果与实际成果之间有多大差距，讨论下一步的对策与措施。只有一次次启动这个循环，才能从根本上解决问题。综上所述，需要记住以下tips： 采取某种行动之后，你必须对其实施情况进行确认。 如果不能正确把握现状，你就无法准确解决问题 在采取某项措施后，情况可能会发生新的变化，之前的解决方案可能不再是最优选项。你必须在确认现状之后，再考虑下一步措施。内省：平复情绪波动，避免冲动决策人类很难避免出现情绪波动，重要的是，不能让情绪波动带来负面影响。要想完全消除情绪波动十分困难，但是你可以将情绪波动带来的负面影响尽可能减小。为此，你可以： 发现自己处于不冷静的状态 发现自己处于不冷静状态，不要作任何决策或言行 让自己冷静下来，或先搁置问题或争议，不要急着决策 检查自己是否已经处于冷静状态在不冷静的状态下，人们做出的决策虽然不一定是错误的，但极有可能存在偏颇或隐患，另外，在此情况下，人们很可能受感情驱使，而误判问题的本质。不断自问现在的自己是否冷静，这种行为本身也能抑制情绪波动。比较麻烦的是，明明没有冷静下来，却误以为自己已经冷静，并做出决策，这种情况会带来严重问题而不自知。 每个人要有分辨自己是否处于冷静状态的意识 “现在的你好像正被愤怒（或者是悲伤、灰心丧气）的情绪支配。你现在这种状态能算幸福吗？是你的初衷吗？继续沉浸在这种状态也好，脱离这种状态也好，都是你自己的选择。自己想想应该怎么做吧！” 通过客观观察自己，你就能将愤怒、悲伤、灰心丧气的情绪从自身剥离。当情绪与人自身紧紧绑在一起时，它就会变得很难控制。然而，通过客观观察自己，你就能将其剥离出来，并加以控制或和谐相处。 显然，最重要的就是捕捉到“我正被愤怒的情绪支配”这个信息。你的目的是客观地观察自己，因此不需要分析其原因，也不需要对其进行解释或赋予意义。切记，你的首要目的在于通过客观观察自身的情绪状态，摆脱剧烈的情绪波动，不被感情所左右。 已经发生的事情显然无法改变了。然而，是继续受其负面影响，还是彻底摆脱过去的阴影，通过自己的思考与行动，你就能做出选择。需要指出的是，情绪会随着我们的行动而发生转变。双层思考：在思考问题的同时查验“思考””偏见陷阱“引起的问题，稍不留意就会出现，所以想要事先预防非常困难。可见，如果能了解大脑有些什么样的运作习惯，那在做决策时，你就可以判断自己是否受其影响。另外，大脑更加偏好带有感情色彩的故事或描写。有些东西，如果重新查看，你可能会发现其逻辑漏洞，但如果没有这种意识，一不留神你就会全盘接受。另外，大脑存在一种机制： 会自动将积极向上的表达方式联系在一起 也同样会将负面的表达方式联系在一起。 同时，在带有感情色彩的故事或描写面前，大脑往往会忽略总体数量或概率大小，有的不怀好意的人会利用大脑的这个特性进行信息操纵。对比分析：深度挖掘缺乏责任感的原因其实很多时候，在没有特大问题需要优先处理的情况下，对某些特定的事情，人们通常缺乏责任意识，只是按吩咐去做，这种情况我觉得有改善的余地。如果只考虑怎么处理眼前的事情，或不思考行为目的，只按吩咐去做，那么事情确实也能得到“处理”，然而你从中学不到任何经验教训，也体会不到工作的乐趣与完成工作时的成就感。另外，人们过去的某些痛苦经历也可能导致了这种行为模式的产生。可能在过去，他们本想自主思考，积极行动，然而却因此受到斥责，被人否定。这样一来，他们就习惯了“不去多想，按命令行事”的行为模式。“责任性”的副作用极大，而且影响深远。如果发现自己染上了“事不关己综合性”，那么你必须做出努力，争取及早脱身。定期升级：根据全新环境重新审视问题为了避免掉入这个陷阱，你最好定期对自身的情况与周围的情况进行检查。即使我们自己没有任何变化，但周围环境的改变可能已经解决了问题，或者问题自身发生了蜕变。我们无法确保过去的对策到现在仍是最优选项。我建议大家务必要定期对问题重新审视，思考新的变化会给自己领域带来什么样的影响，并参考国际上的做法，或是参考其他公司、其他行业的一些做法。这里的“参考”并不是全盘照搬其他公司或其他行业的做法。全盘照搬的做法其实完全就是掉入了“思维惰性陷阱”。另外，思考其他公司或其他行业的做法为什么跟自己公司不一样，这对摆脱“思维静态化陷阱”也很有帮助。本质思考的训练具备良好的习惯，懂得各式各样的陷阱及跳出这些陷阱的方法，人们就走上了迈向本质的正途。然而，要想更高效地把握事物的本质，人们还需要具备一些能力。当然，这些能力都是可以通过不断训练二培养起来的。假设力：尽可能涵盖所有可能方案很多人不用自己的大脑仔细思考问题的本质、行为的目的，致死一味顺从世间法则，或者套用以往的经验，妄加判断。那为什么大家会跳过自己思考这个过程呢？原因多种多样，我认为其中最主要的原因是：大家倾向于只追求答案本身，同时缺乏善于提出假设的能力。一件事情，如果进展顺利的结果与进展不顺利的结果之间落差，那么越值得我们认真思考。思维惰性会让我们更喜欢夸大事情进展不顺利时带来的危害与损失，而看清事情进展顺利时带来的利益和好处。因此，对一件事情进展顺利的结果（最佳情况）与进展不顺利的结果（最坏情况）进行设想的能力就变得十分重要。一般来说，人们对最佳情况的假设都不会好过真实的最佳情况，而我们对最坏情况的假设也都不会坏过真实的最坏情况。善于提出假设能让人们进行认真思考，而思考的结果，能让自己更容易做出判断，究竟哪些是最接近真实的最佳情况与最坏情况。最理想的是，我们能做出所有可能得假设，考虑到所有的最佳情况与最坏情况。然而，现实中，这一点往往无法实现。 送思考最佳情况与最坏情况的阶段开始。 如果预想中的最佳情况与最坏情况并没有什么区别(无论事情进展顺利与否都没有差别)，那么就可能认为，它没有思考的价值。 另外，我们往往只考虑了最佳情况或者最坏情况(大多场合人们只考虑了最佳情况)。 由于我们有时只考虑了最佳情况，所以感受不到它与最坏情况的差别。 这样一来，我们会觉得自己思考好像也意义不大，还白白浪费了思考成本，因此会跳过自己思考这一步骤。 如果人们没有意识到这一点，那么这些判断都会在一瞬间完成。在完成了判断之后，本来应该思考的问题，大脑也会放弃思考，从而有可能引起重大失误。 在处理事情的时候，我们最好稍微多花一点儿时间，只要能意识到事情发展的最佳情况与最坏情况，事情就会发生戏剧性变化。 如果能从长远的角度来思考某件事情的最佳情况与最坏情况，那当然最理想不过了。其实，哪怕我们多想一步，事情也会发生许多变化。 我们应该把眼光放得长远一些，不要只盯着“今天”，也要考虑未来可能出现的变化。有的东西从短期看只是成本支出，但从长远来看可能变成了先期投资。如果我们能把眼光放长远，从今天看到未来，那我们的决策也会发生巨大变化。平时训练可以采取的方法： 寻找极限：找出最好最坏结果 最优选择：计算每种可能性的得失逆向思考力：从未来可能得失败倒推在并未进行深入思考的情况下，很多人喜欢把过去的成功经历，其他公司的成功事例，抑或世间所谓的“常识”，套用在自己公司上面，结果造成了很多错误。自己当初为什么使用那种方法取得了成功，其他公司又是为什么使用那种方法取得了良好效果，世间“常识”又是为什么会变成常识？本来，人们应该在深入分析之后再采用合适的方法去解决问题。世上没有万能的解决方案。有的解决方案只是在一定条件下才能见效，但如果满足不了条件要求，那该解决方案就不会奏效。很多时候，照搬其他公司的做法往往麻烦不断，这是因为解决方案需要满足一定的条件。其他公式能够满足的条件，自己公司不一定能够满足，因为每家公司的聘用标准、员工研修项目、企业文化各不相同。人们经常会机械地选择解决方案： 是因为我们以为自己选择的解决方案一定会行之有效。 对自己不够自信，对自己或公司面临的情况把握不到位为了避免这种情况，大家平时应该注意养成一种习惯： 主动思考什么样的情况下自己选择的解决方案会失效（或者进行反向思考）。如果能充分意识到，自己选择的解决方案在某种情况下会失效，那么就能避免机械套用解决方案的问题。除了商业领域以外，很多地方也适用这个原则。现在是一个多元化的时代，全体一致同意反而不合常理。大家的立场多种多样，每个人之间也存在着不同的利害关系，如果所有人都是同一个意见，那这个决策过程肯定不合理。另外，“因为大家都赞同，所以我也跟着赞同”的做法也很有问题。共情力：不断地站在他人的角度看问题如果不了解事情原委，就一味地认为某人的行为或决策有问题或不可理解或生气，你就会给对方留下很差的印象。这种做法虽然让自己精神上感到舒服了，但学不到东西。尝试站在对方角度，模拟其做出决策的过程，这样我们才能所有收获。不过，此时你也需要注意：必须严格区分站在自己角度时所思考的东西与站在他人角度所思考的东西。如果模拟两可，弄不清自己到底是站在哪个角度思考问题的话，反而会将事情复杂化。另外，你还可以进一步训练自己“站在他人角度进行思考”的能力。比如，对于那些跟自己毫无关系的问题，你也可以尝试站在当事人的角度来思考，也就是说“自我问题化”。通过“自我问题化”，你对那些至今为止没有关心过的事情会产生一种责任意识，这样你才会认真对待问题。漠不关心会让进步停止。信息整理力：辨别每种信息的类型和属性真相、谎言、错误，统统交织在一起。其中有的消息只是单纯的错误信息，而有的假消息却暗含恶意。因此，正确识别和使用信息变得非常重要。 要学会区分事实与观点 对事物进行思考的时候，你必须基于事实 很多观点被伪装成事实的样子出现 有的时候，事实与虚构交织在一起 事实又与推测交织在了一起 一则消息里面，哪部分属于事实，哪部分又属于观点，想要区分清楚并不简单 要练习正确分辨对方的观点及其表达方式 你要学会分辨哪些表达是对方的主观表达，哪些是情感表达，哪些又是对别人的评价。 这个练习方法是为了让我们能够分辨观点的相关表达方式，同时思考对方使用这种表达方式的目的。 显然，你不仅要分辨出对方到底是生气，还是在悲伤，还要思考对方为什么要生气（或装作生气），为什么要悲伤（或装作悲伤） 要学会观察事实有些报道的确传达了部分事实，也没有进行主观性的评述，但未必就真的客观公正。因为就算没有明确发表意见，通过对信息进行取舍拼接，同样可以通过操纵信息来表达自己的观点。如果觉得一些新闻不太对劲，那么你可以尝试搜寻其他消息来源，这样才能掌握整个新闻的全貌。警惕“思维惰性陷阱”，即使是相同的数据，通过不同的展现方式，就可以传达不同的信息，甚至得到截然相反的结论。观点也好，事实也好，总之要养成习惯，学会揣摩信息发送者的意图。图像化能力：掌握更直观的表达方式语言是强有力的武器，同时语言也存在局限性，这一点千万别忘记。对于同一个行为，存在着各种各样的表达方式，有的表达方式可能对于有的人来说并不能理解。在对复杂事物进行解释说明时，不要光使用语言（文章），你还可以展示照片、图表或播放视频，努力尝试更多的组合型表达方式。定规则能力：不断推演怎样的制度更合理遵守规则本身并不是坏事，然而如果没有理解规则的本质，只是觉得既然是规则就必须遵守，那么人们很快就会掉入“思维惰性陷阱”。制定规则必须考虑方方面面的东西，或许你经常抱怨社会上的有些规则或政府制定的有些规则，可视想制定让所有人都满意的规则其实是很难的事情。当你想抱怨社会上的有些规则或政府制定的有些规则的时候，不要发完牢骚就算了，你应该尝试一下自己来制定规则。可能你的规则不会生效，但尝试思考一下也无妨。自己不满意的地方应该怎样解决，新出现的抱怨又该如何应对，思考这些问题可以成为一种训练。另外，如果现行规则不那么令人满意，追寻其原因可以让自己思考得更加深入。是否有什么限制条件影响了规则的实施，规则本身是否已经跟不上时代，你都可以进行思考。遵守规则者如果想获得更进一步的发展，那么可以尝试一下成为规则制定者，这也是一种准备活动。知识消化力：搭建自己的知识库人们常常“自以为懂了”。“自以为懂了”又经常会引发“思维惰性”。因为自以为懂了之后，人们就不会再进行深入的思考。是否真的懂了，只有尝试整理知识形成完整的知识库，并向对面的人或网友解释清楚，才能做出判断。数据力：探索事物之间的量化关系收集那些与生活息息相关的数据，进行分析后相出一些好点子来提高我们的生活质量。养成收集数据、分析数据、依托数据采取行动的习惯极其重要。那么我们就不会那么容易掉进“认知扭曲”与“盲区”的陷阱了。深度思考：基于底层逻辑思考潜在威胁大家可以想一下，在大家各自的领域里，出现什么样的技术革新会破坏大家现有的事业基础呢？如果现在行业的准入壁垒突然消失了又会发生什么呢？另外，由于行政法规的一些限制，有些些行业很难进入，那要是这些行政法规突然消失的话，又会怎么样呢？行政法规限制一旦消失，或者新技术的应用，本来是不同行业的公司，可能进入同一个领域。如果能从根本上理解我们致力于发展的事业，那我们就能更容易发现这项事业，以及相关产业周边的新威胁。同时，如果我们把我们致力于发展的事业仅仅当做是实现某个目标的手段，那我们就很难发现那些潜在的威胁。因此，首先我们必须思考我们致力于发展的事业的本质，思考什么样的东西会破坏我们的事业基础，也要思考潜在威胁一旦成真（比如行政法规限制消失，新技术的应用）又会发生哪些情况。这样的思考练习必须反复进行，每一个季度都值得我们重新思考一次。因为随着时间变化，技术不断革新，国际形势不断改变，行政法规限制也可能已经废除。为了按时间确认自己的想法如何改变，我们每次思考后务必要保留记录，便于下次重新进行审视。另外，如果习惯了这种方式，不光是我们自己公司，我们还可以对自己感兴趣的行业或项目进行同样的思考。这并非易事，因为我们没有明确的答案。但是，如果能定期进行这样的思考，我们的本质把握能力将实现质的飞跃。训练实施日常生活中，如果我们将这9种训练形成习惯，那我们的本质把握能力就会有质的飞跃。 一开始，我们可以一天只做一种训练，一周或两周完成所有9种训练。这样会比较容易上手。 当我们习惯以后，可以每天挑战多个训练，直到每天可以完成9种训练。慢慢地我么会形成习惯，最后我们会下意识地进行某种训练，连自己都不会意识到这一点。 另外，那些当我们掉入陷阱时的应对方法，我们可以找导师帮助我们进行练习，这样会更有效果。导师能起很多作用，例如他们能帮我们判断是否处于冷静状态，避免我们在情绪波动时做出不理智的决策。或者当我们化身为规则的制定者制定规则时，他们也可以进行聆听并做出评价。再或者能帮我们检查我们“自己的知识库”是否正确。我们最好寻找那些我们打心底敬佩、信赖，同时能为我们着想的人来做我们的导师。如果对方知晓我们的秉性那是最好不过，但这不是绝对必要的条件。另外，我强烈推荐找那些与我们身处不同行业的人来帮忙，因为他们新颖的观点往往能带给我们很多启示。如果有这样的导师，对我们提高本质把握能力会有很大的帮助。思考模型思维在经过长久训练后会自然固化，因此思维模型应该具有弹性和开放性，同时具备实用性。历史演化模型知识在不断地演化中会越来越分散庞大，理解起来也越来越趋向于细枝末节。这引发了以下问题： 某类知识过于分散庞大，大脑难以整合，很难知晓全貌 过于分散，很难理清里面的来龙去脉和因果关系，从而很难用逻辑来合理概括 因很难摸清全貌，因此很难对知识分门别类，也很难区分轻重不过在知识刚产生时，所涉及的东西往往比较少，因此找到知识的源头有利于彻底理解整个体系。找源头有以下方法： 通过视频或请求这方面的行家了解概括 先阅读或关注其概论性书籍或文章 了解整个体系的演化历史，理清时间线和该时间线伴随着的其他相关事物或知识 不断提问（对自己或者模仿不同角色），探讨每个发展阶段的机理，理清演化的原因、必要性或必然性" }, { "title": "etcd 杂谈", "url": "/2023/03/etcd.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2023-03-02 07:05:25 +0800", "snippet": " 本文主要对 ETCD 的相关资料进行收集，以备查阅和整理。 架构简介 etcd 应用 典型应用场景 常用工具和命令 etcd 实现原理 通讯协议 etcd 集群 etcd 故障及调优 etcd 综合 etcd 源码和常见面试题架构简介 etcd 架构原理学习（来自etcd实战） etcd技术架构以及其内部的实现机制 Etcd—...", "content": " 本文主要对 ETCD 的相关资料进行收集，以备查阅和整理。 架构简介 etcd 应用 典型应用场景 常用工具和命令 etcd 实现原理 通讯协议 etcd 集群 etcd 故障及调优 etcd 综合 etcd 源码和常见面试题架构简介 etcd 架构原理学习（来自etcd实战） etcd技术架构以及其内部的实现机制 Etcd——基础架构和相关原理 ETCD 六 etcd总体架构 ETCD 架构与实现解析 ETCD 的组件架构和内部通信 etcd技术架构以及其内部的实现机制 etcd基础架构etcd 应用典型应用场景 etcd的应用场景 etcd的应用场景 kubernetes关键组件之etcd ETCD：从应用场景到实现原理的全方位解读 etcd学习(1)-etcd的使用场景 etcd学习和实战：3、go使用etcd实现服务发现和管理 基于etcd实现大规模服务治理应用实战常用工具和命令 ETCD命令大全 ETCD 命令集合 etcdctl的使用(v3版本) Etcd可视化管理工具 etcd安装dashboard-ectd keeperetcd 实现原理 多维度解析etcd 基础架构：etcd一个读请求是如何执行的？ 基础架构：etcd一个写请求是如何执行的？ 深入解读raft算法与etcd工程实现 etcd：etcd的原理和应用场景全面解析 etcd实现-全流程分析 ETCD：从Raft原理到实践，一文带你全部掌握！ etcd 部署集群 etcd 网络层实现 etcd 是什么 ETCD实现及原理分析 Etcd raft算法实现原理分析 etcd教程(五)—watch机制原理分析 etcd教程(六)—etcd多版本并发控制 高可用分布式存储 etcd 的实现原理 ETCD 十四 服务端处理客户端请求过程 RAFT算法详解 拜占庭将军问题和 Raft 共识算法讲解 分布式理论知识学习(拜占庭将军，cap理论，base理论) 这怕是我看过的最好的关于 “ 拜占庭将军问题 ” 的文章 Raft 算法（详细版）通讯协议 ETCD数据库源码分析——客户服务端通信serveCtx etcd跨主机集群通信 【raft】学习一：etcd/raft 19种消息类型解读 ETCD数据库源码分析——客户服务端通信API层 读猿码系列——2. 搞懂Etcd核心API ETCD http接口Api请求示例etcd 集群 分布式存储之 etcd 的集群管理 搭建高可用Etcd集群 (TLS) 容器编排之etcd集群管理 etcd集群etcd 故障及调优 ETCD-节点挂掉会怎样？ ETCD单节点故障应急恢复 将有问题的etcd节点重新加入集群 ETCD集群故障应急恢复-从snapshot恢复 万级 K8s 集群背后 etcd 稳定性及性能优化实践 一个优化etcd（Raft）的方法etcd 综合 你想了解的关于ETCD都在这了 ETCD系列教程1 - Raft原理 ETCD系列教程2 - ETCD体验 ETCD系列教程3 - 深入ETCD ETCD系列教程4 - 应用场景 ETCD介绍—etcd概念及原理方面分析 彻底搞懂 etcd 系列文章（一）：初识 etcd 彻底搞懂 etcd 系列文章（二）：etcd 的多种安装姿势 彻底搞懂 etcd 系列文章（三）：etcd 集群运维部署 彻底搞懂 etcd 系列文章（四）：etcd 安全 彻底搞懂 etcd 系列文章（五）：etcdctl 的使用 彻底搞懂 etcd 系列文章（六）：etcd 核心 API v3 彻底搞懂 etcd 系列文章（七）：etcd gRPC 服务 API 彻底搞懂 etcd 系列文章（八）：etcd 事务 API 彻底搞懂 etcd 系列文章（九）：etcd compact 和 watch API 完全搞懂 etcd 系列文章（十）：etcd 租约 Lease API 讲真的，etcd 服务入门一篇文章足够了！ ETCD结构、特点及和zookeeper对比 etcd 部署集群 etcd 网络层实现 etcd 是什么 云原生|kubernetes|etcd集群详细介绍+安装部署+调优 ETCD实现技术总结etcd 源码和常见面试题 面试题：为什么用etcd而不用Zookeeper？ 如何阅读 etcd 源码 etcd-raft 源码分析 etcd源码学习笔记 基于etcd的源码分析 —— 概述篇 基于etcd的源码分析 —— 组成篇 基于etcd的源码分析 —— 源码篇(上) 基于etcd的源码分析 —— 源码篇(中) 基于etcd的源码分析 —— 源码篇(下) ETCD v2 源码分析 ETCD源码分析（三）Raft协议入门 etcd教程(十三)—watch 机制源码分析（上） etcd教程(十四)—watch 机制源码分析（下） etcd教程(十二)—etcd mvcc 源码分析 Etcd raft源码阅读" }, { "title": "docker 精要", "url": "/2022/06/docker.html", "categories": "高效工具", "tags": "Tool", "date": "2022-06-19 15:08:19 +0800", "snippet": " docker 在开发、测试、部署和微服务治理、PaaS（平台即服务）以及云原生或云计算等领域已举足轻重。本文将简要探讨一下 docker，主要从使用角度（而非源代码角度）的各个层面呈现其功能的强大和设计上的魅力。 远观 docker docker 容器集群编排工具 DockerFile docker compose Docker Desktop ...", "content": " docker 在开发、测试、部署和微服务治理、PaaS（平台即服务）以及云原生或云计算等领域已举足轻重。本文将简要探讨一下 docker，主要从使用角度（而非源代码角度）的各个层面呈现其功能的强大和设计上的魅力。 远观 docker docker 容器集群编排工具 DockerFile docker compose Docker Desktop Portainer swarm kubernetes 架构简介 API server Controller Manager Scheduler Kubelet Kube-proxy Etcd 全面了解 k8s docker 底层核心技术与实现原理 docker 分层机制 docker 隔离机制 NameSpace机制 Namespace 实现 资源使用限制 Docker 容器网络通信原理 网络模式 容器之间通信 容器与宿主机之间通信 容器与外网通信 远观 dockerdocker 在 LInux 系统实现的框架如下图：各个部分简单说明如下： Docker Client：是和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker（类似可执行脚本的命令），docker命令后接参数的形式来实现一个完整的请求命令 docker daemon：后台守护进程 Docker Server：相当于C/S架构的服务端。功能为接受并调度分发Docker Client发送的请求。接受请求后，Server通过路由(Router)与分发调度，找到相应的Handler来执行请求 Job：一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job Repository 已下载镜像的保管者（包括下载镜像和dockerfile构建的镜像）。 一个repository表示某类镜像的仓库（例如Ubuntu），同一个repository内的镜像用tag来区分（表示同一类镜像的不同标签或版本）。一个registry包含多个repository，一个repository包含同类型的多个image。 镜像的存储类型有aufs，devicemapper,Btrfs，Vfs等。其中centos系统使用devicemapper的存储类型。 同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs。 GraphDB 已下载容器镜像之间关系的记录者。 GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录 graphdriver：主要用于完成容器镜像的管理，包括存储与获取。 存储：docker pull下载的镜像由graphdriver存储到本地的指定目录（Graph中）。 获取：docker run（create）用镜像来创建容器的时候由graphdriver到本地Graph中获取镜像。 execdriver：作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。现在execdriver默认使用native驱动，不依赖于LXC libcontainer：是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API Docker 容器就是 Docker 镜像的运行实例docker 命令图解 docker 生命周期docker 生命周期 是指容器所处的状态 ，容器本质上是Host宿主机的进程，操作系统对于进程的管理是基于进程的状态切换的，进程从创建到销毁可能经过的路径图可以称之为“生命周期”。docker 部署开发流程docker 容器集群编排工具DockerFileDockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，执行结束后，commit 这一层的修改，构成新的镜像。因此每一条指令的内容，就是描述该层应当如何构建。有了 Dockerfile，当我们需要定制自己额外的需求时，只需在 Dockerfile 上添加或者修改指令，重新生成 image 即可，省去了敲命令的麻烦。有了该文件，可以通过 build 命令来构建镜像：docker build -f /path/to/a/Dockerfile .Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，都会新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像DockerFile 样例：# This my first nginx Dockerfile# Version 1.0# 这个变量在每个 FROM 中都生效# 构建参数和 ENV 的效果一样，都是设置环境变量。# 所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的ARG DOCKER_BASE_IMAG=centos# Base images 基础镜像FROM ${DOCKER_BASE_IMAG}:7.7.1908#MAINTAINER 维护者信息MAINTAINER someone#ENV 设置环境变量#无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。ENV PATH /usr/local/nginx/sbin:$PATH#ADD 文件放在当前目录下，拷过去会自动解压ADD nginx-1.8.0.tar.gz /usr/local/ADD epel-release-latest-7.noarch.rpm /usr/local/# 所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADDCOPY package.json /usr/src/app/# 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。# 当然，运行时可以覆盖这个挂载设置。比如：# docker run -d -v mydata:/data -t ny_nginx# 以上在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置VOLUME /data#RUN 执行以下命令# RUN rpm -ivh /usr/local/epel-release-latest-7.noarch.rpm# RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre &amp;&amp; yum clean all# RUN useradd -s /sbin/nologin -M www# 上面的这种写法，创建了 3 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里# 推荐下面的写法RUN buildDeps='wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre' \\ &amp;&amp; rpm -ivh /usr/local/epel-release-latest-7.noarch.rpm \\ &amp;&amp; yum install -y $buildDeps \\ &amp;&amp; useradd -s /sbin/nologin -M www#WORKDIR 相当于cdWORKDIR /usr/local/nginx-1.8.0RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre &amp;&amp; make &amp;&amp; make installRUN echo \"daemon off;\" &gt;&gt; /etc/nginx.conf# USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，# USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。# 当然，和 WORKDIR 一样，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换RUN groupadd -r nginx_user &amp;&amp; useradd -r -g nginx_user nginx_userUSER nginx_user#EXPOSE 映射端口EXPOSE 80/tcp 8080 123456#CMD 运行以下命令# 比如在终端执行命令 docker run my_nginx# 则会执行下面的 CMD 命令# 与 CMD 类似的还有 ENTRYPOINT，不过后者支持终端 docker run 命令追加参数# 如 docker run my_nginx -v# ENTRYPOINT [\"nginx\"]# 以上两个命令相当于 CMD [\"nginx\", \"-v\"]CMD [\"nginx\"]docker compose前面提到的 dockerFile 可以构建单个镜像，当然单个镜像中可以打包多个应用（比如mysql、redis）。但不建议这么做，因为会导致这个镜像非常大，而且东西多了，重用它的额外代价也比较高。同时对于集群应用（比如mysql，redis 集群）是无法通过单个镜像完成的。那对于需要同时启动众多镜像的场景，你可以有以下方案： 在命令行中敲命令逐个启动容器，直到所需的容器全部启动完毕 把要执行的所有命令写在一个shell脚本中，执行这个脚本即可 使用 docker compose 等 docker 编排工具Docker Compose 是一个用来定义和运行复杂应用的Docker工具。一个使用Docker容器的应用，通常由多个容器组成。使用Docker Compose 不再需要使用shell脚本来启动容器。Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。Docker-Compose是一个容器编排工具。通过一个.yml或.yaml文件，将所有的容器的部署方法、文件映射、容器端口映射等情况写在一个配置文件里，执行 docker compose up 命令就像执行脚本一样，一个一个的安装并部署容器。compose 支持的配置项详见官方文档，下面只给出一个简单的实例。常用的命令有：# 当配置文件修改后或者对于一个新的配置文件最好逐个执行以下命令# 删除上次构建的容器docker compose down# 重新构建镜像 --force-rm 删除构建过程中的临时容器。docker compose build --force-rm# 运行容器# 对于没有变动过的配置文件，之前已经执行了这里的所有命令的，之后启动只需要执行这个即可docker compose up -d# 其他命令可以使用 helpdocker compose -help配置文件样例：version: '3'networks: dev:# 系列服务组services:####################### mongodb ####################### mongo:# container_name: mongo# image: mongo# restart: always# environment:# MONGO_INITDB_ROOT_USERNAME: root# MONGO_INITDB_ROOT_PASSWORD: 123456# networks:# - dev# ports:# - 27017:27017##################### kafka ####################### 某个服务的配置 zookeeper: image: wurstmeister/zookeeper ports: - \"2181:2181\" networks: - dev kafka: image: wurstmeister/kafka depends_on: [ zookeeper ] ports: - \"9092:9092\" environment: KAFKA_ADVERTISED_HOST_NAME: 192.168.33.20 KAFKA_CREATE_TOPICS: \"test:1:1\" KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 volumes: - ./data/kafka/docker.sock:/var/run/docker.sock networks: - dev####################### etcd ######################## etcd: container_name: etcd image: bitnami/etcd:3 #image: quay.io/coreos/etcd:v3.3 restart: always environment: - ALLOW_NONE_AUTHENTICATION=yes - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379 networks: - dev ports: - 2379:2379 - 2380:2380####################### nsqdb ######################### nsqlookupd:# image: nsqio/nsq# command: /nsqlookupd# networks:# - dev# hostname: nsqlookupd# ports:# - \"4161:4161\"# - \"4160:4160\"# nsqd:# image: nsqio/nsq# command: /nsqd --lookupd-tcp-address=nsqlookupd:4160 -broadcast-address=192.168.33.20# depends_on:# - nsqlookupd# hostname: nsqd# networks:# - dev# ports:# - \"4151:4151\"# - \"4150:4150\"# nsqadmin:# image: nsqio/nsq# command: /nsqadmin --lookupd-http-address=nsqlookupd:4161# depends_on:# - nsqlookupd# hostname: nsqadmin# ports:# - \"4171:4171\"# networks:# - dev####################### mysql5.7 ######################## mysql5.7: container_name: mysql5.7 image: mysql:5.7 restart: always command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci environment: - MYSQL_ROOT_PASSWORD=123456 - LANG=C.UTF-8 networks: - dev volumes: - ./data/mysql:/var/lib/mysql ##自建目录 ports: - 3306:3306 phpmyadmin: image: phpmyadmin container_name: phpmyadmin environment: - PMA_ARBITRARY=1 restart: always links: - mysql5.7 ports: - 8090:80 volumes: - /sessions networks: - dev######################## redis ######################## redis: image: bitnami/redis:latest container_name: redis restart: always ports: - 6379:6379 networks: - dev environment: - ALLOW_EMPTY_PASSWORD=yes volumes: - ./redis.conf:/usr/local/etc/redis/redis.conf:rw - ./data/redis:/data:rw ##自建目录 command: /bin/bash -c \"redis-server /usr/local/etc/redis/redis.conf\"######################## nginx ######################### web:# container_name: web# image: nginx:latest# restart: always# volumes:# - \"./etc/nginx:/etc/nginx\" ##自建目录# - \"./logs:/logs\" ##自建目录# ports:# - 80:80# - 443:443# networks:# - dev#################################Microservices################################ service_user:# container_name: service_user# image: alpine:latest# restart: always# volumes:# - \"./bin/service_user:/service_user\"# - \"./etc/service_user.yaml:/service_user.yaml\"# - \"./logs:/logs\"# command: /service_user -f /service_user.json# networks:# - dev# ports:# - 8080:8080compose 支持以下使用场景： 单服务单容器使用 多服务多容器依赖使用 多服务多容器独立使用 单服务多容器使用Docker DesktopDocker Desktop 官方口号“容器化和共享任何应用程序”，支持跨云、语言和框架的任意组合。其包括开发者工具、Kubernetes 和与生产 Docker 引擎的版本同步。你可以把它理解成对应命令行工具的图形界面软件，比较简便，这里不再详述。至于如何安装可参阅官方文档Docker Desktop 和 Desktop Enterprise 为开发人员提供了与生产集群一致的Docker 和 Kubernetes环境。使用唯一能够提供可信且经过认证的端到端安全性的平台，在任何地方构建和运行相同的应用程序。对于开发人员和相关测试人员来说，不需要对 Docker 或 Kubernetes 有着非常深的理解。Docker 可以在几分钟内轻松启动和运行，快速编码、测试和协作，同时确保开发和生产之间的一致性。PortainerPortainer是一个可视化的容器镜像的图形管理工具，利用Portainer可以轻松构建，管理和维护Docker环境（如docker的containers、images、volumes、networks等等）。而且完全免费，基于容器化的安装方式，方便高效部署。 它由一个可以运行在任何docker引擎上的容器组成。Portainer提供管理docker的非常值得推荐的是它可以图形化的管理docker和本地的k8s，并且通过agent的方式发现不同主机的docker列表和k8s集群，并可以通过api去管理相关服务。具体使用方法和场景可参阅官方文档适合使用Docker或Docker Swarm，没有容器管理工具的场景，如开发环境、测试环境和暂时不想使用k8s的场景的生产环境。可以把它当做轻量级的微服务部署管理系统。swarmDocker 的单节点引擎工具 Docker Compose，它能够在单一节点上管理和编排多个容器，当我们的服务和容器数量较小时可以使用 Docker Compose 来管理容器。然而随着我们的业务规模越来越大，我们的容器规模也逐渐增大时，数量庞大的容器管理将给我们带来许多挑战。Docker 官方为了解决多容器管理的问题推出了 Docker Swarm ，我们可以用它来管理规模更大的容器集群。如何使用可以通过命令 docker swarm --help 得到对应帮助。Docker Swarm 是一个 Dockerized 化的分布式应用程序的本地集群。具体来说，Docker Swarm 支持用户创建可运行 Docker Daemon 的主机资源池，然后在资源池中运行 Docker 容器。Docker Swarm 可以管理工作负载并维护集群状态。除了资源优化，Docker Swarm 可以保证应用的高可用性和容错性。Docker Swarm 会不断的检查 Docker Daemon 所在主机的健康状态。当某个主机不可用时，Swarm 就会将容器迁移到新的主机上。Docker Swarm 的亮点之一是它可以在应用的生命周期内扩展，也就是说当应用从一个主机扩展到 2 个、20 个或者 200 个的时候，用户可以保证接口的一致性。具体操作可以参考以下文章 Docker容器与虚拟化技术——容器集群之Docker Swarm SWARM（集群部署，弹性伸缩，滚动更新，监控，GLOBAL模式的设置)kubernetes当微服务数量众多或者依赖的集群化组件过多时，如果用 Docker Compose 配置文件或者脚本来管理，会让人崩溃而且很难维护，只要部署完了之后，没人敢去动了。因此，落地庞大的微服务架构是绕不开类似k8s的部署和运行动态管理平台的。k8s 是什么： Kubernetes 是舵手的意思，我们把 Docker 比喻成一个个集装箱，而 Kubernetes 正是运输这些集装箱的舵手。 Kubernetes 是一个可移植的，可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes 目前已经支持在多种环境下安装，我们可以在公有云，私有云，甚至裸金属中安装 Kubernetes。minikube 是官方提供的一个快速搭建本地 Kubernetes 集群的工具，主要用于本地开发和调试。详细介绍和使用指南可参阅官方文档k8s 至少有以下特点： 自动装箱,水平扩展,自我修复 服务发现和负载均衡与伸缩(Ingress和kube-proxy) 自动灰度发布(默认滚动发布模式)和回滚 集中化配置管理和密钥管理(ConfigMap和Secrets) 存储编排(Volume) 任务批处理运行架构简介API serverAPI Server 扮演着通信枢纽的位置。API Server 不仅负责和 etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），并且对外提供统一的API调用入口, 所有的交互都是以 API Server 为核心的。API Server 提供了以下的功能： 集群控制的入口：提供了 RESTful API 接口的关键服务进程，是 Kubernetes 里所有资源的增删改查等操作的唯一入口。创建一个资源对象如Deployment、Service、RC、ConfigMap等，都是要通过API Server的。通过API Server，我们就可以往Etcd中写入数据。Etcd中存储着集群的各种数据。 资源配额控制的入口： Kubernetes 可以从各个层级对资源进行配额控制。如容器的CPU使用量、Pod的CPU使用量、namespace的资源数量等。这也是通过API Server进行配置的。将这些资源配额情况写入到Etcd中 集群内部各个模块之间通信的枢纽：所有模块之前并不会之间互相调用，而是通过和 API Server 打交道来完成自己那部分的工作。Controller ManagerController Manager作用是通过API Server监控Etcd中的节点信息，定时通过API Server读取Etcd中的节点信息，监控到异常就会自动进行某种操作。负责管理集群各种资源，保证资源处于预期的状态。Controller Manager由多种controller组成，包括node controller、replication controller、endpoints controller、namespace controller、serviceaccounts controller等。由控制器完成的主要功能主要包括生命周期功能和API业务逻辑，具体如下：生命周期功能：包括Namespace创建和生命周期、Event垃圾回收、Pod终止相关的垃圾回收、级联垃圾回收及Node垃圾回收等。API业务逻辑：例如，由ReplicaSet执行的Pod扩展等。Node Controller：node controller 通过API Server监控Etcd中存储的关于节点的各类信息，会定时通过API Server读取这些节点的信息，这些节点信息是由kubelet定时推给API Server的，由API Server写入到Etcd中。这些节点信息包括：节点健康状况、节点资源、节点名称、节点地址信息、操作系统版本、Docker版本、kubelet版本等。监控到节点信息若有异常情况，则会对节点进行某种操作，如节点状态变为故障状态，则删除节点与节点相关的Pod等资源的信息。Namespace Controller：用户是可以通过API Server创建新的namespace并保存在Etcd中的。Namespace Controller会定时通过API Server读取这些Namespace信息并做对应的对于Namespace的一些操作。ResourceQuota Controller：将期望的资源配额信息通过API Server写入到Etcd中。然后ResourceQuota Controller会定时的统计这些信息，在系统请求资源的时候就会读取这些统计信息，如果不合法就不给分配该资源，则创建行为会报错。SchedulerKubernetes的调度器，负责 Pod 资源调度。Scheduler监听API Server，当需要创建新的Pod时。Scheduler负责选择该Pod与哪个Node进行绑定。将此绑定信息通过API Server写入到Etcd中。若此时与Node A进行了绑定，那么A上的Kubelet就会从API Server上监听到此事件，那么该Kubelet(Kubelet除了监听API Server做相应的操作之外，还定时推送它所在节点的信息给API Server)就会做相应的创建工作。此调度涉及到三个对象，待调度的Pod，可用的Node，调度算法。简单的说，就是使用某种调度算法为待调度的Pod找到合适的运行此Pod的Node。KubeletKubelet负责 Pod 对应的容器的创建，启动等任务，同时与Master节点密切协作。每个Node节点上都会有一个Kubelet负责Master下发到该节点的具体任务，管理该节点上的Pod和容器。而且会在创建之初向API Server注册自身的信息，定时汇报节点的信息。它还通过cAdvisor监控容器和节点资源。 节点管理：Kubelet在创建之初就会向API Server做自注册，然后会定时报告节点的信息给API Server写入到Etcd中。默认为10秒。 Pod管理：Kubelet会监听API Server，如果发现对Pod有什么操作，它就会作出相应的动作。例如发现有Pod与本Node进行了绑定。那么Kubelet就会创建相应的Pod且调用Docker Client下载image并运行container。 容器健康检查： 有三种方式对容器做健康检查。 在容器内部运行一个命令，如果该命令的退出状态码为0，则表明容器健康 TCP检查 HTTP检查 cAdvisor资源监控：Kubelet通过cAdvisor对该节点的各类资源进行监控。如果集群需要这些监控到的资源信息，可以安装一个组件Heapster。Heapster会进行集群级别的监控，它会通过Kubelet获取到所有节点的各种资源信息，然后通过带着关联标签的Pod分组这些信息。如果再配合InfluxDB与Grafana，那么就成为一个完整的集群监控系统了。Kube-proxy实现 Kubernetes Service 的通信与负载均衡机制的重要组件。负责接收并转发请求。Kube-proxy的核心功能是将到Service的访问请求转发到后台的某个具体的Pod。无论是通过ClusterIP+Port的方式，还是NodeIP+NodePort的方式访问Service，最终都会被节点的Iptables规则重定向到Kube-proxy监听服务代理端口，该代理端口实际上就是SocketServer在本地随机打开的一个端口，SocketServer是Kube-proxy为每一个服务都会创建的“服务代理对象”的一部分。当Kube-proxy监听到Service的访问请求后，它会找到最适合的Endpoints，然后将请求转发过去。具体的路由选择依据Round Robin算法及Service的Session会话保持这两个特性。首先k8s 里所有资源都存在 etcd 中，各个组件通过 apiserver 的接口进行访问etcd来获取资源信息kube-proxy 会作为 daemon（守护进程） 跑在每个节点上通过watch的方式监控着etcd中关于Pod的最新状态信息,它一旦检查到一个Pod资源被删除了或新建或ip变化了等一系列变动，它就立即将这些变动，反应在iptables 或 ipvs规则中，以便之后 再有请求发到service时，service可以通过ipvs最新的规则将请求的分发到pod上EtcdEtcd一种k-v存储仓库，可用于服务发现程序。在Kubernetes中就是用Etcd来存储各种k-v对象的。所以我也认为Etcd是Kubernetes的一个重要组件。当我们无论是创建Deployment也好，还是创建Service也好，各种资源对象信息都是写在Etcd中了。各个组件是通过API Server进行交流的，然而数据的来源是Etcd。所以维持Etcd的高可用是至关重要的。如果Etcd坏了，任何程序也无法正常运行了。etcd在kubernetes集群是用来存放数据并通知变动的。Kubernetes中没有用到数据库，它把关键数据都存放在etcd中，这使kubernetes的整体结构变得非常简单。在kubernetes中，数据是随时发生变化的，比如说用户提交了新任务、增加了新的Node、Node宕机了、容器死掉了等等，都会触发状态数据的变更。状态数据变更之后呢，Master上的kube-scheduler和kube-controller-manager，就会重新安排工作，它们的工作安排结果也是数据。这些变化，都需要及时地通知给每一个组件。etcd有一个特别好用的特性，可以调用它的api监听其中的数据，一旦数据发生变化了，就会收到通知。有了这个特性之后，kubernetes中的每个组件只需要监听etcd中数据，就可以知道自己应该做什么。kube-scheduler和kube-controller-manager呢，也只需要把最新的工作安排写入到etcd中就可以了，不用自己费心去逐个通知了全面了解 k8s想进一步了解更多细节的读者可以继续阅读以下文章： 一文深入理解 Kubernetes 运维实战 kubernetes(k8s) 之 servicedocker 底层核心技术与实现原理docker其实是使用了Linux Kernel的一些特性Features来实现的资源隔离，文件系统就是其中一种，但docker为了使资源可以更高效的被利用，采用了分层次的文件系统结构，来实现container的文件系统。docker 分层机制docker镜像是一种分层结构，每一层构建在其它层之上，从而实现增量增加内容的功能，这是如何实现的？这里用到了Linux的Union File System分层技术。Union File System(简称，UnionFS)：是为 Linux 系统设计的将其他文件系统联合到一个联合挂载点的文件系统服务。UnionFS使用 branch(分支)将不同文件系统的文件和目录透明地叠加覆盖，形成一个单一一致的文件系统，此外 UnionFS 使用写时复制(Copy on Write，简称，CoW)技术来提高合并后文件系统的资源利用。其实docker镜像分层、增量增加就是利用UnionFS功能，在基础的文件系统上增量的增加新的文件系统，通过叠加覆盖的形式最终形成一个文件系统，同时这也导致了运行 docker 容器如果没有指定 volume（数据卷）或 bind mount，则 docker 容器结束后，运行时产生的数据便丢失了（一般会指定宿主主机的目录）。可以将docker 镜像看成一个整体。所有的docker 镜像都是一个 基础镜像（可以理解为依托点），在基础镜像的层次和基础之上，所做的修改以及增加的功能，都会生成新的一层。根据这个分层机制可以对特定的镜像进行瘦身优化。 分层好处 拉取更快：因为分层了，只需拉取本地不存在的层即可 存储更少：因为共同的层只需存储一份即可 运行时存储更少：容器运行时可以共享相同的层。多个基于相同镜像运行的容器，都可以直接使用相同的镜像层，每个容器只需一个自己的可写层即可。容器写策略用的是Copy-on-write，它是一种提高文件共享和复制效率的策略。如果一个文件和目录在低一层的镜像层中存在，并且其它层想要读取这个文件，就直接使用这个文件。如果其它层想要修改这个文件（不管是构建镜像时，还是在容器运行的过程中），这个文件都会被先拷贝到新的一层中，然后再修改它总而言之，镜像层是只读的，新的镜像层是基于前一个镜像层的修改，只保留了增量修改的部分！使用了联合文件系统，对文件系统的修改作为一次提交来一层层的叠加！ 容器本质上也是在镜像的基础上加了一层可写层docker 隔离机制Linux Namespace是Linux提供的一种内核级别环境隔离的方法。不知道你是否还记得很早以前的Unix有一个叫chroot的系统调用（通过修改根目录把用户jail到一个特定目录下），chroot提供了一种简单的隔离模式：chroot内部的文件系统无法访问外部的内容。Linux Namespace在此基础上，提供了对UTS、IPC、mount、PID、network、User等的隔离机制。Docker的隔离性主要运用Namespace 技术。传统上Linux中的PID是唯一且独立的，在正常情况下，用户不会看见重复的PID。然而在Docker采用了Namespace，从而令相同的PID可于不同的Namespace中独立存在。如，A Container 之中PID=1是A程序，而B Container之中的PID=1同样可以是A程序。虽然Docker可透过Namespace的方式分隔出看似是独立的空间，然而Linux内核（Kernel）却不能Namespace，所以即使有多个Container，所有的system call其实都是通过主机的内核处理，这便为Docker留下了不可否认的安全问题。docker 主要用到了以下技术实现隔离： Linux的Capability机制：capability把权限进行了拆分，可以把部分权限赋予给普通用户进程，而不需要切换到root。 写入时复制（Copy-On-Write）：所有运行的容器可以先共享一个基本文件系统镜像，一旦需要向文件系统写数据，就引导它写到与该容器相关的另一个特定文件系统中。这样的机制避免了一个容器看到另一个容器的数据，而且容器也无法通过修改文件系统的内容来影响其他容器。 NameSpace机制：使用Namespaces实现了系统环境的隔离。Namespace的6项隔离看似完整，实际上依旧没有完全隔离Linux资源，如/proc 、/sys 、/dev/sd* 等目录未完全隔离，SELinux、time、syslog等信息都未隔离。/proc/[pid]/ns 目录下会包含进程所属的 Namespace 信息，用 ls 命令查看即可。 CGroups：使用CGroups限制这个环境的资源使用情况。只能限制资源消耗的最大值，而不能隔绝其他程序占用自己的资源NameSpace机制man page 中对其有较为简明的阐述。每种namespace都有对应的id用于该namespace下的唯一标识，防止重复映射。我们可以到proc下（/proc/进程pid/ns）查看进程的各个namespace的id，用 ls -l /proc/进程pid/ns命令可以查看。如果两个进程指向的namespace编号相同，就说明他们在同一个namespace下，否则则在不同namespace里面。namespace 解决了环境隔离和资源名称映射的问题。UTS Namespace:UTS Namespace 对主机名和域名进行隔离。为什么要隔离主机名？因为主机名可以代替IP来访问。如果不隔离，同名访问会出冲突。IPC NamespaceLinux 提供很多种进程通信机制，IPC Namespace 针对 System V 和 POSIX 消息队列，这些 IPC 机制会使用标识符来区别不同的消息队列，然后两个进程通过标识符找到对应的消息队列。IPC namespace使得相同的标识符在两个Namespace代表不同的消息队列，因此两个Namespace 中的进程不能通过 IPC 来通信。PID NamespacePID Namespace 用来隔离进程的 PID 空间，使得不同 PID Namespace 里的进程 PID 可以重复且互不影响。PID Namespace 对容器类应用特别重要，可以实现容器内进程的暂停/恢复等功能，还可以支持容器在跨主机的迁移前后保持内部进程的 PID 不发生变化。Mount NamespaceMount Namespace 为进程提供独立的文件系统视图。可以这么理解，Mount Namespace 用来隔离文件系统的挂载点，这样进程就只能看到自己的Mount Namespace中的文件系统挂载点。进程的Mount Namespace中的挂载点信息可以在 /proc/[pid]/mounts、/proc/[pid]/mountinfo 和 /proc/[pid]/mountstats 这三个文件中找到。在一个 Namespace 里挂载、卸载的动作不会影响到其他 Namespace。Network NamespaceNetwork Namespace 在逻辑上是网络堆栈的一个副本，它有自己的路由、防火墙规则和网络设备。默认情况下，子进程继承其父进程的 Network Namespace。每个新创建的 Network Namespace 默认有一个本地环回接口 lo，除此之外，所有的其他网络设备(物理/虚拟网络接口，网桥等)只能属于一个 Network Namespace。每个 socket 也只能属于一个 Network Namespace。在Linux下，我们一般用ip命令创建Network Namespace（Docker的源码中，它没有用ip命令，而是自己实现了ip命令内的一些功能）。下面的shell操作基本上就是docker网络的原理了，但具体实现方式有所不同。## 首先，我们先增加一个网桥lxcbr0，模仿docker0brctl addbr lxcbr0brctl stp lxcbr0 offifconfig lxcbr0 192.168.10.1/24 up #为网桥设置IP地址## 接下来，我们要创建一个network namespace - ns1# 增加一个namesapce 命令为 ns1 （使用ip netns add命令）ip netns add ns1 # 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）ip netns exec ns1 ip link set dev lo up ## 然后，我们需要增加一对虚拟网卡# 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中ip link add veth-ns1 type veth peer name lxcbr0.1# 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了ip link set veth-ns1 netns ns1# 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）ip netns exec ns1 ip link set dev veth-ns1 name eth0 # 为容器中的网卡分配一个IP地址，并激活它ip netns exec ns1 ifconfig eth0 192.168.10.11/24 up# 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上brctl addif lxcbr0 lxcbr0.1# 为容器增加一个路由规则，让容器可以访问外面的网络ip netns exec ns1 ip route add default via 192.168.10.1# 在/etc/netns下创建network namespce名称为ns1的目录，# 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了mkdir -p /etc/netns/ns1echo \"nameserver 8.8.8.8\" &gt; /etc/netns/ns1/resolv.conf无论是Docker的NAT方式，还是混杂模式都会有性能上的问题，NAT不用说了，存在一个转发的开销，混杂模式呢，网卡上收到的负载都会完全交给所有的虚拟网卡上，于是就算一个网卡上没有数据，但也会被其它网卡上的数据所影响。这两种方式都不够完美，我们知道，真正解决这种网络问题需要使用VLAN技术，于是Google的开发者为Linux内核实现了一个 IPVLAN 的驱动，这基本上就是为Docker量身定制的。User NamespaceUser Namespace 用于隔离安全相关的资源，包括 user IDs and group IDs，keys, 和 capabilities。同样一个用户的 user ID 和 group ID 在不同的User Namespace 中可以不一样(与 PID Namespace 类似)。可以这样理解，一个用户可以在一个User Namespace中是普通用户，但在另一个User Namespace中是root用户。结合程序的阐述可参考#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;sys/mount.h&gt;#include &lt;sys/capability.h&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = { \"/bin/bash\", NULL};int pipefd[2];void set_map(char* file, int inside_id, int outside_id, int len) { FILE* mapfd = fopen(file, \"w\"); if (NULL == mapfd) { perror(\"open file error\"); return; } fprintf(mapfd, \"%d %d %d\", inside_id, outside_id, len); fclose(mapfd);}void set_uid_map(pid_t pid, int inside_id, int outside_id, int len) { char file[256]; sprintf(file, \"/proc/%d/uid_map\", pid); set_map(file, inside_id, outside_id, len);}void set_gid_map(pid_t pid, int inside_id, int outside_id, int len) { char file[256]; sprintf(file, \"/proc/%d/gid_map\", pid); set_map(file, inside_id, outside_id, len);}int container_main(void* arg){ printf(\"Container [%5d] - inside the container!\\n\", getpid()); printf(\"Container: eUID = %ld; eGID = %ld, UID=%ld, GID=%ld\\n\", (long) geteuid(), (long) getegid(), (long) getuid(), (long) getgid()); /* 等待父进程通知后再往下执行（进程间的同步） */ char ch; close(pipefd[1]); read(pipefd[0], &amp;ch, 1); printf(\"Container [%5d] - setup hostname!\\n\", getpid()); //set hostname sethostname(\"container\",10); //remount \"/proc\" to make sure the \"top\" and \"ps\" show container's information mount(\"proc\", \"/proc\", \"proc\", 0, NULL); execv(container_args[0], container_args); printf(\"Something's wrong!\\n\"); return 1;}int main(){ const int gid=getgid(), uid=getuid(); printf(\"Parent: eUID = %ld; eGID = %ld, UID=%ld, GID=%ld\\n\", (long) geteuid(), (long) getegid(), (long) getuid(), (long) getgid()); pipe(pipefd); printf(\"Parent [%5d] - start a container!\\n\", getpid()); int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWUTS | CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWUSER | SIGCHLD, NULL); printf(\"Parent [%5d] - Container [%5d]!\\n\", getpid(), container_pid); //To map the uid/gid, // we need edit the /proc/PID/uid_map (or /proc/PID/gid_map) in parent //The file format is // ID-inside-ns ID-outside-ns length //if no mapping, // the uid will be taken from /proc/sys/kernel/overflowuid // the gid will be taken from /proc/sys/kernel/overflowgid set_uid_map(container_pid, 0, uid, 1); set_gid_map(container_pid, 0, gid, 1); printf(\"Parent [%5d] - user/group mapping done!\\n\", getpid()); /* 通知子进程 */ close(pipefd[1]); waitpid(container_pid, NULL, 0); printf(\"Parent - container stopped!\\n\"); return 0;}Namespace 实现主要是三个系统调用，详细文档在Namespaces in operation: clone()： 实现线程的系统调用，用来创建一个新的进程，并可以通过设计上述参数达到隔离。 unshare()： 使某进程脱离某个namespace setns()： 把某进程加入到某个namespaceNamespace 种类和以上系统调用的参数对应关系如下： 分类 系统调用参数 Mount namespaces CLONE_NEWNS UTS namespaces CLONE_NEWUTS IPC namespaces CLONE_NEWIPC PID namespaces CLONE_NEWPID Network namespaces CLONE_NEWNET User namespaces CLONE_NEWUSER 系统调用参数的使用例子如下，模仿docker实现隔离的详细例子请参阅 DOCKER基础技术：LINUX NAMESPACE（上）：#define _GNU_SOURCE#include &lt;sys types.h=\"\"&gt;#include &lt;sys wait.h=\"\"&gt;#include &lt;sys mount.h=\"\"&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = { \"/bin/bash\", \"-l\", NULL};int container_main(void* arg){ printf(\"Container [%5d] - inside the container!\\n\", getpid()); //set hostname sethostname(\"container\",10); //remount \"/proc\" to make sure the \"top\" and \"ps\" show container's information if (mount(\"proc\", \"rootfs/proc\", \"proc\", 0, NULL) !=0 ) { perror(\"proc\"); } if (mount(\"sysfs\", \"rootfs/sys\", \"sysfs\", 0, NULL)!=0) { perror(\"sys\"); } if (mount(\"none\", \"rootfs/tmp\", \"tmpfs\", 0, NULL)!=0) { perror(\"tmp\"); } if (mount(\"udev\", \"rootfs/dev\", \"devtmpfs\", 0, NULL)!=0) { perror(\"dev\"); } if (mount(\"devpts\", \"rootfs/dev/pts\", \"devpts\", 0, NULL)!=0) { perror(\"dev/pts\"); } if (mount(\"shm\", \"rootfs/dev/shm\", \"tmpfs\", 0, NULL)!=0) { perror(\"dev/shm\"); } if (mount(\"tmpfs\", \"rootfs/run\", \"tmpfs\", 0, NULL)!=0) { perror(\"run\"); } /* * 模仿Docker的从外向容器里mount相关的配置文件 * 你可以查看：/var/lib/docker/containers/&lt;container_id&gt;/目录， * 你会看到docker的这些文件的。 */ if (mount(\"conf/hosts\", \"rootfs/etc/hosts\", \"none\", MS_BIND, NULL)!=0 || mount(\"conf/hostname\", \"rootfs/etc/hostname\", \"none\", MS_BIND, NULL)!=0 || mount(\"conf/resolv.conf\", \"rootfs/etc/resolv.conf\", \"none\", MS_BIND, NULL)!=0 ) { perror(\"conf\"); } /* 模仿docker run命令中的 -v, --volume=[] 参数干的事 */ if (mount(\"/tmp/t1\", \"rootfs/mnt\", \"none\", MS_BIND, NULL)!=0) { perror(\"mnt\"); } /* chroot 隔离目录 */ if ( chdir(\"./rootfs\") != 0 || chroot(\"./\") != 0 ){ perror(\"chdir/chroot\"); } execv(container_args[0], container_args); perror(\"exec\"); printf(\"Something's wrong!\\n\"); return 1;}int main(){ printf(\"Parent [%5d] - start a container!\\n\", getpid()); int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWUTS | CLONE_NEWIPC | CLONE_NEWPID | CLONE_NEWNS | SIGCHLD, NULL); waitpid(container_pid, NULL, 0); printf(\"Parent - container stopped!\\n\"); return 0;}资源使用限制Namespace解决的问题主要是环境隔离的问题，这只是虚拟化中最最基础的一步，我们还需要解决对计算机资源使用上的隔离。这就需要 ```Cgroup`` 技术。Linux CGroup全称Linux Control Group， 是Linux内核的一个功能，用来限制，控制与分离一个进程组群的资源（如CPU、内存、磁盘输入输出等）Linux 将 CGroup 实现成了一个file system，可以借助 mount 命令使用。子系统是CGroups中一个重要的概念，子系统可以理解为资源控制器，每种子系统就是一个资源的分配器，可以独立的控制一种资源。例如CPU子系统就是控制CPU分配的。每一个CGroup下面都有tasks文件，tasks文件中存储着属于当前控制组的所有进程的pid，如果用户需要控制Docker某个容器的资源占用情况，可以在Docker的控制组下面找到对应的子系统，并改变对应文件的内容。当然Docker提供了相应的指令在运行容器时由Docker进程去完成相应文件内容的变更；当我们关闭容器时，Docker子系统对应的文件夹会被Docker进程同步移除。目前Docker使用了以下几种子系统： 子系统 功能 blkio 可以为块设备设定I/O限制 cpu 可以控制任务对CPU的使用 cpuacct 记录CPU的使用情况 cpuset 为任务分配独立的CPU和内存 devices 开启或关闭对设备的访问 freezer 可以挂起或恢复任务 memory 可以设定任务对内存的使用上限，并自动记录内存资源使用情况 perf_event 可以进行统一的性能检测 net_cls 使用等级识别符classid标记网络数据包，允许 Linux 流量控制程序 tc 识别从具体 cgroup 中生成的数据包 net_prio 设计网络流量的优先级 Docker 容器网络通信原理前面已经提到过，docker 容器可以看做是一个被隔离的进程，可视为一个虚拟化的单机。那么这种虚拟化设备–单机，要想能够连通网络，则需要独立的网络栈设备（当然这也是虚拟的，需要借助物理机的一些真实设备来完成）： 网卡(Network Interface) 回环设备(Loopback Device) 路由表(Routing Table) iptables 规则有了这些虚拟设备之后，需要实现以下需求： 容器之间通信 容器与宿主机之间通信 容器与外部主机通信为实现这些需求，docker 主要提供了以下几种工具： network namspace：网络名称空间默认是相互隔离的 Linux bridge：虽为虚拟网络设备，但其工作方式非常类似于物理的网络交换机设备。 可以工作在二次，也可以工作在三层，默认工作在二层。 工作在二层时，可以在同一网络的不同主机间转发以太网报文，可以视为小的局域网 给 Linux Bridge 分配了 IP 地址之后，其就开启了三层工作模式 在 Linux 下，你可以用 proute2 工具包或 brctl 命令对其进行管理 Veth Pair 设备：它被创建出来后，总是以两张虚拟网卡（Veth Peer）的形式成对出现的。并且，从其中一个“网卡”发出的数据包，可以直接出现在与它对应的另一张“网 卡”上，哪怕这两个“网卡”在不同的 Network Namespace 里。 这两张网卡都与网桥连通着。网络模式 Host 模式docker不会为容器创建独有的network namespace；使用宿主机的默认网络命名空间，共享一个网络栈；表现为容器内和宿主机的IP一致；这种模式用于网络性能较高的场景，但安全隔离性相对差一些。 Bridge 模式桥接模式，有点类似 VM-NAT，dockerd 进程启动时会创建一个 docker0 网桥，容器内的数据通过这个网卡设备与宿主机进行数据传输。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。从 docker0 子网中分配一个 IP 给容器使用，并设置 docker0 的 IP 地址为容器的默认网关。在主机上创建一对虚拟网卡 veth pair 设备，Docker 将 veth pair 设备的一端放在新创建的容器中，并命名为 eth0（容器的网卡），另一端放在主机中，以 vethxxx 这样类似的名字命名，并将这个网络设备加入到 docker0 网桥中。bridge 模式是 docker 的默认网络模式，不写 –net 参数，就是 bridge 模式。使用 docker run -p 时，docker 实际是在 iptables 做了 DNAT 规则，实现端口转发功能。可以使用 iptables -vnL 查看。 docker 会为容器创建独有的 network namespace，也会为这个命名空间配置好虚拟网卡，路由，DNS，IP地址与iptables规则（也就是sandbox的内容）。 none 模式使用 none 模式，Docker 容器拥有自己的 Network Namespace，但是，并不为 Docker 容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。这种网络模式下容器只有 lo 回环网络，没有其他网卡。none 模式可以在容器创建时通过 –network=none 来指定。这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性。 joined-container 模式这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。这种模式是host模式的一种延伸。容器之间通信前面我们提到一个概念，把容器作为单机来看。其实不同容器之间的通信，类似于不同主机之间的通信。两台主机连接只需要一个网线即可；多台主机则需要多根网线实现，网线的一端连接主机，另一端连接在一台交换机上。在 Linux 中对应的虚拟设备是 docker0 是 docker 容器之间的网桥 Veth Pair 相当于网线，把容器连接到 docker0 网桥上容器中的虚拟网卡是一个 Veth Pair，它的一端在这个容器的 Network Namespace 里，另一端则位于宿主机上(Host Namespace)，这类似物理网线，网线汇集在了宿主机的 docker0 网桥上。一旦一张虚拟网卡被“插”在网桥上，它就会变成该网桥的“从设备”。从设备会被“剥夺”调用网络协议栈处理数据包的资格，从而“降级”成为网桥上的一个端口。而这个端口唯一的作用，就是接收流入的数据包，然后把这些数据包的“生杀大权”（比如转发或者丢弃），全部交给对应的网桥。 容器间通信的大致流程： 容器 A 首先查看自己的路由表，拿到连通容器 B 的那条路由（此路由一般经过本机的 eth0 网卡，通过二层网络直接发往目的主机，无需 gateway 转发便可以直接将数据包送达） 容器 A 向 B 绑定的 IP（路由中有 IP 信息）发起 ARP 请求，查询容器 B 的 mac 地址（要么从 arp cache 中找到，要么在 docker0 这个二层交换机中泛洪查询） 容器 A 把数据包发往容器 B 的 mac 地址（即 B 的虚拟网卡）即可。这可类比局域网中两台主机间的通信。实际上是直连网络，实质上是 docker0 在二层起到的作用。容器与宿主机之间通信容器与宿主机之间的通信类似容器之间的通信，只不过宿主机属于 Host Namespace，而容器属于各自的 Namespace。docker0 连通了 Host Namespace 和 容器的 Namespace 的，也就是充当着网桥的作用。因此宿主机通过 docker0（在 Host Namespace 中）抽象后相当于一个特殊的”容器“，其通信机制可以参考容器之间通信。容器与外网通信容器跨主机通信有多种方案，不论哪种方案都要确保： 处于外网中时，有自己或者自己组织的有效 IP 处于局域网中时，有自己独有的内网 IP 外网能识别的 IP 和 内网 IP 有映射关系以上几个条件都是为了数据包在主机内部能够有效转发，需要有有 IP 和端口。由于已经在主机内部，这里的 IP 和端口可以是虚拟的，不需要全网唯一，只要能够找到对应关系到达容器或应用程序即可。不过需要指出的是，这种容器与外网间的通信方式免不了会多转发几次，在网络性能上是有损耗的。在这种机制中，namespace命名空间起到了至关重要的作用，相当于主机内重用了 IP 和端口，从而不需要改变原有的基础设施。" }, { "title": "画图，简单到无法拒绝", "url": "/2022/05/text-draw-uml.html", "categories": "高效工具", "tags": "Tool", "date": "2022-05-17 22:58:19 +0800", "snippet": " 本文介绍一种通过文本代码来画常用图的方法，包括脑图、UML图、原型界面等。只需要一个链接就可以展示图、修改图、随时随地传送图等，可以消除常常忘记可编辑原图的文件在哪里、不便修改、图中内容不可复制、不可重定向等各种烦恼。 工具简介 想法落地流 图模板 使用方法 模板 脑图(思维导图) 工作分解图 ...", "content": " 本文介绍一种通过文本代码来画常用图的方法，包括脑图、UML图、原型界面等。只需要一个链接就可以展示图、修改图、随时随地传送图等，可以消除常常忘记可编辑原图的文件在哪里、不便修改、图中内容不可复制、不可重定向等各种烦恼。 工具简介 想法落地流 图模板 使用方法 模板 脑图(思维导图) 工作分解图 顺序图 用例图 类图 对象图 PERT 图 组件图 部署图 状态图 架构图 实体关系图 甘特图 网络图 线框图 时序图 活动图或流程图 辅助图像布局 一切皆在链接中工具简介画图的工具很多，不过我们经常会遭遇以下麻烦： 图片放大之后变得模糊 事后发现图片有错误想修改，取找不到对应的可编辑的文件。改动小还可以ps或者干脆重新画，图内容比较多且改动大就麻烦了。 分享或转移不方便。如果是远程地址的话，还可能被平台删除或者链接转移了，再也定位不到原来的图片。 图片中的文字无法拷贝 图片中的某个子图很难被重用，往往需要多次画类似的图，而不是拷贝过来稍微修改就能搞定。 图片的改动无法引入git等版本控制工具，无法随心所欲的快速回退到指定想要的里程碑版本。往往只能使用工具自带的撤销命令一次次撤销。 图片无法与其对应的工具合为一体，即图片是图片，工具是工具，无法从图片反推到所使用的工具及其对应的代码。 画图效率太低，不断选择画图组件按钮，鼠标拖来拖去，整体布局调来调去，太费时费力。 画图速度赶不上思维的速度如果你遇到了上面的麻烦，并且不止一次，更可气的是，这些麻烦还将不断地重复出现，挥之不去，隆重推荐你使用 plantuml 对应的 远程工具。想法落地流头脑中有某种想法或者事情需要理解、表达或者落实时，一般会经过以下几个过程： 头脑中酝酿或者“触景生情” 大脑中构思或大脑中对话或自言自语 纸上涂涂画画或罗列构图 思维导图发散或收敛思维 归纳出架构图或宏观概念图形成概念框架 从客户的视角对系统绘制用例图 绘制组件图对框架图进行初步细化，寻找已有的构件对架构进行搭积木式地实现 对还没有的组件借助类图进行实体结构化分解 对某些特定时刻的结构状态通过对象图进行具象化 对某个具有复杂状态的对象通过状态图给出有限状态机 对某些需要存储或落盘的状态信息通过实体关系图映射成多层二维关系，以便存储和检索 对有工作量的各个项目通过工作分解图进行分解 工作分解后通过甘特图展示工作排期 通过PERT图识别出关键逻辑或者风险点 具体开发实现时可以通过活动图和顺序图识别出数据流和控制流，在具体实现的过程中用到嵌入式硬件的可能还需要时序图 软件或逻辑上的可靠性通过部署图落实到硬件或现实上的可靠性。部署的过程中可能需要用到网络图对网络进行规划。需要指出的是，上述落地流并不是每个项目或想法都需要其中的所有步骤，也不需要严格按照以上先后顺序来完成。你可以跳过某些步骤或调整某些步骤的顺序，甚至并行某些步骤、合并其中的某些步骤、或者再细化某些步骤等。图模板使用方法plantuml 是一个用文本就可以画各种图的开源工具，详细介绍可参考前面提供的网址。为了帮助大家快速使用起来，并且达到能够应付绝大数使用场景，本文将提供各种实用模板。你只要复制粘贴到远程工具适当修改即可。至于其他非常个性化的需求可参考这个网站自行搜寻。模板这里为大家准备了各种常用图的模板，根绝自己的需要选择即可。如果你不知道自己的想法适合用那种图表现出来，快速浏览一下本文的各种模板对应的图形之后，或许就有了答案。看看例图和对该图的基本用途的描述大概就可以知道此时此刻你需要那种图了。然后结合上述“使用方法”这一节即可呈现效果。脑图(思维导图)思维导图主要用于发散思维，以某个中心论题进行发散分解。当你想解决一个问题却无从下手时，可以试试思维导图随性的先画起来，想到什么就画什么，然后逐步横向展开和纵向分层延伸，层层深入，直到脉络较为清晰为止。一次性完成不了也没关系，想起来就追加上去就行。其灵活性可见一斑。样例代码可点击这里，效果见下图。工作分解图工作分解图的语法和脑图非常类似，只是比脑图多了一个限制：不支持多中心节点。另一方面，与脑图再外观上的区别是：布局从上往下，连线也随之不同。与脑图样例对应的工作分解图为 样例1，样例2，相应的图如下：顺序图顺序图用于展示各个相关对象交互（请求与响应，即消息传递与应答）的先后顺序。 顺序图的作用 描述对象之间依赖关系的动态转换时序 展示对象之间的数据流或消息流 顺序图为一种动态建模方法，可弥补静态建模的不足在顺序图中流动的消息有以下三种： 简单消息：实线+常规箭头表示。是从一个对象到另一个对象的控制流的转移。 异步消息：实线+一半的箭头。消息发出了以后，发送对象不必等到接收对象的应答，就可以继续自己的操作。 同步消息：实线+实心三角形表示。消息发出了以后，发送对象必须等到接收对象的应答，才能继续自己的操作。顺序图的样例代码可点击这里，效果图如下：用例图用例图描述了系统外的参与者与系统内的功能模块（用例）之间的交互关系，是外部用户（被称为参与者）所能观察到的系统功能的模型图。用例图的主要目的是帮助开发团队以一种可视化的方式理解系统的功能需求。这简单道出了几个要素： 外部用户视角（不用关心系统内部是如何完成各种功能的） 参与者（外部用户） 用例（系统功能）：系统功能可以认为是产品需求适当分解之后的产物。应根据需要控制系统功能的划分粒度 参与者与用例之间的交互关系 系统边界源代码样例，效果图如下：类图类图用于描述各个概念实体的性质和具有的行为特征，以及各个概念实体之间的静态结构关系和逻辑归属。这些关系包括： 继承关系 实现关系 依赖关系 关联关系 聚合关系 组合关系类图的源代码样例，效果图如下：对象图对象图可以看成是类图的某一时刻的具体状态变迁（属性值和行为上的变化）。对象图是类图的具体化，侧重在属性值经过行为方法的作用发生的变化，即对象图是类图的某个类的某个状态（即对象）经过其行为（类中的方法）或受到其他类的某个行为的影响而产生的状态（属性值）变化。对象图与类图的绘制极其类似，有区别的地方有下面几个： 类图中的某些绘图特性是无法用到对象图 绘图的关键字不同：类图中的类使用 class 声明，对象图中的对象使用 object 声明 具体化程度不同：类图中的成员变量和函数可以看做是一种声明；对象图中的变量和函数是需要赋予具体的值，某些部分需要关注值的变化过程。在全局变量赋值时需要用到map对全局数组或映射关系进行描述。 一个类可以同时存在多个对象，这些对象之间也可以存在某种关联。源代码样例，效果图如下：PERT 图PERT(Program Evaluation and Review Technique)即计划评估和审查技术PERT图的优点在于，可以让项目负责人更明确工作重点，聚焦于可能需要采取纠正措施的关键问题上，使控制工作更加有效。当然，它也有局限性，需要事前对项目的工作（包括每个独立的活动）进行较准确的描述和预估（所需时间、资源等源代码样例，效果图如下：组件图组件一般提供了一组接口或通讯协议，只要满足了这些接口或通讯协议就可以为其他系统所用。组件可独立于某个具体的系统而存在，可单独运行，当然系统中所用到的某个组件也可以用其他更优的类似组件替换。可见，组件摆脱了具体实现或具体语言等的束缚，具有更强的跨系统的可重用特性。组件图主要强调系统的逻辑实现。组件图的源代码样例，效果图如下：部署图部署图描述了一个系统运行时的硬件或软件组件处理节点的物理分布和部署及通信方式的静态视图。部署图主要强调系统的物理实现，从物理层面保障系统的可用性、可靠性、稳定性和安全性。源代码样例，效果图如下：状态图状态图用来描述某个对象在其生命周期中的所有可能状态及其触发事件。通常用于表示单个对象在其生命周期中行为。源代码样例，效果图如下：架构图架构有很多种，比如组织架构和软件架构（产品架构，业务架构，系统架构，技术架构，模型架构，数据架构）等。软件架构指的是软件系统的顶层设计（Rank），它定义了系统由哪些角色（Role）组成，角色之间的关系（Relation）和运作规则（Rule）。架构也可以简单理解为系统需要用到哪些积木、积木如何配合进行系统构造。分层架构图建议用 PPT 的各种形状加文本框完成，也可以使用工具Visio和diagrams等，因为其兼简单美观和灵活性为一体。当然也可以用本文介绍的 plantuml 完成，不过比较复杂，具体见样例1，样例2，效果图如下：更复杂的架构图有样例，效果图如下：实体关系图实体关系图通过具有属性的实体间的驱动（用动词描述）和数量关系来对现实世界建立信息概念模型。源代码样例，效果图如下：甘特图甘特图描述的是项目或活动的起止时间、项目之间在时间上的关系以及项目的进度情况。借助甘特图可以发现正在并行做的项目集、整个大项目的起止时间、项目的时间人员资源的调配情况、项目进度的风险点等。源代码样例，效果图如下：网络图源代码样例，效果图如下：线框图这种图主要是在画UI图的初期用到，用于产品和开发确认UI的原型，因使用场景比较窄且复杂，这里就不给出样例了。感兴趣的伙伴可以自行参考这里。时序图玩过单片机控制的同学应该对时序图还有印象。这里有个样例，效果图如下：活动图或流程图活动图描述的是一个活动到另一个活动之间的控制流。通过控制流来表征活动间的约束关系。有利于识别并行活动。强调对象间的控制流程，活动图在本质上是一种能支持并发行为的流程图。源代码样例，效果图如下：辅助图像布局plantuml 不建议刻意地去控制图像的布局，不过你还是可以通过以下手段调整布局： 改变某些图形的声明顺序，改变图形分布的相对位置 改变箭头的方向(up/down/left/right)，改变箭头两端的图形相对位置 用虚拟箭头(up/down/left/right)把没有关系的元素串起来（所谓虚拟箭头，就是带方向但是箭头颜色和背景一致）。 改变箭头连线的长度（如 ———&gt;） 改变图形的尺寸或间距 通过隐藏箭头(hidden)把某些图形按某个方向排列在一起 通过package等把多个图形捆绑在一起作为一个整体来布局，改变参与布局的图形粒度 通过 left to right direction 或者 up to down direction 来控制整体布局，改变画布的延展方向建议在画图完成之前不要使用辅助图像布局，先充分展现其自动布局。虽然在图像布局上可以有不小的作为，但不要过于追求图像规整布局。如果你有图像布局规整的洁癖，建议你还是用那些可以借助鼠标拖放的画图工具。一切皆在链接中plantuml 在线画图工具中，画图的源代码、各种格式的图像都可以在链接（URL）里获取到。这就意味着只要有这个链接，任何人都可以修改图像并且输出一个新的链接指向新的已修改过的图像。同时也意味着，只要你找不到这个链接，那么源代码和修改对应图像的可能性也一起丢失了。因此，建议使用链接地址去分享或展示你的图像，而不是下载图像文件。在线画图工具没有自动补全或语法高亮或格式化，不是很友好。建议你使用线下工具先把源代码写好，然后再粘贴到在线工具得到URL。 不要执迷某种工具需要指出的是，不要执迷某种工具，重要的是把你的思想或目标可视化。你不仅可以用本文的工具，还可以： 头脑中绘图或“放电影” 纸上、白板或电子绘板等手工绘图 具有画面感的文字，如类比熟悉的事物 其他任何绘图软件或具有绘图模块的软件 其他类似的图形或者自创图形集" }, { "title": "git 高手跃迁", "url": "/2022/04/git-jump.html", "categories": "高效工具", "tags": "Tool", "date": "2022-04-03 19:11:48 +0800", "snippet": " 本文试图从应用和原理及设计层层多角度探究 git，帮助读者相对全面透彻的理解 git，并能随心所欲高效地使用 git 俯视 git 基本流程 基本概念 应用层面的概念 底层概念 git 存储快照是不是很低效 图解 git 的概念关系设计 ...", "content": " 本文试图从应用和原理及设计层层多角度探究 git，帮助读者相对全面透彻的理解 git，并能随心所欲高效地使用 git 俯视 git 基本流程 基本概念 应用层面的概念 底层概念 git 存储快照是不是很低效 图解 git 的概念关系设计 git 命令及其使用场景 各区穿梭 改变文件状态 分支管理 分支互操作 打补丁 commit 整理 查看分支列表 差异比较 commit 前比较 commit 后比较 不同分支间比较 不同仓库间比较 工具 查看或搜索提交历史 后悔药 git 操作原则 俯视 git本节将从应用中涉及到的顶层概念到底层实现原理，深入浅出地呈现 git 的蓝图。基本流程基本概念概念是设计的很重要的元素和精简描述，因此我们将从基本概念入手窥探 git 的顶层设计思想。同时，了解了基本概念之后，能够更好地利用搜索引擎查找所需的命令。同时也有助于我们理解上面的基本流程图。应用层面的概念在用户使用git时都会涉及到以下这些应用层面的概念。这些概念往往会体现在常用的 git 命令的应用中。 工作区(workspace)：正常情况下能看到的目录(不包括隐藏文件，如同级目录下的 .git 隐藏目录),也就是用户主动创建的目录，如通过系统命令 ls 或者文件管理器能够看到的目录。 暂存区(stage/index)： 工作区下的隐藏 .git 目录下的 index 文件（每个git仓库只有一个）, 因此也称为索引。 数据暂时存放的区域，类似于工作区写入版本库前的缓存区。 暂存区是独立于各个分支的。 实际上就是一个包含文件索引的目录树，像是一个虚拟的工作区。在这个虚拟工作区的目录树中，记录了文件名、文件的状态信息（时间戳、文件长度等），文件的内容并不存储其中，而是保存在 git 对象库（.git/objects）中，文件索引建立了文件和对象库中对象实体之间的对应关系。git 通过文件状态信息可以很高效地知道哪些文件改变了。 版本库(Repository)：也称为本地仓库。 在工作区中有一个隐藏文件 .git ，它不属于工作区，而是 git 版本库。 .git 目录下包括很多其他文件，其中重要的是暂存区（.git/index）、对象库（.git/objects）、分支（master 分支和其他分支）、指向当前分支的指针 HEAD 远程仓库(Remote）：相对于本地仓库而言，该仓库在远程，两者可以认为是各自的备份（但内容不一定时刻一致） Commit objects 节点：每次提交都会产生一个节点，相关信息存储在对象库 heads：head 就是指向一个节点的索引。每个 head 都有自己的名字。默认情况下，每个 Repository 都有一个叫做 master 的 head。一个Repository 可以有很多 heads（一个分支一个，位于.git/refs/heads）。在任何时刻，只有一个 head 被当做“当前head”（当前分支）。这个 head 一般用大写字母 HEAD 表示（.git/HEAD）。HEAD 指向当前分支的最新的一次提交。 分支：和 “head” 几乎是同义词 一条 commit objects 节点的链条，链头（head）被命名为分支名（指向该分支的最新节点） 各个分支可以有相同的节点，而所有分支的所有节点信息都存储在对象库中 每一个分支都有一个head，每一个head都代表一个分支 Repository 是一棵树（也称为树对象，不同分支共用相同的节点，即一个节点可能在多条链上），“分支” 用来表示以 head 为叶子节点的所有祖先节点的序列，而 “head” 仅仅表示 head 所指向的那一个节点，即分支中最近被提交的节点 git 目录结构这里只是粗略的标注一下各个文件夹的作用。如果想得到更为详细地官方解读，可在终端输入 git help gitrepository-layout .git/ ├── COMMIT_EDITMSG # 记录最近一次提交的 commit 编辑信息 ├── config # 项目的配置信息，git config命令会改动它 ├── description # 项目的描述信息 ├── HEAD # 当前分支 ├── hooks # 系统默认钩子脚本目录 │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── prepare-commit-msg.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ └── update.sample ├── index # 索引文件(暂存区), 二进制文件 ├── info │ └── exclude ├── logs # 各个refs的历史信息, 保存所有更新的引用记录 │ ├── HEAD │ └── refs │ ├── heads │ │ ├── dev │ │ └── master │ └── remotes │ └── origin │ └── master ├── objects # 可以视为 git 数据库; Git本地仓库的所有对象(commits, trees, blobs, tags) │ ├── 2d │ │ └── d2c71b69c837a7459f4bd9c9f7db6520731d06 │ ├── 5c │ │ └── 7b8eda18a75e13d27c31e65a54b0abd7948510 │ ├── 77 │ │ └── cad3aecf7c2754231095598119979d62a1e1da │ ├── info │ └── pack └── refs # 标识你项目里的每个分支指向了哪个提交(commit) ├── heads # 目录有以各个本地分支名命名的文件，保存对应分支最新提交的ID │ ├── dev │ └── master ├── remotes # 目录有以各个远程分支名命名的文件，保存对应分支最新提交的ID │ └── origin │ └── master └── tags # 存储在开发过程中打的标签，里面的文件以标签名命令，文件内容为对应的ID git 文件状态机文件状态涉及到的的概念： 未跟踪：就是新创建的文件没添加过一次，没有之前的快照记录 已跟踪：个新创建的文件进行第一次git的添加，这样文件就有了快照记录后，这文件就转变成已跟踪状态了 已修改状态：如果从远程仓库取出Git目录后，作了修改但还没有放到暂存区域，就是已修改状态 暂存状态：如果对Git目录作了修改并已放入暂存区域，就属于已暂存状态 提交状态：如果是 Git 目录中保存着的特定版本文件，也就是说将暂存区的文件提交到仓库中，就属于已提交状态 (git commit)。底层概念相对于应用层概念而言，大部分 git 用户是很少遇到底层概念。底层概念与git的内部实现紧密相关，也映射出一套较为底层的命令。因此，要想理解git的底层原理，就很难避开这些底层概念。对象库(.git/object)有四种类型：块（blob）、目录树(tree)、提交(commit)、标签(tag)。这四种原子对象构成了 git 高层数据结构的基础。 blob(块对象)：在add操作后生成, blob 对象存储文件的时间内容，实际为工作空间的文件内容。具体为对文件内容使用zlib算法压缩，然后对得到的字节取hash算法。因此相同的文件内容，得到的blob对象肯定是相同的 tree(树对象)：在commit操作后生成, git目录树对象映射操作系统中工作空间的目录，不同的是工作空间的目录下是文件和文件夹的集合，而目录树对象则为blob对象和目录树对象的集合。 commit对象：一次提交即为当前版本的一个快照，该快照就是通过提交对象保存，其存储的内容为：一个顶级树对象、上一次提交的对像啥希、提交者用户名及邮箱、提交时间戳、提交评论。Git对象库被组织及实现成一个内容寻址的存储系统。具体而言，对象库中的每个对象都有一个唯一的名称，这个名称是向对象的内容应用SHA1得到的SHA1散列值。因为一个对象的完整内容决定了这个散列值，并且认为这个散列值能有效并唯一地对应特定的内容，所以SHA1散列值用来做对象数据库中对象的名字和索引是完全充分的。文件的任何微小变化都会导致SHA1散列值的改变，使得文件的新版本被单独编入索引SHA散列计算的一个重要特性是不管内容在哪里，它对同样的内容始终产生同样的ID。换言之，在不同目录里甚至不同机器中的相同文件内容产生的SHA1哈希ID是完全相同的。因此，文件的SHA1散列ID是一种有效的全局唯一标识符如果两个文件的内容完全一样，无论是否在相同的目录，Git在对象库里只保存一份blob形式的内容副本。Git仅根据文件内容来计算每一个文件的散列码，如果文件有相同的SHA1值，它们的内容就是相同的，然后将这个blob对象放到对象库里，并以SHA1值作为索引。项目中的这两个文件，不管它们在用户的目录结构中处于什么位置，都使用那个相同的对象指代其内容。如果这些文件中的一个发生了变化，Git会为它计算一个新的SHA1值，识别出它现在是一个不同的blob对象，然后把这个新的blob加到对象库里。原来的blob在对象库里保持不变，为没有变化的文件所使用。当文件从一个版本变到下一个版本的时候，Git的内部数据库有效地存储每个文件的每个版本，而不是它们的差异。因为Git使用一个文件的全部内容的散列值作为文件名，所以它必须对每个文件的完整副本进行操作。Git不能将工作或者对象库条目建立在文件内容的一部分或者文件的两个版本之间的差异上。随着时间的推移，所有信息在对象库中会变化和增长，项目的编辑、添加和删除都会被跟踪和建模。为了有效地利用磁盘空间和网络带宽，git 把对象压缩并存储在打包文件（pack file）里，这些文件也在对象库里。另外，还有两个比较重要但不在对象库中的概念： 标签(tag)：一个标签对象分配一个任意的且人类可读的名字给一个特定对象，通常是一个提交对象 索引：索引是一个临时的、动态的二进制文件，它描述整个版本库的目录结构。更具体地说，索引捕获项目在某个时刻的整体结构的一个版本。项目的状态可以用一个提交和一棵目录树表示，它可以来自项目历史中的任意时刻，或者它可以是你正在开发的未来状态。Git的关键特色之一就是它允许你用有条理的、定义好的步骤来改变索引的内容。索引使得开发的推进与提交的变更之间能够分离开来。作为开发人员，你通过执行Git命令在索引中暂存（stage）变更。变更通常是添加、删除或者编辑某个文件或某些文件。索引会记录和保存那些变更，保障它们的安全直到你准备好提交了。还可以删除或替换索引中的变更。因此，索引支持一个由你主导的从复杂的版本库状态到一个可推测的更好状态的逐步过渡。引在合并（merge），允许管理、检查和同时操作同一个文件的多个版本中起到的重要作用 底层命令这里列出几个底层命令协助大家理解git的底层原理，具体使用方法请自行参阅其他资料。 git hash-object -w fileName：用来创建一个新的数据对象并将其手动存储到新的Git数据库中 git cat-file -p hash-object-id：读取git对象内容 git cat-file -t hash-object-id：读取git对象类型 git cat-file -p master^{tree}：查看树对象 git ls-files -s：查看暂存区内容 构建树对象： git update-index git write-tree git read-tree git commit-tree：创建commit对象git 存储快照是不是很低效一个聪明的读者也许已经有了关于Git的数据模型及其单独文件存储的挥之不去的问题：直接存储每个文件每个版本的完整内容是否太低效率了？即使它是压缩的，把相同文件的不同版本的全部内容都存储的效率是否太低了？’如果你只添加一行到文件里，Git是不是要存储两个版本的全部内容？幸运的是，答案是“不是，不完全是！”相反，Git使用了一种叫做 打包文件（pack file） 的更有效的存储机制。要创建一个打包文件，Git首先定位内容非常相似的全部文件，然后为它们之一存储整个内容。之后计算相似文件之间的差异并且只存储差异。例如，如果你只是更改或者添加文件中的一行，Git可能会存储新版本的全部内容，然后记录那一行更改作为差异，并存储在包里。存储一个文件的整个版本并存储用来构造其他版本的相似文件的差异并不是一个新伎俩。这个机制已经被其他VCS（如RCS）用了好几十年了，它们的方法本质上是相同的。然而，Git文件打包得非常巧妙。因为Git是由内容驱动的，所以它并不真正关心它计算出来的两个文件之间的差异是否属于同一个文件的两个版本。这就是说，Git可以在版本库里的任何地方取出两个文件并计算差异，只要它认为它们足够相似来产生良好的数据压缩。因此，Git有一套相当复杂的算法来定位和匹配版本库中潜在的全局候选差异。此外，Git可以构造一系列差异文件，从一个文件的一个版本到第二个，第三个，等等。Git还维护打包文件表示中每个完整文件（包括完整内容的文件和通过差异重建出来的文件）的原始blob的SHA1值。这给定位包内对象的索引机制提供了基础。打包文件跟对象库中其他对象存储在一起。它们也用于网络中版本库的高效数据传输。图解 git 的概念关系设计git 中各个概念之间的联系或状态变迁都是通过命令（高层或底层命令）产生的，这样可以灵活组合而不乏清晰。 一次提交过程一次提交过程有以下子过程： 初始提交（即本次提交的上一次提交） 编辑文件 提交（相对于初始提交而言可称为二次提交）文件f1没有修改，在此过程后，它的blob哈希没有改变；文件f2修改内容，在此过程后文件为f22，它的blob哈希发生改变，如图：git 命令及其使用场景git 命令很多，一定要善用搜索和 git 帮助文档，可以通过 git help 命令动词 来获得帮助，比如 git help pull。如果连命令动词都不记得的话，可以使用git help -a列出所有关键字。当执行一个命令或者打错了命令，git 都会有智能提示，根据提示操作一般都会得到解决。提示的内容一般会有以下类型： 下一步操作（即继续执行） 相反操作（即反悔）需要指出的是，本章不会穷尽git命令，而是根据常用的场景来组织命令集。详尽的命令可以自行参考git的帮助文档。各区穿梭git 可以区化为：工作区、暂存区、堆栈、本地版本库、远程副本和远程仓库等。下图收集的命令可以帮助你在各大区中任意穿梭。改变文件状态这里的文件包括单个文件或多个文件、目录。因此下面的命令都省略了所要操作的文件名或目录名列表。 未跟踪到已跟踪的命令有： git add fileName 已跟踪到未跟踪的命令有： git rm（要反悔可以按提示操作，比如 git restore） 暂存修改：git add fileName 撤销暂存（保留暂存区和工作区中相同文件的新修改）： 少量文件推荐：git restore –staged fileName git reset – fileName 撤销大量暂存文件推荐：git reset – git rm –cached fileName 撤销工作区的修改（但会保留暂存区中的修改）：git checkout [–] fileName【注意】从以上各命令的相似性和危险性来看，容易混淆容易出错，为安全起见，应遵守以下安全规则： 在 git 仓库不要使用 rm，而是尽量使用 git rm 在操作之前尽量使用 git stash save \"note 一下\" 保留已经跟踪的文件（包括工作区和暂存区中的文件）分支管理一般一个git仓库都会根据不同的需要或者不同的开发人员都会创建多个分支，这就少不了分支间的互操作。当处于某个特定分支时，我们经常有整理提交链条的需求。这一节我们一起来探讨一下。分支互操作所谓分支互操作，就是两个或两个以上分支之间的切换或复制及合并等操作。 merge 参数（分支合并）merge 之后发生冲突时推荐使用开源工具lazygit来解决冲突。在merge发生冲突时在对应仓库下终端输入 lazygit 即可，详细用法请参考相应文档。 git merge --squash branchName -m \"更清爽的提交\": 把branchName中特有的所有提交合并为一次待提交状态（其中所有的commit描述信息都会被丢弃，但代码都不会少）。 git merge --no-ff branchName -m \"merge branchName with --no-ff\": 保留branchName中的独有的提交链条，可以清楚地看到合并的来源；一般配合rebase使用会使合并的提交链条更笔直清爽。比如要把dev分支合并到mater分支，可以： git rebase master git merge –no-ff dev -m “merge dev with –no-ff” git merge [--ff] branchName: git在合并两个没有分叉的分支时的默认行为(特别是在 git rebase branchName 之后使用该合并策略会没有分叉，无法判断这些合并过来的commit来自哪个分支，特别是这个分支被删除后)。保留分支提交记录，但没有像–no-ff那样的总结性的一次提交记录。 rebase 分支图解使用rebase命令的黄金法则就是：不要在公共分支中使用。否则会给其他开发的同学带来很多并且很难解决的冲突。 merge 和 rebase 的区别图解 分支切换或更新交互 git branch –set-upstream-to=origin/远程分支名 本地分支名: 将本地分支和远程分支关联 git checkout -b 本地分支名 origin/远程分支名: 从远程仓库里拉取一条本地不存在的分支（如果无法识别，则需要先执行 git fetch origin/远程分支名） git checkout -b 分支名 [commitID]：基于当前分支或某个commitID创建一个新分支，并切换到新分支 git checkout 分支名：切换分支 git pull 远程仓库地址 本地指定分支:远程指定分支：拉取远程指定仓库指定分支到本地指定分支 git pull origin 远程分支或者git pull：从远程分支更新本地分支 git push 远程仓库地址 本地指定分支:远程指定分支：将本地指定分支推送到远程指定仓库指定分支 git push origin 远程分支 或者 git push：从本地分支更新远程分支 git branch -d 分支 或强制 git branch -D 本地分支：删除本地分支 git push origin :远程分支 或者 git push origin --delete 远程分支名：删除远程分支 git branch -r -d origin/branchName：删除远程分支 git fetch origin 远程分支名 &amp;&amp; git reset --hard origin/远程分支名 &amp;&amp; git pull origin 远程分支名：远程强行覆盖本地代码打补丁只是想应用某个分支的某些文件的修改，而不是全部，则可以使用打补丁的方式在提示中合并应用部分代码。 合并部分文件这里假设要把分支 test1_branch 中的 test_file.txt 合并到分支 master 中的相应文件，则可以： git checkout master git checkout --patch test1_branch test_file.txt 然后根据提示一步步操作即可 分支打补丁正常情况下，对于本地分支，我们可以直接 git merge 就行，然后提交就行。但是，在有些情况下需要代码审核通过之后才能提交，或者对于某个分支你没有提交权限，此时就需要把补丁文件发送给有权限操作的人去使用这些补丁。假设你在 fix_branch 分支中 commit 了多次，和 master 分支存在了多个不同的地方，那么，可以通过以下流程对 master 打补丁，以应用fix_branch 中的修改。 git checkout fix_branch git format-patch -M master 然后在终端 ls 一下就可以看到 patch 文件（每次提交会生成一个补丁文件） 把这些补丁文件复制到其他地方或者打包发邮件给打补丁的人生成好了补丁之后，就可以打补丁了。 git checkout master git apply --reject 所有的补丁文件（可以使用通配符） 如果有冲突，就根据生成的 rej 文件手动解决冲突，然后删掉相应的 rej 文件 解决好所有冲突之后，使用 git add 应用修改 最后使用 git am --resolved 告诉 git 打补丁结束commit 整理在特定分支中，可以通过相关命令重组或修剪commit链条，包括合并多个commit为一个、删除某次提交的内容等操作。需要注意的是： 不能在公共分支中进行 在操作之前先创建一个分支作为备份，然后在原来的分支中进行操作 操作完之后要和用于备份的分支进行diff对比，确保结果符合预期 修改 commit 信息 git commit --amend -m 'new commit message': 修改最近一次提交的备注信息 git rebase -i commitID: 此时会打开编辑器，在想修改的commit信息所在行的行首，把pick改成r，保存退出。之后会跳出编辑框，然后输入新的commit信息保存，按提示继续操作即可。 整理 commit 节点 git rebase -i commitID: 根据编辑框的提示和自身需求对相应的commit所在行的行首词进行修改。 p, pick = use commit # 保留这个 commit r, reword = use commit, but edit the commit message # 修改 message message e, edit = use commit, but stop for amending # 停下来，修改内容 s, squash = use commit, but meld into previous commit # 合并 f, fixup = like “squash”, but discard this commit’s log message # 合并且抛弃 message d, drop = remove commit # 抛弃这个 commit 调整commit的时间先后顺序：只要调换行顺序即可，不建议这样做，因为会导致时间错乱。 git reset --soft commitID: 把其中的commit信息都去掉，但文件内容会保留在暂存区。此时你可以： git commit -m “提交信息”: 作为一个提交，并且赋予新的提交信息 git restore –stage fileOrFold: 把部分文件放回工作区，分几次提交 git reset --hard commitID: 直接重置到该commitID，丢弃最近到commitID的所有提交 git revert commitID：撤销某次指定提交，原来的提交记录还在，只是当前代码已经不包含已被车撤销的提交。一般用于公共分支 里程碑或打 tag，更友好的描述信息对于已经完成一个大的版本或者里程碑，需要定格时，在不想或不便于新建分支的情况下，可以打 tag。 git tag -a tagName -m “描述一下”：建立本地标签 git push origin tagName：提送到远程仓库（也可以通过 git push origin --tags 把所有的标签都推送）其他常用的 tag 操作： git tag：列出本地当前分支的所有 tag git tag -l v1.0.\\*：通过通配符显示特定的 tag git show tagName：显示标签的详细信息 git tag -d tagName：本地删除标签 tagName git push origin :refs/tags/tagName：删除远程 tag（应在删除本地 tag 之后） git push origin --delete tag tagName：删除远程 tag查看分支列表 git branch: 查看本地分支列表 git branch --merged：已经合并到当前分支的分支 git branch --no-merged：还没有合并到当前分支的分支 git branch -a: 查看所有分支列表，包括远程和本地差异比较在提交前或合并前最好先知道你到底改了些什么，是否符合预期，这样可以达到二次检查的目的。commit 前比较提交前确认一下这次到底改了些什么之后再提交会安心很多！ git status：显示修改过的文件列表 git diff：未 add 时的文件变化情况（命令后可接具体的文件等） git diff --cached/--stage：在 add 之后 commit 之前文件变化情况（命令后可接具体的文件等） git diff HEAD：在 commit 前文件变化情况（前两条命令和合并）以上命令都可以指定版本、分支或具体文件，以聚焦自己感兴趣的内容commit 后比较要想知道最近一次或某次历史提交修改的具体内容，可以使用 git log 或 git diff 等命令。 git log：提交的历史记录 git log --oneline：简化 log 显示 git log --stat：输出 log 的统计信息 git log -p：输出修改的具体内容 git log --author=作者：指定显示某个作者的提交记录 git diff 版本1 版本2：列出相同分支两个版本之间的差异，这个在 rebase 多个提交时可以提供参考 git blame 文件：追踪是谁改了哪些代码以上命令都可以指定版本或具体文件，以聚焦自己感兴趣的内容不同分支间比较我们在基于某个分支新建了一个分支作为开发或bug修复，在合并或提交前往往想知道改了些什么，是否符合预期。 git log --left-right dev...master：查看两个分支提交记录的不同处，主要用于合并分支前 git diff 分支1 分支2：列出两个分支最近不同的详细信息 git diff 分支1...分支2：列出两个分支所有不同的详细信息 git diff 分支1 分支2 --stat：列出两个分支的不同点的统计信息不同仓库间比较只要两个仓库都是git仓库，两个不同的仓库也是可以比对差异的，常用的是git diff 命令，详细参考前面的章节。这种场景主要用于某个仓库是由另一个仓库衍生发展而来的情况。工具如果你只想使用 git 自带的工具，可以 git diff --word-diff 或者 git diff --color-words。至于 diff 工具本人推荐使用开源工具 dandavison/delta，其中.gitconfig 配置如下。事实上，该工具对 git log 也有更友好的显示方式。[core] pager = delta[interactive] diffFilter = delta --color-only[delta] navigate = true # use n and N to move between diff sections side-by-side = true commit-decoration-style = none dark = true file-added-label = [+] file-copied-label = [C] file-decoration-style = none file-modified-label = [M] file-removed-label = [-] file-renamed-label = [R] file-style = 232 bold 184 hunk-header-decoration-style = none hunk-header-file-style = \"#999999\" hunk-header-line-number-style = bold \"#03a4ff\" hunk-header-style = file line-number syntax line-numbers = true line-numbers-left-style = black line-numbers-minus-style = \"#B10036\" line-numbers-plus-style = \"#03a4ff\" line-numbers-right-style = black line-numbers-zero-style = \"#999999\" minus-emph-style = syntax bold \"#780000\" minus-style = syntax \"#400000\" plus-emph-style = syntax bold \"#007800\" plus-style = syntax \"#004000\" whitespace-error-style = \"#280050\" reverse zero-style = syntax syntax-theme = Nord[merge] conflictstyle = diff3[diff] colorMoved = default查看或搜索提交历史好的 commit 描述和拆分合并策略有助于 git log 的展示，同时帮助了解代码的时间线。一般遵循以下原则： 外部库引入或者依赖包更新等单独作为一次提交 自身业务代码，按相对完整的功能进行提交，便于功能增删或回滚 bug 修复和性能优化等不同目的和性质的更新要分开提交 log 的各种参数log 查看工具推荐开源工具vim-flog，常用命令Flog -all。 详细的提交信息：git log [-n] [branchName] [fileOrFold1] [fileOrFold2] 其中 n 指的是你感兴趣的 log 条数 查看提交的统计信息：git log --stat ，这包括了更新的文件列表 单行显示：git log --oneline ，这会缩写 commitID ASCII 图形显示：git log --graph ，本人更喜欢用 vim 插件，相对而言更友好。 只显示某个人的提交：git log –anthor=oneName 使用 grep：git log –grep=”要匹配的串” 查看包含特定字符串的提交：git log [-i] [-p] -S\"function login()\" 根据是否merge来过滤提交历史：git log --merges 或者 git log --no-merges 显示某段时间内的提交：git log --since=2.weeks后悔药只要是已经被git跟踪的文件，一般都会有后悔药（即撤销、回滚操作）。 add 之前丢弃修改：git checkout -- fileOrFold ，如果想再次找回这些修改，则无能为力了。因此，最好操作前做好备份。 add 之后，commit 之前：git reset HEAD fileOrFold 或者 git restore --staged fileOrFold commit 之后，push 之前： git reset --soft HEAD^ 或者 git reset HEAD^ 或者 git reset --hard HEAD^ 或者 git revert HEAD 它们的区别或者其他方法请参考“整理 commit 节点”一节 rebase 过程中撤销本次 rebase：git rebase --abort merge 过程中撤销： git merge --abort rebase 或者 merge 成功之后撤销： git reflog 找到操作前的 commitID git reset --hard commitID 修改了代码，git add 之后发现分支搞错了，必须切换分支，可以： git stash save \"note 一下\" ，暂时把修改保留到堆栈区 git checkout branchName，切换到目的分支 git stash apply stash@{0}，如果不知道是哪一个，可以用 git stash list 查看列表 代码提交了，才发现搞错了分支（原分支 branch1，目的分支 branch2），可以： git checkout branch2 git log branch1 查出 commtiID git cherry-pick commitID 此时提交已经落到该去的分支了 git checkout branch1 git reset --hard HEAD^ 此时在错误的分支中删掉了不需要的最近提交 不小心把还未push的分支删除了： git log -g 或者 git reflog 找出被误删分支的最近一次提交的 commitID git checkout -b 误删分支名 commitID git 操作原则有了这篇文章的帮助，我想你已经对git有了非常全面和深刻的理解，内心开始飘了，有了随心所欲地冲动。经验告诉我，此时是你冒险犯大错的开始！最疯狂之时，也就是毁灭之时。为此，我为你准备了以下心法，帮助你克服自大的心理，尽量养成低风险的操作习惯： 在做任何操作之前请做好备份 commit 尽量直观，言简意赅 常用 git stash 常建备份分支 常打tag 任意操作之后要做 diff，明确改动 尽量少在公共分支操作，尽量保留合并记录 不要过分依赖“后悔药” 不要手动或用脚本操作 .git 隐藏目录你不知道的东西远远多于你知道的，谦虚不是客套话，而是客观需要" }, { "title": "leetCode 题解", "url": "/2021/12/leetcode.html", "categories": "算法", "tags": "Algorithm", "date": "2021-12-15 01:40:08 +0800", "snippet": " 本文用于收集 leetcode 题解，以训练思维，同时精进算法 刷题正确打开方式 算法思想 链表 判断链表是否存在环 标记法 快慢双指针法 链表有环则找出线与环的交接点 标记法 快慢双指针法 ...", "content": " 本文用于收集 leetcode 题解，以训练思维，同时精进算法 刷题正确打开方式 算法思想 链表 判断链表是否存在环 标记法 快慢双指针法 链表有环则找出线与环的交接点 标记法 快慢双指针法 找出相交单链表的交点 方法一 方法二 方法三 方法四 删除链表的倒数第 N 个结点 方法一 方法二 方法三 方法四 合并两个有序链表 哨兵迭代法 递归法 合并K个有序链表 逐一两两合并 分治递归法(归并排序) K指针 优先队列(二叉堆) 快速排序 败者树 值排序重建链表 基数排序 分隔链表 链表的中间结点 两次遍历 快慢双指针法 数组存储一次链表遍历结果 反转链表 方法一 方法二 方法三 方法四 方法五 反转链表II 刷题正确打开方式 刷起来：千里之行始于足下 按算法分类来选题 难度循序渐进 有思路：先不考虑算法是否高效，能解决就行。不要一味追求高效，而迟迟不动手，最后连一种解法都没有。性能高效是优化出来的，没有一个基础的解法，哪来优化的对象！ 暴力法是思路的起点 不要一看题，觉得不会，或者没思路就急着搜答案，而是要尝试思考。多在草稿纸上写写画画，实在想不出来再去搜 多题一解：解法迁移 一题多解：多维度思考和尝试，每种算法思想都设法熟练 动手实现：不要有思路或者看懂了就认为自己会了，只有动手去实现才能提高代码能力和快速思维能力 不断总结完善补充：总结算法思想、算法思维模版等，吃透每一种算法和思想 坚持刷下去，不断重复算法思想 八大算法基础思想链表判断链表是否存在环题目要求标记法遍历过程中遇到已经出现过的节点，则认为存在环/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func hasCycle(head *ListNode) bool { mp := make(map[*ListNode]struct{}) for head != nil { if _, ok := mp[head]; ok { return true } mp[head] = struct{}{} head = head.Next } return false}快慢双指针法快慢指针同时遍历，快慢指针能相遇则存在环func hasCycle(head *ListNode) bool { slow, fast := head, head for fast != nil { slow = slow.Next if fast.Next != nil { fast = fast.Next.Next } else { return false } if slow == fast { return true } } return false}链表有环则找出线与环的交接点题目要求标记法遍历过程中遇到已经出现过的节点，则认为存在环（同上一题，返回值做调整）func detectCycle(head *ListNode) *ListNode { mp := make(map[*ListNode]struct{}) for head != nil { if _, ok := mp[head]; ok { return head } mp[head] = struct{}{} head = head.Next } return nil}快慢双指针法 快慢指针找到相遇节点 慢指针回到起点，快指针停留在相遇节点 快慢指针以相同速度前进，再次相遇则会交接点/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func detectCycle(head *ListNode) *ListNode { slow, fast := head, head for fast != nil { slow = slow.Next if fast.Next != nil { fast = fast.Next.Next } else { fast = nil break } if slow == fast { break } } if fast == nil { return nil } slow = head for slow != fast { slow = slow.Next fast = fast.Next } return slow}找出相交单链表的交点题目要求方法一对齐长短两个链表的起点(两链表从该起点到终点的长度相等)，同速前进，首个相遇节点即为交点。/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func getIntersectionNode(headA, headB *ListNode) *ListNode { var lenA, lenB int pA, pB := headA, headB for pA != nil { lenA++ pA = pA.Next } for pB != nil { lenB++ pB = pB.Next } pA, pB = headA, headB switch { case lenA &gt; lenB: for lenA &gt; lenB { lenB++ pA = pA.Next } case lenA &lt; lenB: for lenA &lt; lenB { lenA++ pB = pB.Next } default: } for pA != nil { if pA == pB { return pA } pA = pA.Next pB = pB.Next } return nil}方法二假设两个链表的尾部有条虚线连接着对方的头部，这样连个链表相当于是等长的，相遇时即为交点（思想类似方法一，但方法一更直观一点）func getIntersectionNode(headA *ListNode, headB *ListNode) *ListNode { pA, pB := headA, headB for pA != pB { if pA == nil { pA = headB } else { pA = pA.Next } if pB == nil { pB = headA } else { pB = pB.Next } } return pA}方法三用map存储已经遍历过的两链表节点，正在遍历的当前节点已经遍历过，说明该节点即为交点func getIntersectionNode(headA, headB *ListNode) *ListNode { pA, pB := headA, headB mp := make(map[*ListNode]struct{}) for pA != nil || pB != nil { if pA != nil { if _, ok := mp[pA]; ok { return pA } mp[pA] = struct{}{} pA = pA.Next } if pB != nil { if _, ok := mp[pB]; ok { return pB } mp[pB] = struct{}{} pB = pB.Next } } return nil}方法四把较短的链表A视为首尾相连的环，从另一个链表B出发，则整体上可以认为是带环的一个链表。转化成了6字形的环形链表问题，求环形的入口节点。func makeCirleLink(head *ListNode) *ListNode { var last *ListNode p := head for p != nil { if p.Next == nil { last = p last.Next = head break } p = p.Next } if last == nil { return nil } return last}func findCirleEntry(head *ListNode) *ListNode { slow, fast := head, head for fast != nil { if fast.Next == nil { fast = nil break } fast = fast.Next.Next slow = slow.Next if slow == fast { break } } if fast == nil { return nil } slow = head for slow != fast { slow = slow.Next fast = fast.Next } return slow}func getIntersectionNode(headA, headB *ListNode) *ListNode { lastA := makeCirleLink(headA) if lastA == nil { return nil } defer func() { lastA.Next = nil }() return findCirleEntry(headB)}删除链表的倒数第 N 个结点题目要求，这个题目的关键是定位到指定节点。方法一先反转链表(头插法)，删除此时的顺数第N个节点，再次反转即可/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func reverseList(head *ListNode) *ListNode { p := &amp;ListNode{Next: nil} tmp := head for head != nil { tmp = head.Next head.Next = p.Next p.Next = head head = tmp } return p}func removeNthFromEnd(head *ListNode, n int) *ListNode { if head == nil { return nil } r := reverseList(head) p := r n-- for n &gt; 0 { n-- p = p.Next } if p == nil { return nil } p.Next = p.Next.Next r = reverseList(r.Next) return r.Next }方法二（逆向思维）算出整个链表的长度 len，把倒数第 N 个转化成顺数第 len - N + 1func listLen(head *ListNode) int { var size int for head != nil { size++ head = head.Next } return size}func removeNthFromEnd(head *ListNode, n int) *ListNode { size := listLen(head) if n &lt;= 0 || n &gt; size || head == nil { return nil } m := size - n p := &amp;ListNode{} ret := p p.Next = head for m &gt; 0 { m-- p = p.Next } p.Next = p.Next.Next return ret.Next}方法三（把只能顺序访问的结构转化为可随机访问的结构）遍历链表时把所有节点地址存入一个数组中，倒数定位第 N+1，将其指向倒数第 N-1 个节点即可func removeNthFromEnd(head *ListNode, n int) *ListNode { if head == nil || n &lt;= 0 { return nil } stack := make([]*ListNode, 0, 30) p := head for p != nil { stack = append(stack, p) p = p.Next } if len(stack) &lt; n { return nil } m := len(stack) - n - 1 if m &lt; 0 { return head.Next } stack[m].Next = stack[m+1].Next return head}方法四（快慢双指针法）以N个节点作为步长来遍历，直到链尾，则此时步长区间的左端点即可定位到对应的节点。快慢可以是遍历的间距上的快慢，也可以是起跑线的先后。func removeNthFromEnd(head *ListNode, n int) *ListNode { if head == nil { return nil } p := head for n &gt; 0 &amp;&amp; p != nil { n-- p = p.Next } if n &gt; 0 { return nil } if p == nil { return head.Next } q := head for p.Next != nil { p = p.Next q = q.Next } q.Next = q.Next.Next return head }合并两个有序链表题目要求哨兵迭代法不哨兵迭代法：断重复相同的步骤直到达到目的/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { result := &amp;ListNode{} p := result for list1 != nil &amp;&amp; list2 != nil { if list1.Val &lt; list2.Val { p.Next = list1 list1 = list1.Next } else { p.Next = list2 list2 = list2.Next } p = p.Next } if list1 != nil { p.Next = list1 } if list2 != nil { p.Next = list2 } return result.Next}递归法递归的思想是把一个大型复杂问题层层转化为一个与原问题规模更小的问题，问题被拆解成子问题后，递归调用继续进行，直到子问题无需进一步递归就可以解决的地步为止。一般来说，递归需要有边界条件、递归前进段和递归返回段。当边界条件不满足时，递归前进；当边界条件满足时，递归返回。说白了就是： 原问题是什么：输入、映射关系、输出 缩小规模后子问题是什么（需要和原问题一致，只是规模不同） 如何缩小规模，即递归前进，f(n-1) 与 f(n) 之间的关系，这种关系成立的条件是什么 最基本问题是什么：即边界条件(退出条件)，如 f(0)、f(1)等原问题是合并两个链表，当我们提取出最小值的时候，子问题就可以变成合并缩小规模后的两条链表，例如合并两个链表list1=[1,2,4,8],list2=[2,3,6,7]，我们提取出当前最小值是list1的头节点，子问题就变成合并两个链表list1=[2,4,8],list2=[2,3,6,7],然后将list1的头节点拼接上即可上述问题实际上，可以改为 listNew.next = merge(list1.next, list2);「假设 list1的头结点比list2的头结点值小的情况下」，和总问题的出入参一样，就可以采用递归的解法。递归思想可参考全面理解递归、递归思想(总结)算法分解如下： 最基本问题或边界条件func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { if list1 == nil { return list2 } if list2 == nil { return list1 }} 原问题和子问题的共性（输入、映射关系、输出）：函数入参、函数功能、返回值func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { if list1.Val &lt; list2.Val { return list1 } return list2} 递归前进：原问题不断缩小规模直至边界退出func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { if list1.Val &lt; list2.Val { list1.Next = mergeTwoLists(list1.Next, list2) return list1 } list2.Next = mergeTwoLists(list2.Next, list1) return list2} 完整解法func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { if list1 == nil { return list2 } if list2 == nil { return list1 } if list1.Val &lt; list2.Val { list1.Next = mergeTwoLists(list1.Next, list2) return list1 } list2.Next = mergeTwoLists(list2.Next, list1) return list2}合并K个有序链表题目要求逐一两两合并我们可以先前两个合并，合并好了之后再跟第三个、然后第四个直到第k个。至于两个有序链表合并的若干方法，可以参考上一题。/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func mergeTwoList(listA, listB *ListNode) *ListNode { if listA == nil { return listB } if listB == nil { return listA } head := &amp;ListNode{} ret := head for listA != nil &amp;&amp; listB != nil { if listA.Val &lt; listB.Val { ret.Next = listA listA = listA.Next } else { ret.Next = listB listB = listB.Next } ret = ret.Next } tmp := listA if listB != nil { tmp = listB } ret.Next = tmp return head.Next}func mergeKLists(lists []*ListNode) *ListNode { var ret *ListNode for i := 0; i &lt; len(lists); i++ { ret = mergeTwoList(ret, lists[i]) } return ret}分治递归法(归并排序)不断分治，直到只剩两个链表，再合并两个链表 方法一func mergeTwoList(listA, listB *ListNode) *ListNode { if listA == nil { return listB } if listB == nil { return listA } head := &amp;ListNode{} ret := head for listA != nil &amp;&amp; listB != nil { if listA.Val &lt; listB.Val { ret.Next = listA listA = listA.Next } else { ret.Next = listB listB = listB.Next } ret = ret.Next } tmp := listA if listB != nil { tmp = listB } ret.Next = tmp return head.Next}func merge(lists []*ListNode, left, right int) *ListNode { if left == right { return lists[left] } mid := left + (right - left) / 2 l := merge(lists, left, mid) r := merge(lists, mid + 1, right) return mergeTwoList(l, r)}func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } return merge(lists, 0, len(lists)-1)} 方法二func mergeKLists(lists []*ListNode) *ListNode { n := len(lists) switch n { case 0: return nil case 1: return lists[0] case 2: //针对两个链表进行归并排序 return mergeTwoList(lists[0], lists[1]) default: key := n / 2 //数组拆分,使下一次递归的lists的长度=2 //优化思路: mergeKLists(lists[:key]),使用Goroutine+channel进行并发合并(归并排序的特点) return mergeKLists([]*ListNode{mergeKLists(lists[:key]), mergeKLists(lists[key:])}) }}func mergeTwoList(listA, listB *ListNode) *ListNode { if listA == nil { return listB } if listB == nil { return listA } head := &amp;ListNode{} ret := head for listA != nil &amp;&amp; listB != nil { if listA.Val &lt; listB.Val { ret.Next = listA listA = listA.Next } else { ret.Next = listB listB = listB.Next } ret = ret.Next } tmp := listA if listB != nil { tmp = listB } ret.Next = tmp return head.Next} 方法三func mergeKLists(lists []*ListNode) *ListNode { if len(lists)==0{ return nil } if len(lists) == 1{ return lists[0] } if len(lists) == 2{ return mergeTwoLists(lists[0],lists[1]) } mid := len(lists)/2 lists1 := lists[:mid] lists2 := lists[mid:] return mergeTwoLists(mergeKLists(lists1),mergeKLists(lists2))}func mergeTwoLists(l1,l2 *ListNode) *ListNode{ if l1==nil{return l2} if l2==nil{return l1} pre := &amp;ListNode{Val:0,Next:nil} cur := pre if l1.Val&gt;l2.Val{ cur.Next = l2 cur.Next.Next = mergeTwoLists(l2.Next,l1) }else{ cur.Next = l1 cur.Next.Next = mergeTwoLists(l1.Next,l2) } return pre.Next} 方法四func mergeKLists(lists []*ListNode) *ListNode { n := len(lists) if n == 0 { return nil } // sz/2 &gt; n时，意味着已经合并过一次 size &gt; n，而该合并仅需一次 for sz := 2; sz/2 &lt; n; sz *= 2 { for i := 0; i &lt; n; i += sz { if i+sz/2 &lt; n{ lists[i] = mergeTwoLists(lists[i], lists[i+sz/2]) } } } return lists[0]}func mergeTwoLists (list1, list2 *ListNode) *ListNode { dummy := &amp;ListNode{} pre := dummy for { if list1 == nil { pre.Next = list2 break } else if list2 == nil { pre.Next = list1 break } else if list1.Val &lt;= list2.Val { pre.Next, pre = list1, list1 list1 = list1.Next } else { pre.Next, pre = list2, list2 list2 = list2.Next } } return dummy.Next} 方法五：二路归并func mergeKLists(lists []*ListNode) *ListNode { if len(lists) &lt; 1 { return nil } queue := lists for len(queue) &gt; 1 { var nextQueue []*ListNode current, end := 0, len(queue)-1 for current &lt;= end { node := queue[current] // 当前这一轮，如果只有最后一个节点，不需要合并 if (current + 1) &gt; end { nextQueue = append(nextQueue, node) queue = nextQueue break } nextNode := queue[current+1] // 合并两个链表 newNode := mergeTwoLists(node, nextNode) nextQueue = append(nextQueue, newNode) if current+1 == end { queue = nextQueue } current += 2 } } return queue[0]}func mergeTwoLists(l1,l2 *ListNode) *ListNode { newNode := ListNode{Val: -1, Next: nil} markPoint := &amp;newNode for l1 != nil &amp;&amp; l2 != nil { if l1.Val &lt;= l2.Val { markPoint.Next = l1 l1 = l1.Next } else { markPoint.Next = l2 l2 = l2.Next } markPoint = markPoint.Next } if l1 == nil { markPoint.Next = l2 } else { markPoint.Next = l1 } return newNode.Next} 方法六：多协程归并func mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode {\thead := &amp;ListNode{}\tnow := head\tfor l1 != nil &amp;&amp; l2 != nil {\t\tif l1.Val &lt; l2.Val {\t\t\tnow.Next , l1 = l1 , l1.Next\t\t}else{\t\t\tnow.Next , l2 = l2 , l2.Next\t\t}\t\tnow = now.Next\t}\tif l1 == nil {\t\tnow.Next = l2\t}else {\t\tnow.Next = l1\t}\treturn head.Next}// 多线程// 思路 ： map - reducefunc mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 {\t\treturn nil\t}\tvar receiver *ListNode\tlatch := &amp;sync.WaitGroup{}\tlatch.Add(1)\tmergeKListsByGo(lists,0,len(lists)-1,latch,&amp;receiver)\treturn receiver}func mergeKListsByGo(lists []*ListNode , left , right int , latch *sync.WaitGroup , receiver **ListNode) {\tdefer latch.Done()\tif left == right {\t\t*receiver = lists[left]\t\treturn\t}\tif left == right - 1 {\t\t*receiver = mergeTwoLists(lists[left],lists[right])\t\treturn\t}\tnewLatch := &amp;sync.WaitGroup{}\tnewLatch.Add(2)\tvar lr , rr *ListNode\tmiddle := (left + right) / 2\tgo mergeKListsByGo(lists , left , middle ,newLatch , &amp;lr)\tgo mergeKListsByGo(lists , middle+1 , right ,newLatch , &amp;rr)\tnewLatch.Wait()\t*receiver = mergeTwoLists(lr,rr)}K指针在”合并两个有序链表”中，相对较小的节点链入新链表，且对应链表顺链移动，直到其中某个链表结束。对于K个有序链表，我们可以获取其中最小的节点，链入新链表，且对应链表顺链移动，直到只剩下一个非空链表为止。 方法一：slice存放K个指针/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func getMinNode(lists []*ListNode) int { minVal := math.MaxInt minIdx := -1 for i, node := range lists { if node == nil { continue } if node.Val &lt; minVal { minIdx = i minVal = node.Val } } return minIdx }func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } head := &amp;ListNode{} p := head curListNode := make([]*ListNode, 0, len(lists)) for _, v := range lists { if v == nil { continue } curListNode = append(curListNode, v) } for { minIdx := getMinNode(curListNode) if minIdx &lt; 0 { return head.Next } p.Next = curListNode[minIdx] p = p.Next if cur := curListNode[minIdx].Next; cur == nil { if minIdx == len(curListNode) - 1 { curListNode = curListNode[:minIdx] } else { curListNode = append(curListNode[:minIdx], curListNode[minIdx+1:]...) } continue } if len(curListNode) &lt; 2 { break } curListNode[minIdx] = curListNode[minIdx].Next } return head.Next} 方法二：链表存放K指针type nodeInfo struct { node *ListNode next *nodeInfo} func getMinNode(head *nodeInfo) *ListNode { minVal := math.MaxInt var minNode *nodeInfo for head.next != nil { if head.next.node == nil { head.next = head.next.next continue } if val := head.next.node.Val; minVal &gt; val { minVal = val minNode = head.next } head = head.next } if minNode == nil { return nil } ret := minNode.node minNode.node = minNode.node.Next return ret }func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } head := &amp;ListNode{} p := head curListNodeHead := &amp;nodeInfo{} curListNode := curListNodeHead for _, v := range lists { if v == nil { continue } curListNode.next = &amp;nodeInfo{ node: v, } curListNode = curListNode.next } for { minNode := getMinNode(curListNodeHead) if minNode == nil || minNode.Val == math.MaxInt { break } p.Next = minNode p = p.Next if curListNodeHead.next == nil || curListNodeHead.next.next == nil { break } } return head.Next}从运行时间来看，方法一笔方法二要高效得多（切片删除元素比链表删除元素还快？）优先队列(二叉堆)在“合并两个有序链表”时，我们把相对较小的节点链入新链表，直到某个链表结束。合并K个有序链表也是类似的，只不过要在K个链表节点得到最小节点（K个链表中每个链表各出一个节点），然后链入新链表，直到只剩下一个链表有节点或者都没有节点为止。从K个节点获取最小节点这个过程，可以使用优先队列(二叉堆)这种数据结构。复杂度比“逐一两两合并”的要小很多。 方法一：标准库heap接口实现小顶堆func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } dummy := &amp;ListNode{-1, nil} p := dummy pq := make(PriorityQueue, 0) heap.Init(&amp;pq) for _, head := range lists { if head != nil { heap.Push(&amp;pq, head) } } for pq.Len() &gt; 0 { node := heap.Pop(&amp;pq).(*ListNode) p.Next = node if node.Next != nil { heap.Push(&amp;pq, node.Next) } p = p.Next } return dummy.Next}type PriorityQueue []*ListNodefunc (pq PriorityQueue) Len() int { return len(pq)}func (pq PriorityQueue) Less(i, j int) bool { return pq[i].Val &lt; pq[j].Val}func (pq PriorityQueue) Swap(i, j int) { pq[i], pq[j] = pq[j], pq[i]}func (pq *PriorityQueue) Push(x interface{}) { node := x.(*ListNode) *pq = append(*pq, node)}func (pq *PriorityQueue) Pop() interface{} { old := *pq n := len(old) node := old[n-1] *pq = old[0 : n-1] return node} 方法二：标准库二叉堆接口实现func mergeKLists(lists []*ListNode) *ListNode { heap := binaryheap.NewWith(compare) // push heads to heap for _, node := range lists{ if node != nil{ heap.Push(node) } } dummy := &amp;ListNode{} node := dummy for heap.Size() &gt; 0{ tmp,_ := heap.Pop() node.Next = tmp.(*ListNode) node = node.Next if node.Next != nil{ heap.Push(node.Next) } } return dummy.Next}func compare(a,b interface{}) int{ x := a.(*ListNode) y := b.(*ListNode) if x.Val &gt; y.Val{return 1} if x.Val &lt; y.Val{return -1} return 0} 方法三：自行实现小顶堆``gofunc mergeKLists(lists []*ListNode) *ListNode {\t// 1.初始化变量\t// 生成一个基于小顶堆的优先级队列\tqueue := priorityQueue{}\t// 初始化结果链表头结点\thead := &amp;ListNode{}\tp := head// 2.首先将所有链表的首元节点入队，从而初始化构建一个基于小顶堆的优先级队列for _, list := range lists {\tif list != nil {\t\tqueue.push(list)\t}}// 3.此时堆顶元素就是最小值，循环获取堆顶元素for len(queue) &gt; 0 {\t// 将堆顶元素连接到新链表头结点的下一个节点\tminNode := queue.pop()\tp.Next = minNode\tp = p.Next\t// 将堆顶元素原来所属链表的下一个节点入队，并调整堆结构\tif minNode.Next != nil {\t\tqueue.push(minNode.Next)\t}}// 4.循环执行上述操作，直到所有的链表都完成入队出队，返回结果链表return head.Next }// 优先级队列type priorityQueue []*ListNode// 入队func (p priorityQueue) push(node *ListNode) {\t// 将元素入堆\t*p = append(p, node)\t// 上浮调整\tp.upAdjust()}// 出队func (p priorityQueue) pop() *ListNode {\t// 获取堆顶元素\ttop := (p)[0]\t// 删除堆顶元素，并将堆中最后一个元素移到堆顶\tn := len(p) - 1\t(p)[0], (p)[n] = (p)[n], (p)[0]\t*p = (p)[:n]\t// 如果堆的大小不为0，则对堆进行下沉调整\tif len(*p) &gt; 0 {\t\tp.downAdjust()\t}\t// 返回堆顶元素\treturn top}// 插入元素时，上浮调整func (p priorityQueue) upAdjust() {\t// 获取新插入元素的索引（新插入的元素在堆的最后一个位置）\tchildrenIndex := len(p) - 1\t// 获取新插入元素父节点的索引，父节点索引 = ( 左/右孩子节点索引 - 1) / 2\tparentIndex := (childrenIndex - 1) / 2\t// 记录新插入元素的值，用于比较和最后的赋值，而不需要每一步都进行交换\ttemp := (*p)[childrenIndex]// 循环上浮判断并调整// 如果新元素索引越界或父节点元素的值&lt;=新元素的值，说明堆调整完毕，跳出循环for childrenIndex &gt; 0 &amp;&amp; (*p)[parentIndex].Val &gt; temp.Val {\t// 将父节点的值赋值到新元素位置\t(*p)[childrenIndex] = (*p)[parentIndex]\t// 获取上浮的下一轮新元素索引\tchildrenIndex = parentIndex\t// 获取上浮的下一轮父节点索引\tparentIndex = (childrenIndex - 1) / 2}// 堆调整完毕，将新元素的值插入新元素的正确索引位置(*p)[childrenIndex] = temp }// 删除元素时，下沉调整func (p priorityQueue) downAdjust() {\tparentIndex := 0\tendIndex := len(p) - 1\t// 保存父节点的值，用于比较和最后的赋值，而不需要每一步都进行交换\ttemp := (p)[parentIndex]\t// 获取左孩子节点的索引，左孩子节点索引 = 2 * 父节点索引 + 1\tchildrenIndex := 2parentIndex + 1// 当该父节点存在孩子（如果不存在孩子，则说明父节点是叶子节点，无需继续判断），则循环下沉判断并调整for childrenIndex &lt;= endIndex {\t// 如果父节点的值同时&lt;=左右孩子的值，则说明符合小顶堆，调整结束\tif childrenIndex+1 &lt;= endIndex &amp;&amp; (*p)[childrenIndex+1].Val &lt; (*p)[childrenIndex].Val {\t\tchildrenIndex++\t}\tif temp.Val &lt;= (*p)[childrenIndex].Val {\t\tbreak\t}\t// 将更小的那个孩子节点的值赋值到父节点中\t(*p)[parentIndex] = (*p)[childrenIndex]\t// 获取下沉的下一轮父节点索引\tparentIndex = childrenIndex\t// 获取下沉的下一轮左孩子节点索引\tchildrenIndex = 2*parentIndex + 1}// 堆调整完毕，将父节点的值插入父节点的正确索引位置(*p)[parentIndex] = temp } ```func mergeKLists(lists []*ListNode) *ListNode { dummyHead := new(ListNode) tail := dummyHead pq := new(primaryQueue) // 将所有链表头节点加入小顶堆有序队列 for i := 0; i &lt; len(lists); i ++ { if lists[i] != nil { pq.Insert(lists[i]) } } // 不断选取最小值结点加入结果链表，直到所有的有序链表遍历完 for !pq.IsEmpty() { node := pq.Pop() tail.Next = node tail = tail.Next if node.Next != nil { pq.Insert(node.Next) } } return dummyHead.Next}// 实现小顶堆优先级队列type primaryQueue struct { heap []*ListNode}func (p *primaryQueue) swap(index1, index2 int) { p.heap[index1], p.heap[index2] = p.heap[index2], p.heap[index1]}func (p *primaryQueue) IsEmpty() bool { return len(p.heap) == 0 }// 插入新节点func (p *primaryQueue) Insert(node *ListNode) { p.heap = append(p.heap, node) p.shitUp(len(p.heap) - 1) // 向上调整新插入节点}// 弹出最小值结点func (p *primaryQueue) Pop() *ListNode { p.swap(0, len(p.heap) - 1) // pop node node := p.heap[len(p.heap) - 1] p.heap = p.heap[:len(p.heap) - 1] // 向下调整交换后的第一个节点 p.shitDown(0) return node }// 如果父节点值比新插入节点值大则交换，调整为小顶堆，然后继续向上递归调整 // 上浮func (p *primaryQueue) shitUp(index int) { if index &gt; 0 { parent := (index - 1) /2 if p.heap[parent].Val &gt; p.heap[index].Val { p.swap(parent, index) p.shitUp(parent) } }}// 向下调整当前节点为小顶堆，然后继续向下递归调整 // 下沉func (p *primaryQueue) shitDown(index int) { left, right := 2*index +1, 2*index + 2 lesser := index if left &lt; len(p.heap) &amp;&amp; p.heap[left].Val &lt; p.heap[lesser].Val {\t\tlesser = left\t}\tif right &lt; len(p.heap) &amp;&amp; p.heap[right].Val &lt; p.heap[lesser].Val {\t\tlesser = right\t} if lesser != index { p.swap(lesser, index) p.shitDown(lesser) }} 方法四：小顶堆简单写法func mergeKLists(lists []*ListNode) *ListNode { if lists == nil || len(lists) == 0 { return nil } minHeap := []int{} for i := range lists { head := lists[i] for head != nil { minHeap = append(minHeap, head.Val) head = head.Next } } buildMinHeap(minHeap) dummyHead := new(ListNode) cur := dummyHead for len(minHeap) &gt; 0 { cur.Next = &amp;ListNode{Val: minHeap[0]} swap(minHeap, 0, len(minHeap)-1) minHeap = minHeap[:len(minHeap)-1] heapify(minHeap, 0) cur = cur.Next } return dummyHead.Next}func buildMinHeap(minHeap []int) { n := len(minHeap) for i := n/2-1; i &gt;= 0; i-- { heapify(minHeap, i) }}func heapify(minHeap []int, i int) { n := len(minHeap) for { cur := i left, right := 2*i+1, 2*i+2 if left &lt; n &amp;&amp; minHeap[cur] &gt; minHeap[left] { cur = left } if right &lt; n &amp;&amp; minHeap[cur] &gt; minHeap[right] { cur = right } if i == cur { break } swap(minHeap, i, cur) i = cur }}func swap(arr []int, i, j int) { arr[i], arr[j] = arr[j], arr[i]} 方法五：低效的堆排序实现ype PriorityQueue struct {\tlength int\tmax int\telements []*ListNode}func NewPriorityQueue(max int) *PriorityQueue {\treturn &amp;PriorityQueue{max: max}}func (pq *PriorityQueue) IsEmpty() bool {\treturn pq.length == 0}func resort(array *[]*ListNode) {\tif len(*array) == 0 {\t\treturn\t}\tcurrentElementIndex := len(*array) - 1\tfor currentElementIndex &gt; 0 {\t\tfatherElement := int((currentElementIndex - 1) / 2)\t\tinnerIndex := currentElementIndex\t\tfor (*array)[fatherElement].Val &gt; (*array)[innerIndex].Val {\t\t\texchange(array, innerIndex, fatherElement)\t\t\t\tinnerIndex = fatherElement\t\t\tfatherElement = int((innerIndex - 1) / 2)\t\t}\t\tcurrentElementIndex -= 1\t}}func (pq *PriorityQueue) Add(n *ListNode) {\tpq.elements = append(pq.elements, n)\tpq.length += 1\tif pq.length == 1 {\t\treturn\t}\t// re-sort\tresort(&amp;pq.elements)}func (pq *PriorityQueue) Poll() *ListNode {\t// get min element from pq\tif pq.length &lt; 1 {\t\treturn nil\t} // re-sort\tresort(&amp;pq.elements)\tpq.length -= 1\tminNode := pq.elements[0]\tpq.elements = pq.elements[1:]\treturn minNode}func exchange(array *[]*ListNode, i int, j int) {\ttmp := (*array)[i]\t(*array)[i] = (*array)[j]\t(*array)[j] = tmp}func mergeKLists(lists []*ListNode) *ListNode {\tk := len(lists)\tdummy := &amp;ListNode{Val: -1}\tp := dummy\tpq := NewPriorityQueue(k)\tfor _, listnode := range lists { if listnode != nil { pq.Add(listnode) }\t}\tfor !(pq.IsEmpty()) {\t\tminNode := pq.Poll()\t\tp.Next = minNode\t\t\t\tif minNode != nil &amp;&amp; minNode.Next != nil {\t\t\tpq.Add(minNode.Next)\t\t}\t\tp = p.Next\t}\treturn dummy.Next}快速排序func mergeKLists(lists []*ListNode) *ListNode { // 清除掉链表数组中的空链表 for i := 0; i &lt; len(lists); i++ { if lists[i] == nil { lists = append(lists[0:i], lists[i+1:]...) i-- } } // 如果链表数组被清除掉空链表后为空则直接返回 nil if len(lists) == 0 { return nil } node := new(ListNode) // 合并中的链表游标 head := node // 合并后的链表头为 head.Next quickSort(&amp;lists, 0, len(lists)-1) // 先对链表数组根据各链表地一个元素进行排序 for len(lists) &gt; 1 { // 链表数组第一个元素始终是当前最小的元素 node.Next = lists[0] node = node.Next lists[0] = lists[0].Next // 及时清理掉空链表 if lists[0] == nil { lists = lists[1:] continue } // 使用二分法找到第一个链表的新位置，并重排链表保持有序 index := findIndex(lists, lists[0].Val) temp := lists[0] copy(lists[:index], lists[1:index+1]) lists[index] = temp } // 链表数组中剩余最后一个链表直接拼接在末尾 if len(lists) == 1 { node.Next = lists[0] } return head.Next}func findIndex(lists []*ListNode, target int) int { l := 0 r := len(lists)-1 for l + 1 &lt; r { mid := l - (l - r) / 2 if lists[mid].Val &lt; target { l = mid } else { r = mid } } // 注意这里的 &lt;= 条件 if lists[r].Val &lt;= target { return r } return l}func quickSort(lists *[]*ListNode, begin, end int) { if begin &gt;= end { return } l := begin r := end for l &lt; r { for l &lt; r &amp;&amp; (*lists)[r].Val &gt;= (*lists)[begin].Val { r-- } for l &lt; r &amp;&amp; (*lists)[l].Val &lt;= (*lists)[begin].Val { l++ } (*lists)[l], (*lists)[r] = (*lists)[r], (*lists)[l] } (*lists)[begin], (*lists)[l] = (*lists)[l], (*lists)[begin] quickSort(lists, begin, l-1) quickSort(lists, l+1, end)}败者树type ListNode struct {\tVal int\tNext *ListNode}type loserTree struct {\ttree []int\tleaves []*ListNode}var dummyVal = 100000var dummyListNode = ListNode{Val: dummyVal}func New(leaves []*ListNode) *loserTree {\tk := len(leaves)\tif k &amp; 1 == 1 {\t\tleaves = append(leaves, &amp;dummyListNode)\t\tk++\t}\tlt := &amp;loserTree{\t\ttree: make([]int, k),\t\tleaves: leaves,\t}\tif k &gt; 0 {\t\tlt.initWinner(0)\t}\treturn lt}func (lt *loserTree) initWinner(idx int) int {\tif idx == 0 {\t\tlt.tree[0] = lt.initWinner(1)\t\treturn lt.tree[0]\t}\tif idx &gt;= len(lt.tree) {\t\treturn idx - len(lt.tree)\t}\tleft := lt.initWinner(idx*2)\tright := lt.initWinner(idx*2+1)\tif lt.leaves[left] == nil {\t\tlt.leaves[left] = &amp;dummyListNode\t}\tif lt.leaves[right] == nil {\t\tlt.leaves[right] = &amp;dummyListNode\t}\tif lt.leaves[left].Val &lt; lt.leaves[right].Val {\t\tleft, right = right, left\t}\tlt.tree[idx] = left\treturn right}func (lt *loserTree) Pop() *ListNode {\tif len(lt.tree) == 0 {\t\treturn &amp;dummyListNode\t}\ttreeWinner := lt.tree[0]\twinner := lt.leaves[treeWinner]\tlt.leaves[treeWinner] = winner.Next\tif lt.leaves[treeWinner] == nil {\t\tlt.leaves[treeWinner] = &amp;dummyListNode\t}\ttreeIdx := (treeWinner + len(lt.tree)) / 2\tfor treeIdx != 0 {\t\ttreeLoser := lt.tree[treeIdx]\t\tif lt.leaves[treeLoser].Val &lt; lt.leaves[treeWinner].Val {\t\t\ttreeLoser, treeWinner = treeWinner, treeLoser\t\t}\t\tlt.tree[treeIdx] = treeLoser\t\ttreeIdx /= 2\t}\tlt.tree[0] = treeWinner\treturn winner}func mergeKLists(lists []*ListNode) *ListNode {\tdummy := new(ListNode)\tpre := dummy\tlt := New(lists)\tfor {\t\tnode := lt.Pop()\t\tif node == &amp;dummyListNode {\t\t\tbreak\t\t}\t\tpre.Next = node\t\tpre = node\t}\treturn dummy.Next}值排序重建链表/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func mergeKLists(lists []*ListNode) *ListNode { head := new(ListNode) newHead := head // 最笨的方法 nums := []int{} for i := 0; i &lt; len(lists); i++ { for lists[i] != nil { nums = append(nums, lists[i].Val) lists[i] = lists[i].Next } } sort.Ints(nums) for i := 0; i &lt; len(nums); i++ { node := &amp;ListNode{Val: nums[i]} head.Next = node head = head.Next } return newHead.Next}基数排序const ( MAXSIZE = 20010 OFFSET = 10000)func mergeKLists(lists []*ListNode) *ListNode { cnt := make([]int, MAXSIZE) for i := 0; i &lt; len(lists); i++ { for p := lists[i]; p != nil; p = p.Next { cnt[p.Val+OFFSET]++ } } head := &amp;ListNode{} for num := len(cnt)-1; num &gt;= 0; num-- { for cnt[num] &gt; 0 { s := &amp;ListNode{Val: num-OFFSET, Next: head.Next} head.Next = s cnt[num]-- } } return head.Next}分隔链表题目要求 双链表头结点法：两个链表(有头结点)分别收集小于x的节点和大于等于x的节点，然后再连接两个链表/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func partition(head *ListNode, x int) *ListNode { if head == nil || head.Next == nil { return head } h1, h2 := &amp;ListNode{}, &amp;ListNode{} p1, p2 := h1, h2 for head != nil { if head.Val &lt; x { p1.Next = head p1 = p1.Next head = head.Next continue } p2.Next = head p2 = p2.Next head = head.Next } p1.Next = h2.Next p2.Next = nil return h1.Next} 双链表非头结点法：比“双链表头结点法”复杂且低效func partition(head *ListNode, x int) *ListNode { if head == nil || head.Next == nil { return head } var h1, h2, p1, p2 *ListNode if head.Val &lt; x { h1 = head p1 = h1 head = head.Next for head != nil &amp;&amp; head.Val &lt; x { p1.Next = head p1 = p1.Next head = head.Next } if head != nil { h2 = head p2 = h2 head = head.Next } } else { h2 = head p2 = h2 head = head.Next for head != nil &amp;&amp; head.Val &gt;= x { p2.Next = head p2 = p2.Next head = head.Next } if head != nil { h1 = head p1 = h1 head = head.Next } } for head != nil { if head.Val &lt; x { p1.Next = head p1 = p1.Next head = head.Next continue } p2.Next = head p2 = p2.Next head = head.Next } if p1 == nil { return h2 } if p2 == nil { return h1 } p1.Next = h2 p2.Next = nil return h1} 方法三：类似快排partition的原地交换func partition(head *ListNode, x int) *ListNode { if head == nil || head.Next == nil { return head } prevHead := &amp;ListNode{Next: head} par := prevHead prev, curr := head, head.Next for par.Next.Val &lt; x &amp;&amp; curr != nil { par = par.Next prev = prev.Next curr = curr.Next } for curr != nil { if curr.Val &lt; x { prev.Next = curr.Next next := par.Next curr.Next = next par.Next = curr par = par.Next curr = prev.Next } else { prev, curr = prev.Next, curr.Next } } return prevHead.Next}链表的中间结点找出链表的中间节点 题目要求两次遍历一次遍历求出链表长度，第二次遍历得到对应节点/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func middleNode(head *ListNode) *ListNode { n := getListLength(head) half := n / 2 for i := 0; i &lt; half; i++ { head = head.Next } return head}func getListLength(head *ListNode) int { n := 0 for head != nil { n++ head = head.Next } return n}快慢双指针法慢指针一次走一步，快指针一次走两步。快指针指向链尾时，慢指针也就到了中间节点。func middleNode(head *ListNode) *ListNode {\tfastPointer := head\tslowPointer := head\tcount := 0\tfor {\t\tcount++\t\t// 1次走1步\t\tif fastPointer.Next == nil {\t\t\treturn slowPointer\t\t}\t\tfastPointer = fastPointer.Next\t\t// 2次走一步\t\tif count%2 == 1 {\t\t\tslowPointer = slowPointer.Next\t\t}\t}}func middleNode(head *ListNode) *ListNode { slow, fast := head, head for fast != nil &amp;&amp; fast.Next != nil &amp;&amp; fast.Next.Next != nil { fast = fast.Next.Next slow = slow.Next } if fast == nil || fast.Next == nil { return slow } return slow.Next}func middleNode(head *ListNode) *ListNode { slow, fast := head, head for fast != nil &amp;&amp; fast.Next != nil { fast = fast.Next.Next slow = slow.Next } return slow}数组存储一次链表遍历结果遍历链表时，把节点存入数组，利用数组的随机访问特性，直接找出中间节点var arr = make([]*ListNode, 0, 100)func middleNode(head *ListNode) *ListNode { arr = arr[0:0] for head != nil { arr = append(arr, head) head = head.Next } return arr[len(arr)/2]}反转链表题目要求方法一新建一个链表头节点，遍历原链表，使用头插法插入到新链表中即可。/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func reverseList(head *ListNode) *ListNode { if head == nil { return head } rev, tmp := &amp;ListNode{}, head for head != nil { tmp = head.Next head.Next = rev.Next rev.Next = head head = tmp } return rev.Next}方法二链表转化成数组，然后再按要求重新建立链接即可。func reverseList(head *ListNode) *ListNode { if head == nil { return nil } arr := []*ListNode{} for head != nil { arr = append(arr, head) head = head.Next } for i := len(arr)-1; i &gt;= 1; i-- { arr[i].Next = arr[i-1] } arr[0].Next = nil return arr[len(arr)-1]}方法三就地反转（先处理两个节点的反转，再传导到第三个节点）。就地逆置法和头插法的实现思想类似，但相对费解一些func reverseList(head *ListNode) *ListNode { if head == nil || head.Next == nil { return head } p1, p2 := head, head.Next for p2 != nil { p1.Next = p2.Next p2.Next = head head = p2 p2 = p1.Next } return head}方法四迭代法：每一次对过程的重复称为一次“迭代”，而每一次迭代得到的结果会作为下一次迭代的初始值func reverseList(head *ListNode) *ListNode { var prev, next *ListNode for head != nil { next = head.Next head.Next = prev prev = head head = next } return prev}方法五递归反转： 递归相当于函数参数的栈，通过 head.Next 遍历链表，直到 head.Next == nil 遍历的时候，会把 head.Next 压入栈中，通过 head = head.Next 使 head 的指向不断变化(从而实现遍历) 遍历完之后（newHead 成为最后一个节点，从函数的出口 if 可知），开始逐层退出，即出栈 递归函数前至递归函数所在行，属于压栈阶段 递归函数后至最后的return前，属于出栈阶段 全局变量是不会压栈的（这个地方特别注意）func reverseList(head *ListNode) *ListNode { if head == nil || head.Next == nil { return head } //一直递归，找到链表中最后一个节点 newHead := reverseList(head.Next) // 当逐层退出时，new_head 的指向都不变，一直指向原链表中最后一个节点； // 递归每退出一层，函数中 head 指针的指向都会发生改变，都指向上一个节点。 // 每退出一层，都需要改变 head-&gt;next 节点指针域的指向，同时令 head 所指节点的指针域为 NULL。 head.Next.Next = head head.Next = nil //每一层递归结束，都要将新的头指针返回给上一层。由此，即可保证整个递归过程中，能够一直找得到新链表的表头。 return newHead}栈是一段内存空间，用来存储数据，在函数的调用过程中存储什么呢？当一个函数的运行期间调用另一个函数时，在运行被调用函数之前，系统需要完成3件事 将所有的实参、返回地址等信息传递给被调用函数保存(返回地址是指程序从函数返回时应该继续执行的地方) 为被调用函数的局部变量分配存储区 将控制转移到被调函数的入口而被调用函数返回调用函数之前，系统也应完成3件事 保存被调函数的计算结果 释放被调函数的数据区 依照被调函数保存的返回地址将控制转移到调用函数递归的压栈过程可以参看递归与栈的状态反转链表II" }, { "title": "算法基石", "url": "/2021/07/foundation-of-algorithm.html", "categories": "算法", "tags": "Algorithm", "date": "2021-07-10 10:55:40 +0800", "snippet": " 本文旨在收集经典的算法，此处称之为算法基石。你可以通过这些算法根据具体的应用场景或算法背景进行适当地变形，从而得到其他变种的算法或更高效的算法。 排序和查找 经典排序 查找或搜索 二叉树 遍历 前序遍历 排序和查找排序是不断将局部逆序变成局部正序，直到全局...", "content": " 本文旨在收集经典的算法，此处称之为算法基石。你可以通过这些算法根据具体的应用场景或算法背景进行适当地变形，从而得到其他变种的算法或更高效的算法。 排序和查找 经典排序 查找或搜索 二叉树 遍历 前序遍历 排序和查找排序是不断将局部逆序变成局部正序，直到全局有序的过程。这个过程中可以采取以下一种或多种策略： 交换：逆序的元素之间经过交换变成正序。交换可以有相邻交换、跨距交换 选择：从待排序的元素中选出符合条件的元素，并追加到有序的列表中（头部或尾部），直到待排序的元素为空。 归并：把局部分段有序的列表不断合并成更大有序段，直到全局有序。这其中会涉及到选择或交换。 插入：已知一个有序列表（元素个数可以为0）和待排序列表，不断从待排序列表中逐个拿出元素不断插入到有序列表中，直到待排序列表为空。 计数排序：参见 计数排序 桶排序： 参见 桶排序 基数排序： 参见 基数排序经典排序 交换排序： 冒泡排序、快速排序 选择排序： 直接选择排序、树形选择排序、堆排序 插入排序： 直接插入排序、折半插入排序、2-路插入排序、表插入排序、希尔排序 计数排序： 计数排序 桶排序： 桶排序 基数排序： 基数排序查找或搜索 静态查找： 可参见 常用查找算法、查找算法总结、七大查找算法详解 动态查找： 可参见 数据结构&amp;算法学习笔记——查找二叉树二叉树可以帮助我们更好的理解递归及其对应的非递归实现。很多问题都可以转化为二叉树模型来解决。遍历所有遍历就是访问二叉树中的所有节点有且只有一次。这是对二叉树进行其他操作的基础。前序遍历用 N 表示根节点，L 表示左子树，R 表示右子树，则前序遍历可表示为 NLR，即先访问根节点，再访问左子树和右子树。func NLR(root *TreeNode,visitFn func()node *TreeNode)) { if root == nil { return } visitFn(root) NLR(root.Left, visitFn) NLR(root.Right, visitFn)}" }, { "title": "git 常用技巧", "url": "/2021/05/git.html", "categories": "高效工具", "tags": "Tool", "date": "2021-05-29 16:10:52 +0800", "snippet": " 本文旨在介绍 git 的常用操作技巧，尽量覆盖常用使用场景，以充分利用 git 这个高效的代码管理工具。 获取帮助 初始化 git 项目 设置常用配置 项目初始化 修改了些什么？ 提交前改了啥 提交之后的某个版本改了啥 分支合并前改了啥 丢弃修改 优化提交记录 修...", "content": " 本文旨在介绍 git 的常用操作技巧，尽量覆盖常用使用场景，以充分利用 git 这个高效的代码管理工具。 获取帮助 初始化 git 项目 设置常用配置 项目初始化 修改了些什么？ 提交前改了啥 提交之后的某个版本改了啥 分支合并前改了啥 丢弃修改 优化提交记录 修改注释信息 合并提交记录 多分支处理 打补丁 合并部分文件 分支打补丁 合并分支 新建分支 新建本地分支： 新建远程分支 查看分支 删除或更新分支 切换分支 打 tag 其他获取帮助在终端使用 man git-子命令 的形式获取帮助。如 man git-commit、man git-pull初始化 git 项目设置常用配置 全局用户名：git config --global user.name \"your_name\" 全局邮箱：git config --global user.email \"you@example.com\" 配置命令别名：如 git config --global alias.co checkout 删除命令别名：如 git config --global --unset alias.co 查看系统配置：git config --list 查看用户配置：cat ~/.gitconfig 查看暂存区配置：cat ~/.gitconfig 查看当前项目配置：cat .git/config 修改默认编辑器：如 git config –global core.editor vim ，这样你就可以使用自己熟悉的编辑器进行 git 的一些交互命令操作 绑定多个远程仓库：git push 的时候可以同时更新多个仓库 git remote set-url --add origin https://github.com/ShengChangJian/ShengChangJian.github.io.git git remote set-url --add origin https://gitee.com/shengchangjian/ShengChangJian.git 项目初始化git 初始化，进入项目文件夹： git init git add . git commit -m \"这次做了些啥\" git push修改了些什么？建议每次开发或修 bug 的时候自己单独新建一个本地分支和远程分支，等合并本次开发或 bug 修复所有提交记录后，在测试没有问题之后再合并到主分支中去。如此可以省去很多麻烦，也可以降低很多风险。想知道你刚才修改了些什么，历史上修改了些什么吗？ 以下命令会告诉你答案。提交前改了啥提交前确认一下这次到底改了些什么之后再提交会安心很多！ git status：显示修改过的文件列表 git diff：未 add 时的文件变化情况（命令后可接具体的文件等） git diff --cached：在 add 之后 commit 之前文件变化情况（命令后可接具体的文件等） git diff HEAD：在 commit 前文件变化情况（前两条命令和合并） git diff --staged：有时候修改了不想 commit 又要切换分支，会使用 stage 命令，此后可以用该 diff 命令列出到底 stage 了些什么内容。以上命令都可以指定版本、分支或具体文件，以聚焦自己感兴趣的内容提交之后的某个版本改了啥 git log：提交的历史记录 git log --oneline：简化 log 显示 git log --stat：输出 log 的统计信息 git log -p：输出修改的具体内容 git log --author=作者：指定显示某个作者的提交记录 git diff 版本1 版本2：列出相同分支两个版本之间的差异，这个在 rebase 多个提交时可以提供参考 git blame 文件：追踪是谁改了哪些代码以上命令都可以指定版本或具体文件，以聚焦自己感兴趣的内容分支合并前改了啥 git log --left-right dev...master：查看两个分支提交记录的不同处，主要用于合并分支前 git diff 分支1 分支2：列出两个分支最近不同的详细信息 git diff 分支1...分支2：列出两个分支所有不同的详细信息 git diff 分支1 分支2 --stat：列出两个分支的不同点的统计信息丢弃修改改了很多，发现有问题或者不再需要时，往往会取消修改或回滚版本。在执行以下命令前强烈建议先使用 git stash 保留快照，以便想挽回时使用 git stash pop 恢复。 未 add 时：git checkout -- fileName 回到最近一次提交或add时的状态 已 add 未 commit 时：get reset HEAD -- fileName 已提交时：可以有以下处理方式 抹掉刚错误提交的版本（不推荐）：git reset --hard 需要到达的版本，然后强制推送到远程仓库git push -f -u origin 分支名称 不回退版本，而是形成新的版本（推荐）：git revert -n 想要的版本，然后 git commit -m \"做了些啥\"，最后git push 优化提交记录理想的提交记录状态是：每次提交都能实现一个相对完整的功能、需求或修复相对独立的bug；每次提交的内容描述都能恰到好处地概述代码修改。可惜的是，我们往往因为某种原因会很随意地填写 commit，然后就提交了。此后，其他人甚至提交着过了一段时间之后也不知道该提交到底做了些什么。如此下去，git log 的查看提交流水时也无法清楚地知道其中的脉络。万一要回退到某次提交也无从下手。为优化提交记录，我们需要修改提交的描述或者合并几个紧密相关的版本。修改注释信息建议每次开发或修bug的时候自己单独新建一个本地分支和远程分支，等合并本次开发或bug修复所有提交记录后，在测试没有问题之后再合并到主分支中去。如此可以省去很多麻烦，也可以降低很多风险。 先本地备份分支：git checkout -b 新的分支名，如此备份分支之后，在后面的操作中一旦失误，还可以想办法恢复 回到原分支： git checkout 原分支修改注释信息，至少有以下两种情景： 修改最近一次的注释信息：git commit --amend -m \"新的描述\" 修改某次提交的注释信息： git -i 需要修改的版本，在该版本前把 pick 改成 reword，然后保存 根据提示操作即可 合并提交记录建议每次开发或修 bug 的时候自己单独新建一个本地分支和远程分支，等合并本次开发或 bug 修复所有提交记录后，在测试没有问题之后再合并到主分支中去。如此可以省去很多麻烦，也可以降低很多风险。 先本地备份分支：git checkout -b 新的分支名，如此备份分支之后，在后面的操作中一旦失误，还可以想办法恢复 回到原分支： git checkout 原分支合并提交记录，至少有以下两种情景： 合并[当前最新, 某个版本)： git rebase -i bddesdd6 #要合并的提交(bddebfb1)的上一条提交ID 在打开的编辑器中，只留下最上面一行为 pick，其他非注释行改为 f，如 pick bddebfb1 退出修改 f 68326b8c 接口修改 f 699501f7 接口修改 f 784e86b3 接口修改 合并中间的某几个版本：同上，只是把中间的版本由 pick 改为 f修改之后，要确认修改了些什么，可以 git log，没问题再 git push origin 分支名 -f（确保此分支没有别的提交或者只有你在用）。如果出现错误提示， 很有可能该分支启用了分支保护，不允许使用 -f，只要暂时去掉这层保护即可。多分支处理打补丁只是想应用某个分支的某些文件的修改，而不是全部，则可以使用打补丁的方式在提示中合并应用部分代码。合并部分文件这里假设要把分支 test1_branch 中的 test_file.txt 合并到分支 master 中的相应文件，则可以： git checkout master git checkout --patch test1_branch test_file.txt 然后根据提示一步步操作即可分支打补丁正常情况下，对于本地分支，我们可以直接 git merge 就行，然后提交就行。但是，在有些情况下需要代码审核通过之后才能提交，或者对于某个分支你没有提交权限，此时就需要把补丁文件发送给有权限操作的人去使用这些补丁。假设你在 fix_branch 分支中 commit 了多次，和 master 分支存在了多个不同的地方，那么，可以通过以下流程对 master 打补丁，以应用fix_branch 中的修改。 git checkout fix_branch git format-patch -M master 然后在终端 ls 一下就可以看到 patch 文件（每次提交会生成一个补丁文件） 把这些补丁文件复制到其他地方或者打包发邮件给打补丁的人生成好了补丁之后，就可以打补丁了。 git checkout master git apply --reject 所有的补丁文件（可以使用通配符） 如果有冲突，就根据生成的 rej 文件手动解决冲突，然后删掉相应的 rej 文件 解决好所有冲突之后，使用 git add 应用修改 最后使用 git am --resolved 告诉 git 打补丁结束合并分支在独享的分支中完成开发胡log优化后需要合并到主分支，此时如果主分支已经有其他人做了新的提交，我们需要先把主分支合并到独享分支，解决冲突后再合并到主分支中去。为此，至少有以下几种方式： 变基 rebase： 更新 master 分支： git checkout master 然后 git branch 查看当前分支，如果已经切换到 master 分支，最后 git pull 更新 回到独享分支：git checkout 独享分支 在独享分支中执行 git rebase master 合并主分支，解决冲突 git status 查看，然后 git add 对应文件 或者 git add -u git rebase --continue 继续解决剩下的冲突，如果想终止变基，可以 git rebase --abort 使用 merge： 更新 master 分支： git checkout master 然后 git branch 查看当前分支，如果已经切换到 master 分支，最后 git pull 更新 回到独享分支：git checkout 独享分支 在独享分支中执行 git merge master 解决所有冲突之后再提交 新建分支新建本地分支： clone 主分支： git clone --recurse-submodules URL checkout 新分支： 基于当前分支：git checkout -b 本地新分支 基于当前分支的某个版本：git checkout -b 版本号 基于远程分支：git checkout -b 本地新分支 origin/远程分支 新建远程分支新建本地分支后，使用 git push origin 本地分支:远程分支 即可创建远程分支。查看分支 当前分支： git branch 已经合并到当前分支的分支：git branch --merged 还没有合并到当前分支的分支：git branch --no-merged 所有分支： git branch -a删除或更新分支 删除本地分支：git branch -d 分支 或强制 git branch -D 本地分支 删除远程分支：git push origin :远程分支 从远程分支更新本地分支：git pull origin 远程分支 或者 git pull 从本地分支更新远程分支：git push origin 远程分支 或者 git push 远程强行覆盖本地代码：git fetch --all &amp;&amp; git reset --hard origin/master &amp;&amp; git pull切换分支切换分支可以使用 git checkout 分支，当出现无法切换时，可以按照提示提交。当改了一些东西之后发现分支不对，或者不应该在主分支改，此时肯定不能提交，只能新建分支。为此， 可以： 使用 git stash 暂存 使用 git checkout -b 新分支 创建新分支 在新分支中使用 git stash pop 把修改应用到新的分支 使用 git diff 命令核实是否为自己想要的改动注意：切换分支之前或之后开始编辑文件之前一定要关掉相关的编辑窗口，这样可以避免分支编辑混乱。打 tag对于已经完成一个大的版本或者里程碑，需要定格时，在不想或不便于新建分支的情况下，可以打 tag。 git tag -a tagName -m “描述一下”：建立本地标签 git push origin tagName：提送到远程仓库（也可以通过 git push origin --tags 把所有的标签都推送）其他常用的 tag 操作： git tag：列出本地当前分支的所有 tag git tag -l v1.0.*：通过通配符显示特定的 tag git show tagName：显示标签的详细信息 git tag -d tagName：本地删除标签 tagName git push origin :refs/tags/tagName：删除远程 tag（应在删除本地 tag 之后）其他 不再跟着某个文件：git rm --cached fileName 执行该命令后, git不再跟踪fileName, 但是fileName文件仍保留 删除文件：git rm -f fileName 负略某个文件或文件夹： vim .gitignore 编辑该文件，填入如 filename 或者 dir/" }, { "title": "C++ 编程规范", "url": "/2017/12/cpp-code-standard.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2017-12-08 18:49:35 +0800", "snippet": " 该编程规范参考了 Google 的 C++ 编程规范，同时加入了本人一些取舍和改变。这是本人比较喜欢的编程规范。 概述 命名规范 配套规范： 源文件名 头文件 减少包含头文件的数量 命名空间 类 成员函数 结构体和类 继承 多重继承 接口 操...", "content": " 该编程规范参考了 Google 的 C++ 编程规范，同时加入了本人一些取舍和改变。这是本人比较喜欢的编程规范。 概述 命名规范 配套规范： 源文件名 头文件 减少包含头文件的数量 命名空间 类 成员函数 结构体和类 继承 多重继承 接口 操作符重载 存取控制 声明次序 编写短小函数 重载函数 函数参数约定 嵌套类（成员类） 友元 运行时类型识别 RTTI 类型转换 自增自减 预处理宏 0 和 NULL sizeof 排版规范 注释规范概述实际上，不论你采用何种编程规范，理论上只有在同一个项目中保持一致就可以了。不过最好在所有的项目中保持一致，同时，参与相同项目的所有人也最好约定好编程规范，并坚持到底，至少被其他人使用的接口规范保持一致。这有助于自己找错、也有利于其他人阅读理解你的程序，提高沟通效率，当然也有助于自己今后修改或重构之前的程序。一旦养成好的编程习惯，不仅可以提高编程效率，也可以提高程序的易用性，同时减少错误发生的概率，减少不必要的回眸。如上所述，后面提出的编程规范只是参考而已，只要你找到适合自己的编码规范并坚持下去就可以了，当然有时候需要适应项目和团队的编程规范。总体上的规范是：命名型义简明、排版区块分明命名规范总体上类型名使用大驼峰方式，即单词首字母大写；变量名使用小驼峰方式（为了适当加小写前缀标识特殊作用域或类型的变量），即第一个单词首字母小写，其他单词首字母大写；其他则加以前缀或后缀标识。尽量不使用下划线，主要是为了： 区分自己定义和库定义（针对 Linux 而言）的类型、函数等； 减小名称的长度； 项目 命名规范 文件名 大驼峰，尽量表明文件内容，比如与类名字同名 typename 类型名 大驼峰，不用加前缀 命名空间 大驼峰，加N前缀，建议具有真实含义的命名空间放在项目命名空间内，表示 namespace 类名 大驼峰，加C前缀，形容词名词组合，表示 class 枚举类型 大驼峰，加以E前缀，表示 enum 联合体类型 大驼峰，加以U前缀，表示 union C 结构 大驼峰，加以S前缀，表示 struct 模板参数 大驼峰，加T前缀，表示 template，不论是类还是函数模板 接口 大驼峰，加I前缀，表示 interface typedef 类型 后面加_t标识（虽然有点别扭），表示 type 函数名 大驼峰，动宾短语 回调函数 （函数作为其他函数的参数）大驼峰，加以On前缀 虚函数 大驼峰，加以Do前缀，取之于TODO，表示“待实现”之意 protect 函数 大驼峰，加以单下划线_前缀，不用担心会和系统内部函数混淆，因为作用域不同 private 函数 大驼峰，加以双下划线__前缀 bool 函数 大驼峰，加以Is或Enable前缀 虚函数 bool型 大驼峰，加以DoIs或DoEnable前缀 普通变量名 小驼峰 全局变量 小驼峰，加以g前缀，表示 global 成员变量 小驼峰，加以m前缀，表示 member 结构体中的变量 小驼峰，不需要加前缀 静态变量 小驼峰，加以s前缀，表示 static 静态全局变量 小驼峰，加以s，不用再加g，因为作用域可区别 静态成员变量 小驼峰，加以s前缀，不用再加m，因为作用域就可区别 bool 变量 小驼峰，加以is前缀 宏定义 全大写，用下划线_隔开 常量(const)或枚举值 小驼峰，加以k前缀，因为 const 里面的 c 字母对应的发音是 k 注意：名称中尽量不要使用单词缩写，除非是熟知的专业术语（如 URL、URI，但仍然需要注解或缩写词对照表）。但同时在正确表义的情况下减少单词数量（如剔除不必要虚词、用 2 代替 to 等）和单词长度（如有近义词则选择长度短的，双重否定用肯定词等）。typedef 的范围尽量要缩小，比如在类中使用，这样可以起到指示声明或定义位置的作用（因为使用它的时候必须带作用域指示符）。也可以防止出现冲突，比如typedef unsigned int uint32_t可能与升级后的编译器头文件中的typedef unsigned long uint32_t等冲突，导致无法编译通过，如果是在某个类或命名空间中使用这种typedef的话就可以减少这种移植性问题。这个问题我在用新版本编译器，编译较老的项目时遇到了这个问题。总之： 任何量都应且只出现在它必须出现的地方，而且要尽量缩小范围，如此可尽可能的避免冲突、可读性、可维护性、可移植性等问题。 类型尽量要匹配，不要使用隐式转型，实在需要则使用强制转型以明确告诉编译器，否则在以后的编译重构中，可能出现：新编译器无法编译通过的问题。可能新版编译器类型检查更为严格，已经摈弃了不太安全的隐式转型。 以上命名规范基于以下原因： 源文件中使用的单词尽量简单，并且意思相同的尽量重用： 尽量利用好编译器的检查功能；有时候，类型、函数、变量等在意义上相同，但是基于名字唯一性，不得不另取名字，增加了理解的难度，同时也给编程人员带来了选词的困难，或许你会说，可以加前缀或后缀，或者通过大小写来区分，这样不就不用同义多词了，但是也得有个规则来支持这样做。而本命名规范就提供了这样的规则： 类型名和函数名都采用大驼峰（都使用大驼峰的原因在于类构造函数与类名称相同，保持整体和谐），类型名加前缀，函数名不加，不同函数（静态成员函数（作用域为类）、全局函数（作用域为工程）、静态全局函数（作用域为文件）、普通成员函数（作用域为对象））间不区分（因为作用域已经可以界定，并且很少有命名冲突，不过还是建议把非成员函数放在命名空间中、以进一步缩小作用域而减少冲突或被隐藏的概率），但是，public 和 protect 及 private 成员函数间需要区分，因为需要名称复用，它们之间加前缀下划线加以区分（区别于类型、变量标识，同时作用域帮助区分了某些带前后缀下划线的系统函数）； 变量名采用小驼峰，特殊变量加前缀标识，为的是单词意义重用，同时显示其作用域区别，防止相互隐藏而降低程序的可读性和可调式性； 特殊类型要加以区分： 结构体默认只用于公开数据； 类默认只公开接口（函数）； 枚举中的值类似 const 常量； 宏全大写并下划线分割，为的警示少用； 虚和非虚要区分： 警示重写或继承； 区分重写和重载； 函数参数要显著区分：提高对参数修改的晶体和提示； 类型标识取大写首字母加以区分，变量则用小写首字母区分； typedef 要与原类型求同存异： 尽量用原类型的名称加_t； 达到简化原类型的目的，特别是名字空间或类名很长的情况； 是同一数据结构在不同场景下根据意义取不同名称，同时用后缀暗示其存在原始类型名； 不用标识函数输入输出参数，而是： 尽量使用 const 以编译器限定不可变输入； 用 const 引用类型输入大对象； 作为输出参数的要用指针，不改变指针指向的用指针常量，不改变指针所指对象的内容用常量引用； 以上说这么多，也只是增加自觉遵守上述规范的可能性，同时特别强调：尽量不要使用缩写，因为很多词或短语的缩写形式是一样的，实在要缩写，请一定在后面添加注释或者在文档中给出缩写词对照表。配套规范：下面的规范是为了配合命名规范有效实施的配套规范或者拓展规范。 命名空间简化全局命名空间以项目主文件夹为基础，例如，项目名称为 cpp_test ，则全局命名空间为NCppTest，而二级命名空间以原文件名为基础，例如，源文件名为 CTest，则二级命名空间为 NTest，这样可以暗示变量或类所在的位置，当项目很大时也便于查找，同时可读性也会得到提高，不过要注意命名空间的简化。为了配合以上规范，全局性质的变量请使用::警示全局作用域，不要用 using namespace 指令，如果命名空间层次太多或名字太长，可以用typedef定义类型别名（如原类型名加_t后缀）或者使用命名空间别名using(如 using Project = PC.MyCompany.Project; )来减少代码量（尽管有代码补全，但命名空间层次太多，也会增加补全次数而影响编码速度），同时增加可读性，而且可以尽量保证同行代码不换行（毕竟长的命名空间名容易导致换行）。 尽量消除全局变量、常量最好将全局变量和常量（包括静态的变量和常量）封装成有意义的逻辑模块，便于修改（如果有变动，只需要修改该模块就可以了，即使需要大面积修改，也便于查找替换）。class CGlobal{ private: static int sSize; static double sScale; static const char *sSystem; private: Global(); public: static void SetSize(int size){sSize = size;} static void SetScale(double scale){sScale = scale;} static void SetSystem(const char *system){sSystem = system} static int GetSize(){return sSize;} static double GetScale(){return sScale;} static const char *GetSystem(){return sSystem;}} 限定枚举类型、typedef 和 常量数据作用范围，缩小名称冲突，增加名称的重用性，同时不失定位性（便于查找替换） 限制自由函数并不是所有的函数都需要依附在某个类中的，不收任何类管制的函数成为自由函数，这样的函数也会污染全局空间，为此，应将这些函数声明成静态函数，并放在具有意义名称的结构体中（集中放在单独的头文件中，并在对应的 cpp 文件中定义），这样既限定了其作用域，同时也赋予其一定的意义，增加了可读性和可重用性。void uint2str(unsigned int num);//bastruct SConversion{ static void uint2str(unsigned int num);//good} 函数参数顺序：先是输出参数，再输入参数，中间是同时作为输入输出的参数。这条规则参考自C 语言（如 char *strcpy( char *dest, const char *src );），同时兼顾 C++ 的默认参数值形式（输出参数一般不会省略，输入参数则可能省略，所以输入参数放在参数列表后面），而且，输出参数间的顺序按照重要性或常识排列（比如，客观顺序），输入参数间顺序可以按照可省略性最大的排在最后的规则排序。注意：输入参数使用值传递（小对象或内置类型）或 const 引用或常指针，输出参数使用指针。返回值不能是局部 引用或指针。 类中函数声明顺序：先构造函数和析构函数，如果有继承并且继承中有虚函数或其他函数要实现或覆盖，则按照父类中函数的相对顺序声明；如果继承了多个类，声明也保持继承声明的顺序，如此可以提示本类尽可能少的声明函数（父类中已经有类似的函数了，就不用再造了）；最后到本类独有的函数，这也是有顺序的，先重要性和复合性大的函数放在前面，这遵守的是函数式编程（完成复杂函数时，其中小的功能模块事先用函数名称代替（先不实现这些用到的函数，之后再实现，最后考虑这些函数是否提供给外部使用），如此使得复杂函数具有自解说性，从而提高了可读性，同时降低了注释文档的代价，同时这也符合人的思维习惯。 成员变量和成员函数间的顺序：成员变量放在最后，思考时也建议先想好应有哪些数据，然后再想如何操作这些数据实现功能，当然，在实现函数的过程中，可以增加成员变量，以达到某种设计上要求（比如，安全性或某种规范要求）。 控制符顺序：public 在上，protect 在中间，private 在最下边；成员函数在上方区域，成员变量在下方区域。这种顺序是符合访问控制权限定义的（把这种结构看做一个“栈”，则上面的更容易访问到，这恰好顺应访问控制层次）。 cpp 中函数定义顺序：同 h 文件中的声明顺序。这便于写程序和读程序。因为我们一般喜欢至少同时打开 3 个文件：h 文件、对应的 cpp 文件、测试测序文件（main 函数），这样就可以很快地对照定位，同时也符语文中的“前后呼应”的要求，总之，尽量重用（吾称之为“思想重用”）我们大脑或常识中已有的规则或知识，减少精力损耗，以节省精力应对新问题。 注释：尽量将表达的意思放在类型名、变量名、函数名、函数式编程（对逻辑解读很重要）、设计模式等中，使这些就有“自我诠释性”，从而减少注释的需求和代价，而且看注释有时候也是需要时间的，同时，经常会忘记更新注释（不恰当的注释比没有注释还糟糕）。所以，注释要少而精，“少”意味着漏掉更新的几率减少，“精”意味着非常必要和重要，如此可以增加可读性，此所谓“一分钟文档低过几小时源码”、源文件名编程之前，当然首先遇到的是文件名了。源文件名命名规范： 文件名表义简明，大驼峰，尽量表明文件内容，比如与类名字同名； 类或模块定义时文件名一般一一对应（虽然类名规则与文件名规则不同，但可以去除类名的前缀即可对应）。 文件后缀名用.cpp、.h、.c；头文件头文件命名规则见“源文件名”一节。头文件中要使用#define保护，防止头文件被多重包含，命名格式为：&lt;PROJECT&gt;_&lt;PATH&gt;_&lt;FILE&gt;_H_。为保证唯一性，头文件的命名应基亍其所在项目源代码树的全路径（这是唯一的）。例如，项目 foo 中的头文件foo/src/bar/baz.h 挄如下方式保护：#ifndef FOO_BAR_BAZ_H_#define FOO_BAR_BAZ_H_...#endif // FOO_BAR_BAZ_H_注意：实际上，#define 保护是不够的，它只能在编译时有保护作用，但在连接时已无能无力。通常会发生类似重定义的错误，原因在于：编译时 cpp 是分开编译的，所以多个 cpp 都包含同一个头文件时，这些 cpp 文件中都会嵌入同一个头文件内容（即有冗余和重复），所以在编译 main 函数并连接时，如果在该头文件中定义了变量，则会出现重定义或二义性。为此，头文件中不能定义变量，只能用extern声明变量；而声明变量应放在对应的 cpp 文件中（注意：* 头文件声明变量时，除了加了extern关键字和不能赋值外，其他都与 cpp 中定义变量的形式保持一致，否则，连接时被认为是不同的变量，此时声明就会被转为定义，从而导致 建议：像常量或配置信息或全局性变量等容易变化的量或需要经常查询的量应根据功能分块集中起来放在头文件（该头文件最好明确指示文件中的内容），以便于修改。## 头文件包含顺序头文件包含顺序没有一致的观点，这里建议以下顺序：+ OS SDK .h（操作系统相关的头文件）；+ C 标准库；+ C++ 标准库；+ 其他第三方库的头文件；+ 自己工程的头文件总体上遵循的是*从一般到特殊的原则*，不过，为了加强可读性和避免隐含依赖，应首先包含```*.cpp```对应的头文件```*.h```（放在上述序列的第一条）。 例如：如 a.cpp 文件中应该优先包含 a.h。首选的头文件是为了减少隐藏依赖，同时确保头文件和实现文件是匹配的。具体的例子是：假如你有一个 cpp 文件是google-awesome-project/src/foo/internal/fooserver.cc，那么它所包含的头文件的顺序如下：```cpp#include \"foo/public/fooserver.h\" // Preferred location.#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;hash_map&gt;#include &lt;vector&gt;#include \"base/basictypes.h\"#include \"base/commandlineflags.h\"#include \"foo/public/bar.h\"在包含头文件时应该加上头文件所在工程的文件夹名，即假如你有这样一个工程 base，里面有一个 logging.h，那么外部包含这个头文件应该这样写：#include \"base/logging.h\"，而不是 #include \"logging.h\"之所以要将头文件所在的工程目录列出，作用应该是命名空间是一样的，就是为了区分不小心造成的文件重名。C++ 编程思想一书中倡导的顺序从最特殊到最一般。 如果包含头文件的顺序是“从最特殊到最一般”，如果我们的头文件不被它自己解析。我们将马上找到它，防止麻烦事情发生。换句话说，当出现莫名错误时，可能和头文件包含顺序有关。实际上，这种种都是 C 语言作用域规则的结果。后包含的头文件会隐藏之前包含的头文件中相同名称（可见性相同的情况下）的内容。小技巧：可以使用预编译头文件来提高编译速度。减少包含头文件的数量使用前置声明（forward declarations）尽量减少 .h 文件中 #include 的数量。当一个头文件被包含的同时也引入了一项新的依赖（dependency）（见“Makefile”），叧要该头文件被修改，代码就要重新编译。如果你的头文件包含了其他头文件，返些头文件的任何改变也将导致那些包含了你的头文件的代码重新编译。因此，我们应该尽量少的包含头文件。如何使用前置声明使用前置声明可以显著减少需要包含的头文件数量。举例说明：头文件中用到类 foo，但不需要访问 foo的声明，则头文件中叧需前置声明 class foo;无需 #include “base/foo.h”。在头文件如何做到使用类 foo 而无需访问类的定义？ 将数据成员类型声明为 foo * 或 foo &amp;； 参数、返回值类型为 foo 的函数只是声明（但不定义实现）； 静态数据成员的类型可以被声明为 foo，因为静态数据成员的定义在类定义之外。有时，使用指针成员（pointer members，如果是 scoped_ptr 更好）替代对象成员（object members）的确更有意义。然而，返样的做法会降低代码可读性及执行效率。如果仅仅为了少包含头文件，还是不要返样替代的好。因为执行效率的优先级大于编译效率。不能使用前置声明的情形（即必须使用定义）： 函数返回值和参数为类对象； 类继承，类对象成员变量； 内联函数使用类指针引用或对象则不能进行前置声明。当然，.cpp 文件无论如何都需要所使用类的定义部分，自然也就会包含若干头文件。不过，能依赖声明就不要依赖定义。命名空间建议一个项目一个全局命名空间（以项目文件夹为全局命名空间，以文件名为二级命名空间，这样可以最大程度防止命名冲突，同时表示良好的定位性和可读性，但是会增加名字长度，需要施行命名空间简化），然后如果需要再在该命名空间下定义一个子命名空间（需要取一个具体 意义的名字）。在 cpp 文件中，提倡使用不具名的命名空间，可避免运行时的命名冲突；在头文件中不要使用不具名的命名空间，也不要使用 using 指令。命名空间结束时要做标识，防止尾部花括号与函数等的花括号等混淆导致缺少或冗余花括号，减少编译错误。不具名命名空间：namespace { // .cpp 文件中// 命名空间的内容无需缩迕enum{ kYellow, kBlue, kBlack }; // 经常使用的符号bool AtEof(){ return pos == EOF; } // 使用本命名空间内的符号 EOF} // namespace具名的命名空间：// .h 文件namespace NMynamespace{// 所有声明都置亍命名空间中, 注意丌要使用缩迕class CMyClass{public: ... void Foo();};} // namespace mynamespace// .cpp 文件namespace NMynamespace{// 函数定义都置亍命名空间中void CMyClass::Foo(){ ...}} // namespace mynamespace// 复杂的 .cpp 文件#include \"a.h\"class C; // 全尿命名空间中类 C 的前置声明namespace a { class A; } // 命名空间 a 中的类 a::A 的前置声明namespace b{...code for b... // b 中的代码} // namespace b不要声明命名空间 std 下的任何内容，包括标准库类的前置声明。声明 std 下的实体会导致不明确的行为，如，不可移植。声明标准库下的实体，需要包含对应的头文件。最好不要使用 using 指示符，以保证命名空间下的所有名称都可以正常使用。在 .cpp 文件、.h 文件中的函数、方法或类中，可以使用 using，还可以使用命名空间别名（当该命名空间使用较多时，建议使用，可以减少编码，同时增加可读性），如 namespace fbz = ::foo::bar::baz;类类是 C++ 中的基本代码单元，需要知道写一个类时要做什么，不要做什么。成员函数需要注意一些特殊的成员函数。 构造函数构造函数可以初始化引用和指针，尽可能少的进行其他操作；可能的话，尽量使用 Init() 方法集中初始化为有意义的（non-trivial）数据。在构造函数中执行操作引起的问题有： 构造函数中不易报告错误，不能使用异常； 操作失败会造成对象初始化失败，引起不确定状态； 构造函数内调用虚函数，调用不会派发到子类实现中，这会造成错觉； 如果有人创建该类型的全局对象（虽然违背了上节提到的原则），构造函数将在 main() 之前被调用，有可能破坏构造函数中暗含的假设条件。结论：如果对象需要有意义的（non-trivial）的初始化，考虑使用另外的 Init() 方法并（或）增加一个成员标记用亍指示对象是否已经初始化成功。 默认构造函数如果类中定义了成员变量，没有提供其他构造函数，你需要定义一个默认构造函数（没有参数），以防止编译器自动生成默认构造，使成员变量处于不确定的状态。因此，需要自定义默认构造函数对成员变量明确初始化，以保证变量有确定的状态，便于调试。如果你定义的类继承现有类，而你又没有增加新的成员发量，则不需要为新类定义默认构造函数。 明确的构造函数对所有单参数构造函数使用 C++ 关键字 explicit，以避免隐式转换造成的麻烦。例外：在少数情冴下，拷贝极造函数可以不声明为 explicit；特意作为其他类的透明包装器的类。类似例外情况应在注释中明确说明。 拷贝构造函数仅在代码中需要拷贝一个类对象的时候使用拷贝构造函数；不需要拷贝时应使用 DISALLOW_COPY_AND_ASSIGN（拷贝构造函数使得拷贝对象更加容易，STL 容器要求所有内容可拷贝、可赋值）。C++ 中对象的隐式拷贝是导致很多性能问题和 bugs 的根源。拷贝构造函数降低了代码可读性，相比按引用传递，跟踪按值传递的对象更加困难，对象修改的地方变得难以捉摸。大量的类并不需要可拷贝，也不需要一个拷贝构造函数或赋值操作。不幸的是，如果你不主劢声明它们，编译器会为你自劢生成，而丏是 public 的。可以考虑在类的 private 中添加空的（dummy）拷贝构造函数和赋值操作，只有声明，没有定义。由亍返些空程序声明为 private，当其他代码试图使用它们的时候，编译器将报错。为了方便，可以使用宏DISALLOW_COPY_AND_ASSIGN：// 禁止使用拷贝构造函数和赋值操作的宏// 应在类的 private: 中使用#define DISALLOW_COPY_AND_ASSIGN(TypeName) \\ TypeName(const TypeName&amp;); \\ void operator=(const TypeName&amp;)class Foo {public: Foo(int f); ~Foo();private: DISALLOW_COPY_AND_ASSIGN(Foo);};如上所述，绝大多数情冴下都应使用 DISALLOW_COPY_AND_ASSIGN，如果类确实需要可拷贝，应在该类的头文件中说明原由，并适当定义拷贝构造函数和赋值操作，注意在 operator= 中检测自赋值（self-assignment）情况。在将类作为 STL 容器值得时候，你可能有使类可拷贝的冲劢。类似情冴下，真正该做的是使用指针指向 STL 容器中的对象，可以考虑使用 std::tr1::shared_ptr。 非成员函数使用命名空间中的非成员函数或静态函数，尽量不要使用全局函数。结构体和类仅当只有数据时使用 struct，其他一概使用 class。如果与 STL 结合，对于仿函数和特性（traits）可以不用 class 而是使用 struct。继承所有继承必须是public的，如果想私有继承的话，应该采取包含基类实例作为成员的方式替代。不要过多的使用继承，组合通常更合适一些，努力做到明确是is-a的时候才使用继承。必要的话（如果该类具有虚函数），令其析构函数为 virtual。限定仅在子类访问的成员函数为 protected，需要注意的是，数据成员应始终未私有（否则使用结构体更为合适）。多重继承真正需要用到多重实现继承的时候非常少，只有当最多一个基类中含有实现，其他基类都是 Interface的纯接口类时才会使用多重继承。当然也有例外，除非你明确这样做的好处大于其带来的影响。接口当一个类满足以下要求时，称之为接口： 只有纯虚函数和静态函数（下文提到的析构函数除外）； 没有非静态数据成员； 没有定义任何构造函数。如果有，也不含参数，并且为 protected； 如果是子类，也只能继承满足上述条件的类。接口类不能被直接实例化，因为它声明了纯虚函数。为确保接口类的所有实现可被正确销毁，必须为之声明虚析构函数。操作符重载除少数特定环境外，不需要重载操作符，一般可以用明确的函数来代替。虽然操作符重载令代码更加直观，但也有一些不足： 查找重载操作符的调用处更加困难，查找 Equals() 显然比同等调用 == 容易的多； 有的操作符可以对指针迕行操作，容易导致 bugs，Foo + 4 做的是一件事，而&amp;Foo + 4可能做的是完全不同的另一件事，对亍二者，编译器都不会报错，使其很难调试； 重载还有令你吃惊的副作用，比如，重载操作符&amp;的类不能被前置声明。一般不要重载操作符，尤其是赋值操作（operator=）比较阴险，应避避免重载。如果需要的话，可以定义类似 Equals()、CopyFrom()等函数。然而，除少数情况下需要重载操作符以便与模板戒“标准”C++类衔接（如 operator«(ostream&amp;, const T&amp;)），如果被证明是正当的尚可接叐，但你要尽可能避免返样做。尤其是不要仅仅为了在 STL 容器中作为 key 使用就重载 operator== 或 operator&lt;，取而代之，你应该在声明容器的时候，创建相等判断和大小比较的仿函数类型。有些 STL 算法确实需要重载 operator== 时可以返么做，但不要忘了提供文档说明原因。存取控制将数据成员私有化，并提供相关存取函数，如定义变量 mFoo 及叏值函数 Foo()、赋值函数 SetFoo()。存叏函数的定义一般内联在头文件中。声明次序在类中使用特定的声明次序：public: 在 private: 之前，成员函数在数据成员（发量）前。定义次序如下：public:、protected:、private:，如果那一块没有，直接忽略即可。每一块中，声明次序一般如下： typedef 和 enums； 常量； 构造函数； 析构函数； （静态或）成员函数； （静态或）数据成员；宏 DISALLOW_COPY_AND_ASSIGN 置亍 private: 块之后，作为类的最后部分。参考拷贝极造函数。.cpp 文件中函数的定义应尽可能和声明次序一致。不要将大型函数内联到类的定义（不便于阅读，也暴露了过多细节）中，通常，只有那些没有特别意义（不便于调试）的或者性能要求高的，并且比较短小的函数才被定义为内联函数。编写短小函数倾向亍选择短小、凝练的函数。长函数有时是恰当的，因此对亍函数长度幵没有严格限制。如果函数超过 40 行，可以考虑在不影响程序结极的情况下将其分割一下。即使一个长函数现在工作的非常好，一旦有人对其修改，有可能出现新的问题，甚至导致难以发现的 bugs。使函数尽量短小、简单，便亍他人阅读和修改代码。在处理代码时，你可能会发现复杂的长函数，丌要害怕修改现有代码：如果证实返些代码使用、调试困难，或者你需要使用其中的一小块，考虑将其分割为更加短小、易亍管理的若干函数。重载函数仅在输入参数类型不同，功能相同时使用重载函数（含构造函数），不要使用函数重载模仿缺省函数参数。如果只有一个参数，可以使用 explicit 防止隐式转换（除非你特意这么做），不过也可以想办法使函数名包含参数信息（对于参数比较少的情况）。这样就可以减少重载函数带来的困惑。函数参数约定输入参数使用值传递（小对象或内置类型）或 const 引用或常指针，输出参数使用指针。返回值不能是局部引用或指针。禁止使用缺省函数参数（除非有意为之），虽然很少使用的缺省参数可以减少函数定义（不需要为了很少使用的缺省参数而额外增加一个函数定义）。函数参数只读的尽量用 const 修饰（只要遵循本节首段的规则，只有在引用对象作为输入参数时用，其他情况不建议使用），不改变成员变量的函数要在函数头后加 const；基本类型不要使用 &amp;引用（输出参数可以使用指针），这样会增加理解难度，也无法体现引用的好处；函数中变量意义改变时，可以使用引用别名增加可读性（如果确实必要才这样做）；返回值可能作为判断时（比如 bool 型函数），也可以加 const，防止出现==写成=的形式，当然如果遵守常量==变量或函数的条件判断写法，本身就可以最大程度的防止这种错误。嵌套类（成员类）当公开嵌套类作为接口的一部分时，虽然可以直接将他们保持在全局作用域中，但将嵌套类的声明属于命名空间中是更好的选择。不要将嵌套类定义为 public，除非它们是接口的一部分（如前所述），比如，某方法使用了返个类的一系列选项。当嵌套（成员）类只在被嵌套类（enclosing class）中使用时很有用，将其置亍被嵌套类作用域作为被嵌套类的成员不会污染其他作用域同名类。可在被嵌套类中前置声明嵌套类。注意：在 .cpp 文件中定义嵌套类，避免在被嵌套类中包吨嵌套类的定义，因为嵌套类的定义通常只与实现相关。不过，只能在被嵌套类的定义中才能前置声明嵌套类。因此，任何使用 Foo::Bar* 指针的头文件必须包含整个 Foo 的声明。class Foo {private: // Bar 是嵌套在 Foo 中的成员类 class Bar { ... };};友元允许吅理使用友元类及友元函数。通常将友元定义在同一文件下，避免读者跑到其他文件中查找其对某个类私有成员的使用。经常用到友元的一个地方是将 FooBuilder 声明为 Foo 的友元，FooBuilder 以便可以正确构造 Foo 的内部状态，而无需将该状态暴露出来。某些情冴下，将一个单元测试用类声明为待测类的友元会很方便。友元延伸了（但没有打破）类的封装界线，当你希望只允许另一个类访问某个成员时，使用友元通常比将其声明为 public 要好得多。当然，大多数类应该叧提供公共成员与其交互。运行时类型识别 RTTI除单元测试外，不要使用 RTTI，如果你収现需要所写代码因对象类型不同而动作各异的话，考虑换一种方式识别对象类型。虚函数可以实现随子类类型不同而执行不同代码，工作都是交给对象本身去完成。如果工作在对象之外的代码中完成，考虑双重分发方案，如 Visitor 模式，可以方便的在对象本身之外确定类的类型类型转换使用 C++ 风格而不要使用 C 风格类型转换： static_cast：和 C 风格转换相似可做值的强制转换，或指针的父类到子类的明确的向上转换； const_cast：移除 const 属性； reinterpret_cast：指针类型和整型或其他指针间不安全的相互转换，仅在你对所做的一切了然亍心时使用； dynamic_cast：除测试外不要使用，除单元测试外，如果你需要在运行时确定类型信息，说明设计有缺陷。自增自减对亍迭代器和其他模板对象使用前缀形式（++i）的自增、自减运算符。：对简单数值（非对象）来说，两种都无所谓，不过建议尽量使用前自增前自减（对于 for 循环使用后自增后自减，可能更符合人的思维）。注意，对于自减的情形，最好不要使用像 size_t 之类的不可能为负的类型，因为可能永远不会达到你的判断条件。预处理宏使用宏时要谨慎，尽量以内联函数（除非你故意逃避类型检查）、枚举和常量代替之。宏意味着你和编译器看到的代码是不同的，因此可能导致异常行为，尤其是当宏存在亍全尿作用域中，而且不便于调试。0 和 NULL整数用 0，实数用 0.0，指针用 NULL，字符（串）用 ‘\\0’。sizeofsizeof 尽量用变量而不是类型，如 sizeof(varName).排版规范编译器对源代码的排版没有要求，但好的排版对编写代码的人查错、修改和思维有很大的好处，同时也可增加可读性。 缩进：使用 2 个空格； 括号：括号与字符（括号与括号)之间不要有空格； 代码块：开花括号始终与函数在)在同一行；开花括号后不能空行，闭花括号前不能空行；闭花括号与 else 同行； namespace：命名空间中的顶级代码不要缩进（其他缩进参考前述）； 类中访问控制符：缩进一个空格，不同的控制段间有空行； 类中成员函数或变量：缩进两个空格（相对与最左端）； 预处理宏：不要缩进； 指针或引用：使用类似 char *c;的格式； 运算符：运算符（如=、==、&lt;等）两边各有一个空格；自增自减除外。 分号；分号后与字符之间有一个空格（如在 for 中）； if/for/while 语句：原则上要带花括号，如果只有一条语句，则应共行；有 else 必须都要花括号； 成员调用或指针调用符号：其左右不能有空格； 函数或语句一行写不下时：折行，并且所有元素单独成行（比较短的元素可以几个工行，但一定在分割符后断行，如,）并且要对齐(相对于第一行缩进 4 个字符，这是为了与代码块缩进相区分)，每行的末尾必须是符号（如,、&amp;&amp;等）；除 main 函数外，所有的开花括号都不能单独成行（main 函数开闭花括号必须单独成行，以警示）。 函数声明尽量要在一行，不能同行的，至少返回类型和函数名及(同行，所有参数单独成行（闭括号和开花括号紧接最后一个参数）。 return：可以 return x; 不能写成 return (x); 行长度：一般不要超过 80 列；类继承符或构造函数初始化列表符:同行其后空格，折行其前要空格（目的是要显目）。 不同的函数或功能模块要空一行。 除 main 函数外，所有的函数、类、命名空间等模块结束之后要注释，例如/**&lt; std*/，这可以显著标识功能块结束位置。 过长的名字，比如带有多个命名空间，则要在函数内部或类内部用 using =（尽量不要使用using namespace）或 typedef 缩短(typedef 最好不要断行，否则不便于阅读和理解)，同时尽量明确意义。 模板函数或模板类比较长时，模板单独一行，函数或类另起一行（不要缩进）。注释规范本节所用的注释规范是为了配合 doxygen 从源代码中借助注释生成帮助文档。使用 JavaDoc 风格且 JAVADOC_AUTOBRIEF 为 YES：不使用 C++ 风格的原因是为了兼容 C 和Java，如此一套注释规范可以用于三种语言，减少了遵循规则的难度和代价。为了更快更省时的写注释，本人用的是 vim 插件DoxygenToolkit ，把 license 说明和作者版本说明整合了一下，并加入了公司名称的变量，并修改作者版本说明字段对齐，同时添加了行尾注释功能，这些修改在 DoxygenToolkit.vim 文件中完成：let s:licenseTag = \"Unpublished copyright. All rights reserved. This material contains\\&lt;enter&gt;\"let s:licenseTag = s:licenseTag . \"proprietary information that should be used or copied only within\\&lt;enter&gt;\"let s:licenseTag = s:licenseTag . \"COMPANY, except with written permission of COMPANY.\\&lt;enter&gt;\"if !exists(\"g:DoxygenToolkit_briefTag_lic_pre\") let g:DoxygenToolkit_briefTag_lic_pre = \"@brief: \"endifif !exists(\"g:DoxygenToolkit_briefTag_pre\") let g:DoxygenToolkit_briefTag_pre = \"@brief: \"endifif !exists(\"g:DoxygenToolkit_fileTag\") let g:DoxygenToolkit_fileTag = \"@file: \"endifif !exists(\"g:DoxygenToolkit_authorTag\") let g:DoxygenToolkit_authorTag = \"@author: \"endifif !exists(\"g:DoxygenToolkit_dateTag\") let g:DoxygenToolkit_dateTag = \"@date: \"endifif !exists(\"g:DoxygenToolkit_versionTag\") let g:DoxygenToolkit_versionTag = \"@version: \"endif修改 DoxygenLicenseFunc 函数，整合作者版本信息，这里默认版本号为1.0，单独添加作者版本信息时要输入版本号\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Doxygen license comment\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"function! &lt;SID&gt;DoxygenLicenseFunc() call s:InitializeParameters() \" Test authorName variable if !exists(\"g:DoxygenToolkit_companyName\") let g:DoxygenToolkit_companyName = input(\"Enter name of your company: \") endif if !exists(\"g:DoxygenToolkit_authorName\") let g:DoxygenToolkit_authorName = input(\"Enter name of the author (generally yours...) : \") endif mark d \" Get file name let l:fileName = expand('%:t') let l:year = strftime(\"%Y\") let l:copyright = \"Copyright (c) \" let l:copyright = l:copyright.l:year.\" \".g:DoxygenToolkit_companyName.\".\" let l:license = substitute( g:DoxygenToolkit_licenseTag, \"\\&lt;enter&gt;\", \"\\&lt;enter&gt;\".s:interCommentBlock, \"g\" ) let l:license = substitute( l:license, \"COMPANY\", g:DoxygenToolkit_companyName, \"g\" ) exec \"normal O\".s:startCommentBlock exec \"normal o\".s:interCommentTag.l:copyright.\"\\&lt;enter&gt;\".s:interCommentTag exec \"normal o\".s:interCommentTag.l:license exec \"normal o\".s:interCommentTag.g:DoxygenToolkit_fileTag.l:fileName exec \"normal o\".s:interCommentTag.g:DoxygenToolkit_briefTag_lic_pre mark d exec \"normal o\".s:interCommentTag.g:DoxygenToolkit_authorTag.g:DoxygenToolkit_authorName exec \"normal o\".s:interCommentTag.g:DoxygenToolkit_versionTag.\"1.0\" let l:date = strftime(\"%Y-%m-%d\") exec \"normal o\".s:interCommentTag.g:DoxygenToolkit_dateTag.l:date if( s:endCommentBlock != \"\" ) exec \"normal o\".s:endCommentBlock endif exec \"normal `d\" call s:RestoreParameters() startinsert!endfunction修改 DoxygenAuthorFunc()，把 DoxygenToolkit_briefTag_pre 替换为 DoxygenToolkit_briefTag_lic_pre 为了对齐。然后在.vimrc增加如下代码块：\"==============================================================\" DoxygenToolkit 自动注释let g:DoxygenToolkit_companyName=\"YY.com\"let g:DoxygenToolkit_authorName=\"ShengChangJian Email: socojo@qq.com\"\"let g:DoxygenToolkit_blockHeader=\"----------------------------------------------------------------------------\"\"let g:DoxygenToolkit_blockFooter=\"----------------------------------------------------------------------------\"let g:DoxygenToolkit_briefTag_funcName = \"no\"let g:DoxygenToolkit_maxFunctionProtoLines = 30nmap &lt;C-k&gt;a :DoxAuthor&lt;CR&gt;\"将光标放在 function 或者 class 的名字所在的一行nmap &lt;C-k&gt;f :Dox&lt;CR&gt;\"将光标放在需要生成 License 的地方nmap &lt;C-k&gt;l :DoxLic&lt;CR&gt;nmap &lt;C-k&gt;b :DoxBlock&lt;CR&gt;这就配置好了，后面可能还会加上行注释，以便更便捷的生成注释。 文件头实际上也叫 license，请替换相应的内容。/* * Copyright (c) 2017 COMPANY. * * Unpublished copyright. All rights reserved. This material contains * proprietary information that should be used or copied only within * YY.com, except with written permission of COMPANY. * * @file: function.h * @brief: * Details. * * @author: YourName Email: XXXX * @version: 1.0 * @date: 2017-12-14 */ 命名空间/** * @brief 命名空间的简单概述 \\n(换行) * 命名空间的详细概述 */namespace OS{} 类、函数、枚举、变量/** * @brief 类的简单概述 \\n(换行) * 类的详细概述 */class Test{ public: /** * @brief 简要说明文字 */ enum TEnum { TVal1, /**&lt; enum value TVal1. */ TVal2, /**&lt; enum value TVal2. */ TVal3 /**&lt; enum value TVal3. */ } *enumPtr, /**&lt; enum pointer. Details. */ enumVar; /**&lt; enum variable. Details. */ Test(); ~Test();/** * @brief: * Details. * * @param[i] a an integer argument. * @param[o] s a constant character pointer. * @param[d] * * @return The test results * @retval 返回值 简要说明 * @pre s 不能为空 * @note 指定函数注意项事或重要的注解指令操作符 * @see Test() * @see ~Test() * @see testMeToo() * @see publicVar() */ int testMe(int a,const char *s); virtual void testMeToo(char c1,char c2) = 0; /** * @brief 成员变量m_c简要说明 * * 成员变量m_variable_3的详细说明，这里可以对变量进行 * 详细的说明和描述，具体方法和函数的标注是一样的 */ int publicVar; int publicVar1; /**&lt; 变量简单注释. */ int (*handler)(int a,int b); /** * @param [in] person 只能输入以下参数： * -# a:代表张三 // 生成 1. a:代表张三 * -# b:代表李四 // 生成 2. b:代表李四 * -# c:代表王二 // 生成 3. c:代表王二 */ void GetPerson(int person);}; 在成员之后放置文档(行注释)int var; /**&lt; Detailed description after the member */这些块只能用于文档化成员和参数，无法用于文件，类，联合，结构，组，名字空间以及枚举， 单独注释注释单独放在源文件的某块区域（不穿插在源代码中间）或者单独形成文件。有时候这个需求是适合的，可以不影响源代码的阅读，特别是对于代码风格很好的项目，阅读源代码时很少需要注释。/*! \\file structcmd.h \\brief A Documented file. Details.*//*! \\def MAX(a,b) \\brief A macro that returns the maximum of \\a a and \\a b. Details.*//*! \\var typedef unsigned int UINT32 \\brief A type definition for a . Details.*//*! \\var int errno \\brief Contains the last error code \\warning Not thread safe!*//*! \\fn int open(const char *pathname,int flags) \\brief Opens a file descriptor. \\param pathname The name of the descriptor. \\param flags Opening flags.*//*! \\fn int close(int fd) \\brief Closes the file descriptor \\a fd. \\param fd The descriptor to close.*//*! \\fn size_t write(int fd,const char *buf, size_t count) \\brief Writes \\a count bytes from \\a buf to the filedescriptor \\a fd. \\param fd The descriptor to write to. \\param buf The data buffer to write. \\param count The number of bytes to write.*//*! \\fn int read(int fd,char *buf,size_t count) \\brief Read bytes from a file descriptor. \\param fd The descriptor to read from. \\param buf The buffer to read into. \\param count The number of bytes to read.*/#define MAX(a,b) (((a)&gt;(b))?(a):(b))typedef unsigned int UINT32;int errno;int open(const char *,int);int close(int);size_t write(int,const char *, size_t);int read(int,char *,size_t); 列表为了让文档看起来更清晰，有时候需要列表呈现内容。/*** Text before the list* - list item 1* - sub item 1* - sub sub item 1* - sub sub item 2* .* The dot above ends the sub sub item list.* More text for the first sub item* .* The dot above ends the first sub item.* More text for the first list item* - sub item 2* - sub item 3* - list item 2* .* More text in the same paragraph.** More text in a new paragraph.*/如果在列表中使用 tabs 进行缩排，请确认配置文件中 TAB_SIZE 选项是否设置了正确的 tab 尺寸。可在列表结束的缩排层级的空白处放置一个点“.”或者开始一个新的段落，即可结束一个列表。doxygen 有太多的指令，这里就不一一列举了，有兴趣的可以参考官方文档。" }, { "title": "进程剖析", "url": "/2017/11/process-anatomy.html", "categories": "C++/C-心得, Linux, 计算机综合", "tags": "IT_Basic, Cpp", "date": "2017-11-06 18:02:13 +0800", "snippet": " 本文将根据自己的经验站在进程的设计者和实用者的双重高度，揭开进程的神秘面纱，具体内容将涉及到进程的由来、进程的结构、进程的生命周期、进程信息的捕捉、进程的调试等 进程的由来 操作系统简史 进程信息捕捉 进程基本信息 进程关系 进程占用的内存 系统内存信息 ...", "content": " 本文将根据自己的经验站在进程的设计者和实用者的双重高度，揭开进程的神秘面纱，具体内容将涉及到进程的由来、进程的结构、进程的生命周期、进程信息的捕捉、进程的调试等 进程的由来 操作系统简史 进程信息捕捉 进程基本信息 进程关系 进程占用的内存 系统内存信息 进程打开的文件 进程使用的动态库 进程使用的系统调用 前台后台进程切换 进程间通信信息 栈调用关系跟踪 运行日志查看和分析 在现代操作系统中，进程是一个最基本的概念，它是线程（处理机）和资源的容器，是操作系统管理软硬件资源的基本管理单位。你可以把进程看做对软硬件资源的封装，既然是封装，必将涉及到数据结构及其对数据结构的使用策略（换句话说，就是建立在数据结构基础上的一些操作或数据结构管理策略，这是内部管理的需要）和外界使用它需要的接口（这是为外部提供服务的需要）。进程的由来进程是由操作系统系统引入的，那么进程的由来和操作系统的发展史分不开的。事实上，进程就是伴随着操作系统的进化而发展起来的。操作系统简史最开始是没有操作系统的，是通过人工控制开关的方式以卡片作为媒介把输入、计算、输出打印等过程衔接起来的。这种人工方式是非常低效的。于是人们试图将这些过程自动化。而磁带（后来则出现了硬盘）作为输入输出的缓冲和存储设备使自动化得以实现。如何顺利实现这些设备的衔接呢？如何在一个作业输入完成后马上输入另一个作业，计算完一个作业之后马上计算另一个作业等？这至少有两种解决方案： 由前一个作业负责后一个作业的调度：即，后一个作业的调度信息写在前一个作业中，这样就可以等前一个作业执行完之后马上调度下一个作业。比如，第一个作业输入完之后马上启动第二个作业的输入，第一个作业并马上开始计算，计算完之后马上计算第二个作业……，如此便实现了无缝衔接和完全自动化。不过这种方案耦合性太强，因为需要知道作业执行的一次顺序才能依次添加后续作业的调度信息，而且一旦上一个作业执行出错而没有执行到下一个作业的调度信息处，那么很有可能所有作业都将中断，此时免不了人工干预来恢复正常。 把调度信息从作业中分离开来，当做成为监督程序：不过这是输入输出是联机完成的，CPU 需要大量干预输入输出操作。可见，，批处理系统使得主机从输入和输出中某种程度的解放出来了。因为输入和输出通常是比较慢的，如果联机输入和输出的话，必然浪费具有更快速度的主机时间。 只有使输入、输出与主机运算达到并行才能尽可能的提高主机利用率。为了克服与缓解告诉主机与慢速外设（输入输出设备），提高 CPU 利用率，用又引入了脱机批处理系统，即输入输出脱离主机控制。出现了```脱机批处理系统```。不过，此时内存中仍然只能驻留一道程序（毕竟内存太小了，而且程序是整体载入的，没有把程序分段加载），这就意味着，在输入输出结束（没有空闲的输入输出设备用于下一个作业）时，CPU 仍然需要等待，即使下一个作业暂时不需要 IO 设备（因为内存中只能存放一道程序，在输入输出时，该道程序不能脱离内存来支持 IO 操作）而只需要 CPU计算。随着内存的增大和硬盘的出现以及容量的增大，此时出现了```多道程序```和```假脱机```技术。内存中可以：+ 驻留多道程序；+ 输入可以先输入到硬盘，然后再通过硬盘输入到内存；+ 输出则可以先输出到硬盘，然后再通过硬盘输出到设备。此处的硬盘相当于输入输出的```缓冲设备```。这就好像泉水一点点的涌出（如同慢速设备），而你需要一大桶水，需要你直接用桶去装，并且等着它满，那你多少回有点不耐烦，至少你会打开手机去做其他事情；这种情况，你不妨在泉水涌出的地方挖一个池子，下次你需要水的时候，提着桶一下就可以打满了（甚至可能打好几桶水），而这一切你不再需要等待，这就是池子作为```缓冲```作用带来的好处。于是 CPU 就从输入输出中解放出来了。那 CPU 多出的时间用来干嘛呢？不妨让正在输入输出的程序脱离 CPU 的控制，将 CPU 让给同时驻留在内存中的其他程序。你可能会问，输入输出设备不是还被占用着么？其实，不同的程序需要的设备不一样，同一设备使用的时间长短和频次也不一样，计算和输入输出的时间比例也不一样，甚至同一个程序中使用设备的先后顺序无关紧要（这使改变程序使用设备的次序成为可能）。这样就极有可能找到一种方法，使这些过程穿插进行，提高设备和 CPU 的使用效率。比如 A 程序正在占用打印机进行输出，那么 B 程序就可以同时用 CPU 进行计算和使用显示器进行输出。可见，CPU 与设备之间、不同的设备之间、不同的程序之间是可以并行的。前面还是出现了一个低效的问题：一个设备自始至终只能由一个程序使用，除非它主动放弃。那需要使用该设备的其他用户就会等得不耐烦，这是就对在前面的空间并行（不同设备之间）的基础上提出了时间分段使用设备的需求，即不同用户不同程序可以在一个时间段的不同时间片中使用同一设备，此时用户就会感觉自己的程序也同时再跑，而且不断地输出结果，这就是```分时系统```。```分时系统```虽然提高了程序的响应时间和减少了等待时间，但是增加了程序从开始执行到完成时所需要的时间，因为其中一段时间中该程序只能使用一小片时间，这必然比程序独占所有设备完成任务的时间要长，从而推迟了任务完成的时间。有些紧急用户就等不及了，便要求：我的任务必须在某某时间前完成，即提出了```时间截```的要求，于是```实时系统```应运而生。后来，随着计算机的普及，不同人使用计算机的时间不同，这就导致有的人的计算机性能不能满足要求（毕竟提高单机的性能代价太高），而有的人的计算机则太空闲了。于是人们想到：能不能把不同人的计算机，不同地域的计算机都用起来以共同完成一项任务，这样就可能充分的利用闲散的计算机软硬件资源，同时降低对单机性能的要求，并降低成本。此时```网络操作系统```和```分布式操作系统```就出现了。## 进程简史没有操作系统的那个时候还没有进程这个概念，因为根本不需要，反正一道程序或作业霸占所有软硬件资源，此时的程序可以直接操作硬件资源（包括内存等），有时甚至需要人工观察程序的进度，适时的打开相应设备的开关。随着监督程序的出现和程序的完全自动化，进入到了```批处理系统```时代，出现了```作业```的概念。作业把用户任务的提交、执行到完成并输出结果看成一个整体，其输入、执行、输出可以单独进行，但输入（需要在输入队列中等待）、执行、输出（需要在输出队列中等待）的每一个阶段中都不可中断，也就是说，某个作业一旦占用某个设备，必须等它用完之后，其他程序才能用，中间不允许作业之间穿插使用。之后```多道程序设计```、```假脱机技术```、```中断技术```的出现改变了作业独占设备的特性，使得有些设备可以被多个作业交替穿插使用。不过也带来了管理上的难度，之前设备只需要两个状态（忙、空闲）就可以了，但是现在还需要记录“忙”的时候是被那个程序占用，当 A 程序被 B 程序抢占时，A 程序执行到哪里，此时设备的各个部件的状态是怎么样的等等都需要记录下来，以便再次执行 A 程序时能够恢复到原来的状态。不仅如此，CPU 也可以被抢占、内存中不再只有一道程序，程序在内存的物理地址不再总是从零开始。所以 CPU的状态和程序在内存中的位置都需要记录，有时需要```换人换出```等还需要记录被换出到硬盘中的位置，如此多的信息需要记录和处理，之前的```作业```概念已经不够用了。而且程序在内存中走走停停，需要不断的保护现场和恢复现场、不同用户对不同程序的要求不一样（有的要求尽快完成、有的要求尽快响应、有的要求尽可能的节约费用等），这就需要在管理好如此多的信息的基础上不断优化调度，实现设备利用率和用户满意度最大化。```作业```这个模型要求程序要么不执行要么执行完成，不能中断或暂停，这显然不再适应引入了```多道程序和中断技术```而允许程序执行过程中走走停停的系统。于是提出了```进程```模型。进程可以简单理解城```进行中的程序```（程序已经开始执行，但还没有完成）。相比```作业```而言，```进程```把```作业```中的执行过程从作业输入队列和作业输出队列中脱离开来，单独把作业的执行作为研究对象，并把该执行过程进一步分解成可以并发或并行的子过程，以便进一步提高 CPU、内存、其他输入输出设备等的利用率和吞吐量。# 进程相关的数据结构这里不会详细列出进程相关的数据结构，只是粗略谈谈其应有的数据成分。上一节讲了```进程简史```，应该对进程提出时的北京有所了解了。进程是在```多道程序和中断技术```得到应用的情况下提出的。后面将基于这个事实展开讨论。## 进程如何应对“多道程序”所谓```多道程序```，可以简单理解成：*多道程序同时驻留内存并可在同一时间段并发执行*。可见，多道程序必将共享“之前只能一道程序独享的所有软硬件资源”，当然一般而言，所有设备同一时刻只能供一道程序使用，只不过多道程序可以在不同时刻使用同一资源、同一时刻使用不同资源、同一时刻使用同一资源的不同部分。&gt; 为支持“多道程序”，也就是支持```进程```模型，需要哪些数据结构或数据字段呢？值得注意的是，```进程```由```作业```进化而来，按照用户的观点而言，不论你采用作业还是进程模型都不应该影响到任务的执行和完成，换句话说，```进程```至少应该带给用户与```作业```模型相同的体验，甚至更好的体验。```作业```独占内存和处理机及其他资源，所以只要程序和程序的执行环境一定，其结果必须是确定的，而且结果和程序及其所属用户是对应起来的，也就是说，用户要结果的时候，能够从众多用户和程序中识别出来。前面已经提及过了，```进程```和```作业```的执行环境是不同的，但是至少要达到没有引入进程之前相同的效果。以下讨论要达到相同效果应具备的条件：+ 用户角度：用户在多道程序多用户的环境下，需要识别出属于本用户的进程及其统计信息（以便付费、改善程序或者找出程序中的错误），并且需要保证本用户的程序和数据不被其他用户使用（安全性要求）。这就需要```进程标识符```来区分和归类进程，以根据不同的进程做不同的处理（比如实施不同的安全策略），还需要一些```记账信息```（比如使用了哪些设备，执行了多长时间等，以便计费）。+ 管理者角度：不同的用户有不同的需求，由于资源有限，管理者需要根据不同的需求和资源情况给出不同的对待方式（如哪一个用户的程序优先执行，哪一个进程优先使用打印机等），以便尽量使更多的用户更满意，同时使资源的利用率更高。这就需要给不同的进程和设备设定不同的```优先级```等以便对进程、处理机和资源进行调配，而且需要根据情况使用不同的调度策略等，这就需要给出```进程调度信息```。内存中同时存在多道程序，需要共享处理机和其他资源，那就需要记录处理机的状态和资源状态，以便根据状态结合进程的请求来分配处理机和资源，这就需要给出```处理机状态```和```资源分配信息```。当进程使用完处理机和资源后则需要回收，这也需要登记已回收资源以便重新调度资源。同时需要记录资源被使用情况，以便计费或下次运行相同或类似程序时提供优化的可能。有时候需要满足特殊用户特别紧急的需要，不得不抢占处理机或其他资源，这就需要保存中断时被抢断进程执行到的位置信息和处理机信息以及其他被抢断设备的状态信息，即```保护现场```，等呗抢断的进程需要再度被执行时，则需要```恢复现场```。这种```进程切换```需要```进程控制信息```的支持。有时，用户为了抢占更多的资源以更快的完成任务，会把一个程序分解城多个进程来执行（毕竟进程是操作系统的分配资源的基本单位，这样一个用户）或者虽然提交的是一个进程，但是该进程又创建了一个进程。管理者需要识别出这种情况，也就是说，管理者需要识别并记录进程之间的关系，以便更好的调度，同时尽可能地节约资源完成这些进程之间的通信。这需要```进程亲属关系信息``的支持。`可见，进程是用户之间、用户与管理者之间、管理者与资源之间博弈的结果。以上种种，都是为了让多道程序中的每道程序都好像自己独占所有资源一样（目的），而进程描述信息就是为了实现这一目的而添加的。这就好像“撒了一个谎，就要一千个谎来圆”一样（前面的目的就是第一个谎，而进程描述信息以及其他的配套设施就是后面的一千个谎 ^_^）。## 进程如何应对“中断技术”为了应对和更好的使用“中断技术”，进程需要记录中断时 CPU、内存及其他设备的状态信息以便中断返回或再次回到中断前的运行状态时恢复现场。中断包括```硬中断```和```软中断```，硬中断是硬件报告的状态信息，一般来说这种中断是不能屏蔽的，而软中断是进程报告其运行进度和请求的状态信息，这种中断是可以根据某种规则屏蔽的或者自行定制中断处理程序。```软中断```最有名的就是```信号机制```。&gt; 为更好的使用中断技术，演化出了```信号机制``````信号机制```的相关数据结构也被与进程关联起来，以支持虚拟终端（把终端也改造成了多个，让多用户多道程序误以为自己独占终端）。信号机制很多情况只面向特点的用户、用户组和特定的终端。硬件中断将会影响所有进程，而信号（```软中断```）则只影响特定的进程或特定范围内的进程。如果你是一个嵌入式开发者，很可能需要简化操作系统，因为嵌入式设备只需运行特定的少量进程，所以可以简化一下进程调度信息、信号机制等模块、数据结构或调度策略。设置你可以实现一个简单的操作系统用于该嵌入式设备。&gt; 兼容作业模型作业模型中有一张描述资源的全局表，进程模型为了兼容作业模型，同时为了统筹分配资源，也有一些全局性的记录资源情况的表格。这些信息是为了支持全局性的需求，比如，回答诸如“计算机的外部设备有哪些？”之类的存在性问题，它是进程资源分配的基础。## 进程组织方式上一节只谈到了如何区分进程，而没有说如何区分没有正在运行的程序和正在运行的程序（进程）。实际上，操作系统是以```进程控制块```（PCB）作为进程存在的唯一标志。PCB 实际上是上一节已经说过的进程描述信息的数据结构。操作系统管理进程和资源都是通过 PCB 来完成的。计算机在同一时段可能存在许多进程，也就意味着有许多 PCB，那这些 PCB 如何组织呢？PCB 的组织方式实际上就是进程的组织方式。进程组织起来的目的是为了更好更快地完成进程切换和调度，提高 CPU 和其他资源的利用率。而进程切换实际上就是进程状态的改变，因此进程的组织应根据进程的状态来进行，同时需要适应进程切换和调度算法。系统中有许多处于不同状态的进程，同时阻塞（进程的一个具体状态）的原因也可能各不相同，所以需要不同的队列将它们组织起来，以便对所有进程进行有效管理。这就需要适当的方式将 PCB 组织 起来。有三种通用的队列组织方式：线性方式、链接方式和索引方式。+ 线性方式：把所有进程的 PCB 都放在一个线性表中。该线性表是静态分配空间。为了采用某种调度算法，必须扫描整个线性表，从而降低了调度效率。这种方式适合状态多或切换时机多但进程少的情况。+ 链接方式：根据不同的进程状态和阻塞原因或其他某种特定需求（如优先级，每个优先级一个队列）分成不同的队列。从而减少了每次扫描的 PCB 数，提高了灵活性和效率。灰机上，只要组织恰当，只需要在队列两端操作即可，不需要扫描。这种方式适合进程多且进程切换时机相对较少的情况。+ 索引方式：索引方式是线性方式的一种改进，结合了链接方式的优点。可以认为索引方式是用静态链表的方式来实现的链接方式。这种方式可以结合“链接方式”以实现更快速的定位，例如操作系统如果打算只支持 128 个优先级，那么就可以将 128 个队列的队头存入有 128 个单元的数组（线性表）中（实质上是一种哈希表），如此便可以随机定位到队头（如果该队列给出了尾指针，也可以随机定位到队尾），那么此时所有队列的所有操作的时间复杂度就是 O(1)。这种方式适合进程多且进程切换时机也较多的情况。&gt; 前面说的组织方式是针对 PCB 之间的，那 PCB 内部该如何组织诸多的项目呢？随着外部设备和 CPU 数目的增加以及各种需求的增加，导致描述进程的数据项越来越多，有的操作系统一个 PCB 就占了上 k 的内存，有几百个数据项。如此多的数据项，如果不组织好的话，很难适应变化着的需求，也不能客观反映进程间和需求间的关系。比如许多进程同属于一个用户，安全控制策略相同，操作的数据相同而只是数据处理的方式不同等。这样就可以采取某种措施将可能相同的部分单独分离出来，然后不同的进程用一个指针指向它就可以了，并且增加一个计数，当没有指向它的进程时再释放这部分内存。也可以将经常需要访问的数据单独成为一部分，然后把所有进程的这部分以最快最适合的方式组织起来，换句话说，根据数据项本省的特点以及需求可以将 PCB 中的数据项分门别类，然后分别以最合适的方式组织起来，这使得以最低的代价应对快速变化的需求以及最真实最高效的反映客观规律成为可能。例如，在进程结束生命周期之后，其他进程需要统计有关该进程的一些信息，那就没有必要将 PCB 中的所有项都长期驻留在内存等待统计，只把需要的信息留下来即可，但是如果事先的 PCB没有把这些信息较好的组织起来，很有可能需要把这些信息重新拷贝到特定的区域，很显然太浪费时间了；要是一开始就合理的分离了这些信息，只需要保留这部分信息并保存指向存储这部分信息的指针即可。有些数据项只在进程执行的某个阶段有效，其他阶段已经失去了意义，其实针对这种情况，也可以把它们单独分离开来，然后组织起来，适时进行处理货释放，以便更大程度的节约资源和提高效率。不过值得提醒的是，这些高效方式很可能增加 PCB 的设计复杂度，有时需要权衡。# 进程的生命周期进程是操作系统分配处理机（当有线程概念的操作系统，则线程是处理机的分配单位）和其他资源（如内存）分配的基本单位。所以进程的生命周期与处理机和资源的申请、等待资源、拥有、被剥夺、放弃占有等行为和状态密切相关。## 进程状态进程的生命周期可以用进程的状态来描述，根据进程在执行过程中不同情况需要定义不同的状态。 三态模型：+ 运行态：进程正占用处理器。+ 就绪态：只缺处理器资源。+ 等待（阻塞）态：正在等待某个时间完成或资源空闲而不具备运行条件![进程三态模型](/assets/img/it_basic/OS/os_basic/os-basic-06.PNG) 五态模型在很多系统中，增加两个进程状态：新建态和终止态。+ 新建态：对应于进程被创建时的状态。又是将根据系统性能的要求或主存容量的限制推迟新建态进程的提交。创建进程需要两个步骤：&lt;br&gt;①为新进程分配所需资源，建立必要的管理信息；&lt;br&gt;②设置此进程为就绪态，等待被调度执行。+ 终止态：处于终止态的进程不再被调度执行，下一步将被系统撤销，最终从系统中消失。类似地，进程终止也要通过两个步骤实现：&lt;br&gt;①等待操作系统或相关进程进行善后处理（如抽取信息）；&lt;br&gt;②回收被占用的资源并由系统删除进程。 进程终止通常由下列条件引起：+ 正常退出（自愿的）；+ 出错退出（自愿的）；+ 严重错误（非自愿的）；+ 被其他进程杀死（非自愿的）。&gt; 具有挂起功能的进程状态很多系统引入了挂起状态。所谓挂起状态，实际上就是一种静止状态。一个进程被挂起之后，不管它是否在就绪状态，系统都不分配给它处理机。 引起挂起状态的原因：+ 终端用户的请求+ 父进程请求考察子进程的活动+ 系统负荷的需要：资源紧缺，挂起不重要的进程。+ 操作系统的需要：检查和统计运行中的资源使用情况。挂起状态又引入了两个新状态：挂起就绪态和挂起等待态。挂起就绪态表明进程具备运行条件，但目前在辅存中，只有当进程被兑换到主存时才能被调度执行；挂起等待态则表明进程正在等待某一事件发生且进程在辅存中。引进挂起状态后，进程状态可分为新建态、活动就绪态、运行、活动阻塞、静止就绪、静止阻塞和终止状态。![进程状态转换](/assets/img/it_basic/OS/os_basic/os-basic-07.PNG)## 进程上下文切换中断和异常是激活操作系统的仅有方法，它暂停当前运行进程的执行，把处理器切换至核心态，内核获得处理器的控制权之后，如果需要就可以实现进程切换。所以，进程切换必定在核心态而非用户态发生。这种切换通过核心栈来完成。 内核在下列情况会发生上下文切换：![内核上下文切换](/assets/img/it_basic/OS/os_basic/os-basic-08.PNG)进程在运行过程中执行系统调用、产生中断或异常时，操作系统从当前运行进程那里获得控制权，此后，进程切换可以在任何时刻发生。在执行进程上下文切换时，保存老进程的上下文且装入被保护的新进程的上下文，以便新进程运行。进程切换的实现步骤如下：![上下文切换步骤](/assets/img/it_basic/OS/os_basic/os-basic-09.PNG)*进程的切换会引起进程状态的改变，进程的切换也需要以进程现有的状态作为依据，并根据进程调度策略来切换进程*。从前面进程状态的描述和进程上下文切换中可以看出，进程切换的时机或引起进程切换的原因是不同的，这也是选取进程组织方式的一个参考因素，也使得程序员尽量为自己的进程尽可能地夺取资源的做法提供了可能。比如程序员可以通过合理安排申请和释放资源的时机、合理地利用多进程多线程等途径提高自身进程的竞争力。当然作为一个系统程序员，则需要尽可能地防止个别进程或用户多度消耗资源。这就引出了安全性问题和公平性问题：+ 安全问题：用户进程可能破坏或擅自侵占已分配给其他用户或进程的资源，导致其他用户的数据遭到窃取或损坏，甚至致使其他进程出现异常。更有甚者，有意或无意的破坏操作系统，从而破坏所有进程的执行环境，最后只能重启或重装系统。+ 公平问题：有的用户或进程为了尽快的执行完任务，会大量申请资源或长时间占有资源，导致其他用户或进程出现缺少运行的基本条件而长时间等待，这就失去了公平性，也不利于操作系统尽可能地提高资源利用率和改善大多数用户体验。为此，操作系统在进程切换的基础上引入了模式切换。## 进程模式切换进程模式切换，实际上就是处理器的模式切换，与进程上下文切换有关的是 CPU 模式切换，用户态和核心态之间的相互切换（称为“模式切换”），此时仍然在同一个进程中进行。仍在自己的上下文中执行。可见，进程不论是在核心态还是用户态，都是进程状态的延续，换句话说，进程在核心态执行时也可能出现进程上下文的切换，当然这种切换尽量避免为妙。 模式切换的步骤如下：![模式切换步骤](/assets/img/it_basic/OS/os_basic/os-basic-10.PNG)模式切换不同于进程切换，它不一定会引起进程状态的转换，在大多数情况下，也不一定引起进程切换，在完成系统调用服务或中断处理之后，可通过逆向模式切换来恢复被中断进程的运行。CPU 上所执行进程在任何时刻必定处于三个活动范围之内：![运行态不同情形](/assets/img/it_basic/OS/os_basic/os-basic-11.PNG)# 进程间竞合关系进程有自己的地址空间和所需资源等私有资源，在某个时间这是排他性质的，但计算机总的系统资源是有限的，这导致了进程间的竞争关系；而有些资源可以在时间和空间上实现共享，以便减少拷贝（如共享内存）和设备数量（如虚拟终端），由于资源是操作系统垄断和管理的，所以需要操作系统作为中间人提供共享服务；同时进程间有时需要共同完成某些任务，必然需要同步，这时操作系统需要提供同步信号传递服务。## 进程间关系由于多道程序技术、多处理技术、分布式处理技术等导致了进程并发，并且并发会在不同的上下文中出现：+ 多个应用程序；+ 同一个应用程序内部；+ 操作系统自身内部。支持并发进程必需解决进程间的同步、互斥和通信问题。并发在单处理机上表现为进程的交替执行，在多处理机上表现为重叠执行。并发必然要求资源共享，共享的资源包括全局数据、硬件软件资源等，而且对共享资源的访问或读写顺序不同可能得到的结果也不同。所以，需要操作系统控制好进程对资源的互斥访问和顺序访问。 并发带来的困难：+ 全局资源的共享充满了危险，不同进程使用的时机不同，资源被使用的前后状态也不同。+ 操作系统很难对资源进行最优化分配，可能导致死锁。+ 定位程序设计错误是非常困难的。这是因为结果通常是不确定的和不可再现的。操作系统需要为并发做的工作如下：+ 记录各个活跃进程的状态，为进程的同步、互斥等管理工作收集信息。+ 为每个活跃进程分配和释放各种资源。+ 必须保护每个进程的数据和物理资源。+ 保证一个进程的功能和输出结果与执行速度无关。### 进程的交互![进程的交互](/assets/img/it_basic/OS/os_basic/os-basic-34.PNG)实际情况并不总是像上表中给出的那么清晰，多个进程可能既表现出竞争，又表现出合作。### 临界资源竞争进程面临三个控制问题（互斥、死锁和饥饿）。首先是互斥的要求。这涉及到不可共享或同时访问的资源互斥访问问题。该类资源称之为```临界资源```。不论硬件临界资源，还是软件临界资源，多个进程必需互斥对其进行访问。每个进程中访问临界资源的那段代码称为```临界区```。所以，若能保证各进程互斥地进入临界区，便可实现各进程对临界资源的互斥访问。为此，必须在临界区前面增加一段用于检查临界资源是否在使用的代码，该段代码称为“```进入区```”；相应地，在临界区后面再加一段用于设置刚用完临界资源的状态，以便临界资源被其他进程使用的代码，该代码称为“```退出区```”，其他部分代码称为“```剩余区```”。### 进程同步机制进程同步是指有协作关系的进程之间不断地调整它们之间的相对速度或执行过程，以保证临界资源的合理利用和进程的顺利执行。实现进程同步的机制称为进程同步机制。&gt; 同步机制应遵循的规则：为实现进程互斥地进入自己的临界区，可用软件或硬件方法。不过所有同步机构都应遵循下列准则：+ 空闲让进；+ 忙则等待；+ 有限等待；+ 让权等待：当进程不能进入自己的临界区时，应立即释放处理机。&gt; 实现临界区管理的设施 硬件设施：+ 关中断：在多处理机环境下，很难有效工作。+ 专用机器指令：用于保证两个动作的原子性。 * 如比较和交换指令（使用了忙等待或者自旋等待）。```忙等待```或```自旋等待```指的是这样一种技术：进程在得到临界区访问权之前，它只能继续执行测试变量的指令来得到访问权，除此之外不能做其他事情。![机器指令方法的特点](/assets/img/it_basic/OS/os_basic/os-basic-35.PNG) 软件算法实现互斥+ 锁机制：实现互斥的一种软件方法是采用锁机制，即提供一对上锁和开锁原语，以及一个锁变量 w 或者是锁位。进入临界区之前不断地检测 w 的状态，若没有上锁则进入临界区，否则继续测试 w 的状态；进入后上锁，退出时开锁。+ 信号量机制信号量机制是一种广义的锁机制或者成为计数锁的同步机制，既能解决互斥，又能解决同步。后来发展成了 P 操作（原语）和 V 操作（原语）。P 操作用于检测和申请临界资源，V 操作用于释放临界资源。```信号量```也叫信号灯，是在信号量同步机制中用于实现进程的同步和互斥的有效数据结构。可以为每类资源设置一个信号量。信号量有多种类型的数据结构，如整型信号量，记录型信号量、AND 型信号量及信号量集等。 信号量类型举例：+ 整型信号量：它是信号量的最简单的类型，也是各种信号量类型中必须包含的类型。整型信号量的数值表示当前系统中可用的该类临界资源的数量。如，![整型信号量](/assets/img/it_basic/OS/os_basic/os-basic-36.PNG)+ 记录型信号量![记录型信号量](/assets/img/it_basic/OS/os_basic/os-basic-37.PNG)![记录型信号量](/assets/img/it_basic/OS/os_basic/os-basic-38.PNG)+ AND 型信号量AND 同步机制的基本思想是将进程在整个运行过程中需要的所有资源，一次性全部分配给进程，待进程使用完成后再一起释放。只要有一个资源尚未分配给进程，其他所有可能分配的资源也不能分配给它。 AND 型信号量集机制可描述如下：![AND 型信号量](/assets/img/it_basic/OS/os_basic/os-basic-39.PNG)+ 信号量集如果某进程一次需要 N 个某类资源时，就要进行 N 次 wait 操作，这使系统的效率较低，有可能造成死锁。![信号量集](/assets/img/it_basic/OS/os_basic/os-basic-40.PNG) 信号量实现互斥：![信号量实现互斥](/assets/img/it_basic/OS/os_basic/os-basic-41.PNG)### 经典同步问题&gt; 生产--消费者问题+ 问题的描述：![生产消费者问题描述](/assets/img/it_basic/OS/os_basic/os-basic-42.PNG)+ 问题的分析：![生产消费者问题分析](/assets/img/it_basic/OS/os_basic/os-basic-43.PNG)![生产消费者问题分析](/assets/img/it_basic/OS/os_basic/os-basic-44.PNG)+ 算法程序：![生产消费者问题算法](/assets/img/it_basic/OS/os_basic/os-basic-45.PNG)![生产消费者问题算法](/assets/img/it_basic/OS/os_basic/os-basic-46.PNG)![生产消费者问题算法](/assets/img/it_basic/OS/os_basic/os-basic-47.PNG)+ 注意事项：![生产消费者问题注意事项](/assets/img/it_basic/OS/os_basic/os-basic-48.PNG)![生产消费者问题注意事项](/assets/img/it_basic/OS/os_basic/os-basic-49.PNG)&gt; 读者--写者问题+ 问题的提出：![读者歇者问题提出](/assets/img/it_basic/OS/os_basic/os-basic-50.PNG)+ 问题的分析：![读者歇者问题分析](/assets/img/it_basic/OS/os_basic/os-basic-51.PNG)![读者歇者问题分析](/assets/img/it_basic/OS/os_basic/os-basic-52.PNG)![读者歇者问题分析](/assets/img/it_basic/OS/os_basic/os-basic-53.PNG)+ 算法程序：![读者歇者问题算法](/assets/img/it_basic/OS/os_basic/os-basic-54.PNG)![读者歇者问题算法](/assets/img/it_basic/OS/os_basic/os-basic-55.PNG)![读者歇者问题算法](/assets/img/it_basic/OS/os_basic/os-basic-56.PNG)+ 注意事项：![读者歇者问题注意事项](/assets/img/it_basic/OS/os_basic/os-basic-57.PNG)&gt; 哲学家进餐问题+ 问题的提出：![哲学家进餐问题的提出](/assets/img/it_basic/OS/os_basic/os-basic-58.PNG)+ 问题的分析：![哲学家进餐问题的分析](/assets/img/it_basic/OS/os_basic/os-basic-59.PNG)+ 算法程序：![哲学家进餐问题的算法](/assets/img/it_basic/OS/os_basic/os-basic-60.PNG)+ 其他算法：![哲学家进餐问题的其他算法](/assets/img/it_basic/OS/os_basic/os-basic-61.PNG)&gt; 理发师问题+ 问题提出：![理发师问题的提出](/assets/img/it_basic/OS/os_basic/os-basic-62.PNG)+ 问题分析：![理发师问题的分析](/assets/img/it_basic/OS/os_basic/os-basic-63.PNG)+ 算法程序：![理发师的算法程序](/assets/img/it_basic/OS/os_basic/os-basic-64.PNG)### 管程（进程高级同步）虽然 PV 操作可以解决进程间的同步互斥问题，但用于同步互斥的共享变量及信号量的操作被分散于各个进程中，它是否能达到同步互斥的功能还需要依靠程序员的正确编写。 PV 同步机制的缺点：+ 易读性差：因为要了解对于一组共享变量及信号量的操作是否正确，则必须通读整个系统或者并发程序。+ 不利于修改和维护：因为程序的局部性很差，所以任一组变量或一段代码的修改都可能影响全局。+ 正确性难以保证：因为操作系统或并发程序通常很大，要保证这样一个复杂的系统没有逻辑错误是很难的。为了克服 PV 同步机制的缺点，提出了管程的概念。&gt; 管程定义：管程是一种抽象数据类型。它将描述共享资源的数据（私有数据）及操作这些数据的一组过程或方法（公有，当需要通过\"管程名.方法名\"的方式调用，不过也有内部函数，只允许管程方法使用，对外部隐藏）封装在一个具有名字的对象中。该对象可以引用外部方法或变量。可见管程是用于管理资源的公用数据结构（而进程是占有资源的私有数据结构），管程和调用它的进程不能同时工作（而进程之间可以并发），而且管程是语言或操作系统的成分，不必创建和撤销。&gt; 管程组成：+ 名称：即，管程名称。对不同类的共享资源可能有不同管程，而且也需要引用管程名来调用其中的方法。+ 数据结构说明：局部于管程的共享变量说明，也是该管程所管理的共享资源的清单。+ 对该数据结构进行操作的一组过程/函数+ 初始化语句：规定数据结构中数据的初始值。&gt; 管程的属性：+ 共享性：通过调用管程的过程或方法进行共享。+ 安全性：管程内变量（私有变量）只允许管程的过程访问。+ 互斥性：任一时刻最多只有一个调用者能真正引入管程，其他进程将在管程入口处等待。+ 易用性：进入管程的互斥由编译器负责，从而减轻了写管程的程序员工作。![莞城](/assets/img/it_basic/OS/os_basic/os-basic-65.PNG)&gt; 管程基本形式：![管程的基本形式](/assets/img/it_basic/OS/os_basic/os-basic-66.PNG) 具体例子：![管程的具体例子](/assets/img/it_basic/OS/os_basic/os-basic-67.PNG)&gt; 条件变量：前面提到的管程（并不完整）实现了临界资源的正常进入和退出，但没有考虑临界区内因为某种原因必须中途暂时退出的情况。也就是说，还需要一种方法使得进程在临界区内其他资源不能满足而无法继续运行时被阻塞，等条件满足之后再次运行。而```条件变量```同步机制，以及在其上操作的仅有的两个同步原语 wait 和 signal 的引入就是为了解决这一问题。当进程中途等待资源时将被加入资源等待队列（称为```紧急等待队列```），该队列由相应的条件变量维护，资源等待队列可以有多个，每种资源一个队列。紧急等待队列的优先级应当高于```入口等待队列```的优先级。+ 当一个管程过程发现无法继续执行下去时，它将在相应的条件变量上执行 wait ，这个操作引起调用进程阻塞；当然，这是允许先前被挡在管程之外的一个进程进入管程。+ 另一个进程可以通过对其伙伴在等待的同一个条件变量上执行 signal 操作来唤醒等待进程。+ wait 和 signal 是两条原语，在执行时不允许被中断。它们分别表示把某个进程加入等待使用资源的条件变量的等待队列，从等待资源的条件变量的等待队列上释放一个进程。+ 当执行 wait 之后，相应的进程被置成等待状态，同时开放管程，允许其他进程调用管程中的过程或方法。+ 当执行 signal 之后，指定条件变量上的一个进程被释放。某个进程（P）在管程内运行时可能中途释放某个条件变量（及时尽早释放临界资源和条件变量的原则），这将唤醒等待该条件变量的等待队列队首进程（Q），按照条件变量机制，该被唤醒的进程将再次进入管程（P 仍在管程内），很显然是不允许。可采用两种方法来防止这种现象的出现。+ 进程 P 释放管程转为等待直至进程 Q 退出管程，或者进程 Q 等待另一条件（中途又被阻塞）；+ 进程 Q 等待直至进程 P 退出管程（类似“非剥夺式”），或者进程 P 等待另一个条件（被阻塞）；+ 规定唤醒为管程中最后一个可执行的操作（即，最后统一释放所有的条件变量，统一唤醒）。霍尔采用了第一种办法，而汉森选择了第三种方法，进程执行 signal 操作后立即退出管程，因而，进程 Q 马上被恢复执行。 注意事项：虽然条件变量也是一种信号量，但它并不是 P、V 操作中所论述的纯粹计数信号量，不能像信号量那样积累供以后使用，仅仅起到维护等待进程队列的作用。当一个条件变量上不存在等待条件变量的进程时，signal 操作发出的信号将丢失，等于做了一次空操作。wait 操作一般应在 signal 操作之前发出，这一规则大大简化了实现。&gt; 管程实现互斥和同步+ 互斥：进入管程的互斥由编译器负责，写管程的人无需关心。+ 同步：管程实现同步，需设置：![管程实现同步](/assets/img/it_basic/OS/os_basic/os-basic-68.PNG)![管程实现同步](/assets/img/it_basic/OS/os_basic/os-basic-69.PNG) 具体例子：+ 生产者消费者问题：![管程解决生产者消费者问题](/assets/img/it_basic/OS/os_basic/os-basic-70.PNG)![管程解决生产者消费者问题](/assets/img/it_basic/OS/os_basic/os-basic-71.PNG)+ 哲学家用餐问题：![哲学家进餐问题](/assets/img/it_basic/OS/os_basic/os-basic-72.PNG)![哲学家进餐问题](/assets/img/it_basic/OS/os_basic/os-basic-73.PNG)![哲学家进餐问题](/assets/img/it_basic/OS/os_basic/os-basic-74.PNG)![哲学家进餐问题](/assets/img/it_basic/OS/os_basic/os-basic-75.PNG)![哲学家进餐问题](/assets/img/it_basic/OS/os_basic/os-basic-76.PNG)+ 读者写者问题：![读者写者问题](/assets/img/it_basic/OS/os_basic/os-basic-77.PNG)![读者写者问题](/assets/img/it_basic/OS/os_basic/os-basic-78.PNG)![读者写者问题](/assets/img/it_basic/OS/os_basic/os-basic-79.PNG)![读者写者问题](/assets/img/it_basic/OS/os_basic/os-basic-80.PNG)![读者写者问题](/assets/img/it_basic/OS/os_basic/os-basic-81.PNG)除了前面说过的进程同步互斥机制外，有些操作系统还支持原子事务。对于事务的细节可以参考数据库原理。而且消息传递机制（参本文后面章节）也可以解决进程互斥和同步问题。## 进程通信进程之间互相交换信息的工作成为```进程通信```。通信分为两大类：低级通信和高级通信。+ 低级通信将进程间控制信息的交换称为```低级通信```，如信号量通信机制、信号通信机制。+ 高级通信：进程之间大批量数据的交换称为```高级通信```。 通信方式列举：+ 信号通信机制；+ 信号量通信机制；+ 管道通信机制；+ 消息传递通信机制；+ 共享主存通信机制；+ 网络进程通信机制。### 信号通信机制信号是一种软终端，是传递短消息的简单通信机制，通过发送指定信号来通知进程某个异步事件发生，以迫使进程执行信号处理程序（在用户态下执行）。信号处理完毕后，被中断进程将恢复执行。一般地，分成操作系统标准信号和应用进程定义信号，这种机制模拟硬中断，但部分优先级，简单且有效，但不能传送数据，故能力较弱。![信号通信机制](/assets/img/it_basic/OS/os_basic/os-basic-82.PNG)### 管道通信机制```管道```是指用于连接一个读进程和一个写进程，以实现它们之间通信的一个共享文件（又名“pipe 文件”）。向管道（共享文件）提供输入的发送进程（写进程），以字符流的形式将大量的数据送入管道；而接收管道输出的接收进程（“读进程”），则从管道接收（读）数据。由于发送进程和接收进程是利用管道进行通信的，故称为```管道通信```。 管道通信必须提供以下能力：+ 互斥：即当一个进程正在对 pipe 执行读/写操作时，其他进程必需等待。+ 同步：同步是指，当写（输入）进程把一定数量的数据写入 pipe，便去等待，直到读（输出）进程取走数据后，再把它唤醒；当读进程读一空 pipe 时，也应睡眠等待，直至写进程将数据写入管道后才将之唤醒。![pipe 通信](/assets/img/it_basic/OS/os_basic/os-basic-83.PNG)管道是一种功能机制很强的通信机制，但仅用于连接具有共同祖先的进程，使用时需要临时建立，难以提供全局服务。为了克服这些缺点， UNIX 推出管道的一个变种，称为```有名管道```或```FIFO 通信机制```，用来在不同的地址空间之间进行通信，特别为服务器通过网络与多个客户进行交互而设计。### 共享主存通信机制共享存储通信有两种方式：+ 基于共享数据结构的通信方式：公用数据结构的设置及对进程间同步的处理，都是程序员的职责，而操作系统只需提供共享存储器。因此，通信效率低，只适用于传递相对少量的数据。+ 基于共享存储区的通信方式：进程在通信钱，先向系统申请获得共享存储区中的一个分区，并指定该分区的关键字：若系统已经给其他进程分配了这样的分区，则将该分区的描述符返回给申请者，然后，由申请者把获得的共享存储区连接到本进程上；此后，便可以像读写普通存储器一样访问该公用存储分区。实际上，很多系统可以通过系统调用来操控共享分区。![共享主存通信](/assets/img/it_basic/OS/os_basic/os-basic-84.PNG)### 消息传递机制不论单机系统、多机系统还是计算机网络，消息传递机制都是应用最为广泛的一种进程间通信的机制。在消息传递系统中，进程间的数据交换是以格式化的消息（Message）为单位的；在计算机网络中，又把 Message 称为报文。程序员直接利用系统提供的一组通信命令进行通信。操作系统隐藏了实现通信的细节，提高了透明性，因而获得了较为广泛的使用。因实现方式不同可分为直接通信方式和间接通信方式。+ 直接通信方式：这种通信固定在一对进程之间。+ 间接通信方式：又称为“```信箱通信```”方式。信箱是一种数据结构，逻辑上可分为信箱头和信箱体两部分。+ 信箱头包含信箱体的结构信息以及多进程共享信箱体时的同步互斥信息。+ 信箱体由多个格子构成，它实际上就是一个有界缓冲器。信箱通信的同步、互斥方式与生产者消费者问题的方式类似。它一般是进程之间的双向通信。消息传递的复杂性在于：地址空间的隔离，发送进程无法将消息直接复制到接收进程的地址空间中，这项工作只能由操作系统来完成。为此，消息传递机制至少需要提供两条原语 send 和 receive。为了实现异步通信，必须采用简洁的通信方式。简洁通信解除了发送进程和接收进程之间的直接联系，在消息的使用上加大了灵活性。一个进程可以分别与多个进程共享信箱。于是，一个进程可以同时和多个进程通信，一对一关系允许在两个进程间建立不受干扰的专用通信链接；多对一关系对客户服务器间的交互非常有用；一个进程为其他进程提供服务，这时的信箱又称为```端口```，端口通常划归接收进程所有并由接收进程创建，服务进程被撤销时，其端口也随之消失。当然还有多对多关系的公用信箱。&gt; 信箱的设置：信箱可以在用户空间或系统空间开辟。+ 用户空间信箱：创建者进程撤销时，信箱也随之消失，这时必须通知所有使用者。+ 系统空间设置公用信箱：可以充分利用预留空间（如果在系统空间内分别开辟私有空间则很难确定分配多大，当然可以延迟到接收时分配）。&gt; 通信进程的同步两个进程间的消息通信就隐含着某种程度的同步，当发送进程执行 send 发出消息后，本身执行可分为两种情况：+ 同步的（阻塞型），等待接收进程回答消息后才继续进行；+ 异步的（非阻塞型），将消息传送到接收进程的信箱中，允许继续运行，直到某个时刻需要接收进程送来回答消息（如信箱已满）时，才查询和处理。对于接收进程而言，执行 receive 后也可以是阻塞型和非阻塞型，前者指直到消息交付完成（一有消息就要停下来接收消息）它都处于等待消息的状态；后者则不要求接收进程等待，当他需要消息时，再接收并处理消息。&gt; 消息传递机制解决进程的互斥和同步问题+ 解决进程互斥问题![解决互斥问题](/assets/img/it_basic/OS/os_basic/os-basic-86.PNG)![解决互斥问题](/assets/img/it_basic/OS/os_basic/os-basic-87.PNG)+ 解决同步问题：生产者消费者问题的一种解法![解决同步问题](/assets/img/it_basic/OS/os_basic/os-basic-88.PNG)![解决同步问题](/assets/img/it_basic/OS/os_basic/os-basic-89.PNG)![解决同步问题](/assets/img/it_basic/OS/os_basic/os-basic-90.PNG)![解决同步问题](/assets/img/it_basic/OS/os_basic/os-basic-91.PNG)![解决同步问题](/assets/img/it_basic/OS/os_basic/os-basic-92.PNG)### 消息缓冲队列通信机制![消息缓冲队列](/assets/img/it_basic/OS/os_basic/os-basic-93.PNG)![消息缓冲队列](/assets/img/it_basic/OS/os_basic/os-basic-94.PNG)![消息缓冲队列](/assets/img/it_basic/OS/os_basic/os-basic-95.PNG)![消息缓冲队列](/assets/img/it_basic/OS/os_basic/os-basic-96.PNG)# 进程调度这里所说的```进程调度```（进程切换的时机和策略）可以认为是```处理机调度```，在没有线程概念的操作系统中，处理机调度的单位是进程，而有```线程```概念或```轻量级进程```概念的操作系统中，处理机调度的单位是线程。所以有必要讨论下线程。## 线程如果说操作系统中引入进程的目的是为了使多个程序并发执行，以便改善资源利用率和提高系统效率，那么，在进程之后再引入线程的概念，则是为了减少程序并发执行（进程切换）时所付出的时空开销，使得并发粒度更细，并发性更好。此时，进程成为了独立分配资源的基本单位，无须频繁地切换；而线程则作为系统（处理机）调度和分派的基本单位，会被频繁地调度和切换。进一步产生了多线程进程。 线程和进程的比较如下：![线程和进程对比](/assets/img/it_basic/OS/os_basic/os-basic-12.PNG)![多线程](/assets/img/it_basic/OS/os_basic/os-basic-13.PNG) 线程的组成部分有：![线程组成部分](/assets/img/it_basic/OS/os_basic/os-basic-14.PNG)![进程和线程任务分配](/assets/img/it_basic/OS/os_basic/os-basic-15.PNG) 线程的状态：线程和进程一样，也有自己的状态。线程有 3 种基本状态，即执行、阻塞和就绪，但没有挂起（由于线程不是资源的拥有单位，挂起状态对于线程是没有意义的）。进程中可能有多个线程，至于单个线程是否要阻塞整个进程取决于系统实现。有的系统只有所有的线程都阻塞之后才阻塞整个进程（这种方式更能体现多线程的优越性）。 线程切换：针对线程的 3 种基本状态，存在 5 种基本操作来转换线程的状态。+ 派生：线程在进程中派生出来，也可再派生线程。+ 调度；+ 阻塞；+ 激活；+ 结束。&gt; 多线程程序设计的优点![多线程优点](/assets/img/it_basic/OS/os_basic/os-basic-16.PNG)![多线程优点](/assets/img/it_basic/OS/os_basic/os-basic-17.PNG)&gt; 线程的组织![线程的组织](/assets/img/it_basic/OS/os_basic/os-basic-18.PNG)&gt; 多线程实现多线程的实现分为三类：用户级线程（ULT）、内核级线程（KLT）或者混合方式。+ 用户级线程：其由用户应用程序建立，并由用户应用程序负责调度和管理，操作系统内核不知道有用户级线程的存在。 ULT 的优点：![ULT 的优点](/assets/img/it_basic/OS/os_basic/os-basic-19.PNG) ULT 的缺点：![ULT 的缺点](/assets/img/it_basic/OS/os_basic/os-basic-20.PNG)+ 内核级线程：内核级线程中所有线程的创建、调度和管理全部由操作系统内核负责完成，一个应用程序可按多线程方式编写程序，其他交给内核处理。![KLT 的优缺点](/assets/img/it_basic/OS/os_basic/os-basic-21.PNG)多线程技术利用线程库提供一整套有关线程的过程调用或系统调用来支持多线程运行，有的操作系统直接支持多线程，有的语言则提供线程库。因而，线程库可分为用户空间线程库和内核空间库。线程库实际上是多线程应用程序的开发和运行环境。 多线程模型许多系统都提供对用户和内核线程的支持，从而有不同的多线程模型。以下是 3 种常用类型：+ 多对一模型该模型将许多用户线程映射到一个内核线程。详情请参看“用户级线程”。+ 一对一模型（参见“内核级线程”）+ 多对多模型多对多模型多路复用了许多用户线程到同样数量或更小数量的内核线程上。开发人员可创建任意多的必要用户线程，并且相应内核线程能在多处理器系统上并行执行。而且，当一个线程执行阻塞系统调用时，内核能调用另一个线程来执行。为了防止无限制的创建线程，可使用线程池。## 处理器调度某些进程花费了绝大多数时间在计算上（注意，某些 I/O 活动可以看做是计算），称之为“```计算密集型进程```”；而有些进程则在等待 I/O 上花费了绝大多数时间，称之为“```I/O 密集型进程```”。如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持始终忙碌。### 调度时机CPU 调度决策可以在如下四种环境下发生：![调度时机](/assets/img/it_basic/OS/os_basic/os-basic-22.PNG)### 分级调度一个批处理型作业，从进入系统并驻留在外存的后备队列上开始，直至作业运行完毕，可能要经历以下三级调度：作业调度、对换和进程调度。+ 高级调度其又称为```作业调度、长程调度```。用于选择把外存上处于后备队列中的哪些作业调入内存，并为它们创建进程、分配必要的资源，然后，再将新创建的进程排在就绪队列上，准备执行。高级调度控制多道程序的道数，被选择进入主存的作业越多，每个作业所获得的 CPU 时间就越少，所以有时为了满足某种特定需求，需要限制道数。每当有作业执行完毕并撤离时，作业调度会选择一个或多个作业补充进入主存。此外，如果 CPU 的空闲时间超过一定的阈值，系统也会引出作业调度选择后备作业。可见，高级调度负责作业的调入和撤离，与交换（对换或中级调度）有着很大的区别。![作业流程](/assets/img/it_basic/OS/os_basic/os-basic-29.PNG)+ 中级调度中级调度又称为“```平衡调度、中程调度```”，根据主存资源决定主存中所能容纳的进程数目，并根据进程的当前状态来决定辅助存储器和主存中的进程的对换。当主存资源紧缺时，会把暂时不能运行的进程换出主存，此时这个进程处于“挂起”状态，不参与低级调度；当进程具备运行条件且主存资源有空闲时，再将进程重新调回主存工作，起到短期均衡系统负载的作用，充分提高主存的利用率和系统吞吐率。+ 低级调度低级调度又称为```进程调度/线程调度、短程调度和微观调度```，其主要功能是：根据某种原则决定就绪队列中的哪个进程/内核级线程获得处理器，并将处理器出让给它还用。低级调度是操作系统最为核心的部分，执行十分频繁，其调度策略的优劣将直接影响整个系统的性能，因而，这部分代码要求精心设计，并常驻内存。 进程调度可分为如下两种方式：+ 非抢占方式：不允许进程抢占已经分配出去的处理机。该方式的优点是实现简单、系统开销小，适用于大多数的批处理系统环境。但它很难满足紧急任务的要求。因而可能造成难以预料的后果。显然，在要求比较严格的实时系统中，不宜采用这种调度方式。+ 抢占方式：抢占方式允许调度程序根据某种原则暂停某个正在执行的进程，将处理机收回，重新分配给另一个进程。抢占的原则有优先权原则、短作业（或进程）优先原则、时间片原则等。 各级调度的关系：![各级调度的关系](/assets/img/it_basic/OS/os_basic/os-basic-23.PNG)![各级调度的关系](/assets/img/it_basic/OS/os_basic/os-basic-24.PNG)![各级调度的关系](/assets/img/it_basic/OS/os_basic/os-basic-25.PNG)![各级调度的关系](/assets/img/it_basic/OS/os_basic/os-basic-26.PNG)![各级调度的关系](/assets/img/it_basic/OS/os_basic/os-basic-27.PNG)![各级调度的关系](/assets/img/it_basic/OS/os_basic/os-basic-28.PNG)## 调度算法的评价及准则在操作系统的设计中，如何选择作业调度及进程调度的方式和算法取决于操作系统的类型和目标。显然，根据不同的目标，会有不同的调度算法。 面向用户的准则：+ 公平性+ 周转时间短：周转时间是指，作业被提交给系统开始，到作业终止为止的这段时间间隔。+ 响应时间快：响应时间指的是，从用户提交一个作业请求开始，直至系统首次产生响应（如屏幕显示提示信息）为止的时间。+ 截止时间保证截止时间是指，某任务必须开始执行的最晚时间，或必须完成的最晚时间。 面向系统的准则：这是为了提高整个系统的效率。+ 系统的吞吐量：吞吐量是指，在单位时间内系统所完成的作业数，它与批处理作业的平均长度有密切关系。+ 处理机的利用率+ 各类资源的平衡利用。+ 尽量保持系统所有部分尽可能忙碌### 调度算法分类不同的环境需要不同的调度算法。![调度算法分类](/assets/img/it_basic/OS/os_basic/os-basic-30.PNG)### 调度机制从概念上来看，调度机制由 3 个逻辑功能程序模块组成：+ 队列管理程序+ 上下文切换程序+ 分派程序：转入上下文，开始执行获得 CPU 的进程。## 调度算法在操作系统中，存在多种调度算法，有的算法仅适用于作业调度，有的算法仅适用于进程/线程调度，但大多数调度算法对两者都适用。有的调度算法适合批处理系统或其他特定的系统，但一些算法既适合批处理系统也适合交互式系统等。### 批处理系统中的调度算法+ 先来先服务（FCFS）易于理解和实现，但没有考虑作业的特点和用户的实际需要，所以无法满足用户的大部分需求，也不能充分利用系统资源。不过，它是其他算法的基础，当各种条件都一样时，此时，就需要先来先服务原则来保证公平性。+ 最短作业优先（SJF）该算法一般是非抢占式的，所以这里的最短作业指的是，调度的当时是最短（虽然有时很难估计时间）的。而不是在该作业运行期间（如，后面又来了一个更短的作业）。+ 最短剩余时间优先：SRTF 和最短作业优先一样，有时该时间是很难预先知道的。+ 高响应比优先：HRN 调度算法为了克服短作业优先算法的缺点，采用了一种折中的方法，既让短作业优先，又考虑到系统内等待时间过长的作业。![高相应比](/assets/img/it_basic/OS/os_basic/os-basic-31.PNG)### 交互式系统中的调度下面的调度算法也可以用于批处理系统的调度器中，尽管三级调度不大可行，但两级调度是可行的。+ 时间片轮转调度：时间片设得太短会导致过多的进程切换开销；而设得太长有可能引起对短交互请求的响应变差。一般设为 20-50 ms。+ 优先级调度：优先级可以是静态的，也可以是动态的，系统和用户均可指定优先级。优先级调度可以是抢占式的，也可以是非抢占式的。不过，可能造成高优先级的进程无限制执行下去，而低优先级的进程处于饥饿状态，所以优先级标准和如何变化将会影响用户体验和系统性能。+ 多级反馈队列调度算法不论哪一种算法都无法满足不同的需要。为此，可以将不同的需求分到不同的队列中，而且不同的队列具有不同的优先级，不同队列中可以根据具体的需求采用最适合该队列的调度算法。而且进程根据不同的运行情况会被动态的分配到不同的队列中。此种算法称为“多级反馈队列调度算法 MLFQ ”或 “反馈循环队列”。可见，该算法中，同一个进程随着占用 CPU 的次数的增加，优先级在不断递减。MLFQ 调度算法具有较好的性能，能满足各类应用的需要。但仍会导致“饥饿”问题。例如，一个耗时很长的作业，最终将进入优先级最低的队列，然后，系统不断的进入新的作业，那么，该长作业就很难得到再运行的机会。为此，可以允许使用高响应比来提升优先级（通常只允许降低优先级）。+ 彩票调度算法其基本思想是：为进程/线程发放针对各种资源（如 CPU 时间）的彩票，当调度程序需要作出决策时，随机选择一张彩票，彩票的持有者将获得相应的系统资源。对于 CPU 调度，系统可能每秒钟抽取彩票 50 次，中奖者每次可以获得 20 ms 的运行时间。一般情况下，所有进程都是平等的，不过某些进程需要更多机会，所以需要得到额外的彩票以增加中奖的机会。进程拥有多少彩票份额，就能获得多少资源。合作进程如果愿意，可以交换彩票，以便相应进程得到更多的机会。可见，彩票调度法很灵活，而且反应非常迅速，因为中奖机会与其持有的彩票数成正比。+ 公平分享调度该算法考虑了进程的拥有者。主要应对不同作业拥有的进程数是不一样的情况，如果不考虑拥有者，则拥有更多进程的作业显然获得 CPU 时间更多。### 实时系统调度实时系统通常分为```硬实时```系统和```软实时```系统。前者意味着存在必须满足的时间限制；后者意味着偶尔超过时间限制是可以容忍的。实时系统根据响应的事件可进一步分为```周期性```（每隔一段固定时间发生）和```非周期性```（在不可预知的时间发生）。一个系统更可能必须响应多个周期的事件流。根据每个事件需要多长的处理时间，系统可能根本来不及处理所有事件。实时调度算法可以是静态的或动态的。前者在系统启动之前完成所有的调度决策；后者在运行时做出调度决策。如果使用静态调度算法，必须预先知道足够多的需要做的工作和必须满足的约束的时间信息。+ 单比率调度算法对于周期性事件，单比率调度是视周期长度而定的抢占式策略：周期越短，优先级越高。+ 限期调度算法当一个事件发生时，对应的实时进程就被加入就绪队列，此队列按照截止期限排序。对于周期性事件，截止期限即事件下一次发生的时间。系统检测队首截止期限是否比当前运行者早，以决定是否剥夺当前运行的进程资源。+ 最少裕度法![最少裕度法](/assets/img/it_basic/OS/os_basic/os-basic-32.PNG)### 多处理机调度算法多处理机调度的设计要点有 3 个：为进程分配处理机、在单个处理机上是否使用多道程序设计技术和实际指派进程的方法。+ 负载共享调度算法：进程并不被指派到特定的处理机上，系统维护全局性进程就绪队列，当处理机空闲时，就选择进程的一个线程去运行。可见，该算法没有考虑同一个进程的多个线程的同步和切换问题，因为具有同步和互斥等关系的线程很难被按照一定顺序执行，也不能保证被切换的进程在原有的处理机上再次执行，从而增加了切换开销。具体的负载共性调度算法有：先来先服务、最少线程数优先和剥夺式最少线程数优先等。+ 群调度算法其基本思想是：给予一对一原则，一群相关线程被同时调度到一组处理机上运行。紧密相关线程的并行执行能够减少同步阻塞，从而减少进程切换，降低调度代价。当进程的相关线程数小于处理机数时会造成处理机资源空闲。+ 专用处理机调度算法将同属于一个进程的一组线程同时分派到一组处理机上运行。是群调度的一种极端方式。不过该方式也会使有些处理机因线程等待事件阻塞时空闲。然而，对于数目很大的处理机群而言，个别处理机的使用率只是代价的一小部分，对整体影响不大。+ 动态调度算法针对能够动态改变线程数的应用程序。其基本思想是：由操作系统和应用进程共同作出调度决策，操作系统负责在应用进程之间分配处理机；应用进程所分配的处理机上执行可运行线程的子集，这些处理机如何分配到具体的线程完全是应用进程的任务，可借助于运行时库函数完成。![动态调度算法](/assets/img/it_basic/OS/os_basic/os-basic-33.PNG)&gt; 注意： 多处理机调度不宜采用复杂的调度算法， 复杂的调度算法意味着过多的时间开销， 然后这些开销乘以期间空闲的处理机数， 将使开销被放大。# Linux 下进程分析前面章节已经从理论上简单剖析了进程，如果忘记了，可以简单看下前面的目录。本章节将在 Linux 系统下收集进程信息，验证前面提及过的理论，并展现进程在真实系统中的表现，同时会给出 Linux 下有关进程的一些命令，这将帮助你了解自己的程序到底是怎么执行的，到底是怎么组成的，占用了多少空间、使用了哪些系统调用、函数调用情况、程序执行效率等，以便写出更高效更健壮的程序。或许还可以帮助你分析别人写的程序（如开源项目），或者做逆向分析等。## 静态分析在分析进程之前，先了解一下源程序和编译出的可执行文件的基本信息，这些信息相对于进程而言是静态的，但它可以为进程的动态分析提供帮助。### 源文件进程是进行中的程序，那先从源程序文件开始分析。有时候需要了解源文件的类型、权限、大小等信息，以便知道如何处理该文件（如要先改变权限吗？是可执行文件吗？这文件可以删除吗？……）。&gt; ls在终端下使用 ls 命令可以看到当前目录下所有文件（普通文件、目录文件、设备文件等）的基本信息。常用的有:+ ```ls```：只显示名称+ ```ls -a```：显示所有文件名称，包括隐藏文件+ ```ls -l```：显示详细信息至于 ls 详细的参数请参考其他资料或者在终端使用命令```man ls```得到帮助，下图是对 ```ls -l``` 命令执行后结果的一行信息解读：![ls -l命令结果解读](/assets/img/it_basic/process/pro-001.png)上图中设计到的概念和命令分解如下： 文件类型Linux 系统中的文件类型与文件后缀名（后缀名只是给系统使用者或应用程序使用的）无关 ，Linux 系统判断文件类型只与创建文件的命令有关。+ 普通文件（-）：```touch 文件名``` 或 ```vi 文件名```等；+ 目录（d）： ```mkdir 路径名```，注意```ls -a``` 出现的 ```.```和```..```分别表示当前目录和上级目录。+ 符号链接（l）： ```ln -s 被链接的文件名　符号名（快捷方式）```；+ 管道文件（p）： ```mknod 管道名称 p```或者```mkfifo 管道名称```+ 字符设备文件（c）： ```mknod 文件名 c 主设备号　从设备号```，如 mknod char_device c 1 1+ 块设备文件（b）： ```mknod 文件名 b 主设备号　从设备号```；+ 套接口文件（s）：```mksock 文件名```（Redhat系统中）或```nc -l 端口号```（开端口等待连接，需要```netcat```），另开一个终端输入```nc 127.0.0.1 同一个端口号```（建立链接），然后再开一个终端，输入```netstat 同一个端口号```即可看到含有 socket 字样的路径名，然后用```ls -l 路径名```即可知道其为套接口文件。或者通过程序调用 socket 系统调用创建套接字文件。 文件权限文件权限见图，修改文件权限或递归修改权限可以是用命令```chmod```（具体请参考其他资料）。平时创建文件的时候并没有指明文件权限，那权限哪里来的？这可以通过```umask```来设定默认文件权限。 硬连接数```硬连接数```可以通过```ln 被连接的文件名　文件名```来增加硬连接数，此后两文件用```ls -l```得到的描述信息是完全相同的（可以认为是备份）。无法区分。即使信息相同，也不一定互为硬连接，可以通过```ls -il```命令查看信息得知，只要第一列中的数字（inode number）相同，即互为硬连接。所以要找出所有硬连接（查看软连接就简单多了，只需要```ls -l```即可，文件名会有箭头标识，实在不行介先自己创建软连接，然后再查看变化），可以通过 inode 号来实现。使用```find 查找的目录 -inum inode号```即可找出。大家可能很早就发现：*空目录的硬连接数为 2*。原因在于```当前目录含有*.*文件```（通过```ls -a```可以看到），而其上级目录也有指向该目录的文件，此时硬连接数正好为 2.当然为了验证这个猜想，你可以在空目录下新建几个空目录，再看一下，是不是硬连接数增量等于新建目录的个数。*查看某个文件的当期目录下所有的软链接可以使用```find . -lname 文件名```*。也可以使用：+ ```ls -i```得到 inode 号；+ ```find . -follow -inum inode号```即可列出该文件所有的软硬连接。以后找个机会说下上面操作的原理。 所属用户或用户组修改所属用户和用户组，可以分别用命令```chown```和```chgrp```。 文件名修改文件名可以使用命令```mv```或```rename```。&gt; find```find``` 用来在给定的目录下查找符合给定条件的文件。 find [OPTIONS] [查找起始路径] [查找条件] [处理动作]首先讲一下查找条件：+ ```-name```或```-iname```：根据名称（或不区分大小写）查找。如 find ./ -name 'a*'+ ```-regex```：正则匹配整个路径，如 find / -regex /t.*/test/test.*+ 根据文件从属关系查找：```-user```、```-group```、```-uid```、```-gid```、```-nouser```、```-nogroup```，如 find ./ -user root+ ```-type```：根据文件类型查找，如 find ./ -type f * ```f```：普通文件 * ```d```：目录文件 * ```l```：符号链接文件 * ```b```：块设备文件 * ```c```：字符设备文件 * ```p```：管道文件 * ```s```：套接字文件+ ```-size [+|-][c|k|M|G]```：根据文件大小（+、-号表示大于小于）查找，如 find ./ -size 63k+ 根据时间戳查找：如 ```-atime [+|-]```，加号表示大于等于，减号表示小于，```time```的单位为天，```min```的单位为分钟。 * 文件最后访问时间：```-atime```、```-amin``` * 文件最后修改时间：```mtime```、```mmin``` * 文件最后改变时间：```ctime```、```cmin```+ ```-perm [/|-]mode```：根据权限查找，其中 mode 是用于表达权限的数字 * ```mode```：精确权限匹配，如 find ./ -perm 664 * ```/mode```：任何一类用户(u,g,o)的权限中的任何一位(r,w,x)符合条件即满足；9位权限之间存在“或”关系；如 find ./ -perm /122 -ls * ```-mode```：每一类用户(u,g,o)的权限中的每一位(r,w,x)同时符合条件即满足。9位权限之间存在“与”关系；如 find ./ -perm -664 -ls查找到指定文件之后，有时候会接着对文件执行一些操作，这就是“处理动作”的职责：+ ```-print```：这是默认动作+ ```-ls```：执行 ls 命令+ ```-delete```：删除查找到的文件+ ```-fls file_name```：将查找的文件信息保存到指定文件 file_name 中+ ```-ok COMMAND {} \\```：待用户确认方可执行之后的命令+ ```-exec COMMAND {} \\```：对查找到的每个文件执行由 COMMAND 表示的命令；*【注意】*：find 传递查找到的文件路径至后面的命令时，是先查找出所有符合条件的文件路径，并一次性传递给后面的命令；但是有些命令不能接受过长的参数，此时命令执行会失败；下面这种方式可规避此问题： find | xargs COMMAND&gt; file使用命令```file 文件名```即可直观地查看文件类型和文件编码。对```ELF 文件```显示的信息较多。&gt; stat```stat```命令可以查看到文件或目录更为详细的信息，包括创建、访问、更改时间等。&gt; wc```wc```显示文件的行数、单词数和字符数。&gt; 查看文件的内容可以通过```head```、```tail```、```tailf```、```more```、```cat```、```tac```、```less```、```nl```、```vim```等命令或应用查看文件内容。&gt; 查看打开该文件的所有进程有时候需要知道哪些进程在使用某个文件，可以使用```ps -fe | grep 文件名```。&gt; 比较两个文件内容同一个文件可能在不同地方有备份，但是有个本分的内容被修改了，其他备份没有得到更新，此时就需要比较两个文件的异同或者找出最新的那个文件，可以先使用```stat```得到最新修改的文件（最新版本），然后使用```diff```比较文件具体的内容。### ELF 二进制文件ELF(Executable and Linkable Format)即可执行连接文件格式，是 Linux，SVR4 和 Solaris2.0 默认的目标文件格式，目前标准接口委员会 TIS 已将 ELF 标准化为一种可移植的目标文件格式，运行于 32-bit Intel 体系微机上，可与多种操作系统兼容。分析 elf 文件有助于理解一些重要的系统概念，例如程序的编译和链接，程序的加载和运行等。&gt; ELF 文件类型+ 可重定位文件: 用户和其他目标文件一起创建可执行文件或者共享目标文件,例如 lib*.a 文件。+ 可执行文件： 用于生成进程映像，载入内存执行,例如编译好的可执行文件 a.out。+ 共享目标文件：用于和其他共享目标文件或者可重定位文件一起生成elf目标文件或者和执行文件一起创建进程映像，例如 lib*.so 文件。+ 核心转储文件(Core File):.由于时间的关系，这里不打算对 ELF 文件进行详细的分析（网上的资料很多，等有时间再专门写篇文章吧），以下只给出几个分析 ELF 文件的命令。&gt; ELF 文件内容查看+ ```file```： 查看 ELF 文件的少量基本信息；+ ```readelf```: 读取 ELF 文件信息（可以```man readelf```得到帮助） * ```-a```：显示全部信息； * ```-h```：显示文件头信息； * ```-l```：显示程序头（段头）信息； * ```-S```：显示节头信息； * ```-g```：显示(-S)节的详细信息； * ```-s```：显示符号表段中的项； * ```-e```：显示全部头信息； * ```-r```：显示可重定位段信息； * ```-d```：显示动态段信息； * ```-D```：使用动态段中的符号表显示动态段信息； * ```-x```：以 16 进制显示。 * 其他：（略）。+ ```size```：列出目标文件各个部分所占的字节数。可以用于分析 C 语言的内存分布。+ ```objcopy```：实现 ELF 文件的部分转储（如增删 section），以便瘦身或更改格式。+ ```objdump```： 查看目标文件或者可执行文件的构成，类似```readelf```，但可读性更强。+ ```nm```：names 用于显示二进制目标文件的符号表。+ ```ldd```：list dynamic dependencies 列出可执行文件所需的共享库。+ ```cmp```：比较二进制文件内容，类似```dif```（比较文本文件内容）。也可以用```vim -bd```。+ ```hexdump```和```xxd```：以 16 进制的形式显示文件内容。+ ```strings```：在对象文件或二进制文件中查找可打印的字符串。+ ```od```：以常用编码方式显示文件内容，通常用于显示或查看文件中不能直接显示在终端的字符。&gt; ELF 文件编辑可以使用 ```biew```、```hexedit```、```vim -b```、```sed```、```dd```、```xxd```等。## 动态分析前面已经介绍了可执行文件在运行之前收集信息的方法或命令，接下来将阐述进程跑起来之后，如何收集信息，观察进程的行为。### main 函数前后网上有不少博客分析了 ```main 函数```前后的执行过程，在这里只是宏观的提一下。main 函数没有关于可执行文件如何装入内存、如何建堆栈、如何申请资源、如何释放内存和资源等说明信息，但根据操作系统的基本知识可知，这些都是需要的。既然如此，这些不是 main 函数干的，那必然有其他的函数或代码做这些事情。也就是说，在 main 函数之前或之后编译器插入了代码以完成初始化和收尾工作，也意味着，程序员也可以采用某种方式让某些代码在 main 函数前后执行。从作用域的观点来看，在 main 函数作用域之外（或属于全局性质的，比如 ```全局变量```、```static 对象```、```main 函数参数```等）的变量或资源都是在 main 前初始化、在 main 后销毁。 main 函数前后实例：```c#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;//#include&lt;unistd.h&gt;__attribute((constructor)) void before_main(){ printf(\"%s -&gt; \",__FUNCTION__);}__attribute((destructor)) void after_main(){ printf(\"%s -&gt; \",__FUNCTION__); printf(\"game over!\\n\");}void atexit_func(){ printf(\"%s -&gt; \",__FUNCTION__);}int main(){ printf(\"%s -&gt; \",__FUNCTION__); atexit(atexit_func); printf(\"main exit right now -&gt; \"); //_exit(0); /*放开此行有惊喜*/ //至于exit(0)和_exit(0)的区别，自己搜吧 //abort(); return 0;}上面的程序自己运行，然后分析结果哈，我就不啰嗦了。进程信息捕捉进程控制块是进程存在的唯一标志，既然是捕捉进程信息，那 PCB 中的信息是少不了的。同时 Linux （一切皆文件）会把进程的信息存入 /proc/&lt;pid&gt;文件夹下对应文件（注意：由于安全考虑，proc 有可能需要手动 mount）中，只要你非常了解该文件夹下的内容（说白了，就是文本文件而已），那么你完全可以使用上节中类似“源文件”的处理方法处理本节涉及到的内容。进程基本信息查看进程的基本信息（如 所属用户UID、进程 IDPID、父进程 IDPPID、CPU 使用率%CPU、所占内存百分比%MEM、虚拟内存大小VSZ、驻留空间大小RSS、进程相关终端TTY、进程状态STAT、进程使用 CPU 总时间TIME、被执行的命令行COMMAND、进程优先级NI、进程等待的内核事件名WCHAN、进程启动时间START、会话 IDSID、USER、进程优先级编号PRI、与进程相关的数字标识FLAGS、线程组 IDTGID、进程组 IDPGID、控制终端进程组ID TPGID等）可以使用ps命令。ps 命令带有 2 种不一样的风格,分别是 BSD 和 UNIX。在 BSD 风格的语法选项前不带连字符，如ps aux；在 linux 风格的语法选项前面有一个连字符，如ps -ef。两种风格可以混用，如ps ax -f。ps 命令参数太多了，下面只给出常用的组合参数： au或-ef：列出所有的进程； aux或-ef -f：累出所有进程的详细信息； -C：通过进程名得到 pid； ps aux --sort=-pcpu,+pmem：特定字段排序（如 cpu）； auxf：进程树状图（显示进程父子关系，可以使用pstree更直观）。 e：显示进程环境变量。 -o：因字段过多，可自定义显示，如ps -o pid,ppid,pcpu（注意字段名要小写），ps -o pid=process_id； 联合管道：有时 ps 显示的信息太长，一行无法显示完全（默认情况下也不会换行），也无法对齐显示，此时可以使用管道 |来优化显示和阅读，如： ps aux | more或ps aux | less； ps aux | head -5：只显示前 5 行； ps aux | sort -k 5n | tail -5：输出占用内存最多的 5 条（也可以用-e -o pid,pmen替代aux）； ps -ef | grep 你要找的进程名 | grep -v \"grep\" | awk '{print $2}'：该命令可以找出某个进程名对应的进程 ID；当不知道进程的全名时，可以使用正则表达式；还可以使用类似pgrep 进程模糊名 | xargs ps -u --pid命令，其中 pgrep 得到的结果作为 ps -u –pid 的参数（xargs）。要得到更详细的信息可以到/proc/&lt;pid&gt;文件夹中去查看。比如ls -al /proc/1234。进程状态 STAT 说明： D：不可中断的睡眠状态； R: 正在运行或可运行（在运行队列排队中）； S: 可中断睡眠 (阻塞，等待事件发生)； T: 已停止的 进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行； Z: 僵尸进程 进程已终止, 但进程描述符存在，等待收尸； &lt;：高优先级别 N：低优先级别 L: 页面锁定在内存（实时和定制的IO）； s: 一个信息头；session leader 进程，一般启动时要设置 SID 的，这种进程脱离控制终端。一般的 deamon 都要调用 setsid 把自己设置为 session leader，与控制终端脱离关系，这样控制终端退出产生的 SIGHUP 信号就不会发送到这些进程了。这个行为与用 nohup 执行应用的作用相同。 l：多线程。进程关系ps 命令可以给出基本信息，但这是不够的，至少是直观的。进程父子关系： pstree -p 1234：查看进程号为 1234 的所有字进程树。 ps --ppid 1234：查看进程号为 1234 的所有直接子进程。 ps --pid 1234 -o ppid：可以得到进程 1234 的父进程 ID，如此递归（1 进程是所有用户进程的祖先）就可以找出其所有的祖先。当然也可以通过 pstree 顺着树往上走就可得到所有祖先。进程关系已经知道了，但有的进程是多线程的，所以有必要知道某个进程的所有线程。查看线程： ps -xH：配合grep管道可行； ps -mq 1234； ps mp 1234 -o THREAD,tid； ps -Lf 1234； ps -Lo pid,ppid,pgid,nlwp,lwp,stat,command -p 1234：自定义显示； ps -T -p 1234； top -Hp 1234；有时候并不需要知道线程的详细信息，而只需要知道某进程有多少线程。线程计数： ls /proc/1234/task | wc -l; cat /proc/1234/status | grep Threads； ps hH p 1234 | wc -l; ps -Lo nlwp -p 1234 | head -2；在多进程编程时，有时候需要统计某个程序的进程数子进程计数： pstree -p 1234 | wc -l：统计所有子进程数，包括子进程的子进程；或者使用pgrep 进程名称 | wc -l。 cat /proc/*/status | grep PPid | grep 1234 | wc -l：只包括直接的子进程，不包括子进程的子进程等。 ps -ef -o ppid | grep 1234 | wc -l；下面给出测试以上命令的示例程序：#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;int main(){ printf(\"Hello World!\\n...\"); for(int i=0; i&lt;4; ++i){ fork(); } while(1){}; return 0;}进程占用的内存编写 C/C++ 程序，一不小心就会出现内存泄漏，或者过多占用内存的情况，即使是系统维护人员也需要了解内存情况，以便知道进程消耗资源的占比，然后做出对应的决策。top 命令top 命令是 Linux 下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于 Windows 的任务管理器。这里只讲述一些实用的内容，其他具体内容请自行查询。 不带参数： 见上段描述； -p &lt;pid&gt;：只显示进程 ID 为 pid 的进程信息，多个 pid 用逗号隔开； -u 用户名：显示特定用户的进程信息； 定制要显示的列：输入 top 命令之后，按f即可看到所有列名意义的说明，同时可以用上下方向键选择是否显示的列，空格键显示隐藏这个列（显示的列前面有一个星号）； 调整列的位置：出现 top 界面后，按左右方向键可以选定（或取消）需要改变位置的列，然后按上下方向键可调整选定列的位置，最后按回车确定调整位置；或者，按 o 键，选择要调整位置的列（如 K:CUP Usageage），按动一下 大写 K 则显示位置往上调整，按动一下小写 K 则显示位置往下调整。 列排序：执行 top 命令后，按 shift + f（小写），进入选择排序列页面，再按要排序的列的代表字母即可； c：显示完整的 command 列； T：输入 top 命令后回车，再按T，即可固定行次序（否则行次序一直在变），以便于观察。 h：出现 top 界面之后，按h即可得到简单帮助，详细请在终端输入man top； q：退出 top；实际上，还可以用之前的 ps 命令来粗略的查看一下进程占用内存的情况。ps 命令可以使用 ps 定制命令来单独查看内存使用情况。比如，ps --pid &lt;pid&gt; -o pid,rsz,vsz,cmd。pmap 命令pmap 命令用于报告进程的内存映射关系，是 Linux 调试及运维一个很好的工具。比如，pman -d &lt;pid&gt;。/proc/&lt;pid&gt; 文件夹对于不了解该文件夹的童鞋可以使用man proc得到帮助。可以使用以下操作之一可得到内存占用情况不同程度的说明： cat /proc/&lt;pid&gt;/status；这里可以看到概貌的内存统计。 cat /proc/&lt;pid&gt;/smaps：对应每个映射的内存开销详情。 cat /proc/&lt;pid&gt;/statm：列出的项分别为，size（VmSize）、resident（VMRSS）、share（shared pages）、text、lib、data（data+stack）、dt（dirty pages） 的大小，应用程序正在使用的物理内存（resident）的大小 VmRSS/4，为实际使用内存数值的四分之一。 cat /proc/&lt;pid&gt;/maps：进程与可执行程序或动态库文件相关的映射信息。# smaps 信息过多，可以过滤一下cat /proc/$pid/smaps | awk '/Size|Rss|Pss|Shared|Private|Referenced|Swap/{val_name=gensub(/([a-zA-Z_]*).*/,\"\\\\1\",1,$1); list[val_name]+=$2; }END{for(val in list)print val,list[val];}'系统内存信息有时候需要知道整个系统内存的使用情况，可使用以下命令： cat /proc/meminfo：查看系统内存状态信息。 free：查看机器可用内存。也可使用free -m。 top：top 界面头信息含有内存情况。 vnstat：可对操作系统的虚拟内存、进程、CPU活动进行监控。 dmesg |grep [mM][eE][mM]：系统的真实内存大小。进程打开的文件要删除某个文件或者要写某个文件时，可能提示某个进程正在使用，无法删除等信息，此时就有必要查出到底被哪些进程占用。可以使用 fuser（find files or sockets’ user） 命令，并对相应进程执行操作。反过来，自己编写的程序有时候需要打开多个文件，这就需要知道有多少文件被该进程打开了，打开文件的生命周期如何，打开的文件是否在合理的时机被关闭了等信息，可以使用 lsof（list open file）命令。由于 Linux 下一切皆文件，所以也可以查看套接字和连接等。查看某个进程对应的映像文件（即二进制文件）所在的完整路径，可以使用ll /proc/进程号命令，具体有： cwd: 符号链接的是进程的启动目录，可以使用ll /proc/进程号/cwd； exe：符号链接的是进程对应程序的绝对路径； cmdline：执行程序时输入的命令行； environ：进程运行时的环境变量； fd目录：进程打开或使用的文件的符号链接。进程可能一开始执行就崩溃了或者执行了很久由于出现某种异常（如，收到了某种信号，信号默认行为退出）而崩溃，此时你可能迫切需要查找原因，想知道 core 文件 放在哪里（特别是服务器程序），一般就放在进程的启动目录下。进程使用的动态库为了节约内存或者重用，回尽量用动态库。那进程用到了哪些动态库呢？实际上就是确定进程的依赖关系。 查看可执行程序的共享库依赖关系 ldd /path/to/program：如 ldd /usr/bin/gcc注意：ldd 可能会直接调用可执行程序来明确其库文件依赖关系，如果该可执行程序时第三方程序，可能会对你的电脑造成安全问题。 objdump -p /path/to/program | grep NEEDED：这是个安全的方式用于显示一个未知应用程序二进制文件的库文件依赖。 查看进程的共享库依赖关系 sudo pldd ; sudo pmap ：pmap 是一个命令行工具。 strace：可是查看程序启动时加载的动态库等。需要注意的是，在启动程序时，可能会提示找不到动态库，这就需要告诉系统所需动态库的位置。至少有以下三种方式（这也是系统寻找动态库的顺序）： 加入 LD_LIBRARY_PATH 变量：如 export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH； 修改 /etc/ld.so.cache：但不能直接修改它，而需要先修改/etc/ld.so.conf文件，在其中另起一行加入指定路径，如 /usr/local/lib，然后不要忘记在终端中执行sudo ldconfig命令，这样就应用到了 ld.so.cache 中。 在/lib或/usr/lib目录下建立相应动态库的软连接。 程序中主动调用 dlopen打开相关动态库（或者在编译连接时用 -l选项和--as-needed，可以只加载需要的共享库）。注意：共享库可能会冲突，越明确隔离的共享库位置越不容易冲突，所以当使用以上某种方式提示冲突时，就需要更换其他方式（先取消使用的方式）。进程使用的系统调用在 Linux 下可以使用strace、ltrace、truss来跟踪进程，查看进程用到的系统调用情况。实际上，这三个常用的调试工具来快速诊断软件的”疑难杂症”。你不仅可以从命令行调试一个新开始的程序，也可以把itruss、strace 或 ltrace 绑定到一个已有的 PID 上来调试一个正在运行的程序。用调试工具实时跟踪软件的运行情况不仅是诊断软件”疑难杂症”的有效的手段，也可帮助我们理清软件的”脉络”，即快速掌握软件的运行流程和工作原理，不失为一种学习源代码的辅助方法。前台后台进程切换常用的命令有 fg、bg、jobs、&amp;、ctrl + z ，这些命令都是合后台运行、关闭等有关。而且可以用于终端运行 GUI 程序后继续使用该终端，例如，sudo gedit test.txt &amp;，则该终端仍可以执行其他命令，否则是不能的。除非关闭 gedit。 &amp;：这个用在一个命令的最后，然后这个命令就会被放到后台执行（同时会打印出 pid）。 ctrl+z：可以将一个正在前台执行的命令或程序放在后台，并且暂停。 jobs：查看当前有多少命令在后台运行。 fg：将后台中的命令调至前台继续运行，如果后台中有多个命令，可以用 fg %jobnumber 将选中的命令调出，%jobnumber 是通过 jobs 命令查到的后台正在执行的命令的序号(不是 pid)。 bg：将一个在后台暂停的命令，变成继续执行如果后台中有多个命令，可以用 bg %jobnumber 将选中的命令调出，%jobnumber 是通过 jobs 命令查到的后台正在执行的命令的序号(不是 pid) kill：kill 可以杀死进程，也可以杀死 job（任务），执行 kill %job号。 ctrl+c：终止当前前台进程。 nohup：起到守护进程的作用，但不是严格意义的守护进程；一般这种程序即使使用 &amp; 结尾，如果终端关闭，那么程序也会被关闭。为了能够后台运行，我们需要使用 nohup 这个命令，如 nohup /root/start.sh &amp; 即可，当 shell 中提示了 nohup 成功后还需要按终端上键盘任意键退回到 shell 输入命令窗口，然后通过在 shell 中输入 exit 来退出终端（而不是直接通过关闭窗口按钮来关闭终端）。使用 nohup 命令后，原程序的的标准输出被自动改向到当前目录下的 nohup.out 文件，起到了 log 的作用，实现了完整的守护进程功能。如果想要监控标准输出可以使用：tail -f nohup.out进程间通信信息进程间通信的方式有多种，接下来简单讲下如何捕捉这些通信信息。 网络通信：netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态等等，如，监控端口 25，可以：①netstat -anp |grep :25；②lsof -i:25。lsof也可以借助文件来访问网络连接和硬件。tcpdump可以用用于抓取通信数据包，以便进一步分析网络情况。Linux 中查看 socket 状态： cat /proc/net/sockstat：用于 ipv4； cat /proc/net/sockstat6：用于 ipv6；跟踪网络有关的所有系统调用，可以使用strace -e trace=network。 查看共享内存和消息队列查看共享内存和消息队列的命令主要用ipcs，主要有以下参数（以 - 为前缀）： m：查看共享内存信息； q：显示所有的消息队列； qt：显示消息队列的创建时间，发送和接收最后一条消息的时间； qp：显示往消息队列中放消息和从消息队列中取消息的进程 ID； ql：显示消息队列的限制信息； ipcs -q -i msgid：显示该消息队列结构体中的消息信息； ipcrm -m|-q|-s shm_id ：删除 ipc；跟踪所有与进程通讯有关的系统调用，可以使用strace -e trace=ipc。 跟踪进程信号可以使用strace -e trace=signal或者strace -e signal=set跟踪所有与系统信号有关的系统调用。栈调用关系跟踪在发生段错误的时候，打印函数的调用栈信息是定位问题很好的手段。一般来讲，我们可以捕获 SIGSEGV 信号，在信号处理函数中将函数调用栈的关系打印出来。gdb 调试中的 backtrace，简称 bt 就是这个作用。调用的 GNU 的 backtrace 函数，也可以打印函数的调用栈信息。 glibc 中的 backtrace 函数：#include &lt;execinfo.h&gt;void do_gnu_backtrace(){#define BACKTRACE_SIZ 100 void *array[BACKTRACE_SIZ]; size_t size, i; char **strings; size = backtrace(array, BACKTRACE_SIZ); strings = backtrace_symbols(array, size); for (i = 0; i &lt; size; ++i) { printf(\"%p : %s\\n\", array[i], strings[i]); } printf(\"---------------------------------------------------------\\n\"); free(strings);}使用该函数，在编译时，需要加上 -rdynamic 选项，否则符号表信息无法打印。通过 backtrace 返回调用的栈帧，然后通过 backtrace_symbols 把地址转换为字符串。最后，在 Linux 下有个工具 addr2line 可以将地址转换为文件名和行号！通过管道调用 addr2line，最后打印调用栈帧。#include &lt;execinfo.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;/* * 打印栈帧 * * 通过backtrace,backtrace_symbols获取栈帧信息，然后建立管道，通过addr2line解析 * */int32_t myexec(const char *cmd){ FILE *pp = popen(cmd, \"r\"); //建立管道 if (!pp) { return -1; } char tmp[1024]; while (fgets(tmp, sizeof(tmp), pp) != NULL) { if (tmp[strlen(tmp) - 1] == '\\n') { tmp[strlen(tmp) - 1] = '\\0'; //去除换行符 } printf(\"%-30s\",tmp); } printf(\"\\n\"); pclose(pp); //关闭管道 return 0;}void parseName(char * str,char *exeName,char *addr){ char *strTemp = str; char * addrTemp; while (*strTemp != NULL) { if (*strTemp == '(') memcpy(exeName, str, strTemp - str); if (*strTemp == '[') addrTemp = strTemp; if (*strTemp == ']') memcpy(addr, str + (addrTemp - str) + 1, strTemp - addrTemp - 1); strTemp++; }}void print_trace(void){ void *array[10]; size_t size; char **strings; size = backtrace(array,10); strings = backtrace_symbols(array,size); printf(\"Obtained %zd stack frames.\\n\",size); char cmd[500] = {0}; char exeName[100] = {0}; char addr[100] = {0}; for(size_t i = 0;i &lt; size;i++) { memset(cmd,0,sizeof(cmd)); memset(exeName,0,sizeof(exeName)); memset(addr,0,sizeof(addr)); parseName(strings[i],exeName,addr); printf(\"%-15s\",addr); sprintf(cmd,\"addr2line -f -e %s %s\",exeName,addr); myexec(cmd); }}void dummp_function(void){ print_trace();}int main(int argc,char *argv[]){ dummp_function(); return 0;}编译，gcc -Wall -g backtrace.cpp -o bt运行，./bt 使用 ebp函数调用一般遵循：如果有 N 个参数，将 N 个参数压栈，然后是将返回地址压栈，最后是将 ebp 压栈保存起来。如果我们只传递一个参数给某个函数，那么我们完全可以根据参数的地址推算出 ebp 存放的地址，进而得到 ebp 的值。参数地址 -4（32位系统指针的长度为 4Byte）可以得到返回地址的位置。参数的地址 -8 得到 ebp 在栈存放的地址。我们一旦得到 ebp，我们就可以回朔出整个栈调用。第一步：getEBPvoid **getEBP(int dummy){ void **ebp = (void **)&amp;dummy -2 ; return( *ebp );}原理很简单，就是入参的地址下面是返回地址，返回地址的下面是被保存的 ebp 的地址。第二步，有了 ebp,我们可以一步一步前回退，得到调用者的栈的 ebp，调用者的调用者的栈的 ebp,……直到 NULL。while( ebp ){ ret = ebp + 1; dladdr( *ret, &amp;dlip ); printf(\"Frame %d: [ebp=0x%08x] [ret=0x%08x] %s\\n\", frame++, *ebp, *ret, dlip.dli_sname ); ebp = (void**)(*ebp); /* get the next frame pointer */}不过只能拿到栈的信息，和返回地址的信息，拿不到函数名。但可以利用 libdl.so 的 laddr这个函数得到距离入参地址最近的符号表里面的 symbol。最后总结如下：#include &lt;dlfcn.h&gt;void **getEBP( int dummy ){ void **ebp = (void **)&amp;dummy -2 ; return( *ebp );}void print_walk_backtrace( void ){ int dummy; int frame = 0; Dl_info dlip; void **ebp = getEBP( dummy ); void **ret = NULL; printf( \"Stack backtrace:\\n\" ); while( ebp ) { ret = ebp + 1; dladdr( *ret, &amp;dlip ); printf(\"Frame %d: [ebp=0x%08x] [ret=0x%08x] %s\\n\", frame++, *ebp, *ret, dlip.dli_sname ); ebp = (void**)(*ebp); /* get the next frame pointer */ } printf(\"---------------------------------------------------------\\n\");}注意：编译的时候加上 -rdynamic，同时链接 libdl.so 即加上 -ldl 选项。 libunwind#include &lt;libunwind.h&gt;void do_unwind_backtrace(){ unw_cursor_t cursor; unw_context_t context; unw_getcontext(&amp;context); unw_init_local(&amp;cursor, &amp;context); while (unw_step(&amp;cursor) &gt; 0) { unw_word_t offset, pc; char fname[64]; unw_get_reg(&amp;cursor, UNW_REG_IP, &amp;pc); fname[0] = '\\0'; (void) unw_get_proc_name(&amp;cursor, fname, sizeof(fname), &amp;offset); printf (\"%p : (%s+0x%x) [%p]\\n\", pc, fname, offset, pc); } printf(\"---------------------------------------------------------\\n\");}编译的时候加上 -lunwind -lunwind-x86 ，如果是X86_64,则是 -lunwind -lunwind-x86_64优点是不需要 -rdynamic选项，不需要 -g 选项。 动态函数调用追踪基于 Gnu/Gprof 运行时剖析工具。Gnu/Gprof 是类 Unix 平台下对 c/c++ 开源项目的一个 profile 分析工具，它能在程序运行过程中记录下函数间的调用关系，每个函数被调用的次数，每个函数消耗的时间等代码级信息。它的实现原理是通过编译和链接源程序的时候在 gcc 编译器的命令行参数中加入“-pg”调试选项，gcc 编译器就会在程序的每个函数中加入一个名为“mcout”(或“_mcount”，依赖于编译器或操作系统)的函数，该函数在内存中保存了一张函数调用图，可利用函数调用堆栈的形式查找子函数和父函数的地址，从而获得函数间的调用关系，以及每个函数调用次数、运行时间等信息。使用步骤： 如 gcc -pg test.c -o tes 执行程序：./test，之后就会生成 gmon.out的二进制数据； 分析：gprof test gmon.out 使用 GDB 堆栈跟踪程序“调用堆栈”是当前函数之前的所有已调用函数的列表（包括当前函数）。每个函数及其变量都被分配了一个“帧”，最近调用的函数在 0 号帧中（“底部”帧）。要打印堆栈，发出命令 ‘bt’（’backtrace’ [回溯] 的缩写）：(gdb) bt 异常堆栈跟踪在 Linux 中做 C/C++ 开发经常会遇到一些不可预知的问题导致程序崩溃，同时崩溃后也没留下任何代码运行痕迹，因此，堆栈跟踪技术就显得非要重要了。不过编码的时候还是以预防异常为主，最好养成避免已经出现过类似异常的行为习惯（也就是说，在你的编码人生中，该类异常最好只能出现一次）。先看看常见的异常吧： 使用空指针引用数据成员或调用函数； 使用已经删除内存的指针（没有置空，也没有判空）； 不恰当的指针转换及其使用； 容器原地操作，又读又写，导致迭代器失效，但循环或者操作又依赖迭代器的判断； 使用了无意义的变量值（操作前应初始化和作判断）：如除 0 函数栈溢出： 在函数内部定义了太大的局部变量或对象； 函数嵌套调用或递归层次太深； 数组越界：破坏了函数栈； 变量未赋值就参与运算； 内存不足：内存泄漏或碎片过多； 锁使用不当： 多线程或多进程不恰当的使用 new 或 delete 及其相关指针； 使用了线程不安全函数； 资源申请或释放资源在进程间或线程间协调不当，导致前述情形； 浅层拷贝和深层拷贝：导致操作同一块内存（可能导致 delete 多次）或者操作未初始化的指针。 其他情况间接导致上述情形的发生：如， 数据库连接出现问题，导致无法获取数据，接下来依赖该数据的操作可能出现随机的崩溃（当数据库连接不稳定时）； 网络故障，类似上一点； 信号处理不当或没有处理； 针对特定的信号，应用程序可以写对应的信号处理函数。如果不指定，则采取默认的处理方式, 默认处理是 coredump 的信号如下：SIGQUIT、SIGILL、SIGABRT、SIGFPE 、SIGSEGV、SIGBUS、SIGSYS、SIGTRAP、SIGXCPU、SIGXFSZ、SIGIOT 等上面也只是一个大概，以后遇到类似的问题会补充上去。为了减少上面的问题，请参考遵守本人博客“C++ 编程规范”中的编码建议和习惯养成。不过有时候还是会疏忽出现程序崩溃，可以通过 gdb 调试跟踪栈信息，一般会未运行完就会崩溃停止，gdb 会打印出崩溃的原因，也比较容易定位到对应的文件、函数、行数；当然如果是线上程序，不可停止（这不是废话吗？都崩溃了还不下线？有时候并不是一开始就崩溃，而是可能遇到特殊的输入或情形时才出现，况且有些服务器守护进程会把崩溃的程序在有限的时间内重新启动，此类崩溃就相当隐秘了），可以用 gdb 发送信号给进程产生 core 文件，然后再分析 core 文件（可以使用 gdb 加载 core 文件，使用gdb 对应的core文件名，然后使用 bt 等命令）；极限条件下不能使用 gdb，则编码的时候记得在关键位置打上 log，然后通过检索归类日志来查找问题；剩下的只能看设计看源码查问题了。强行产生 core 文件： gdb： 首先 gdb attach 进程号回车； 然后generate-core-file回车即可； detach（这一步不能少）； 然后退出 gdb gcore：使用gcore 进程号回车即可；以上在线上进程卡死或不能打断点重新运行的情况下很实用。如果不能产生 core 文件，可以设置一下 core 文件的大小和路径。好的编码习惯应该是：写出的程序应：方便调试、方便单元测试、方便查找问题，总之，好的编码习惯应该兼顾开发、调试、测试、维护效率。运行日志查看和分析服务器程序大多会通过打印日志来检索问题所在（当然对于崩溃等问题还是会用 gdb 在调试机上查找问题），所以适当地（打 log 的时机）产生日志文件是很重要的手段。接下来说说如何高效地检索日志文件。在服务器上，一般采用系统自带的命令（vim 等第三方编辑器命令可能会因日志文件过大而加载缓慢甚至出现假死的情况）。其实日志文件就是普通的文本文件，所以适合处理文本文件所有命令都可以用来处理日志文件（可参见本博客中“源文件”一节）。Linux 系统日志文件一般放在目录/var/log下，但日志文件的存放位置是可以设置的，所以首先得知道你要查看的日志文件所在的目录，然后才能使用相应的命令。下面只介绍查看日志文件相对高效的命令。 tail: 输出文件末尾的内容。 -f：可以实时查看（监视）日志新增的内容（可使用 ctrl+x 退出）。 -f -n 5：实时查看最后 5 行的日志。 -f -n -r 5：实时逆序查看最后 5 行的日志。 watch：watch -d -n 1 cat 日志文件可以每 1 秒刷新高亮打印新增日志文件。 head -n 5：显示文件最开始的 5 行。 grep：全称Global Regular Expression Print，强大的文本搜索工具。 文件中搜索一个子串：例如 grep “match_pattern” file_name1 file_name2 -n：显示匹配字符串的行号 -v：反向匹配，grep -v “match_pattern” file_name -w：匹配整个单词而不是子串 -i：不区分大小写 -l：找出含有这个字符串的文件 -r：递归搜索，不放过子目录 -A：显示匹配项之后的[number]行，例如 grep -A 3 “match_pattern” file_name -B：显示匹配项之前的[number]行，例如 grep -B 3 “match_pattern” file_name -C：显示匹配行上下文的[number]行，例如 grep -C number “match_pattern” file_name -c：统计匹配的行数，例如 grep -c “match_pattern” file_name 或：显示匹配多个关键字中的至少一个，例如 grep “match_pattern1” | “match_pattern2” file_name 且：显示匹配所有关键字的行，例如 grep “match_pattern1” file_name | grep “match_pattern2” -E：使用正则表达式，如 grep -E “[1-9]+” -o：只输出文件中匹配到的部分，如 echo this is a test line. | grep -o -E “[a-z]+.” 的结果是 line. tail -f 可以和 grep 联合使用可以实时监控日志并且按要求只显示匹配行，例如 tail -f /var/log/test.log grep -w “test”，grep只有使用正则表达式才能发挥其强大的文本搜索功能，使用正则时，需要grep -E或egrep。下面简单列出匹配规则： 限定符 描述 . 匹配任意的一个字符 ? 匹配前面的子表达式，最多一次 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次货多次 {N} 匹配前面的子表达式 N 次 {N,} 匹配前面的子表达式 N 次或更多 {N,M} 匹配前面的子表达式 N 到 M 次 - 表示序列的范围 ^word 匹配以 word 开头的行 word$ 匹配以 word 结束的行 [list] 匹配 list 集合中的一个字符 [^list] 匹配 list 集合中以外的一个字符 \\&lt;word 以 word 开头的单词 word\\&gt; 以 word 结尾的单词 \\ 转义字符 | 以或的方式匹配多个字符串 () 匹配整个括号内的字符串 \\w 匹配[A-Za-z0-9] \\b 匹配一个单词前后的空字符串 \\B 匹配一个单词中间的空字符串 [:alnum:] 字母数字字符 [:alpha:] 字母字符 [:blank:] 空字符: 空格键符和制表符 [:digit:] 数字: ‘0 1 2 3 4 5 6 7 8 9’ [:lower:] 小写字母 [:upper:] 大写字母 [:space:] 空格字符: 制表符、换行符、垂直制表符、换页符、回车符和空格键符 上面没有给出例子，不过可以通过类似 echo this is a test line. | grep -o -E \"[a-z]+\\.\" 的形式在终端进行试验验证。但还是在下面给出几个例子： grep \"^[^48]\" test.txt 显示输出行首不是字符“48”的行） grep \"[Mm]ay\" test.txt 设置大小写查找：显示输出第一个字符以“M”或“m”开头，以字符“ay”结束的行） grep \"[A-Z][9]D\" test.txt 显示输出第一个字符的范围是“A-D”，第二个字符是“9”，第三个字符的是“D”的所有的行 grep \"9\\{2,3\\}\" test.txt 模式出现几率查找：显示输出字符“9”重复出现的次数在一定范围内，重复出现2次或3次所有行 grep -nwE \"g(oo|la)d\" test.txt 匹配 good 或 glad grep -n \"^$\" test.txt 显示输出空行的行号 '\\bgrep\\b' 只匹配 grep。" }, { "title": "探秘 C 指针", "url": "/2017/10/C-pointer.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2017-10-13 15:02:37 +0800", "snippet": " 指针是 C 语言的难点和精华所在，很多初学者对指针都是一知半解。本文的目的在于尽量浅显彻底地理清 C 指针的玄妙，并给您一个清新的轮廓。从此不再害怕指针，同时建立起相对合理的指针编程规范。 指针概述 指针涉及的几个概念 static 修饰指针的特殊性 volatile 修饰指针 概念的图示化 ...", "content": " 指针是 C 语言的难点和精华所在，很多初学者对指针都是一知半解。本文的目的在于尽量浅显彻底地理清 C 指针的玄妙，并给您一个清新的轮廓。从此不再害怕指针，同时建立起相对合理的指针编程规范。 指针概述 指针涉及的几个概念 static 修饰指针的特殊性 volatile 修饰指针 概念的图示化 指针存在的意义 指针语法 指针声明及其解读 指针类型和指针指向的变量类型互推 typedef 和 #define 在声明中的区别 指针运算 指针的算术运算 前自增和后自增的区别 指针的比较运算 指针取址、取值及其使用 指针与数组、结构体、函数 指针与数组 指针与结构体 指针与函数 指针概述在看本文之前，建议你先在网上搜索以下 寻址方式 （这是计算机组成原理中的知识点）。从寻址方式的视角来看，可以把指针视为 举例：比如，现实中的电话号码可以看成一种指针，别人通过与你对应的电话号码找到你，当然也可以通过其他方式（比如，邮件、QQ、家庭住址等）你，从这个意义上不同的指针可以指向相同的变量；当你换号码了，通过原来的号码就不能找到你了，但可以找到它现在的主人或者显示空号，从这个意义上讲，同一个指针可以指向不同变量，也可以为空，甚至成为野指针（你的朋友还以为该手机号是你的，可是你却换号了，但打这个手机号的朋友并不知道，结果你这个无知的朋友被手机号的新主人骗财骗色 ^_^，接下这个朋友的家人认为你应该负责，然后发生了血案......）造成安全问题。或许这个手机号还有其他意义，比如你某个账号的密码等，从这点看，指针还可以转型（指针类型的强制转化）。现在应该对指针的功能特性和安全问题有了一个比较直观的认识了。## 指针类型 首先解读一下本人理解的“类型”：+ 从存储角度来讲：占用空间的大小（多少个字节或单位作为一个整体来解读）```cint a = 1;short b = 2;char c = 'A';char *pc = &amp;c; 从存储的值的意义来看：即使是同一个值，其意义的解读方式也是可以多种多样的，比如，123456 可以解读为门牌号、可以解读为商品的条码、也可以解读为 WIFI 密码、当然有些懒惰的家伙可能拿它当作银行卡密码等。那到底怎么解读呢？这是需要类型这个概念来限定的。比如:short a = 65;char c = 65; 从操作方面理解：即使占用空间一样，值也一样，其可以执行的操作也可以不一样。这和应用场合有很大的关系，比如同一个人可以在不同的场合可能会表现出不同的行为特性（工作中可能很严谨的人，到了生活中可能就很大条）。这在 C 语言当中自定义类型中很常见（虽然两个结构体中的变量的个数以及类型都一一对应相同，但传入函数后加工方式可以不一样）。上面是本人的一些粗浅理解，你如果要对类型下一个明确的定义的话，建议你额外参考其他资料。C 语言为何在声明变量的时候必须指出变量类型呢？实际上变量名只代表了变量所在空间的首地址，但没有指出该空间的具体大小，所以需要指出变量类型来确定空间大小（这样通过首地址、字节数便可以具体确定变量所在的空间、不过这里还有个地址增长方向的问题。到底是往高地址还低地址增长呢？这和存储类型以及大端小端有关，不过你不需要关心这个问题，平台无关性会保证这一点，不过你的程序逻辑最好不要依赖这一点）。当然，现在很多其他语言都没有声明变量这种说法（有兴趣的话，可以了解一下它们是如何做到这一点的）。说了这么多，那指针类型到底是什么呢？既然指针也是一种类型，那它也逃不掉前面对“类型”的特点限制。不过指针类型也有它的特殊性： 指针所占的空间是一定的。不论该指针指向什么变量（可能是内置类型、用户自定义类型、指针类型等），它所占的字节数都是相等的。具体占多少字节呢？这是由计算机硬件和操作系统及编译器共同决定的。比如，32 位和 64 位操作系统中指针占用的字节数可能不相等。即使都是 64 位操作系统，当使用的编译器不同（一个是 32 位的，一个是 64 位的），指针字节数也可能不同。不过你可以修改编译参数来指定指针所占的字节数（但需要考虑可移植性问题）。 指针变量中存储的值的意义是相同的：都是所指向变量的地址（该地址可能是统一编址、也可能独立编址、具体参看计算机组成原理和操作系统相关内容），虽然所指向变量的类型可能不同。 指针变量的操作也几乎相同：有自增自减、解引用（取值，取值之后得到所指向的变量）、取地址、相减（但不能相加）。从上面的三点来看，好像指针没有必要指出类型啊（因为字节数、值的意义、操作几乎一样）！为何还要指出类型？这是因为：如果不指出指针变量类型，那指针变量中的值该如何解读？也就是说，C 语言规定了变量的类型，但没有规定值的类型（如果不是指针的话，也没有必要指出值的类型，这也是为何出现 long int a = 0L 常数加 L 类似定义的原因）。换句话说，指针变量的类型实际上就是其所指向变量的类型（如 int a = 1; int *pa = &amp;a; // * 指出了 pa 是指针， * 前的 int 指出 pa 所指向的变量类型是 int）。有趣的是 C++ 11 为了定义变量时类型与右值保持一致引入了关键字 decltype （有兴趣的可以了解一下），这弥补了 C 语言在这方面的缺憾。那指针变量类型和其所指向的变量类型是否一定要匹配呢？这倒不一定（是不是有点绕，淡定！再坚持一会就好）。从前面的论述当中，你已经知道，C 语言是通过指针类型来解读其所指向的变量类型，至于其所指向变量的真实类型是什么已经无从考究（因为 C 语言没有指出变量值的类型这种概念。所以指针变量所指向的变量作为“指针变量的值”也就失去了类型，如此只能依靠指针类型信息来解读其所指向变量的类型。不过 C++ 增加了多态的概念，可以根据右值（也就是指针的值）来解读指针，也就是说指针所指变量的类型信息得到保留，而且优先级高于指针类型信息，然而这种解读是有条件的，具体条件请参考 C++ 相关内容）。基于前段所说的事实，C 语言为了安全性，当指针类型和其所指向变量类型不匹配时必须施行强制转化（比如，int a = 65; char * pa =(char * )&amp;a //以字符型强制解读变量 a，也就是只取首字节），这就表示程序员有意为之（编译器会说：这是你自己故意这么做的，出了什么问题可别赖我），当然也顺便明确提醒读该段程序的其他人员。比较机智的朋友可能会问：通过解引用（对指针进行取值操作）之后得到了其所指向的变量，那是不是可以像使用所指向的变量一样（-&gt; 或 (*).或赋值操作符等）使用它了？这个问题没那么简单，还得具体问题具体分析。 当指针类型和所指向的变量类型一致时，这种说法是没有问题的； 当不一致时，就得服从指针类型了。除非指针类型和所指变量类型的操作相同，否则就不能像使用所指变量类型那样使用了（只能把所指变量当作指针类型的类型来看，也只能使用该类型对应的操作）。既然指针变量和普通变量有这么多区别，那它们是不是存储的位置也不一样呢？事实上，它们的存储位置（堆、栈等）没有本质的区别，都是由存储类型（static、auto等）决定的（具体内容请参看“存储类型”相关内容）。这一点在指针作为函数的参数和返回值的时候特别注意的地方，使用二级指针还是一级指针呢？这个问题后续再说吧。指针涉及的几个概念上一节已经相继提到了以下指针相关的概念： 指针变量； 指针类型； 指针的值； 指针所指向的变量； 指针所指向的变量的类型； 指针所指向的变量的值；分辨清楚以上几个概念也就对指针有了一个比较清晰地理解了。不过本人不打算从学术的角度理解这些概念，这里只谈谈直观的看法。本人把以上概念分为两类： 指针变量； 指针所指向的变量；事实上，上面两类也可以合并为一大类，都是变量。那么变量在 C 语言中既然就有变量名、变量类型、变量值、变量地址、变量所占空间、变量行为（在变量上可以执行的一组操作或函数行为）。不过为了分析指针，下面还是把变量区分为指针变量和普通变量（非指针变量）。变量分类： 普通变量：前面已经提到 C 语言中变量的几个要素（变量名、变量类型、变量值、变量地址等）。对于普通变量而言有些要素是等价的。 变量名作为右值时代表变量值（无存储空间的概念，所以不可进行赋值等操作，不携带类型信息，比如 float a = 1.5; int b = a;后面的 b = a 中 a 作为右值是没有变量类型信息的，其存入 b 中时，其类型是由 b（左值） 决定的）；作为左值时代表变量值的存储空间，同时携带了变量类型信息。从指令的角度来讲，左值懈怠了操作码（有的甚至携带了立即数（一种默认操作数））；右值只是操作数，所以要结合左值才能完成操作。 变量值（右值）没有类型信息，其行为就由左值决定，不过在 C 语言中运算时会先以运算中涉及到的最高精度的类型为准（低精度的值的副本（实际上原本的值精度不变，只是副本提升精度而已）会被提升精度），最终原酸结果再由左值类型确定最终的精度。 变量名一般会和变量地址区分开（通过取地址符），不过在某些场合变量名也可以代表变量首地址。比如数组名、字符串名等。 变量所占空间实际上是由变量类型决定的（决定了变量所占的字节数，要较真的话，还要考虑对齐，这是对 CPU 访问内存的一种优化措施），不过决定到内存中的那块区域，则还需要变量首地址、地址增长方向来限定（也只是决定了逻辑空间中的位置而已，如果想确定物理空间中的具体位置，还需要逻辑地址到物理地址的变换机构和变换逻辑支持，请查阅操作系统相关内容）。 变量的行为则是通过该变量参与的函数过程（当然还有某些操作符）来体现的。C++ 则将变量（数据成员）、函数（方法、行为）、操作符（操作符重载）等封装成了一个类（你可以把类看作 C 语言中的类型）。 指针变量：首先它是一种特殊的普通变量，所以具备普通变量的有关特性。它的特殊性表现在其变量值具有类型信息（前面已经提到，该类型信息由指针类型提供，不等同鱼其所指向变量的真实类型）。换句话说，指针变量是一种普通变量，并且变量值也是一种普通变量，如此你根据变量具有的属性分别解读即可。这两种变量如何切换呢？通过取址（是右值）和解引用（取值，是右值）操作来实现。前面多次提到左值和右值，好像有必要说下它们的区别了。然而，C 语言增加了 const 关键字，这又增加了区分左值和右值的难度。左值、右值、const 有何区别？简单说来，左值有存储空间（在堆、栈等中）、右值没有存储空间（这怎么找到它？变量值取出后放在寄存器等中暂时存放，已经无法再通过这个值定位它来自那块内存区域，而对于暂时存放的位置是对程序员透明的，也就是说程序员是不能对他进行定位存放操作的）。可见右值是不能通过赋值等来修改的，而左值原则上是可以的。那左值到底能不能修改呢？这是一个访问控制问题，可以通过 const 关键字来修饰。如果已经用 const 修饰过了，能不能修改呢？当然可以，不过需要强制修改其访问控制属性（C++ 中提供了显式修改该属性的运算符 const_cast）或者通过指向它的指针来修改（因为指针访问其指向的变量和通过变量本来来访问，这两种访问控制策略是独立的，虽然访问的是同一内存空间）。我们已经知道指针变量和其所指向的变量都可视为普通变量，也就是说都可以用 const 修饰，那如何知道 const 修饰的指针本身还是指针指向的变量呢？C 语言是通过 const 在声明指针时放置的位置来区分的。已经知道指针类型实际上限定的是指针所指向的变量的类型（不等同于所指向变量的真实类型），而指针在声明的时候是以 “*” 来区别于非指针变量的。根据这条经验不难分辨以下事实： int const *pa = &amp;a; // * 表明 pa 是指针，其指向的变量类型为 int const，也就是说 const 修饰的是指针所指向的变量（即 *pa ） const int *pa = &amp;a; // 同上 int * const pa = &amp;a; // * 表明后面的是关于指针的说明信息，可见 const 修饰的是指针本身（即 pa），也就是说 pa 的值是只读的，不能随便更换指针指向。而指针指向的变量的值是可写的（即使指针所指变量的真实类型中有 const 修饰）。 int * pa const = &amp;a; // const 放置的位置错误，编译不通过。 const int * const pa = &amp;a; // pa 指向不可变（即 pa 不可变）、同时也不可改变所指向变量（*pa）的值。 int const * const pa = &amp;a; // 同上static 修饰指针的特殊性指针类型和指针指向的变量的真实类型可以不匹配，但如果指针声明为 static ，则指针所指向的变量也必须是 static（这是由 static 本身对存储位置的要求，因为 static 必须在编译期间由明确的位置信息，如果所指向的变量不是 static，也就是说其位置不能在编译期间确定，那么指针的值也就无法确定，这就违背了 static 的要求），反之不成立（指针类型优先于其所指变量的真实类型，何况指针此时是 auto变量，对值是编译期间确定还是执行期间确定并不关心，对值指向的变量存储空间在全局区还是堆栈等都不感兴趣）。而且用 static 声明指针时 static 只能放在 * 之前的部分（因为指针指向的变量已经分配空间，其存储位置和生命周期已定，不能再使用存储类型关键字指出其存储类型，所以 static 只能被解读为修饰指针，不存在二义性，于是按照 C 语言习惯和可读性要求，就规定放在 * 前面了）。volatile 修饰指针volatile 也有类似于 const 的用法，而且可以和 const 同时使用。其中volatile只是要求使用变量的时候，它的值都需要直接从内存中取的（不相信寄存器或其他缓存中的值），换句话说，被其修饰的变量的值随时都可能改变，缓存值无效，编译器最好不要擅自优化。概念的图示化这一小节中将以图示的方式直观呈现指针中涉及的几个概念间的关系。从图中可以看出： 指针变量所占的字节数是相等的，与指针类型无关； 指针所指向的变量通过指针操作时，其类型（所占字节数、值的意义、变量行为等）由指针类型决定； 指针的值只指出了其所指向变量的首地址（不携带类型信息）； 指针所指向的变量通过指针访问时，其类型并不一定与其真实的类型相同（只能保证首地址一致）。 当指针类型与其所指向变量的真实类型不同时，可能出现以下情况： 前者解读的空间大小小于后者，此时解读出的意义一般不同，解读出的值可能与大端小端方式有关； 前者解读的空间大小大于后者，此时出现越界，可能破环堆栈和出现运行错误； 前者解读的空间大小等于后者，因类型不同，解读一般也不同（虽然内存中的值是确定的）， 后者通过指针访问表现的行为一般和其真实行为（可以参与的运算或操作）不同。 前者解读的空间即使大于后者，系统也不会因此而重新分配多出的空间，所以可能破环相同地址空间的其他数据，也可能越界访问不存在的空间导致越界中断。 综上，通过指针访问其指向的变量和直接通过变量本身访问（虽然它们共享部分存储空间）是不同的。理解这一点非常重要。既然指针所指向的变量和变量真实本身是共享部分存储空间的，所以指针类型不能改变其所指向变量的存储类型及存储位置。指针类型与指针所指向变量的真实类型最好要匹配（除非你特意为之），否则可能出现出乎意料的值，甚至出现安全问题。指针移动（自增、自减等）的单位是由指针类型解引用之后的类型所占字节数决定的，而非指针所指向变量的真实类型。再次强调：指针变量和普通变量都是一种变量，都具有变量的通性，只不过指针变量的值也具有变量的属性（由指针类型指出），这是其与普通变量非常重要的区别。指针存在的意义上节已经提高了使用指针引起不良后果的警告级别，既然指针如此凶险，为何 C 语言还让指针肆虐？事实上，要增强指针的安全性并不是没有办法，完全可以增加一个“抽象层”对指针安全性进行检查（编码期、编译期和运行期间都可以做相关工作，C++ 增加的很多特性都与指针有关），不过：一旦你和什么东西之间被加上了一个抽象层，那你就一定得在每次访问它时受到某种限制、或者付出某些代价（执行效率、编码自由等）我喜欢知乎上的一句话“指针不是什么精髓，它只是一扇门，推开门，后面是整个世界，任你驰骋”。C 语言情结： C 语言是工程师为自己设计的语言。它是为那些对机器了如指掌的专家设计的。 C 的设计者并不认为需要对工程师做任何约束，因为他们知道自己在干什么（甚至特意这么做）； C 并不是学院派语言，它并不打算为了贯彻什么什么理论、什么什么概念而设置什么条条框框； C 并没有为了纯粹的结构化/面向对象等排斥其他，这些都只是思想而已，你完全可以用 C 实现面向对象甚至泛型编程等。说了这么多，一言以蔽之：如果你，喜欢自由、喜欢和机器近距离打交道、包容万物、喜欢穷尽底层细节。那么 C 语言是你的不二之选。不能光拼情结吧，说点别的。指针带来的好处 简单封装：封装了一块共享内存（与所指向的原变量）、绑定了一组操作（函数、运算符等）； 灵活共享、独立控制：可以共享（全部或部分、甚至有意越界，如攻击者通过这种机制实现跳转到恶意代码处执行）内存、但仍可以不共享操作（当指针类型和所指向变量的真实类型不匹配时）、还可以采用不同的访问控制策略（如，指针类型中无 const 修饰时，可以修改其指向变量的真实类型中有 const 修饰的变量）。换句话说，在内存的同一块区域中实现不同的用途。 以名表义：一个变量在不同时期或过程中可能有不同的意义，而变量名是不可更改的（当然你可以通过 #define 类似的方法，但失去了编译器类型检查的支持），此时可以使用指针选取合适的名称来以名表义（在 C++ 中，你可以使用引用来实现）。 实现多态： 改变指针指向，实际上意味着改变了操作所对应的数据，一般会得到不同的结果；C++ 中函数重载实习了这点。 指针转型可以使用不同操作（这种转型比普通变量转型损失的信息要少很多）。这在 C++ 继承体系中表现明显。 函数指针巧可以同时巧妙地改变输入数据和处理过程。C++ 引入了虚函数（底层仍然是通过指针实现的）实现多态，显得更为强大。 简易访问连续内存：对于一片连续的内存，你没有必要批量分割分别命名，你可能只需要一个指针和合适的增量即可（C 语言中的数组已经显式地提供了这种功能，虽然没有本条说明的那么厉害）。 减少拷贝、节约内存（栈空间）：为了提高安全性、无关性及设计的简单性（函数调用等用栈实现较为容易），不同函数（或进程线程等）操作相同的数据时，一般采用拷贝数据到自己的栈空间（私有空间），然后返回处理结果供外界使用。这样至少付出以下代价： 传入数据很多时，拷贝进入很耗时； 传出（返回）数据很多时，拷贝出去很耗时； 运行栈会增大（可能导致栈溢出）。栈的设计理念（作用域限定在过程内部）导致其不容易实现共享内存，为此 C 语言增加了“堆区”的管理理念（空间申请和释放时机由程序员自己把握，即使在过程外部也可以定位）来配合指针发挥效能。指针语法如果你对指针本来就了解比较多，只是有些模糊而已，那么你只需要看完前一节的概述就可以止步了。本节主要从语法的角度来探讨指针的设计思想和实现机制。虽然本节的标题是“指针语法”，不过不会详细讲解这方面的内容，需要知道所有的语法细节，请参考相关书籍。指针声明及其解读指针声明的一个显著特点是含有 * ，直觉上来说，应先从它入手。既然是变量声明，接下来应该找到声明的变量。找出指针变量之后，剩下的工作只需要确定指针类型即可。找到声明的变量指针变量名必定位于* 之后（=号之前），不过较为复杂的声明可能同时出现多个 *，这增加了分辨出所声明的指针变量名的难度。还好，可以先从简单的开始，然后慢慢过渡到复杂的情形。 int * p = &amp;a;这最为简单，* 之后 = 之前，只有一个 p，很明显 p 为指针变量，此时 * 翻译成指向，剩下的 int 即为指针指向变量的类型。如此，可翻译成“p 为指向 int 类型变量的指针” int * p[3];此时 * 之后出现了 p 和 [3]两个成分，它们是结合看待还是分开呢？这是一个结合方向和结合优先级的问题。p 应该和 [3]结合，这就成了一个数组，也就是说变量无法和指针结合（只有与 “ * “ 结合，才能翻译成 “指向”）。联想到数组的声明（int a[3];），可知 int * 应该是数组中元素的类型。说到优先级了，就说下自己的理解吧。下面给出的优先级顺序，是基于事物内在关系、设计思想、实现先后、特殊到一般的理念归纳出来的。括号（界定对象，该对象可以是变量、表达式等）---&gt;取变量（括号识别对象之后取对象，当然括号可适时省略）---&gt;取变量值---&gt;对值自身运算（运算少的---&gt;运算多的）---&gt;(扩大参与的对象)算术运算---&gt;移位操作(用到算术、同时可实现算术)---&gt;比较运算(有可比性的特殊逻辑)---&gt;位逻辑(可实现比较运算)---&gt;逻辑运算---&gt;条件(对逻辑运算结果进行判断)---&gt;赋值(转移运算结果)---&gt;表达式松散关系(逗号运算符)上面的总体逻辑是：识别对象—&gt;取得对象—&gt;对象自身运算—&gt;对象之间运算—&gt;运算结果判断—&gt;运算结果转移—&gt;运算结果松散汇总。至于具体得运算符优先级，请参考其他资料。 int (*p)[3];根据优先级规则和前面两例提到的指针解读规则，p 与 * 结合，可得出：p 是指向 int [3] 的指针。也就是说，p 是指向数组（有3个整型元素）的指针。 int * p(); int * p(int);int * p(int, char);同理，根据优先级可知 * 之后的 p 应该和 () 结合（即无法与 * 结合，也就无法解读为“指向”），此时 p应该解读为函数，() 中的类型解读为函数参数类型。依据函数声明的形式可知，* 应该与其前的 int 结合，解读为函数的返回值。 int (*o)(int, char);此例中， p 与 * 结合，解读为“p 指向”，去掉 (*p) （或者把它看作一个整体）之后，剩下 int (int, char)，对照函数的声明形式，可知这部分为函数。综合起来可解读为：“p 是指向函数的指针，其中该函数有两个参数，分别为 int、char，而其返回值为 int 类型”。理解上面的例子之后，其他复杂的声明都是由它们的有机组合而成的。不过还是有些麻烦的，这表现在：当有多个*出现在声明中时，应该以哪个作为参照物？这需要适当分组识别，即先看整体，再看部分。但这又引出了一个问题：应先把哪些部分看成一个整体？就如同一个英语长句，如何找出主谓宾，因为主谓宾可能也是一个复杂的短语或从句。对于选择哪个 * 作为参照物的问题，实际上很容易解决。声明一般只出现一个变量名，其他都是类型名（有的可能通过 typedef或 #define 等隐藏了类型信息，看起来类似变量名，这时就需要先识别出变量名；为此，如果你是开发人员，建议 typedef 等的类型名后面加_t 进行标识；如果不是你写的，你可以用其他名字替代有疑问的名称，若替换后不出错，说明你替换的名称就是变量名；当然，你也可以使用开发环境的变量定义跳转功能或者变量查看功能识别出变量名；如果有人故意为难你，不让你使用前面的两种方法，你可以用假设某个名称是变量名或类型名，然后进行解读，如果只有一种解读方式成立，那么可以区分，否则就认命吧），所以只需要定位变量名，然后就近在其前的哪个*就是。至于将哪几个部分作为一个整体来看，请参考前面的规则（优先级及结合规则）。下面给出几个复杂的例子运用以下前面的理论。 const int* (* (* pt)[3])(const double * ,int) = &amp;p;这里有多个*，所以首先找到还未定义的变量 pt，而()使 pt 与 * 结合，因而解读为“pt 指向”，去掉* pt之后来到 (* [3])，根据优先级可知“pt 指向数组（其中有 3 个元素）”，对照数组的声明方式可知，数组的元素是指针，其指向（去掉(* (* pt)[3]) 可知）const int *(const double *, int)，对照函数的声明方式可知，数组元素指向的是一个函数，根据函数声明的组成成分可知，该函数的参数为 const double *, int，返回值为 const int*。前面是解读复杂指针的方法，如果你想写复杂指针声明（不建议这么做，可读性太差了），应先写中心词部分，再写次要部分，然后以此不断扩充。例如你要写前面的例子，首先ta是一个指针，写为(*ptr)，指向的是数组，写为(*ptr)[3]，数组中的元素是……如果实在要写复杂的指针声明，可以借助 typedef 提高可读性。例如：void (* signal(int signum, void (* handler)(int)))(int );可以分解成：typedef void (*sighandler_t)(int);sighandler_t signal(int signum, sighandler_t handler);当然此时你得心里非常清楚，使用的 typedef 意味着什么，与 #define 宏替换有什么区别，是否可以简单替换后重新解读？为此，马上为你理清这些问题。指针类型和指针指向的变量类型互推前面已经强调了指针类型决定了指针指向的变量类型，与被指向的变量真实类型不一定相同（当然，指针类型更不可能改变被指向的变量真实类型），这里又说“指针类型和指针指向的变量类型互推”是怎么回事呢？实际上，这里指的是： 变量类型已知，但你需要声明一个指针来操作该类型的变量； 指针类型已知，你需要一个合适的变量地址赋给或初始化该指针；这么说来，的确是一个互相推导的问题吧 ^_^。对于前者，只要对照变量的声明，将声明中的变量名替换成“*指针名（有时候可能需要外面加()）”即可。例如 int a[3] 对应的指针声明为 int (*a)[3] 。对于后者，则是前者的逆操作。随便说下，顺便说一下，复杂的类型如何声明？可以从简单类型开始根据各组分分别扩充即可。例如数组，数组元素可以指针，这指针可以是函数指针，函数有返回值、参数列表，而返回值、参数列表又可以分别是……typedef 和 #define 在声明中的区别郑重声明一下，typedef 和 #defien 都不能创造新类型，都是在已有的类型上为了可读性或节约书写时间或适应不同场景等而提供的改造。千万别被本节的标题误导。在进入正题之前，先举例说明以下。 typedef int* int_ptr; #define int_ptr int*从上面可以直观的看出：def 对应的是“新名字”，type 表示“类型”。根据这一点确定第一个例子中，int* 和 int_ptr 的先后次序（int* 是一种 type（类型），int_ptr 是你的 def（新名字））；第二个例子中，#define 中的 “def” 确定了 int_ptr 应放在int* 之前。同时，typedef 对应的是一条表达式语句（需要用 ;），而 #define 是一条宏定义语句（单独成行，不能用 ;，除非有其他特殊用途）。#define其中#define 是在预处理时进行替换操作，建立在源码文本处理的基础上。比如上个例子中，只要在源码中遇到单词 int_ptr ，预处理器就会把它替换成 int* ，即使你不小心定义了一个变量 int_ptr, 它也会照常替换，当然这就可能造成莫名奇妙的错误，更糟糕的是，调试也显得无能为力（因为，替换过程在预处理时（即编译之前）已经完成，编译之后根本没有包含对于宏的任何信息，在这种条件下对它引起的问题进行调试，可能太为难调试器了）。所以，旧有类型经 #define 得到的新名字，只是文本替换而已，所以用新名字声明的变量的真实类型 就是文本替换之后的类型。比如，判断 int_ptr ptr1, ptr2; 中 ptr1 和 ptr2 的类型时，应先替换成 int * ptr1, ptr2;（指针声明有点特殊，逗号前后不共享指针声明符）再解读。这样处理之后可知，ptr1 是整型指针，而ptr2不是指针而是整型变量。如果你把新名字当作旧有类型的别名（很可能把 int_ptr 理解成整型指针），可能就会把 ptr1 和 ptr2 都理解成整型指针了。typedef先看对比例子： int* int_ptr;（声明可以使用逗号接连声明） typedef int* int_ptr;（typedef 也可以使用逗号一次性定义多个别名）看到这两个例子，你想到了什么？是不是感觉：typedef 只是加到了变量声明语句的前面，然后本来应该是“变量名”，结果变成了“类型”的别名。这个发现在简单的类型别名声明中比较明显，在复杂的别名声明中可就没那么容易。比如： typedef double (* (* (*fp3) ()) [10]) (); typedef double (* (* (* ) ()) [10]) () fp3;这两例中，前者是正确的，后者会报错。貌似这和刚讲的有冲突，其实不然（即使不适用 typedef，只声明指针也是这样的，去掉typedef 之后，不就是单纯的指针声明了么）。在上一节中解读复杂指针声明时，提到在判定指针类型期间，需要以（指针）变量名作为定位的参照物，同理，作为对类型取别名的 typedef 也需要。从这个方面来看，后者根本无法判断类型，作为需要类型检查的 typedef 当然会报错。综上，对于 typedef 的解读，可以先不看 typedef 。比如前者不看typedef就剩下double (* (* (*fp3) ()) ()) [10] ()，然后判断这个类型（判断方法见上一节）即可。此时判断出的类型，就是用该名字声明变量的真实类型，例如，fp3 a,b,c; 语句中 a b c 的类型是一致的。类型别名与 const（volatile 类似） typedef int* int_ptr; const int_ptr val; #define int_ptr int* const int_ptr val; 上面两例中的 val 的类型是不一样。前者的类型是常量指针还是指向常量的指针呢？换句话说，const 修饰的是指针还是指针指向的变量？根据前面的论述，应先从 typedef int* int_ptr; 中解读出 int_ptr 为整型指针（中心词为“指针”，也就是说，它是一种指针类型），因此紧跟其后的 const int_ptr val; 中 const 修饰的是指针，所以整体应解读为“val 为常量整形指针”。如果，val后面还紧跟其后有 ,val_1，则 val_1 与 val 同类型。后者是通过 #define 来实现的。根据 #define 的特点可知，此时的 val 为指向整型常量的指针。如果紧跟其后有 ,val_1，则此时val_1 为“整型常量”。指针运算指针的值是某个变量的首地址，指针类型指出了指针所指向变量所占字节数（这是由指针类型决定的，而非被指向变量的真实类型）。可见，指针是通过“首地址”为起点、“指针类型所占字节数（步进单位）”为步进、正负号标识步进方向来实现连续内存的访问、所指内存是否相同等。因此，在进行指针运算之前，应知道指针类型、指针类型指明的内存大小、指针的值、指针本身、指针本身地址、指针所指内存的首地址。指针的算术运算 指针加减一个整数指针加减一个整数，表示前进后退整数个步进（指针类型所占空间单位）。没有指针与整数的乘除或取余运算，自增自减（++x; x++;–x; x–）是一种特殊的“指针加减一个整数”的运算（特殊在这个整数为 1）。至于两种自增自减的区别也很明显，++（或–）放在变量前面的，表示使用变量之前自增（或自减）；放在变量之后，表示先使用该变量，执行该条语句之后再自增（或自减），即自增（或自减）效果在本条语句中不表现（这种效果可以通过一个临时变量来实现，即），但会在之后的语句中表现出来。这里所说的语句包括“; 和 ,”分割的表达式（这里又引出了一个问题，逗号表达式对于后自增自减而言，是从逗号左边开始还是从右边开始？这和编译器有关（一般情况：表达式中自左向右计算，参数自右向左运算），所以最好还是不要玩类似的花招）。后面一小节会单独讲下前自增（或自减）与后自增（或自减）的区别。根据硬件的越界中断判断机制（大多以一个地址为基地址和空间大小、或者起始地址和结束地址作为边界，从这可知，指针的加减以及比较运算是由硬件机制原生支持的），指针加减整数的运算实现简单且意义明确（在基地址的基础上，前进或后退多少个单位，程序员可以比较清楚的知道，指针指向了哪里）。而指针乘除一个整数等运算，虽然原理上是可以进行的（可以通过越界中断判断机制来提供最后的安全屏障），但是意义不明确（因为越界中断等属于硬件底层，是对程序员透明的，所以程序员根本无法知道经过这种运算之后指针指向了哪里，更不知道指向的内容是什么，那解读出来的值又有什么意义呢？如果要写入点什么的话，极有可能破环程序运行的管理数据，从而导致程序发生致命错误而推出，更要命的是，这种错误在编译调试的时候很难发现，甚至在运行期间也可能是随机表现的，最后给用户留下了极大的隐患）。所以从安全角度和实际意义上来讲，都不应对指针进行乘除等运算。综上可知，指针加减一个整数非常适合对连续内存块以适当的步进进行访问，添加适当的判断并结合循环便可实现连续内存访问的自动化。其中用指针访问数组就是一个很好的例子（不过对于数组的访问，还是建议使用下标，这种方法意义更明确一些，可读性更好）。下面给出一个实例：int main(){ const size_t arr_size=8; int int_arr[arr_size]={0,1,2,3,4,5,6,7}; //pbegin指向第一个元素,pend指向最后一个元素的下一内存位置 for(int *pbegin=int_arr, *pend=int_arr+arr_size; pbegin != pend; ++pbegin) *pbegin=0; //当前元素置0 return 0;} 指针相减指针相减适合于同类型指针，并且指向同属于同一个有明确意义的连续内存的情况下，否则将失去运算的意义。 假设是不同类型的指针相减，那得到的差值是字节数还是其中某个类型所占内存单位？这是说不清楚的。 假设是同类型指针相减，但指向不同属于一个有明确意义的连续内存（比如数组），也就是说有两种意义（两个指针分别属于不同意义的连续内存）。这种情况下，也不知道差值应解读成何种意义。指针相加也是没有意义的，理由同指针与整除的乘除运算。前自增和后自增的区别前自增(++x)和后自增(x++)在下一条语句执行时，变量中的值是相等的。它们的区别只是表现在执行所在语句的时候。 前自增：变量自增之后，再作为一个变量（已经加 1 了）参与运算； 后自增：先取出变量的值（可以按照这个方式实现：取出的值存入一个临时变量（该临时变量是假想的，可能不是这种实现方式），用完即消失（是一次性，除非是多重后自增，此时操作的仍然是同一个临时变量），但是请注意原变量已经加 1 了，只不过后自增临时使用的是临时变量而已，所以再次使用该变量（不论是取值还是自增自减）时，必须从原变量（已经加 1 了）取值。可见，它们参与运算的身份是不一样的，前自增以变量的身份（左值，后自增整个用括号括起来看做右值，所以多重后自增是不能编译通过的）参与，而后自增一次性的以值（借助临时变量）的身份（右值）参与。为此看以下例子：#include&lt;iostream&gt;using namespace std;int main(){ int a = 1; ++a = a; cout &lt;&lt; a &lt;&lt; endl; ++a = 3; cout &lt;&lt; a &lt;&lt; endl; return 0;}根据优先级规则，可以比较容易得知道两条输出语句分别输出“2 3”。#include&lt;iostream&gt;using namespace std;int main(){ int a = 1; a++ = a; cout &lt;&lt; a &lt;&lt; endl; a++ = 3; cout &lt;&lt; a &lt;&lt; endl; return 0;}上面的程序编译不通过，原因在于后自增的结果是一个右值，不能被赋值。现在应该比较清楚前自增和后自增的区别了。真的吗？看下面的例子：#include&lt;iostream&gt;using namespace std;int main(){ int a = 1; int b = ++a++; cout &lt;&lt; b &lt;&lt; endl; return 0;}上例的输出结果是多少呢？实际上根本无法编译通过！当前自增和后自增同时修饰同一个变量时，涉及到前自增、后自增哪个优先级更高的问题。按照本博客总结出来的优先级规则，可知后自增的优先级更高（后自增只需要取出值即可，而后自增还要自增再取值）。上面的例子中，先后自增得到了一个右值（临时变量已消失），却要求它执行前自增（左值才有的行为），当然会报错。如何修改呢？只需要改成int b = (++a)++ 即可通过编译。你可能会说，现在明白了，不过再看个例子先：#include&lt;iostream&gt;using namespace std;int main(){ int a = 5; int b = a+++a+++a++ + ++a; cout &lt;&lt; b &lt;&lt; endl; return 0;}上面的输出结果是多少呢？是 “20 21 23 24 ……”中的哪一个？实际上正确答案没有给出。应该是“27”。b = a+++a+++a++ + ++a中，从左至右，根据优先级分解成 a++ 、 + 、 a++ 、 + 、 a++ 、 + 、 ++a，先求出给个组分的值再求和。第一个 a 为 5（该值由临时变量给出，实际变量已经加 1 了，变成了 6），第二个 a （需要使用前面的 a，此时的 a 是真实的变量而不是临时变量，所以已经加 1）为 6（该值由临时变量给出，真实变量已经加 1，变成了 7），第三个 a 为 7（同样由临时变量给出，实际上该真实变量已经加 1，变成 8 了），第四个 a 为 9（由 8 增 1 得出），再全部求和就是 27。再看这个例子：#include&lt;iostream&gt;using namespace std;int main(){ int a = 5; cout &lt;&lt; a+++++a &lt;&lt; endl; return 0;}上面的输出结果是多少？实际上编译不通过。原因是 ((a++)++)+a ，从前面的分析可知，问题出在第二重后自增。请根据本分的论述，自行解答一下下面的两条输出语句：int a = 5;cout &lt;&lt; ++++++a &lt;&lt; endl;a = 5;cout &lt;&lt; ++++++a++ &lt;&lt; endl;其中前自减和后自减同“前自增和后自增”。指针的比较运算指针的比较运算目的在于判断两指针是否指向了同一块内存，是否同属于同一个明确意义的连续内存，在同一个有意义的内存中两指针指向位置的相对位置情况（实际上也是为了在一个较大的有意义的连续内存中划分出有更特殊意义的连续内存片段，便于分别处理或做出其他判断）。所以，指针提供“==，!=”比较运算符来判定指针是否指向了同一块内存（然后，进一步确定是否需要释放或申请内存或其他操作）。而“&gt; , &gt;=，&lt;，&lt;= ”等运算符，则必须在同一段有明确意义的连续内存中才有效，一般用于确定有意义内存段或小片段的边界或判断是否在有意义的内存段内。注意，这里说的是指针比较运算，而不是指针所指向的变量之间的比较（这种比较由所指向类型定义，与指针比较运算无关）。指针取址、取值及其使用所谓指针取址得到的是指针本身（指针也要占用内存，必然由地址）的地址（为右值，可见，它可以赋值给其他指针，从而产生多级指针）。指针取值 得到的是与指针类型对应的变量（为左值，可以是普通变量。也可以是指针变量），其可以进行的操作由类型定义的行为方法决定。指针取值（如 (*ptr) ，其中括号根据优先级和结合方式可酌情省略）后，就可以替代指针所指向的类型变量（而非变量的真实类型）角色和地位。如果你不知道指针取值后该如何使用，你可以先找到指针所指向类型的变量，看它是如何使用的，然后比如类似用 (*ptr) 替换该变量即可。特别地，当使用指针调用结构体（或类）中可调用的成员（数据成员或函数成员）时，假设指针为“ptr”，指向的变量为“p”，则此时“ptr-&gt;成员”、“(*ptr).成员”、“p.成员”，三者等价（前提是 p 和 ptr 指针类型对应）。指针与数组、结构体、函数指针可用于有明确意义的连续内存，而数组、结构体就是一块有明确意义的连续内存块，所以它们之间的关系当然不一般，有时候甚至会理不清。指针与数组声明数组之后，数组这块连续内存就由数组名标识了，不过遗憾的是，C 语言并没有记录该块内存的结束位置或所在内存大小（你可能会说，声明的时候不是给出数组的大小了吗？即使没给出也可以使用 sizeof 知道，不过你得清楚这是在编译时完成的，而在运行时不提供这种边界检查（编译时也不提供，它最多提供类似 int a[2]={1,2,3} 的检查，数组大小为 2，却存三个元素，其他就无能为力了，为了防止出现类似错误，我们一般使用类似 int a[]={1,2,3} 的声明，此时可以说，C 语言完全不提供边界检查），这完全要靠程序员自己把控，也就是说，“程序员必须知道其明确意义（类型、大小、边界等）”），即使记录了（在内存分配的时候，应该是记录了），也没有在编译或运行时进行边界检查（如果每次都边界检查，编译效率和执行效率势必大大降低，况且 C 语言的哲学是：工程师知道自己的干嘛。因此 C 语言没有提供这种检查）。数组名是某块内存的标识，那它是“左值”还是“右值”呢？换句话说，它是否能够被赋值或改变呢？假设数组名能够被赋值或者作为左值被改变，那原来被数组名标识的连续内存还能找到吗？当然找不到了，你可能会提出一个解决方案，先把原来的数组名代表的内存信息保存下来，然后再对数组名赋值。这不就是指针的工作吗？而且这种解决方案增加了安全隐患，万一你忘记先保存（这种忘记时常发生）所以，最好的方案是不允许数组名改变和被赋值，即它指针作为右值使用。C 语言采用的就是这个最好的方案。int a[] = {1,2};cout &lt;&lt; a++ &lt;&lt; endl;//错误，左值行为cout &lt;&lt; ++a &lt;&lt; endl;//错误，左值行为不过，上例中改成 cout &lt;&lt; *(a+1) &lt;&lt; endl; 是正确的，这是因为，此处的数组名是在表达式（默认右值）中，且没有使用类似 ++a 等的左值行为，只需要取出地址（数组首地址）然后移动一个单位（单位大小由数组声明时的类型标识符决定，这里是 int）到另一个地址（而且这个地址是由明确意义的，相当于 &amp;a[1]）取出值解读（如何解读，也由数组声明的类型决定）即可。这一个过程完全没有向数组名写入的操作（左值行为）。综上，数组名只是一个地址（数组首地址和数组首元素的地址），是一个右值，不可向指针那样进行自增自减、被赋值等左值行为。不过，你可鞥这样反驳我：为什么类似 a[0]、a[1]等的却可以被赋值或自增自减？前面解读的是数组名（它只是提供了数组的首地址，损失了数组大小、边界等信息），可能会让你误解数组名和数组这两个东西是等价的，实则不然。通过数组的声明形式就可以看出：数组实际上是同类型（这个类型由数组声明时指出）变量的集合，只是这个集合的位置由数组名指出而已（集合中的任何一个变量都和通过这个地址做适当变换来找到）。也就是说，数组名没有存储单元来存放它（当然，符号表中有它的身影，但是这块区域是只读的），当然你就不可能改变它的值了。而数组中的元素是分配了内存的，所以数组中的每个元素都是变量，你就像使用其他普通变量一样使用数组中的每个元素就好，虽然数组中的元素变量名称与普通变量有点不一样，比如 int a[2]={1,2}; int b=2;中a[0]、a[1] 和 b 都是普通变量。既然这样，能不能一次性申请一系列变量（一般这些变量会占用一块连续内存），然后通过类似数组的方式访问这些变量呢？这是可以的。请看下面的例子：#include&lt;iostream&gt;using namespace std;int main(){ int a=10,b=20,c=30; //输出各变量的地址，查看地址是否连续、地址增长方向 cout &lt;&lt; &amp;a &lt;&lt; \" \" &lt;&lt; &amp;b &lt;&lt; \" \" &lt;&lt; &amp;c &lt;&lt; endl; //通过类似数组（指针实现）的方式访问连续内存 cout &lt;&lt; *(&amp;a) &lt;&lt; \" \" &lt;&lt; *(&amp;a-1) &lt;&lt; \" \" &lt;&lt; *(&amp;a - 2) &lt;&lt; endl; //确认用逗号连续声明和下面的独立声明的地址增长方向是否一致 int d = 50; int e = 60; int f = 70; cout &lt;&lt; &amp;d &lt;&lt; \" \" &lt;&lt; &amp;e &lt;&lt; \" \" &lt;&lt; &amp;f &lt;&lt; endl; cout &lt;&lt; *(&amp;d) &lt;&lt; \" \" &lt;&lt; *(&amp;d-1) &lt;&lt; \" \" &lt;&lt; *(&amp;d-2) &lt;&lt; endl; //查看连段连续内存之间时候连续 cout &lt;&lt; *(&amp;f-3) &lt;&lt; \" \" &lt;&lt; *(&amp;d-4) &lt;&lt; \" \" &lt;&lt; *(&amp;d-5) &lt;&lt; endl; return 0;}上例中，在本人使用的编译器中，地址是向低地址增长的。通过第二条输出语句的确可以输出 a、b、c 的值；但最后一条语句无法输出 a、b、c 的值，可能是两段连续内存之间有间隔（或者受到输出语句的影响，也就是说，输出语句可能在栈中留下了有关信息，占用了栈内存，从而导致两段连续内存之间有间隔）。同时从这个例子可以看出，变量存储位置与声明顺序有关。为了验证数组的存储方式，再看一个例子：#include&lt;iostream&gt;using namespace std;int main(){ int a[]={4,5,6}; int b[]={1,2,3}; for(int i=-3; i&lt;3; ++i) cout &lt;&lt; a[i] &lt;&lt; endl; return 0;}在本机中，上例的输出结果是“1 2 3 4 5 6”。下面的例子留给读者自行分析了。#include&lt;iostream&gt;using namespace std;int main(){ // a[0] 标识紧跟着的那个变量的首地址， // 这里是 b 的地址 // 这里 a[0] 中的 a 类似数组名 int a[0],b=1,c=2,d=3; for(int i=0; i&lt;3; ++i) cout &lt;&lt; a[i] &lt;&lt; endl; int e[]={4,5,6}; for(int i=-3; i&lt;0; ++i) cout &lt;&lt; a[i] &lt;&lt; endl; return 0;}再来一个例子：#include&lt;iostream&gt;using namespace std;int main(){ int a[0],b=1,c=2,d=3; for(int i=1; i&lt;4; ++i) cout &lt;&lt; a[i] &lt;&lt; endl; int e[]={4,5,6}, f=7; for(int i=-3; i&lt;1; ++i) cout &lt;&lt; a[i] &lt;&lt; endl; return 0;}举上面两个例子的主要是叮嘱大家，不要使用本博客例子中使用的技巧，因为这些技巧在 C 语言标准中没有明确规定，与编译器有关。综上可知，数组名只是标识一块连续内存的首地址，且数组类型保证用下标访问与地址增长方式无关。如果你想私自访问连续内存（不通过数组类型，而是自行通过地址运算来访问），可能需要考虑地址增长方向和代码的可移植性。 a[1] 和 *(a+1) 是等效的； 按照上面的逻辑，* (a+1)可以写成 *(1+q)，那么 a[1] 也可写成 1[a]； 指针访问同类型的连续内存，也可以用数组的方式。看例子： #include&lt;iostream&gt;using namespace std;int main(){ int a=2,b=1,c=0; //下一跳语句应该加上，防止编译器优化 //导致不分配空间给a b，也就不能访问该部分内存, //导致出现随机值 cout &lt;&lt; &amp;a &lt;&lt; \" \"&lt;&lt; &amp;b &lt;&lt; \" \" &lt;&lt; &amp;c &lt;&lt; endl; int *p = &amp;c; for(int i=0; i&lt;3; ++i){ cout &lt;&lt; p[i] &lt;&lt; endl; } int d[]={10,20,30}; p=d; for(int i=0; i&lt;3; ++i) cout &lt;&lt; p[i] &lt;&lt; endl; return 0;}至于用指针如何访问多维数组，请参考其他资料（实际上也可以从本节叙述中找到缘由，C 语言中内存是一维的，多维（形式而已）是通过指针实现的，也就是说，多维数组中只有最后一维是非指针（除非它本身内容就是地址），其他每一维都是一个指针，看法不一样，指针类型（内存分割方式）也会不一样，指针声明方式不一样，访问方式也不一样，所以用指针访问多维数组有多种方式）。现在你应该清楚了数组（数组名）和指针的区别了吧。再强调一下：数组名是用来标识数组所占内存的首地址（一旦申请内存成功，该地址就定下来了，不可改变），属于右值；数组名可以赋给一个同类型的指针，然后指针就可以访问数组这块连续的内存了。当然该指针也可以改变指向，指向其他数组所占的内存，即指针属于左值。看下面的例子：int main(){ const size_t arr_size=8; int int_arr[arr_size]={0,1,2,3,4,5,6,7}; //pbegin指向第一个元素,pend指向最后一个元素的下一内存位置 for(int * pbegin=int_arr,* pend=int_arr+arr_size; pbegin!=pend; ++pbegin) cout &lt;&lt; *pbegin &lt;&lt; endl; //当前元素置0 for(int i=0; i&lt;arr_size; ++i) cout &lt;&lt; int_arr[i] &lt;&lt; endl; for(int i=0; i&lt;arr_size; ++i) cout &lt;&lt; i[int_arr] &lt;&lt; endl; for(int i=0; i&lt;arr_size; ++i) cout &lt;&lt; *(int_arr+i) &lt;&lt; endl; return 0;}下面抛出一个疑问留给读者，同样看一个例子：#include&lt;iostream&gt;using namespace std;int output(int a[], int size){ while(size--) cout &lt;&lt; *(a++) &lt;&lt; endl; return 0;}int main(){ int a[]={1,2,3,4,5,6}; output(a, 6); return 0;}#include&lt;iostream&gt;using namespace std;int output(int a[], int size){ cout &lt;&lt; *a &lt;&lt; endl; while(--size) cout &lt;&lt; *(++a) &lt;&lt; endl; return 0;}int main(){ int a[]={1,2,3,4,5,6}; output(a, 6); return 0;}上面的例子是可以编译通过，并运行正常。好像不对吧，数组名 a 怎么做了前自增和后自增运算，居然不报错？数组名不是右值吗？何以解释？请自行解答，有兴趣可以看“指针与函数”这一节。在最后，补充一下，数组名和 &amp;数组名 的意义是不一样的，前者表示步进为一个元素，后者则为整个数组。所以两者对应的指针类型也是不一样的。 如 int a[3]; int * p = a; int ( *pa)[3]=&amp;a;指针与结构体从上节已得知，数组是同类型的变量集合。而本节的结构体则是，不同类型（可以是相同类型）变量的集合，这些变量同样连续存放。所以必然可以通过指针来访问。不过通过指针访问结构体中的成员比访问数组中的元素要复杂得多，一般会涉及到指针类型的强制转化，同时可能要考虑移动的步进。先来一个例子：#include&lt;iostream&gt;#pragma pack(2)//指定2字节对齐using namespace std;typedef struct{ double a; char b; long c;}st;int main(){ st test={500.12, 'A',1000}; cout &lt;&lt; \"pointer\" &lt;&lt; endl; double *p = (double*)&amp;test; cout &lt;&lt; *p &lt;&lt; endl; ++p; char *ch = (char*)p;//临时将 p \"视为\" char 指针 cout &lt;&lt; *ch &lt;&lt; endl; ch=ch+2; //这个2与内存对齐有关 long *lg = (long*)ch; cout &lt;&lt; *lg &lt;&lt; endl; cout &lt;&lt; endl &lt;&lt; \"struct\" &lt;&lt; endl; cout &lt;&lt; test.a &lt;&lt; endl &lt;&lt; test.b &lt;&lt; endl &lt;&lt; test.c &lt;&lt; endl; cout &lt;&lt; endl &lt;&lt; \"struct pointer\" &lt;&lt; endl; st *pt = &amp;test;//必须用取地址符 cout &lt;&lt; pt-&gt;a &lt;&lt; endl; &lt;&lt; (*pt).b &lt;&lt; endl; &lt;&lt; pt-&gt;c &lt;&lt; endl; return 0;}从上面的例子可以看出，结构体名不能直接当作地址赋给指针，必须要用取地址符（这是与数组的区别之一）。整个结构体占用一块连续的内存，但成员之间可能存在间隙用于字节对齐（为的是提高 CPU 访问内存的效率），这是与数组的区别之二。在讲述数组时，曾提到声明的顺序决定了存储位置。在结构体中成员变量的声明顺序对结构体有什么影响呢？ 影响结构体占用内存大小，进而影响 cpu 访问内存效率； 影响指针访问结构体的步进方式；#include&lt;iostream&gt;#pragma pack(2)using namespace std;typedef struct{ double a; char b; char c; long d;}st1;typedef struct{ double a; char b; long d; char c;}st2;int main(){ cout &lt;&lt; \"sizeof st1 = \" &lt;&lt; sizeof(st1) &lt;&lt; endl; cout &lt;&lt; \"sizeof st2 = \" &lt;&lt; sizeof(st2) &lt;&lt; endl; return 0;}上面的例子的两个结构体的成员是一样的，只不过声明顺序不一样，导致了两条输出语句的输出结构是不一样的。这是字节对齐造成的。理论上，st1 要比 st2 要高效，不论从内存利用率还是从 CPU 访问内存的效率上。对于 st1 取出 b、c 只需要一次访问（32 位 cpu）即可，然后分别取前后一个字节就可得到 b、c；而 st2 中，取出 b、c 需要两次访问。当然用指针（非结构体指针）访问的方式也不同（具体的代码请参考最开始的例子）。那它们用结构体的访问方式是否相同呢？#include&lt;iostream&gt;#pragma pack(2)using namespace std;typedef struct{ double a; char b; char c; long d;}st1;typedef struct{ double a; char b; long d; char c;}st2;int main(){ st1 t1 = {10.12, 'A', 'B', 1000}; st2 t2 = {10.12, 'A', 1000, 'B'}; st1 *pt = (st1*)&amp;t2; st2 *pt2 =(st2*)&amp;t1; cout &lt;&lt; \"st1 pointer visit st2\" &lt;&lt; endl; cout &lt;&lt; pt-&gt;a &lt;&lt; endl &lt;&lt; pt-&gt;b &lt;&lt; endl &lt;&lt; pt-&gt;c &lt;&lt; endl &lt;&lt; pt-&gt;d &lt;&lt; endl; cout &lt;&lt; \"st1 pointer visit st1\" &lt;&lt; endl; pt = &amp;t1; cout &lt;&lt; pt-&gt;a &lt;&lt; endl &lt;&lt; pt-&gt;b &lt;&lt; endl &lt;&lt; pt-&gt;c &lt;&lt; endl &lt;&lt; pt-&gt;d &lt;&lt; endl; cout &lt;&lt; \"st2 pointer visit st1\" &lt;&lt; endl; cout &lt;&lt; pt2-&gt;a &lt;&lt; endl &lt;&lt; pt2-&gt;b &lt;&lt; endl &lt;&lt; pt2-&gt;c &lt;&lt; endl &lt;&lt; pt2-&gt;d &lt;&lt; endl; cout &lt;&lt; ((st2*)pt)-&gt;a &lt;&lt; endl &lt;&lt; ((st2*)pt)-&gt;b &lt;&lt; endl &lt;&lt; ((st2*)pt)-&gt;c &lt;&lt; endl &lt;&lt; ((st2*)pt)-&gt;d &lt;&lt; endl; return 0;}上面的例子说明，结构体类型记录了每个成员的地址（或相对与结构体起始地址的相对偏移量），访问数据成员就是通过这些地址信息完成的。st1 和 st2 数据成员的声明顺序不一样，成员地址记录信息也不一样，所以通过一个结构体类型指针访问另一个结构体类型变量，则一般不会出现正确的值，然后如果临时强制转化指针成对应的结构体指针则又会得到正确的值（如例子中的最后一组输出）。这进一步说明，C 语言通过类型信息来解读内存中的值，通过强制转变类型可以对同一内存相同的存储内容给出不同的解读，同时不同的类型，一般步进也不同（即位置偏移信息不同）。也不难看出，变量声明（起初的类型）只是决定了内存分配的大小，而没有限死该片内存的解读方式（可以通过强制改变类型，改变解读方式），不过变量声明时的类型是该变量使用时的默认类型。进一步可以推测出，同一类型的多个变量是共享类型信息的（就如同 C++ 的类，同类中的不同对象共享函数代码、静态变量等），而类型信息的使用是通过类型名来识别的（你有可能会说，是通过变量来识别的，变量只是有一种默认类型而已），这也是强制类型转化的运作机制。通过对数组和结构体的论述，应该可以安全地说，C 语言的类型首先是对连续内存的分割方式、然后是对分割出的小单位的解读方式、接着是与解读方式对应的行为绑定（函数），然后把这些用一个类型名打包，最后这种机制不断递归演化成更复杂更多的类型。换句话说，如果两种类型的分割方式、解读方式、行为绑定是一样的，即使类型名不一样，也可以视为同一类型，这为类型的安全转化提供了理论支撑。为了验证这个结论，看下面的例子：#include&lt;iostream&gt;#pragma pack(2)using namespace std;typedef struct{ double a; char b; char c; long d;}st1;typedef struct{ double a; char b; char c; long d;}st2;int main(){ st1 t1 = {10.12, 'A', 'B', 1000}; st2 t2 = {22.22, 'C', 'D', 2000}; st1 *pt = (st1*)&amp;t2; st2 *pt2 =(st2*)&amp;t1; cout &lt;&lt; \"st1 pointer visit st2\" &lt;&lt; endl; cout &lt;&lt; pt-&gt;a &lt;&lt; endl &lt;&lt; pt-&gt;b &lt;&lt; endl &lt;&lt; pt-&gt;c &lt;&lt; endl &lt;&lt; pt-&gt;d &lt;&lt; endl; cout &lt;&lt; \"st1 pointer visit st1\" &lt;&lt; endl; pt = &amp;t1; cout &lt;&lt; pt-&gt;a &lt;&lt; endl &lt;&lt; pt-&gt;b &lt;&lt; endl &lt;&lt; pt-&gt;c &lt;&lt; endl &lt;&lt; pt-&gt;d &lt;&lt; endl; cout &lt;&lt; \"st2 pointer visit st1\" &lt;&lt; endl; cout &lt;&lt; pt2-&gt;a &lt;&lt; endl &lt;&lt; pt2-&gt;b &lt;&lt; endl &lt;&lt; pt2-&gt;c &lt;&lt; endl &lt;&lt; pt2-&gt;d &lt;&lt; endl; cout &lt;&lt; ((st2*)pt)-&gt;a &lt;&lt; endl &lt;&lt; ((st2*)pt)-&gt;b &lt;&lt; endl &lt;&lt; ((st2*)pt)-&gt;c &lt;&lt; endl &lt;&lt; ((st2*)pt)-&gt;d &lt;&lt; endl; return 0;}这个例子和前一个例子的不同点在于两结构体的内存分布是一样的，并且行为一样。输出结果（不像前面的例子那样有乱码）验证了前面的结论。指针与函数函数也可以看作变量，它是一段代码的标识，在运行过程中它的参数和返回值是可以改变的，但函数不能修改自身（也就是说代码不能被动态的修改，只是代码操作的数据是可以改变的）。可见函数也应该有类型之分，在 C 语言中函数的类型是由其返回值的类型决定的（在这里还出现了指针函数 和 函数指针易于混淆的点）。事实上，你可以把函数看作一段完成某种单一功能（这里涉及到函数编写的一些方法论，本篇博客不包括这方面的内容）的代码段，函数名为该段代码的首地址（入口地址），参数为数据的入口，返回值为数据处理之后的出口。数据入口和结果出口都是用变量暂时存放的，当然这些变量必然含有类型信息，也即是说，这里的变量也可以是普通类型、也可以是指针类型或其他混合类型或者自定义类型。根据 C 语言的作用域的概念，函数外部的变量（除去全局变量）在函数内部是无法使用的，同时函数内部的变量在函数外部同样也无法使用。按照这种机制，外界如何传入数据呢？这是函数参数的特殊性所在，函数参数贯通了这两个作用域（貌似是两个作用域的交集，但又不是，因为它不归属外部作用域，你可以在外部定义一个与函数参数相同的变量，编译器不会提示重定义，说明两者归属不同），但归属于函数内部（你可以通过在函数内部定义一个与函数参数相同的变量，编译器会报重定义相关的错误）。看到这里，你可能有疑问：参数的这种特性是如何做到的？这和函数调用实现机制有关，主调函数在调用函数 func 之前，会把函数 func 返回后执行的第一条指令（为了后面叙述方便，该指令称之为 next）压入栈中，然后 func 函数参数入栈，同时把实参赋值给函数参数，接着函数的第一条指令入栈，最后把控制权交给 func（也就是func接着执行函数内部其他指令），等 func 执行完之后，把返回值拷贝到指定位置，此时栈顶指针便自然地指向了 next 指令，从而回到了主调函数。根据前面的叙述，func 是不能直接访问主调函数中的变量的（实参传入是主调函数通过复制存入 func 内部的），因为主调函数的变量压在栈偏底部的位置（相对 func 压入的位置而言），而栈只能通过栈顶来取数据，可见，func 在执行代码时栈顶根本无法到达主调函数所在位置，当然无法访问主调函数中的变量。直到 func 函数返回才回到主调函数，一旦 func 函数返回，主调函数也无法访问 func 函数中的变量（因为栈顶指针已经走出了 func 拥有的栈空间（这段空间以函数参数为起点，next 为终点），除非你故意改变栈顶纸质指向），止痒很自然地实现了作用域隔离，至于返回值则是 func 和主调函数都知道的一个位置（比如某个约定的寄存器或其他特定内存块）。那 func 函数要访问自身的某个变量时怎么办呢（毕竟栈顶指针只能指向一个位置，而需要访问的位置是不同的）？这可以通过相对偏移量来找到相对于当前指令的位置，从而确定变量的位置（当然这是其中一种实现方式）。前面提到函数参数和返回值传递数据都是通过复制拷贝完成的，如果数据量很大，岂不是很耗时，同时还会消耗大量的有限的栈空间？使用拷贝传递数据是为了数据的安全性，更为了实现的简单性。综合以上考虑，使用指针来传递数据，只需要拷贝 指针的值（这字节数是固定的，与指针指向的数据内存大小无关），便可访问到指针指向的那一大片内存区域，减少了数据的拷贝，不过也降低了数据的安全性，因为此时主调函数和被调函数共享了这篇数据区域，也就是说不论是主调函数还是被调函数改变了这片内存区域中的数据，两者都可能看到这种改变并受到其影响。不论是使用指针还是非指针传递数据都用到了值拷贝，不过指针传递方式把这个值解读为一片内存的首地址，至于这片内存多大，如何解读，干什么用等，都是由指针类型决定的。比如，如果该指针类型（参数类型）是函数指针的话，那它就可以通过传入不同的函数（只要函数接口一样或者函数接口可以适配）和数据就可以实现不同的功能，从而增加了函数的灵活性，甚至可以实现多态。在使用指针作为函数参数时要注意： 指针作为参数时，拷贝的是指针的值；通过取值操作可以访问指针指向的内存区域，该区域的改变，主调函数可以看得见。但如果你要改变指针本身，则需要二级指针，将指针本身的地址（区别于指针的值）作为值传递给函数。void func(int **p){ if(*p == NULL) p = malloc(100*sizeof(int));}// 下面的函数是无法找到分配的内存的// 从而造成内存泄漏void func(int *p){ if(p == NULL) p = malloc(100*sizeof(int));} 数组名（传入函数的方式可以类似 int a[], 也可以类似 int *a 等，这是其为地址的本质造就的）、函数名标识了对应的首地址，所以它们都可以赋值给函数对应的指针类型的参数 需要强调的是 数组名 和 &amp;数组名 的含义是不同的。 数组名传入函数后，函数就可以通过数组名找到数组相应的内存区域，也就可以修改该片内存中的数据，所以这种改变是永久性的，但它不能改变数组名（即不能修改数组的首地址），话句话说，改变了数组名代表的内存区域中的数据，但没有改变数组名本身。借机解答一下在讲解“指针与数组”这一节中留下的一个疑问吧。看下面的程序。#include&lt;iostream&gt;using namespace std;int output_1(int a[], int size){ while(size--) cout &lt;&lt; *(a++) &lt;&lt; endl; return 0;}int output_2(int a[], int size){ cout &lt;&lt; *a &lt;&lt; endl; while(--size) cout &lt;&lt; *(++a) &lt;&lt; endl; return 0;}int main(){ int a[]={1,2,3,4,5,6}; output_1(a, 6); output_2(a, 6); return 0;}程序中好像数组名作为指针（左值，进行自增运算）用了，而它实际上只能作为右值用。实际上，output 函数参数中的 a 与 main 中的 a 是不同，前者是一个指针变量，后者是数组名，只不过后者赋值给了前者（作为前者的值）。既然如此，前者作为指针变量当然可以执行自增运算（如果还不理解，可以继续阅读本节中有关函数调用的内容）。再延伸一下，函数实参是 const 类型，而形参不是，那在函数内部能不能修改呢？当然可以，因为它们是不同的变量，归属也不同，当然它们的访问控制策略也可以不同（即使通过指针传递方式，指针类型和指针指向变量的真实类型也可以不一样），实参在主调函数中，其操作由其声明时的类型决定，而形参操作则由其在函数参数中声明的类型决定。按照这种说话，它们的类型可以不同，不过需要通过强制类型转化（或者隐式类型转化）才能传入函数。在使用指针作为函数返回值要注意：函数返回值是指针时，该指针指向的内存不能是栈空间（因为栈空间会随着函数的执行结束而自动释放），但可以是全局区、常量区、堆区等生命周期为整个程序运行期或可以由程序员控制的内存空间。有时候为了防止函数返回值（是一个临时变量，改变它是没有意义的）作为左值，可以在返回值类型中添加 const 控制。这可以防止在类似 if(func()=4) 的判断语句中因输入错误而不容易发现的情形；如果添加了 const，则类似情况下，编译器会报错。" }, { "title": "socket 编程原理", "url": "/2017/07/socket.html", "categories": "Linux", "tags": "Linux", "date": "2017-07-04 17:48:44 +0800", "snippet": " Socket 编程比较抽象，而且需要一定的计算机网络基础才能理解其中的来龙去脉，本文将结合计算机网络基础、TCP/IP 体系结构、Socket 技术及相关实例，试图较彻底地理解 Socket 编程，以求应用自如。 简述 TCP/IP 体系结构 socket 套接字概述 socket 编程模型 简述 TCP/IP 体系结构TCP/IP（Transmissio...", "content": " Socket 编程比较抽象，而且需要一定的计算机网络基础才能理解其中的来龙去脉，本文将结合计算机网络基础、TCP/IP 体系结构、Socket 技术及相关实例，试图较彻底地理解 Socket 编程，以求应用自如。 简述 TCP/IP 体系结构 socket 套接字概述 socket 编程模型 简述 TCP/IP 体系结构TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，是一个工业标准的协议集，它是为广域网（WANs）设计的。以下以图的形式简单给出体系结构，详细请参考计算机网络基础。socket 套接字概述socket 是操作系统的重要组成部分之一，它是网络应用程序的基础。从层次上来说，它位于应用层，是操作系统为应用程序员提供的 API，通过它，应用程序可以访问传输层协议。 socket 位于传输层协议之上，屏蔽了不同网络协议之间的差异； socket是网络编程的入口，它提供了大量的系统调用，构成了网络程序的主体； 在 Linux 系统中，socket 属于文件系统的一部分，网络通信可以被看作是对文件的读取，使得我们对网络的控制和对文件的控制一样方便。TCP/IP 的 socket 提供下列三种类型套接字： 流式套接字（SOCK_STREAM）：提供了一个面向连接、可靠的数据传输服务，数据无差错、无重复地发送，且按发送顺序接收。内设流量控制，避免数据流超限；数据被看作是字节流，无长度限制。文件传送协议（FTP）即使用流式套接字。 数据报式套接字（SOCK_DGRAM）：提供了一个无连接服务（UDP）。数据包以独立包形式被发送，不提供无错保证，数据可能丢失或重复，并且接收顺序混乱。网络文件系统（NFS）使用数据报式套接字。 原始式套接字（SOCK_RAW）：该接口允许对较低层协议，如IP、ICMP 直接访问。常用于检验新的协议实现或访问现有服务中配置的新设备。socket 编程模型典型套接字调用过程举例： 流式套接字编程：TCP/IP协议的应用一般采用客户/服务器模式，因此在实际应用中，必须有客户和服务器两个进程，并且首先启动服务器，其系统调用时序图如下。 面向连接的协议（如TCP）的套接字系统调用如下图所示：服务器必须首先启动，直到它执行完 accept() 调用，进入等待状态后，方能接收客户请求。假如客户在此前启动，则connect()将返回出错代码，连接不成功。服务器调用 socket()、bind()、listen() 完成初始化后，调用 accept() 阻塞等待，处于监听端口的状态，客户端调用 socket() 初始化后，调用 connect() 发出 SYN段并阻塞等待服务器应答，服务器应答一个 SYN-ACK 段，客户端收到后从 connect()返回，同时应答一个 ACK 段，服务器收到后从 accept() 返回。建立连接后，TCP 协议提供全双工的通信服务，但是一般的客户端/服务器程序的流程是由客户端主动发起请求，服务器被动处理请求，一问一答的方式。因此，服务器从 accept() 返回后立刻调用 read()，读 socket 就像读管道一样，如果没有数据到达就阻塞等待，这时客户端调用 write() 发送请求给服务器，服务器收到后从 read() 返回，对客户端的请求进行处理，在此期间客户端调用 read() 阻塞等待服务器的应答，服务器调用 write() 将处理结果发回给客户端，再次调用 read()阻塞等待下一条请求，客户端收到后从 read() 返回，发送下一条请求，如此循环下去。如果客户端没有更多的请求了，就调用 close() 关闭连接，就像写端关闭的管道一样，服务器的 read() 返回0，这样服务器就知道客户端关闭了连接，也调用 close()关闭连接。注意，任何一方调用 close() 后，连接的两个传输方向都关闭，不能再发送数据了。如果一方调用 shutdown() 则连接处于半关闭状态，仍可接收对方发来的数据。TCP 状体转换图： 数据报式套接字编程：无连接协议（UDP）的套接字调用如下图所示：无连接服务器也必须先启动，否则客户请求传不到服务进程。无连接客户不调用connect()。因此在数据发送之前，客户与服务器之间尚未建立完全相关，但各自通过 socket() 和 bind() 建立了半相关。发送数据时，发送方除指定本地套接字号外，还需指定接收方套接字号，从而在数据收发过程中动态地建立了全相关。" }, { "title": "Linux 信号机制", "url": "/2017/07/signal-detail.html", "categories": "Linux", "tags": "Linux", "date": "2017-07-02 04:08:00 +0800", "snippet": " 信号机制对于 Linux 而言是一种异步通信的方式。Linux 信号机制比较复杂，这里只对该机制做简单介绍，不过力求理解。 信号概述 信号来源 信号种类 可靠信号与不可靠信号 实时信号和非实时信号 信号流程 进程对信号的响应 信号发送 ...", "content": " 信号机制对于 Linux 而言是一种异步通信的方式。Linux 信号机制比较复杂，这里只对该机制做简单介绍，不过力求理解。 信号概述 信号来源 信号种类 可靠信号与不可靠信号 实时信号和非实时信号 信号流程 进程对信号的响应 信号发送 信号的安装 信号集及信号集设定 信号阻塞与信号未决 信号生命周期 信号编程注意事项 信号编程实例 信号列表信号概述信号是在软件层次上对中断机制的一种模拟，可以根据中断机制来理解其中的某些细节问题，比如，信号处理程序类似中断处理程序。信号是异步的，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。信号是进程间通信机制中唯一的异步通信机制，可以看作是异步通知，通知接收信号的进程有哪些事情发生了。信号机制经过 POSIX 实时扩展后，功能更加强大，除了基本通知功能外，还可以传递附加信息。信号来源信号事件的发生有两个来源： 硬件来源：比如我们按下了键盘或者其它硬件故障 软件来源：最常用发送信号的系统函数是 kill, raise, alarm 和 setitimer 以及 sigqueue 函数，软件来源还包括一些非法运算等操作。信号种类可以从两个不同的分类角度对信号进行分类： 可靠性方面： 可靠信号与不可靠信号； 与时间的关系上： 实时信号与非实时信号；可靠信号与不可靠信号信号值小于 SIGRTMIN( Red hat 7.2中，SIGRTMIN=32，SIGRTMAX=63)的信号都是不可靠信号。 不可靠信号主要问题： 信号处理程序：信号处理程序不是永久安装的，进程每次处理信号后，就将对信号的响应设置为默认动作（而不是用户定制的处理程序），因此，用户如果不希望这样的操作，那么就要在信号处理函数结尾再一次调用诸如 signal()，重新安装该信号。 信号可能丢失早期 unix 下的不可靠信号主要指的是进程可能对信号做出错误的反应以及信号可能丢失。Linux 支持不可靠信号，但是对不可靠信号机制做了改进：在调用完信号处理函数后，不必重新调用该信号的安装函数（信号安装函数是在可靠机制上的实现）。因此，Linux 下的不可靠信号问题主要指的是信号可能丢失。不可靠的主要原因：不可靠信号不支持排队，后面的信号可能覆盖前面还没有来得及处理的信号。 可靠信号信号值位于 SIGRTMIN 和 SIGRTMAX 之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。随着需求的发展，linux 出现了可靠信号，这些信号支持排队，不会丢失。同时，信号的发送和安装也出现了新版本。 信号安装函数：Linux 在支持新版本的信号安装函数 sigation() ，同时，仍然支持早期的 signal（）信号安装函数。 信号发送函数：Linux 在支持新版本的信号发送函数 sigqueue()的同时，仍然支持早期的信号发送函数kill()。注意：不要有这样的误解：由 sigqueue() 发送、sigaction 安装的信号就是可靠的。事实上，可靠信号是指后来添加的新信号（信号值 位于 SIGRTMIN 及 SIGRTMAX 之间）；不可靠信号是信号值小于 SIGRTMIN 的信号。信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。目前 linux 中的 signal() 是通过 sigation() 函数实现的，因此，即使通过 signal() 安装的信号，在信号处理函数的结尾也不必再调用一次信号安装函数。同时，由signal() 安装的实时信号支持排队，同样不会丢失。新旧信号安装函数的相同点：对于目前 linux 的两个信号安装函数: signal() 及 sigaction() 来说，它们都不能把S IGRTMIN 以前的信号变成可靠信号（都不支持排队，仍有可能丢失，仍然是不可靠信号），而且对 SIGRTMIN 以后的信号都支持排队。新旧信号安装函数的不同点：经过 sigaction 安装的信号都能传递信息给信号处理函数（对所有信号这一点都成立），而经过 signal 安装的信号却不能向信号处理函数传递信息。对于信号发送函数来说也是一样的。实时信号和非实时信号非实时信号都不支持排队，都是不可靠信号；实时信号都支持排队，都是可靠信号。信号流程信号从产生到被处理并撤销的过程中，进程对信号的反应，以及使用的函数有所差别。后面将详细叙述。进程对信号的响应进程可以通过三种方式来响应一个信号： 忽略信号：忽略信号，即对信号不做任何处理，其中，有两个信号不能忽略：SIGKILL 及 SIGSTOP； 自定义信号处理函数：捕捉信号。定义信号处理函数，当信号发生时，执行相应的处理函数； 执行缺省操作：Linux 对每种信号都规定了默认操作，如果没有绑定自定义信号处理函数，则执行缺省操作。注意，进程对实时信号的缺省反应是进程终止。信号发送发送信号的主要函数有：kill()、raise()、 sigqueue()、alarm()、setitimer()以及 abort()。int kill(pid_t pid,int signo) pid 的值 信号的接收进程 pid &gt; 0 进程 ID 为 pid 的进程 pid = 0 同一个进程组的进程 pid &lt; -1 进程组 ID 为 -pid 的所有进程 pid = -1 除发送进程自身外，所有进程大于 1 的进程 Sinno 是信号值，当为 0 时（即空信号），实际不发送任何信号，但照常进行错误检查，因此，可用于检查目标进程是否存在，以及当前进程是否具有 向目标发送信号的权限（root 权限的进程可以向任何进程发送信号，非 root 权限的进程只能向属于同一个 session 或者同一个用户的进程发送信号）。int raise(int signo)向进程本身发送信号，参数为即将发送的信号值。调用成功返回 0；否则，返回 -1。int sigqueue(pid_t pid, int sig, const union sigval val)调用成功返回 0；否则，返回 -1。sigqueue 的第一个参数是指定接收信号的进程ID，第二个参数确定即将发送的信号，第三个参数是一个联合数据结构 typedef union sigval { int sival_int; void *sival_ptr; }sigval_t;指定了信号传递的参数，即通常所说的 4 字节值。sigqueue() 比 kill() 传递了更多的附加信息，但 sigqueue() 只能向一个进程发送信号，而不能发送信号给一个进程组。如果 signo=0，将会执行错误检查，但实际上不发送任何信号，0 值信号可用于检查 pid 的有效性以及当前进程是否有权限向目标进程发送信号。在调用 sigqueue时，sigval_t 指定的信息会拷贝到3参数信号处理函数（3 参数信号处理函数指的是信号处理函数由 sigaction 安装，并设定了 sa_sigaction 指针，稍后将阐述）的 siginfo_t 结构中，这样信号处理函数就可以处理这些信息了。由于 sigqueue 系统调用支持发送带参数信号，所以比 kill() 系统调用的功能要灵活和强大得多。注意： sigqueue() 发送非实时信号时，第三个参数包含的信息仍然能够传递给信号处理函数； sigqueue() 发送非实时信号时，仍然不支持排队。不支持信号排队，即在信号处理函数执行过程中到来的所有相同信号，都被合并为一个信号。unsigned int alarm(unsigned int seconds)专门为 SIGALRM 信号而设，在指定的时间 seconds 秒后，将向进程本身发送 SIGALRM 信号，又称为闹钟时间。进程调用 alarm 后，任何以前的 alarm() 调用都将无效。如果参数 seconds 为零，那么进程内将不再包含任何闹钟时间。返回值，如果调用 alarm（）前，进程中已经设置了闹钟时间，则返回上一个闹钟时间的剩余时间，否则返回 0。int setitimer(int which, const struct itimerval *value, struct itimerval *ovalue));setitimer() 比 alarm 功能强大，支持 3 种类型的定时器： ITIMER_REAL：设定绝对时间；经过指定的时间后，内核将发送 SIGALRM 信号给本进程； ITIMER_VIRTUAL：设定程序执行时间；经过指定的时间后，内核将发送 SIGVTALRM 信号给本进程； ITIMER_PROF：设定进程执行以及内核因本进程而消耗的时间和，经过指定的时间后，内核将发送 ITIMER_VIRTUAL 信号给本进程；Setitimer() 第一个参数 which 指定定时器类型（上面三种之一）；第二个参数是结构 itimerval 的一个实例，第三个参数（可以不做处理）的结构如下：struct itimerval{ struct timeval it_interval; /* next value */ struct timeval it_value; /* current value */};struct timeval{ long tv_sec; /* seconds */ long tv_usec; /* microseconds */};Setitimer() 调用成功返回0，否则返回 -1。void abort(void);向进程发送 SIGABORT 信号，默认情况下进程会异常退出，当然可定义自己的信号处理函数。即使 SIGABORT 被进程设置为阻塞信号，调用 abort() 后，SIGABORT 仍然能被进程接收。该函数无返回值。信号的安装信号安装，即设置信号关联动作和绑定信号处理函数。如果进程要处理某一信号，那么就要在进程中安装该信号。安装信号主要用来确定信号值及进程针对该信号值的动作之间的映射关系，即进程将要处理哪个信号；该信号被传递给进程时，将执行何种操作。linux 主要有两个函数实现信号的安装： signal()signal() 在可靠信号系统调用的基础上实现, 是库函数。它只有两个参数，不支持信号传递信息，主要是用于前 32 种非实时信号的安装； sigaction()igaction() 是较新的函数（由两个系统调用实现： sys_signal 以及 sys_rt_sigaction），有三个参数，支持信号传递信息，主要用来与 sigqueue() 系统调用配合使用，当然，sigaction() 同样支持非实时信号的安装。sigaction() 优于 signal() 主要体现在支持信号带有参数。void (*signal(int signum, void (*handler))(int)))(int);如果该函数原型不容易理解的话，可以参考下面的分解方式来理解：typedef void (*sighandler_t)(int)；sighandler_t signal(int signum, sighandler_t handler));第一个参数指定信号的值，第二个参数指定针对前面信号值的处理，可以忽略该信号（参数设为 SIG_IGN）；可以采用系统默认方式处理信号(参数设为 SIG_DFL)；也可以自己实现处理方式(参数指定一个函数地址)。如果 signal() 调用成功，返回最后一次为安装信号 signum 而调用 signal() 时的 handler 值；失败则返回 SIG_ERR。int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact));sigaction 函数用于改变进程接收到特定信号后的行为（相对于默认行为或已经绑定的行为而言）。该函数的第一个参数为信号的值，可以为除 SIGKILL 及 SIGSTOP外的任何一个特定有效的信号（为这两个信号定义自己的处理函数，将导致信号安装错误）。第二个参数是指向结构 sigaction 的一个实例的指针，在结构 sigaction 的实例中，指定了对特定信号的处理，可以为空，进程会以缺省方式对信号处理；第三个参数 oldact 指向的对象用来保存原来对相应信号 的处理，可指定 oldact 为 NULL。如果把第二、第三个参数都设为 NULL，那么该函数可用于检查信号的有效性。注意：第二个参数最为重要，其中包含了对指定信号的处理、信号所传递的信息、信号处理函数执行过程中应屏蔽掉哪些函数等等。struct sigaction{ void (*sa_handler)(int signo); void (*sa_sigaction)(int signo, siginfo_t *, void *); sigset_t sa_mask; int sa_flags; void (*sa_restorer)(void); // sa_restorer，已过时，POSIX 不支持它，不应再被使用。}typedef struct{ //结构中包含信号携带的数据值\tint si_signo;\tint si_code;\tunion sigval si_value;\tint si_errno;\tpid_t si_pid;\tuid_t si_uid;\tvoid *si_addr;\tint si_status;\tint si_band;} siginfo_t;typedef struct{ unsigned long sig[_NSIG_WORDS]；} sigset_t;union sigval{\tint sival_int;\tvoid *sival_ptr;};联合数据结构中的两个元素 sa_handler 以及 sa_sigaction 指定信号关联函数，即用户指定的信号处理函数。除了可以是用户自定义的处理函数外，还可以为 SIG_DFL (采用缺省的处理方式)，也可以为 SIG_IGN（忽略信号）。采用联合数据结构，说明 siginfo_t 结构中的 si_value 要么持有一个 4 字节的整数值，要么持有一个指针，这就构成了与信号相关的数 据。在信号的处理函数中，包含这样的信号相关数据指针，但没有规定具体如何对这些数据进行操作，操作方法应该由程序开发人员根据具体任务事先约定。前面在讨论系统调用 sigqueue 发送信号时，sigqueue 的第三个参数就是sigval联合数据结构，当调用 sigqueue 时，该数据结构中的数据就将拷贝到信号处理函数的第二个参数中。这样，在发送信号同时，就可以让信号传递一些附加信息。信号可以传递信息对程序开发是非常有意义的。 sa_masksa_mask 指定在信号处理程序执行过程中，哪些信号应当被阻塞。缺省情况下当前信号本身被阻塞，防止信号的嵌套发送，除非指定 SA_NODEFER 或者 SA_NOMASK 标志位。注：请注意 sa_mask 指定的信号阻塞的前提条件，是在由 sigaction() 安装信号的处理函数执行过程中由 sa_mask 指定的信号才被阻塞。 sa_flagssa_flags 中包含了许多标志位，包括刚刚提到的 SA_NODEFER 及 SA_NOMASK 标志位。另一个比较重要的标志位是SA_SIGINFO，当设定了该标志位时，表示信号附带的参数可以被传递到信号处理函数中，因此，应该为 sigaction 结构中的 sa_sigaction 指定处理函数，而不应该为 sa_handler 指定信号处理函数，否则，设置该标志变得毫无意义。即使为 sa_sigaction 指定了信号处理函数，如果不设置 SA_SIGINFO，信号处理函数同样不能得到信号传递过来的数据，在信号处理函数中对这些信 息的访问都将导致段错误（Segmentation fault）。信号集及信号集设定 信号集:所有的信号阻塞函数都使用一个称之为信号集的结构表明其所受到的影响。 信号掩码: 当前正在被阻塞的信号集。 未决集:进程在收到信号时到信号在未被处理之前信号所处的集合称为未决集。可以看出，这三个概念没有必然的联系，信号集指的是一个泛泛的概念，而未决集与信号掩码指的是具体的信号状态。信号集被定义为一种数据类型：typedef struct{ unsigned long sig[_NSIG_WORDS]；} sigset_t信号集用来描述信号的集合，linux 所支持的所有信号可以全部或部分的出现在信号集中，主要与信号阻塞相关函数配合使用。下面是为信号集操作定义的相关函数：int sigemptyset(sigset_t *set)；初始化由 set 指定的信号集，信号集里面的所有信号被清空；int sigfillset(sigset_t *set)；调用该函数后，set 指向的信号集中将包含 linux 支持的 64 种信号；int sigaddset(sigset_t *set, int signum)在 set 指向的信号集中加入 signum 信号；int sigdelset(sigset_t *set, int signum)；在 set 指向的信号集中删除 signum 信号；int sigismember(const sigset_t *set, int signum)；判定信号 signum 是否在 set 指向的信号集中。sigset_t 类型的本质是位图。但不应该直接使用位操作，而应该使用上述函数，保证跨系统操作有效。信号阻塞与信号未决信号阻塞又称为信号屏蔽。每个进程都有一个用来描述哪些信号递送到进程时将被阻塞的信号集，该信号集中的所有信号在递送到进程后都将被阻塞。相关概念： 信号递达：实际执行信号的处理动作称为信号递达(Delivery)。 信号未决：信号从产生到递达之间的状态,称为信号未决(Pending)。下面是与信号阻塞相关的几个函数：int sigprocmask(int how, const sigset_t *set, sigset_t *oldset))；用来屏蔽信号、解除屏蔽也使用该函数。其本质，读取或修改进程的信号屏蔽字(PCB 中)。sigprocmask() 函数能够根据参数 how 来实现对信号集的操作，操作主要有三种： SIG_BLOCK:SIG_BLOCK 在进程当前阻塞信号集中添加 set 指向信号集中的信号。 SIG_UNBLOCK:如果进程阻塞信号集中包含 set 指向信号集中的信号，则解除对该信号的阻塞。 SIG_SETMASK:SIG_SETMASK 更新进程阻塞信号集为 set 指向的信号集。int sigpending(sigset_t *set));sigpending(sigset_t *set)) 获得当前已递送到进程，却被阻塞的所有信号，在 set 指向的信号集中返回结果。int sigsuspend(const sigset_t *mask))；sigsuspend(const sigset_t *mask)) 用于在接收到某个信号之前,临时用 mask 替换进程的信号掩码, 并暂停进程执行，直到收到信号为止。sigsuspend 返回后将恢复调用之前的信号掩码。信号处理函数完成后，进程将继续执行。该系统调用始终返回-1，并将 errno 设置为 EINTR。注意：阻塞和忽略是不同的,只要信号被阻塞就不会递达,而忽略是在递达之后可选的一种处理动作。每个信号都有两个标志位分别表示阻塞(block)和未决(pending),还有一个函数指针表示处理动作。信号产生时,内核在进程控制块中设置该信号的未决标志,直到信号递达才清除该标志。对于上图解读如下： SIGHUP 信号未阻塞也未产生过，当它递达时执行默认处理动作； SIGINT 信号产生过，但正在被阻塞，所以暂时不能递达。虽然它的处理动作是忽略，但在没有解除阻塞之前不能忽略这个信号，因为进程仍有机会改变处理动作之后再解除阻塞。 SIGQUIT 信号未产生过，一旦产生 SIGQUIT 信号将被阻塞，它的处理动作是用户自定义函数 sighandler。如果在进程解除对某信号的阻塞之前这种信号产生过多次，将如何处理？POSIX.1 允许系统递送该信号一次或多次。Linux 是这样实现的：常规信号在递达之前产生多次只计一次，而实时信号在递达之前产生多次可以依次放在一个队列里。从上图来看，每个信号只有一个 bit 的未决标志，非 0 即 1，不记录该信号产生了多少次，阻塞标志也是这样表示的。因此，未决和阻塞标志可以用相同的数据类型 sigset_t 来存储，sigset_t 称为信号集，这个类型可以表示每个信号的“有效”或“无效”状态： 在阻塞信号集中“有效”和“无效”的含义是该信号是否被阻塞； 在未决信号集中“有效”和“无效”的含义是该信号是否处于未决状态。信号生命周期从信号发送到信号处理函数的执行完毕，对于一个完整的信号生命周期(从信号发送到相应的处理函数执行完毕)来说，可以分为三个重要的阶段，这三个阶段由四个重要事件来刻画：信号诞生；信号在进程中注册完毕；信号在进程中的注销完毕；信号处理函数执行完毕。 信号”诞生”：信号的诞生指的是触发信号的事件发生（如检测到硬件异常、定时器超时以及调用信号发送函数 kill() 或 sigqueue() 等）。 信号在目标进程中”注册”；进程的 task_struct 结构中有关于本进程中未决信号的数据成员：struct sigpending pending：struct sigpending{ struct sigqueue *head, **tail; sigset_t signal;};第三个成员是进程中所有未决信号集，第一、第二个成员分别指向一个 sigqueue类型的结构链（称之为”未决信号信息链”）的首尾，信息链中的每个 sigqueue结构刻画一个特定信号所携带的信息，并指向下一个 sigqueue 结构:struct sigqueue{ struct sigqueue *next; siginfo_t info;}信号在进程中注册指的就是信号值加入到进程的未决信号集中（sigpending结构的第二个成员sigset_t signal），并且信号所携带的信息被保留到未决信号信息链的某个sigqueue结构中。只要信号在进程的未决信号集中，表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。注意：当一个实时信号发送给一个进程时，不管该信号是否已经在进程中注册，都会被再注册一次，因此，信号不会丢失，因此，实时信号又叫做”可靠信号”。这意味着同一个实时信号可以在同一个、进程的未决信号信息链中占有多个 sigqueue 结构（进程每收到一个实时信号，都会为它分配一个结构来登记该信号信息，并把该结构添加在未决信号链尾，即所有诞生的实时信号都会在目标进程中注册）；当一个非实时信号发送给一个进程时，如果该信号已经在进程中注册，则该信号将被丢弃，造成信号丢失。因此，非实时信号又叫做”不可靠信号”。这意味着同一个非实时信号在进程的未决信号信息链中，至多占有一个 sigqueue 结构。一个非实时信号诞生后： 如果发现相同的信号已经在目标结构中注册，则不再注册，对于进程来说，相当于不知道本次信号发生，信号丢失； 如果进程的未决信号中没有相同信号，则在进程中注册自己。 信号在进程中的注销在目标进程执行过程中，会检测是否有信号等待处理（每次从系统空间返回到用户空间时都做这样的检查）。如果存在未决信号等待处理且该 信号没有被进程阻塞，则在运行相应的信号处理函数前，进程会把信号在未决信号链中占有的结构卸掉。是否将信号从进程未决信号集中删除对于实时与非实时信号是不同的： 对于非实时信号：对于非实时信号来说，由于在未决信号信息链中最多只占用一个 sigqueue 结构，因此该结构被释放后，应该把信号在进程未决信号集中删除（信号注销完毕）； 对于实时信号：对于实时信号来说，可能在未决信号信息链中占用多个 sigqueue 结构，因此应该针对占用 sigqueue 结构的数目区别对待：如果只占用一个 sigqueue 结构（进程只收到该信号一次），则应该把信号在进程的未决信号集中删除（信号注销完毕）。否则，不应该在进程的未决信号集中删除 该信号（信号注销完毕）。进程在执行信号相应处理函数之前，首先要把信号在进程中注销。 信号生命终止进程注销信号后，立即执行相应的信号处理函数，执行完毕后，信号的本次发送对进程的影响彻底结束。注意： 信号注册与否的判断：信号注册与否，与发送信号的函数（如kill() 或 sigqueue() 等）以及信号安装函数（signal() 及 sigaction()）无关，只与信号值有关（信号值小于 SIGRTMIN 的信号最多只注册一次，信号值在 SIGRTMIN 及 SIGRTMAX 之间的信号，只要被进程接收到就被注册）。 信号丢失情况：在信号被注销到相应的信号处理函数执行完毕这段时间内，如果进程又收到同一信号多次，则对实时信号来说，每一次都会在进程中注册；而对于非实时信号来说，无论收到多少次信号，都会视为只收到一个信号，只在进程中注册一次。信号编程注意事项 防止不该丢失的信号丢失； 程序的可移植性：考虑到程序的可移植性，应该尽量采用 POSIX 信号函数。POSIX信号函数主要分为两类： POSIX 1003.1 信号函数：Kill()、sigaction()、sigaddset()、sigdelset()、sigemptyset()、sigfillset()、sigismember()、sigpending()、sigprocmask()、sigsuspend()。 POSIX 1003.1b 信号函数：POSIX 1003.1b 在信号的实时性方面对 POSIX 1003.1 做了扩展，包括以下三个函数：sigqueue()、sigtimedwait()、sigwaitinfo()。其中，sigqueue 主要针对信号发送，而 sigtimedwait 及 sigwaitinfo() 主要用于取 代sigsuspend() 函数。 程序的稳定性为了增强程序的稳定性，在信号处理函数中应使用可重入函数。因为进程在 收到信号后，就将跳转到信号处理函数去接着执行。如果信号处理函数中使用了不可重入函数，那么信号处理函数可能会修改原来进程中不应该被修改的数据，这样进程从信号处理函数中返回接着执行时，可能会出现不可预料的后果。不可再入函数在信号处理函数中被视为不安全函数。 满足下列条件的函数多数是不可再入的： 使用静态的数据结构; 函数实现时，调用了 malloc() 或者 free() 函数； 实现 时使用了标准 I/O 函数的.即使信号处理函数使用的都是”安全函数”，同样要注意进入处理函数时，首先要保存 errno 的值，结束时，再恢复原值。因为，信号处理过程中，errno 值随时可能被改变。另外，longjmp()以及 siglongjmp() 没有被列为可再入函数，因为不能保证紧接着两个函数的其它调用是安全的。信号编程步骤：linux下的信号应用并没有想象的那么恐怖，程序员所要做的最多只有三件事情： 安装信号（推荐使用sigaction()）； 实现三参数信号处理函数，handler(int signal,struct siginfo *info, void *)； 发送信号，推荐使用sigqueue()。实际上，对有些信号来说，只要安装信号就足够了（信号处理方式采用缺省或忽略）。其他可能要做的无非是与信号集相关的几种操作。不过，对于多线程编程而言，信号的默认动作可能会引起其他线程是致命的，所以必须自定义信号处理函数，以替换掉缺省动作。信号编程实例 信号发送及处理：实现一个信号接收程序 sigreceive（其中信号安装由 sigaction()）。#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv){ struct sigaction act; int sig; sig=atoi(argv[1]); sigemptyset(&amp;act.sa_mask); act.sa_flags=SA_SIGINFO; act.sa_sigaction=new_op; if(sigaction(sig,&amp;act,NULL) &lt; 0) { printf(\"install sigal error＼n\"); } while(1) { sleep(2); printf(\"wait for the signal＼n\"); }}void new_op(int signum,siginfo_t *info,void *myact){ printf(\"receive signal %d\", signum); sleep(5);}说明，命令行参数为信号值，后台运行 sigreceive signo &amp;，可获得该进程的ID，假设为 pid，然后再另一终端上运行 kill -s signo pid 验证信号的发送接收及处理。同时，可验证信号的排队问题。用 sigqueue 实现的命令行信号发送程序 sigqueuesend，命令行第二个参数是发送的信号值，第三个参数是接收该信号的进程 ID，可以配合以上使用：#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;int main(int argc,char**argv){ pid_t pid; int sig; sig=atoi(argv[1]); pid=atoi(argv[2]); sigqueue(pid,sig,NULL); sleep(2);} 信号传递附加信息主要包括两个实例： 向进程本身发送信号，并传递指针参数；#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv){ struct sigaction act; union sigval mysigval; int i; int sig; pid_t pid; char data[10]; memset(data,0,sizeof(data)); for(i=0;i &lt; 5;i++) data[i]=’2’; mysigval.sival_ptr=data; sig=atoi(argv[1]); pid=getpid(); sigemptyset(&amp;act.sa_mask); act.sa_sigaction=new_op; //三参数信号处理函数 act.sa_flags=SA_SIGINFO; //信息传递开关 if(sigaction(sig,&amp;act,NULL) &lt; 0) { printf(\"install sigal error＼n\"); } while(1) { sleep(2); printf(\"wait for the signal＼n\"); sigqueue(pid,sig,mysigval); //向本进程发送信号，并传递附加信息 }}void new_op(int signum,siginfo_t *info,void *myact)//三参数信号处理函数的实现{ int i; for(i=0;i&lt;10;i++) { printf(\"%c＼n \",(*( (char*)((*info).si_ptr)+i))); } printf(\"handle signal %d over;\",signum);}这个例子中，信号实现了附加信息的传递，信号究竟如何对这些信息进行处理则取决于具体的应用。 不同进程间传递整型参数：把上例中的信号发送和接收放在两个程序中，并且在发送过程中传递整型参数。信号接收程序：#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv){ struct sigaction act; int sig; pid_t pid; pid=getpid(); sig=atoi(argv[1]); sigemptyset(&amp;act.sa_mask); act.sa_sigaction=new_op; act.sa_flags=SA_SIGINFO; if(sigaction(sig,&amp;act,NULL)&lt;0) { printf(\"install sigal error＼n\"); } while(1) { sleep(2); printf(\"wait for the signal＼n\"); }}void new_op(int signum,siginfo_t *info,void *myact){ printf(\"the int value is %d ＼n\",info-&gt;si_int);}信号发送程序：#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;main(int argc,char**argv){ pid_t pid; int signum; union sigval mysigval; signum=atoi(argv[1]); pid=(pid_t)atoi(argv[2]); mysigval.sival_int=8; //不代表具体含义，只用于说明问题 if(sigqueue(pid,signum,mysigval)==-1) printf(\"send error＼n\"); sleep(2);} 信号阻塞及信号集操作:#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;static void my_op(int);int main(){ sigset_t new_mask,old_mask,pending_mask; struct sigaction act; sigemptyset(&amp;act.sa_mask); act.sa_flags=SA_SIGINFO; act.sa_sigaction=(void*)my_op; if(sigaction(SIGRTMIN+10,&amp;act,NULL)) printf(\"install signal SIGRTMIN+10 error＼n\"); sigemptyset(&amp;new_mask); sigaddset(&amp;new_mask,SIGRTMIN+10); if(sigprocmask(SIG_BLOCK, &amp;new_mask,&amp;old_mask)) printf(\"block signal SIGRTMIN+10 error＼n\"); sleep(10); printf(\"now begin to get pending mask and unblock SIGRTMIN+10＼n\"); if(sigpending(&amp;pending_mask)&lt;0) printf(\"get pending mask error＼n\"); if(sigismember(&amp;pending_mask,SIGRTMIN+10)) printf(\"signal SIGRTMIN+10 is pending＼n\"); if(sigprocmask(SIG_SETMASK,&amp;old_mask,NULL)&lt;0) printf(\"unblock signal error＼n\"); printf(\"signal unblocked＼n\"); sleep(10);}static void my_op(int signum){ printf(\"receive signal %d ＼n\",signum);}编译该程序，并以后台方式运行。在另一终端向该进程发送信号(运行 kill -s 42 pid，SIGRTMIN+10 为 42)，查看结果可以看出几个关键函数的运行机制，信号集相关操作比较简单。注意：在上面几个实例中，使用了 printf() 函数，只是作为诊断工具，pringf() 函数是不可重入的，不应在信号处理函数中使用。信号列表Linux 支持的信号列表如下。很多信号是与机器的体系结构相关的： 信号值 默认处理动作 发出信号的原因 SIGHUP 1 A 终端挂起或者控制进程终止 SIGINT 2 A 键盘中断（如break键被按下） SIGQUIT 3 C 键盘的退出键被按下 SIGILL 4 C 非法指令 SIGABRT 6 C 由abort(3)发出的退出指令 SIGFPE 8 C 浮点异常 SIGKILL 9 AEF Kill信号 SIGSEGV 11 C 无效的内存引用 SIGPIPE 13 A 管道破裂: 写一个没有读端口的管道 SIGALRM 14 A 由alarm(2)发出的信号 SIGTERM 15 A 终止信号 SIGUSR1 30,10,16 A 用户自定义信号1 SIGUSR2 31,12,17 A 用户自定义信号2 SIGCHLD 20,17,18 B 子进程结束信号 SIGCONT 19,18,25   进程继续（曾被停止的进程） SIGSTOP 17,19,23 DEF 终止进程 SIGTSTP 18,20,24 D 控制终端（tty）上按下停止键 SIGTTIN 21,21,26 D 后台进程企图从控制终端读 SIGTTOU 22,22,27 D 后台进程企图从控制终端写 处理动作一项中的字母含义如下: A 缺省的动作是终止进程 B 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E 信号不能被捕获 F 信号不能被忽略" }, { "title": "数据库基础", "url": "/2016/12/dataBase-basic.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2016-12-10 00:30:24 +0800", "snippet": " 数据库是整个应用的根基，没有坚实的根基，整个应用也就岌岌可危了。现代数据库有很多方便设计数据库的工具，但很难帮你解决数据库的逻辑和结构问题，而逻辑和结构却是数据库设计中极其重要的部分。而保证逻辑和结构良好的设计的基石是对数据库的详尽了解，那么让我们从数据库基础开始吧。 数据库概述 数据管理技术的发展 人工管理阶段 文...", "content": " 数据库是整个应用的根基，没有坚实的根基，整个应用也就岌岌可危了。现代数据库有很多方便设计数据库的工具，但很难帮你解决数据库的逻辑和结构问题，而逻辑和结构却是数据库设计中极其重要的部分。而保证逻辑和结构良好的设计的基石是对数据库的详尽了解，那么让我们从数据库基础开始吧。 数据库概述 数据管理技术的发展 人工管理阶段 文件系统阶段 数据库管理阶段 数据库类型（模型） 数据库管理系统（DBMS） 平面文件数据库模型 层次数据库模型 网状数据库模型 关系数据库 面向对象数据库模型（OODM） 对象-关系数据库 数据库基本概念 数据库系统的特点与功能 数据库系统的用户 数据抽象(数据库系统的体系结构) 数据库的三种模式 数据独立性 视图的作用 数据模型 基于对象的数据模型 基于记录的数据模型 物理数据模型 数据库模式和实例 数据库语言 数据库管理系统的结构 详细结构 简化结构 客户程序/服务程序体系结构 数据库系统运行过程 关系数据库 关系数据库构成 关系数据结构 完整性约束规则 关系运算（操作） 关系数据语言的分类 关系代数 传统的集合运算 专门的关系运算 元组关系演算 域关系演算 关系运算的安全性 关系运算的等价性 关系数据库查询语言 关系数据库标准语言 SQL SQL 概述 SQL 的特点 DQL 基本概念 SQL 各供应商间差异 数据类型 数据定义 创建数据库 模式的定义与删除 模式与表 基本表的定义、删除与修改 索引的建立与删除 视图定义、删除、更新 简单（单表）查询 单表查询—选择列 单表查询—选择元组 ORDER BY 子句 聚集函数 GROUP BY 子句 视图查询 连接查询 等值与非等值连接查询 自然连接查询 自身连接查询 内连接查询 全外连接查询 左外连接查询 右连接查询 交叉连接（CROSS JOIN） Union 查询形成并集 Except 查询形成差集 InterSect 查询形成交集 嵌套查询 带有 IN 谓词的子查询 带有比较运算符的子查询 带有 ANY（SOME）或 ALL 谓词的子查询 带有 EXISTS 谓词的子查询 数据更新 插入数据 修改数据 删除数据 更新视图 查询优化 查询处理 查询处理步骤 实现查询操作的算法示例 关系数据库的查询优化综述 查询优化概述 一个实例 启发式关系代数优化方法 关系代数等价变换规则 启发式代数优化规则 物理优化 基于启发式规则的存取路径选择优化 基于代价的优化 数据库的完整性 完整性控制 实体完整性 实体完整性检查和违约处理 参照完整性 参照完整性检查和违约处理 断言约束 用户定义的完整性 属性上的约束条件的定义 属性上的约束条件检查和违约处理 元组上的约束条件的定义 元组上的约束条件检查和违约处理 完整性约束命名子句 完整性约束命名子句 修改表中的完整性限制 域中的完整性限制 触发器 触发器概述 触发器组成 触发器分类 DML 触发器 系统触发器 替代触发器 删除触发器 触发程序举例 层次与网状数据库系统 层次数据库系统 层次数据模型中的数据结构 M:N 联系的表示 数据操作 完整性约束 IMS 概述 网状数据库系统 数据结构 数据操作 完整性约束 三个特殊的系型 M:N 联系的表示 数据库设计 概述 数据库设计问题 数据库设计的任务 数据库设计特点 数据库设计方法 数据库设计的基本步骤 数据库设计过程中的各级模式 需求分析 需求分析的任务 需求分析几个步骤： 实体联系（ER）模型 实体和属性 实体型、键属性和属性的值域 数据库实例 实体间的联系 弱实体 实体联系图（ER 图） 扩展的实体联系模型 子类、超类、演绎和归纳 演绎和归纳的性质 范畴与范畴化 EER 图 概念数据库设计 概念数据库模式设计概述 概念设计的基本方法 概念设计的策略 数据抽象 局部视图设计 视图集成 事务的设计 逻辑结构（数据库）设计 形成初始关系数据库模式 逻辑模式的规范化和优化 设计用户子模式 评审设计 数据库的物理设计 设计方法与内容 影响物理设计的因素 存取方法的选择 物理存储结构设计 评价物理设计与性能预测 数据库实施与维护 数据库实施 数据加载 数据库试运行 数据库运行与维护 关系数据理论 非规范化关系模式的问题 关系模型的形式化定义 非规范化造成的问题 问题的根源 函数依赖 关系的键码 超键妈 函数依赖规则 计算属性的封闭集（或闭包） 规范化 范式 分解的原则 分解的方法 关系模式规范化小结 多值依赖 属性独立性带来的冗余 多值依赖的定义 第四范式 分解成第四范式 第五范式 数据库概述在设计数据库之前，了解数据库的历史发展，理解数据库的基本概念、熟悉数据模型、基本原理以及如何使用这些概念是非常重要的。这一章节就是给出一张宏观的图纸，建构起对数据库的轮廓，属于森林级别的论述。数据管理技术的发展数据管理指的是如何对数据进行分类、组织、储存、检索及维护。要注意，这里所说的数据，不仅是数字。还包括文字、图形、声音等。凡是计算机中用来描述事物的记录，统称为数据。随着计算机软硬件的发展，数据管理技术不断地完善，经历了如下三个阶段： 人工管理阶段； 文件系统阶段； 数据库系统阶段。人工管理阶段最初，计算机主要用于科学计算。那时的计算机硬件方面，外存只有卡片、纸带及磁带，没有磁盘等直接存取的存储设备；软件方面，只有汇编语言，没有操作系统和高级语言，更没有管理数据的软件；数据处理的方式批处理。这些决定了当时的数据管理职能依赖人工来进行。人工管理阶段的特点是：（1）数据不保存，一组数据对应一个应用程序，应用程序与其处理的数据结合成一个整体，在进行计算时，系统将应用程序和数据一起装入，程序运行结束后，释放内存空间，程序和数据同时被撤销。（2）没有软件对数据进行管理。应用程序设计者不仅要考虑数据之间的逻辑关系，还要考虑存储结构、存取方法以及输入方式等。如果存储结构发生变化，读写数据的程序也要发生改变，数据没有独立性。（3）没有文件概念。数据的组织方法由程序设计人员自行设计和安排。（4）数据面向应用。数据附属于程序，即使两个应用程序使用相同的数据，也必须各自定义数据的存储和存取方式，不能共享相同的数据定义，因此程序与程序之间可能有大量的重复数据。文件系统阶段后来，计算机不仅用于科学计算，也大量用于经营管理活动。硬件设备有了硬盘、磁鼓等直接存储设备；软件发展了操作系统和各种高级语言。人们可以将应用程序所需的大量数据组织成一个数据文件长期保存在直接存储设备上，利用操作系统中的文件管理随时可以对文件中的数据进行存取，并且只需要知道相应的文件名即可实现按名存取。在文件系统阶段数据管理具有以下特点：（1）数据可长期保存在磁盘上，用户可通过程序对文件进行查询、修改、插入或删除操作。（2）文件系统提供程序和数据之间的读写方法。文件管理系统管理是应用程序与数据文件之间的一个接口。应用程序通过文件管理系统建立和存储文件；反之，应用程序要存取文件中的数据，必须通过文件管理系统实现。用户不必关心数据的物理位置，程序和数据之间有了一定的独立性。（3）文件形式多样化。因为有了直接存储设备，所以可以建立索引文件、链接文件和直接存取文件等。对文件的记录可顺序访问和随机访问。文件之间是相互独立的，文件与文件之间的联系需要用程序来实现。（4）数据的存取基本上以记录为单位。但文件系统阶段数据管理存在如下缺陷： 数据冗余大，因为文件是为特定的用途设计的，因此会造成数据在多个文件中被重复存储。 数据的不一致。这是由于数据冗余和文件之间的独立性造成的，在更新数据时，很难保证同一数据在不同文件中的一致。 程序与数据之间的独立性差。修改文件的存储结构后，相关的程序也要被修改。数据库管理阶段存储技术有了很大的发展，产生了大容量磁盘。计算机用于管理的规模更加庞大，数据量急剧增长，原有文件系统的固有缺陷使之不能满足大量应用和用户对数据的共享性和安全性等需求。为了提高效率，人们着手开发和研制更加有效的数据管理模式，并由此提出了数据库的概念。在数据库管理与文件管理相比数据库技术有了很大的改进，主要表现在以下方面：（1）数据库中的数据是结构化的。在文件系统中，数据是无结构的，即不同文件中的记录之间没有联系，它只在数据项之间有联系。数据库系统不仅考虑数据项之间的联系，还要考虑记录之间的联系，这种联系是通过存储路径来实现的。（2）数据库中的数据时面向系统的，对于任何一个系统来说，数据库中的数据结构式透明的，任何应用程序都可以通过标准化接口访问数据库。（3）数据库系统比文件系统有较高的数据独立性，而且共享性好。（4）数据库系统为用户提供了方便统一的接口。用户可以用数据系统提供的查询语言和交互式命令操作数据库。用户也可以用高级语言编写程序来访问数据库，扩展了数据库的应用范围。（5）数据存取粒度小。文件系统中，数据存取的最小单位是记录；而在数据库系统中，数据存取的粒度可以小到记录中的一个数据项。因此数据库中数据存取的方式非常灵活，便于对数据的管理。与此同时，数据库技术的发展是数据管理上了一个新台阶，在数据完整性、安全性、并发控制和数据恢复方面，数据管理系统都提供了非常完善的功能选择，同时为用户提供了友好的接口。数据库类型（模型）上一节简单讲解了数据管理技术的历史，自从进入数据库阶段之后，经过不断的发展，目前主要出现了以下几种数据库类型（模型）： 平面文件数据库模型； 层次数据库模型； 网状数据库模型； 关系数据库模型； 面向对象数据库模型； 对象关系数据库模型。理想数据库应该具有以下特征： 充足的容量； 足够的安全和审核； 多用户环境； 效率和查找能力； 可伸缩性； 用户友好。数据库管理系统（DBMS）数据库管理系统是用来存储数据的软件产品。软件开发商根据特定的数据库模型设计出不同的 DBMS 系统。DBMS 系统应该具备如下一些特点： 数据持久性：数据存储在硬件设备上并且在被访问后仍然存在。数据访问方法包括新数据的创建、现有数据的修改以及数据的删除。 并发性： 控制多用户的并发访问，保证并发访问不相互影响，不损坏数据。 事务管理：支持数据操作以及能够保存批量工作的能力。 可以使用基于用户提供查询条件检索数据的查询语言。 数据可以从失败的事务中恢复。如果出现数据丢失，DBMS 应该具有能够根据各种情况恢复数据的能力。平面文件数据库模型平面文件数据库由一个或多个可读文件组成，这些文件通常按照文本的格式保存。这些文件中的信息按域来保存，这些域可以有固定长度，也可以是变长的，并且域之间通过一些特殊符号（分界符）来分隔，从而必须保证分界符不会出现在数据中。由于不同的公司需要存储不同的数据且具有不同的数据需求，因此每一个平面文件数据库系统都是各不相同的。创建一个平面文件数据库并存储数据后，应该设计检索数据、创建新记录、更新记录以及删除记录的方法。在普通文件中，访问数据的问题是，必须设计一系列的程序来查询存储在普通文件中的信息。如果没有这些方法，用户或客户就必须自己来查询这些文件，这显然是不能接受的。平面文件数据库系统最主要的问题是：不但要掌握这些普通文件的结构，还要知道这些数据的物理存储位置。此外，这种数据库系统还可能会需要大量的普通文件，因为相关数据可能会保存在不同的文件中。在平面文件数据库环境中，对数据联系的管理是一项非常困难的任务。平面数据库系统的缺点： 普通文件无法提供便于数据关联的结构； 不能有效地管理数据并保证数据的准确性； 通常必须存储冗余数据，这导致了准确维护数据的额外工作量； 必须知道文件中数据域的物理存储位置； 必须设计管理数据的程序。层次数据库模型相对平面文件数据库而言，层次数据库可以创建和维护不同类别数据之间的关联关系。层次数据库的体系结构是基于父/子关系的，就像一颗倒转的树。父表可以有多个子表，但子表只能有一个父表。要访问一个字表，必须首先访问父表。分层结构中的关联表是通过指针连接的，指针直接指向子记录的物理位置。相对平面文件数据库模型，层次数据库模型具有如下一些优点： 快速的数据查询； 便于管理数据的完整性。但层次数据库也存在如下缺点： 用户必须时分熟悉数据库结构，任何访问必须从根节点开始； 需要存储存储荣誉数据（以表示那些没有直接关联关系的表之间的逻辑关系），层次数据库在处理一对多关系时表现得很好，但很难表示多对多关系（因为层次数据库子表只允许有一个父表）。网状数据库模型网状数据库相对于层次数据库，一个最主要的优点就是允许父表和子表之间共享关联关系。这意味着子表可以有多个父表。此外，用户可以从网状模型的任何表开始访问数据。在树形结构中支持向上和向下访问方式。用户不在需要从根表开始来访问某个子表。 网状数据库模型的优点是： 快速的数据访问； 用户可以从任何表开始访问其他表数据； 便于复杂数据库的建模； 便于开发更复杂的查询来检索数据。 网状数据库模型的缺点是： 不便于数据库结构的修改； 数据库结构的修改将直接影响访问数据库的应用程序； 用户必须掌握数据库结构。尽管网状数据库模型具备一些优势，但其还是存在几个层次数据库同样的问题。二者都不具备灵活性，任何对结构的改变都需要重建整个数据库；同样，集合关系和记录结构都必须预先定义。网状和层次数据库的主要劣势是它们都是程序员领域。要回应一个最简单的查询，也不得不创建一个程序，这个程序定位数据库结构并最终输出结果；不同于 SQL，这个程序是用程序化语言写成的，这些程序化语言常常都是一些归各个公司所有的专利语言，同时，使用者还需要具备数据库结构和当前操作系统两方面的深厚只是。毫无疑问，这样的程序不具有可移植性，而且编写这些程序将花费大量的时间。关系数据库与层次和网状模型相同，关系型模型是基于二维存储空间（表）的，这些表基于共有的一个字段（或一系列字段）而相互关联。然而，这种关系式由列值来实现的，而不像以往是由低级的物理指针来定义。数据库中数据存储的主要载体是表（所谓的“关系”），或相关数据组。表由行和列组成。在表中，一行表示一条数据记录。一列表示所有数据记录在该特定域的值。表之间通过公共列值实现关联关系，这样的列也叫关键字。关系数据库模型支持三种类型的表关联关系：一对一、一对多以及多对多，数据库应该支持这些不同类型的表间联系。表关联是通过引用完整性定义的，这些完整性又是通过主码和外码（或称为“外键”）约束条件实现的。应用完整性是通过这些约束条件来校验进入表中的数据并且管理父、子表之间的关系的。其他类型的约束条件也可以用来控制表的特定列数据以及创建表之间的联系。在关系模型中，虽然还支持父表和子表之间的关系，但已经没有了根表。父表可以有多个子表，子表也可以有多个父表（它们之间是双向的关系）。 关系数据库中的对象在关系数据库中有许多类型的对象。如下所列的是关系数据库中通用的对象： 表：表是关系数据库中数据存储的主要对象。查询和修改数据操作通常是在表中进行的。表通过多个列来定义。所有列上的一行数据叫做一个数据行（数据记录）。 视图：视图是虚拟表，它具有表的特性。视图是根据表的数据以及结构所定义的。视图可以查询，有时也可以进行数据更新。 约束：约束是放置数据规则的对象。它可以用来控制列中的数据。约束通常定义在列一级，它也可以用来加强引用完整性（父/子表之间的联系）。 索引：索引是用来加速数据检索的对象。索引的每一条记录都指向表中相应的数据记录，类似于图书的目录执行特定的页面。 触发器：触发器是数据库中用来保存程序代码的对象，它是由数据库中发生的特定时间而出发执行的。当一个触发器被触发时，数据可以根据其他被访问或修改的数据而被相应修改。触发器对减少冗余数据非常有用。 过程：也叫做存储过程。它是保存在数据库中的程序。在数据库中，存储过程是可以执行的。过程通常用来管理数据和进行批处理操作。以上介绍的前四个对象是与数据库定义相关的对象，而后两个对象则是访问数据库对象的方法。关系数据库中对象为用户提供了逻辑表现形式，这样使数据的物理位置对用户来说是不重要的。 关系数据库模型的优点： 数据访问非常快； 便于修改数据库结构； 逻辑化表示数据，因此用户不需要知道数据是如何存储的； 容易设计复杂的数据查询来检索数据； 容易实现数据完整性； 数据通常具有更高的准确性（因为冗余数据更少，从而一致性好）； 支持标准 SQL 语言。 关系数据库模型的缺点： 在很多情况下，必须将多个表的不同数据关联起来实现数据查询； 用户必须熟悉表之间的关联关系； 用户必须掌握 SQL 语言。面向对象数据库模型（OODM）数据库的数据模型一般由三部分组成，它们是： 数据模式（数据结构）； 建立在模式上的操作； 数据的完整性约束。在面向对象数据模型中，我们用面向对象方法中的一些基本概念和基本方法表示这三个组成部分：对象、方法、类的继承与合成。我们首先用关系模型来解释数据模型中的这三个部分，然后再与面向对象数据模型进行对比。 关系数据模型组成部分 关系模型的数据结构是二维表； 关系模型上的数据操作：查询、插入、删除、修改 关系模型上的数据完整性约束： 面向对象数据模型（OODM）组成部分 OODM 的数据结构：类层次结构 对象：由一组属性、一组方法和一个对象标识符 OID 所构成的一个封装体。 类：具有相同属性和相同方法的一组对象的集合； 类层次结构：由类与类之间的继承关系和合成关系所构成的一个层次关系图。 OODM 的数据操作：方法与消息 OODM 的数据约束：方法与消息 实体完整性：无 引用完整性：无 用户自定义完整性约束条件：完整性约束方法。 面向对象数据模型就是一个由类及类的继承与合成关系所构成的类层次结构图。例如：OO 模型与关系模型的对应关系：OO 模型对关系模型的扩充： OID 比主关键字更具有一般性； 在对象与类中增加了方法，系统具有更好的稳定性、可扩充性，便于用户使用； 丰富的数据类型：类可以看成一种扩充的数据类型； 数据模型上的操作更为丰富； 数据模型具有更丰富的语义含义。OODM 的新概念：元类 类本身也可以被看成是一种特殊的对象，我们称其为类对象。 所有类对象的集合也构成一个类，我们称其为元类。 元类中的实例就是传统意义上的类，元类中的方法则是传统意义上的消息。 元类实际上就是 OODBS 的数据字典。 面向对象数据库管理系统（OODBMS）除了具有面向对象的概念与方法外，还必需具有传统数据库管理系统的所有功能，是面向对象技术与传统数据库技术的结合体。在 OODM 中，目前所用的语言大多选用类 SQL 形式，其中较为著名的有：SQL-3和OQL 语言。对象-关系数据库为了弄清楚对象-关系数据库所处的地位，先看下面的 DBMS 分类矩阵：可见，对象-关系数据库是下一个大浪潮。对象-关系数据模型的特点： 通过引入面向对象及处理复杂数据类型的构造来扩展关系数据模型； 允许元组属性具有复杂类型，包括非原子值（如嵌套关系）； 保持关系基础，尤其是对数据描述性存取，同时扩展建模能力； 与现有关系向上兼容。 嵌套关系允许非原子域（原子 = 不可分割），非原子域可以是整数集合、原子集合等。如此，使含有复杂数据的应用可以更直观地建模。嵌套关系的特点： 在原先只允许出现原子值（标量）的地方可以出现关系（即关系内关系）； 保持关系模型的数学基础； 违反第一范式。注意事项：对象-关系数据模型很不成熟，还处于争议阶段（虽然有的厂商已经推出了不成熟的产品）。有的人认为大部分厂商和学者犯了一下错误：（1）第一个错误是将对象类与关系变量等同（不幸的是，这一等式在表面上非常吸引人）。我们猜测这一错误来自对术语“对象”两种不同理解的混淆。（2）第二个根本性错误！—即将指针与关系相混淆（当然不犯第一个错误的系统也可能犯第二个错误，并且目前市场上几乎每一个产品都犯有这一错误）。我们认为，第二个根本性错误在许多方面削弱了关系模型的概念完整性。具体来说，它破坏了基本关系与导出关系之间的可交换性原则。数据库基本概念数据库、数据库管理系统和数据库系统经常被作为同义词使用。严格地讲，它们是三个不同的概念： 数据库数据库是相互关联的数据集合。数据是描述显示世界中各种具体事务或抽象概念的可存储并具有明确意义的信息。*相互关联并且可存储的数据集合并定义为数据库 *。数据库的特性： 数据库是具有逻辑关系和确定意义的数据集合。逻辑上无关的数据集合不能称为数据库。 数据库是针对明确的应用目标而设计、建立和加载的。每个数据库都具有一组用户，并为这些用户的应用服务。 一个数据库表示了显示世界的某些方面，该现实的改变必须及时地反映到该数据库中来。 数据库管理系统数据库管理系统是一个通用的软件系统，由一组计算机程序构成。数据库管理系统能够对数据库进行有效的管理，包括存储管理、安全性管理、完整性管理等。数据库管理系统提供了一个软件环境，使用户方便快速地建立、维护、检索、存取和处理数据库中的信息。 数据库系统数据库和数据库管理系统结合在一起就构成了数据库系统。有时人们把数据库系统广义地定义为“数据库 + 数据库管理系统 + 数据库管理员 + 应用程序 + 用户”。数据库系统的特点与功能数据库系统是在文件系统的基础上发展起来的。但是，数据库系统与文件系统具有本质上的区别。文件系统主要提供数据的物理存储和存取方法，数据的逻辑结构和输入输出格式仍由程序员在程序中定义和管理。文件与应用程序紧密相关。每个文件都属于一个特定的应用程序。一个应用程序对应一个或几个文件。不同的应用程序独立地定义和处理自己的文件。文件系统具有如下缺点： 数据共享性差、冗余度大； 数据不一致性：由于相同数据的重复存储，单独管理，给数据的修改和维护带来了困难，容易造成数据不一致。 数据独立性差； 数据结构化程度低。与文件系统相比，数据库系统具有很多优点。具体列举如下： 信息完整、功能通用：数据库系统不仅存储数据库本身，同时也存储数据库的说明信息，这些说明信息称为元数据。元数据存储在称为数据字典的特殊文件中。元数据包括数据库中每个文件的结构、每个数据项的存储格式和数据类型、数据的完整性约束等。数据字典主要由数据库管理系统软件使用，当然用户也可以使用。在文件系统中，描述文件的元数据分散在不同的应用程序中。因此，每个应用程序只能存取特定的文件，无法使用它不了解其元数据的文件。反之，每个文件只能由一个应用程序使用，不能被其他应用程序共享。数据库系统的通用性恰恰是由于抽象出了所有文件的元数据，统一存储，统一管理。 程序与数据独立在文件系统中，文件的元数据嵌套在应用程序中。所以，文件结构的改变将引起所有存取这个文件的应用程序的改变。相比之下，数据库系统把所有文件的元数据与应用程序隔离，统一存储和管理，从而克服了应用程序必须随文件结构的改变而改变的问题。我们程数据库系统的这个性质为程序与数据的独立性。在数据库系统中，我们只需要修改数据字典中的元数据，不需要修改任何应用程序（当然增加和删除后的数据，以前的应用程序可能无法使用这些数据）。而且，数据字典的修改是由数据库管理系统自动完成的。 数据抽象数据库系统提供了数据的抽象概念表示，使得用户不必了解数据库文件的存储结构、存储位置、存取方法等繁琐的细节就可以存取数据库。数据模型是提供数据抽象概念表示的有力工具。在文件系统中，每个文件的定义包括记录长度、每个数据项长度机器在记录中的初始位置等。在数据库系统中，用户一般都不想了解每个数据项有多长、存储记录的什么位置等细节，只希望给出数据项名字就能存取争取的数据（而文件只实现了“按名存取”文件而不是记录和数据项）。为此，数据库系统为用户提供了只涉及文件名字和数据项名字的数据的抽象概念表示，隐藏了文件的存储结构和存取方法等细节，用户只要使用这些名字就可以正确地存取数据。在数据库系统中，每个数据库文件的存储结构、存取方法等详细存储在数据字典中。存取数据时，用户只需要引用数据的抽象概念表示，数据库管理系统负责从数据字典中提取数据库文件的存储结构和存取方法等，把用户引用的抽象概念表示转换为物理表示，完成用户的存取要求。 支持数据的不同视图一个数据库一般都要支持很多应用程序和用户。不同的应用程序和不同的用户对同一个数据库可能有不同的理解。我们称对同一个数据库的每一种理解为这个数据库的一个视图。一个视图可以是一个数据库的子集合，也可以是多个数据库的子集按照某种方式构成的虚拟数据库（不是实际存储的数据库）。数据库系统提供了定义、维护和操纵视图的机制，使得多个用户可以为他们的应用定义、维护和使用自己的视图。 控制数据冗余数据库系统可以克服文件系统的数据冗余问题。在数据库设计阶段，我们只要充分考虑所有用户的数据管理需求，综合考虑所有用户的数据库视图，把它们集成一个逻辑模式，每个逻辑数据项只存储一次，即可避免数据冗余。值得注意的是，为了提高数据库系统的性能，有时需要加以限制数据的冗余。比如，结构字段经常需要一起使用，则可以适当对这些字段冗余（以存储换取时间），不过必须对数据冗余加以控制，防止数据的不一致性。 支持数据共享 限制非授权的存取：为了保证数据库的安全，防止对数据库的非法存取，数据库系统具有一个安全与授权子系统。安全与授权子系统包括两方面的功能：第一。为数据库管理员提供建立用户账号和密码，为用户规定存取数据库权限的工具；第二，进行安全性检查，当一个用户请求进入数据库系统时，安全与授权子系统黑对该用户和密码，禁止非法用户进入系统。 提供多种用户界面 表示数据之间的复杂联系：数据库系统提供了两种鱼数据间联系相关的机制：一是数据间联系的定义机制，供用户定义数据之间的联系；二是通过数据间联系查询数据的机制，供用户通过数据间联系来查询数据库中的数据。 完整性约束：数据库应用对数据的语义一般都具有一定的限制。我们称这种限制为完整性约束。数据项的数据类型是一种最简单的完整性约束，还有包含性约束、唯一性约束等。数据库的完整性约束是在数据库设计阶段，由数据库设计者根据实际应用领域的数据语义推导出来的。数据库系统提供了两种机制来支持完整性约束：第一种机制是完整性定义机制；第二种机制是完整性约束验证机制。我们通过完整性约束定义机制把数据库的完整性约束定义到数据库系统中。当用户执行一个数据更新操作时，完整性约束验证机制验证这个更新操作是否能够保持完整性约束成立，如果不能，则拒绝该操作。完整性约束并不能保证数据完全正确。这是因为数据库中满足完整性约束的数据不一定是正确的数据。 数据恢复：系统恢复子系统可以采用两种方法保证系统故障恢复后数据库能够恢复到正确状态：一种方法是把数据库恢复到更新操作执行前的状态；另一种方法是使更新操作从故障发生时的断点继续执行，保证该操作的更新结果全部写入数据库。数据库系统的用户大型数据库的设计、加载、维护可能涉及很多人。这些人员可以分为四类。没类人员都从不同的角度使用数据库系统。我们统称他们为数据库系统的用户。 数据库管理员在任何一个组织机构中，如果很多人共享相同资源，则需要有一个特殊的人员来监督和管理这个共享资源。在数据库系统环境下，共享资源有两类：第一类是数据库；第二类是数据库管理系统软件和相关软件。这些资源的监督管理由数据库管理员完成。数据库管理员可以由一个人担任，也可以由一组人担任。数据库管理员负责数据库的用户授权，并协调和监管他们对数据库和数据库管理系统软件的使用。数据库管理员也负责系统安全性保护和系统性能的监督和改善。 数据库设计者数据库设计者负责数据库中数据的确定、数据库文件结构设计、存取方法的选择和数据库的最后定义。这些工作完成之后，所设计的数据库才能在数据库系统中实现。数据库设计者首先需要与所有用户接触，讨论研究用户的需求，为每个用户建立起一个适应于他的应用的数据库视图。然后，数据库设计者合并这些视图，形成完整的数据库的定义。最后形成的数据库必须能够支持所有用户的应用要求。最后，数据库设计者与数据库管理员合作，在数据库系统中建立数据库并加载数据。在很多情况下，数据库设计者由数据库管理员担任。 最终用户最终用户是数据库的主要用户，经常对数据库提出查询和更新等操作要求。数据库主要是为这类用户设计和存储的。最终用户可分为如下三类：（1）偶然用户：这类用户不经常访问数据库。他们每次访问数据库时往往需要不同的数据库信息。他们通常使用数据库查询语言表示查询要求。他们一般都是一个企业或一个组织机构的高中级管理人员。（2）简单用户：数据库的多数最终用户都是简单用户。他们的主要工作是查询和更新数据库。他们一般都不直接使用数据库管理系统，而是通过应用程序员精心设计并具有友好界面的应用程序存取数据库。如银行职员（3）复杂用户：复杂用户包括工程师、科学家、经济学家、科学技术工作者等具有较高科学技术背景的人员。这类用户一般都比较熟悉数据库管理系统的各种服务机制，能够直接通过数据库管理系统访问数据库。有些人甚至能够基于数据库管理系统编制自己的应用程序。 系统分析员和应用程序员：系统分析员负责分析最终用户特别是简单最终用户的需求，给出适应这些用户需求的数据库事务的准确定义。应用程序员负责把系统分析师提欧共的数据库事务的定义编制称为计算机软件，并进行编码、调试、维护。系统分析员和应用程序员必须十分熟悉整个数据库管理系统，以完成他们的任务。 与数据库系统有关的其他人员：除了数据库的设计者、管理者、使用者和应用程序设计者意外，还有如下三类与数据库系统有关的人员。第一类人员是数据库管理系统的设计和实现人员。他们负责数据库管理系统软件本身的设计、编码、调试和维护，数据库管理员系统是一个时分复杂的计算机软件系统，包括很多程序模块，如数据字典梳理模块、查询语言处理模块、查询优化模块、数据存取模块、事务处理模块、安全与完整性维护模块等。所有这些模块的设计和实现都是数据库系统设计和实现人员的任务。第二类人员是数据库系统工具开发者。数据库系统工具包括数据库设计软件包、性能监控软件包、自然语言查询处理软件包、图形界面软件包、应用程序辅助设计软件包等。数据库系统工具开发者负责这些工具软件包的开发。很多数据库系统工具开发者都是独立于数据库系统开发公司的软件开发者。第三类人员是操作员和系统维护人员。它们负责数据库系统赖以运行的硬件和软件环境的操作、维护和管理。数据抽象(数据库系统的体系结构)数据库系统的主要目的之一是为用户提供一个数据的抽象视图，隐藏数据的存储结构和存取方法等细节。数据库的三种模式数据库一般提供三种级别的数据抽象： 视图级抽象：它把现实世界抽象为数据库的外模式。视图抽象把现实世界中的信息按照不同用户观点抽象为多个逻辑数据结构。每个逻辑数据结构称为一个视图，描述了每个用户所关心的数据。每个视图抽象地描述了整个数据库的一个侧面。所有视图的集合形成了数据库的外模式。数据库外模式是面向用户的数据库模式。数据库系统中数据定义语言的视图定义机构提供了进行视图抽象的工具，可以用来定义视图的逻辑结构。 概念级抽象：它把数据库的外模式抽象为数据库的概念模式。概念抽象把数据库的外模式抽象为数据库的概念模式。数据库的概念模式结合了外模式中所有视图，反映了所有数据库用户所关心的显示世界的抽象，形成了数据库的整体逻辑结构。数据库系统中数据定义语言的逻辑数据库定义机构提供了进行概念抽象的工具，可以用来定义概念数据库模式的逻辑结构。 物理级抽象：它把数据库的概念模式抽象为数据库的内模式。物理抽象把数据库的概念模式进一步抽象称为数据库的内模式。数据库的内模式抽象地描述了概念数据库如何在物理存储设备上存储。数据库的内模式包括两方面：第一方面是存储策略的描述，包括数据和索引的存储方式、存储记录的描述、记录定位方法等；第二方面是存取路径的描述，包括索引的定义、HASH 结构定义等。数据库系统中数据定义语言的物理数据库定义机构提供了物理抽象的工具，可以用来定义数据库的物理存储结构。三种数据抽象和数据库模式的关系如下图：数据独立性数据库系统提供的三种数据抽象能力和三种数据库模式实现了两种数据间独立性。在介绍数据库系统的两种数据独立性之前，我们需要了解数据库三种模式之间映射的概念。针对数据库的三种模式结构，数据库系统中包括两种映射： 外模式与概念模式之间的映射：该映射实现了外模式与概念模式的相互转换。 概念模式与内模式之间的映射：该映射实现了概念模式与内模式的相互转换。数据库系统的两种映射实现了数据库系统的两种数据独立性： 物理数据独立性：无理数据独立性由内模式与概念模式之间的映射实现。物理数据独立性是指当数据库的内模式（即物理存储结构）发生改变时，数据的逻辑结构不便。物理数据独立性保证：当数据库的内模式发生改变时，用户编写的应用程序可以不便。但是，为了保证应用能够正确执行，我们需要修改内模式与概念模式之间的映射。 逻辑数据独立性：逻辑数据独立性由概念模式与外模式之间的映射实现。逻辑数据独立性是指当概念数据库模式发生改变时，数据库的外模式不便。逻辑数据独立性保证：当数据库的概念模式发生改变时，建立在外模式上的应用程序不需要修改。当然，为了保证应用程序能够正确执行，我们需要修改概念模式与外模式之间的映射。两种数据独立性的本质是把数据定义从应用程序中分离出来，用用程序中的数据存取（即两种映射工作）由数据库管理系统完成，从而简化了编制应用程序的工作量，减少了应用程序的维护和修改。值得注意的是：实际数据库系统的逻辑数据独立性不能保证直接建立在数据库概念模式上的应用程序的独立。当数据库概念模式改变时，这些应用程序仍然需要修改。从这种意义上讲。数据库系统提供的逻辑数据独立性是不完备的。视图的作用视图最终是定义在基本表之上的，对视图的一切操作最终也要转换为对基本表的操作。而且对于非行列子集视图进行查询或更新时还可能出现问题。既然如此，为什么还要定义视图呢？这是因为合理使用视图能够带来许多好处： 视图能够简化用户的操作视图机制使用户可以将注意力集中在所关心的数据上。如果这些数据不是直接来自基本表，则可以通过定义视图，使数据库看起来结构简单、清晰、并且可以简化用户的数据查询操作，如隐藏多表的连接操作。 视图使用户能以多种角度看待同一数据视图机制能使不同的用户以不同的方式看待同一数据，当许多不同种类的用户共享同一个数据库时，这种灵活性是非常重要的。 视图对重构数据提供了一定程度的逻辑独立性数据的物理独立性是指用户的应用程序不依赖于数据库的物理结构。数据的逻辑独立性是指当数据库重构时，如增加新的关系或对原有关系增加新的字段等，用户的应用程序不会受影响。层次数据库和网状数据库一般能较好地支持数据的物理独立性，而对于逻辑独立性则不能完全地支持。在关系数据库中，数据库的重构往往是不可避免的。重构数据库最常见的是将一个基本表“垂直”地分成多个基本表。例如：这样尽管数据库的逻辑结构改变了（变为 SX 和 SY 两个表了），但应用程序不必修改，因为新建立的视图定义为用户原来的关系，使用户的外模式保持不变，用户的应用程序通过视图仍然能够查找数据。当然，视图只能再一定程度上提供数据的逻辑独立性，比如由于对视图的更新是有条件的，因此应用程序中修改数据的语句可能仍会因基本表结构的改变而改变。 视图能够对机密数据提供安全保护有了视图机制，就可以在设计数据库应用系统时，对不同的用户定义不同的视图，使机密数据不出现在不应看到这些数据的用户视图上。这样视图机制就自动提供了对机密数据的安全保护功能。例如 Student 表涉及全校 15 个院系的学生数据，可以在其上定义 15 个视图，每个视图只包含一个院系的学生数据，并只允许每个院系的主任查询和修改自己系的学生视图。 适当的视图可以更清晰的表达查询数据模型数据抽象是数据库系统的主要特点之一，具有很大的优越性。数据模型是实现数据抽象的主要工具。数据模型决定了数据库系统的结构、数据定义语言和数据操纵语言、数据库设计方法、数据库管理系统软件的设计与实现。数据模型是一组描述数据库的概念。这些概念精确地描述数据、数据之间的联系、数据的语义和完整性约束。很多数据模型还包括一个操作集合。这些操作用来说明对数据库的存取和更新。数据模型赢满足三方面要求： 真实地模拟现实世界； 容易为人们理解； 便于在计算机上实现。目前已经存在很多数据模型。这些数据模型可分为四类： 基于对象数据模型； 基于记录的数据模型； 物理数据模型； 逻辑数据模型。基于对象的数据模型基于对象的数据模型用于在概念和视图抽象级别上描述数据。这些数据模型具有相当灵活的结构化能力，而且允许明确地定义完整性约束。目前已经出现了很多基于对象的数据模型，其中比较知名的有： 实体-联系模型； 面向对象的数据模型； 二元数据模型； 语义数据模型； 函数数据模型等。这里主要介绍实体-联系模型、扩展的实体联系模型和面向对象的数据模型。 实体-联系模型实体-联系模型包括实体、属性、实体间联系等概念。 实体：对应于实现世界中刻区别的客观对象或抽象概念。 属性：是实体特征的抽象。抽象地说，实体型是属性的集合。当一个实体型的所有属性的的值都确定以后，我们就得到了一个实例。例如，在人的属性中，“姓名”和“生日”的值可以区别不同的。这组特殊的属性称为实体型的键属性。实体间联系对应于可观世界中各种对象或抽象概念之间的联系。实体-联系模型使用实体、属性、键属性、实体间联系这四个概念来抽象描述现实世界。此外，实体-联系模型还具有表示完整性约束的能力的能力，一个重要的完整性约束是实体间联系的基数（如 1:n，1:1等）。实体-联系模型可以用来实现数据的视图抽象。 面向对象数据模型与实体-联系模型类似，面向对象数据模型建立在对象集合的基础上。 面向对象数据模型的基本数据结构是对象； 面向对象数据模型的主要概念是对象类。对象类由一组变量和一组程序代码构成。变量表示对象类的特征。一个对象类的程序代码定义了该对象变量上的操作，称为这个对象类的方法。一个对象的变量可以是另一个对象（合成）。对象的嵌套层次数没有任何限制。当一个对象类的每个变量都赋以确定的值以后，我们就叨叨了这个对象的一个对象。把数据和方法组合为一个对象的思想类似于程序设计语言中抽象数据类型的概念。在面向对象的数据模型中，一个对象存取另一个对象的数据的唯一途径是调用被存取对象的某个方法。对象方法的调用通过在对象之间传送消息来实现。对象方法调用界面是对外可见的，对象内部的变量和程序编码是封闭不可见的。面向对象数据模型实现了数据独立性。只要方法的接口没有变，应用程序就不需要修改。在面向对象数据模型中，每个对象必须具有一个独立于该对象锁包含的值得唯一标识符。于是，具有相同值得对象可以标识为不同的对象。面向对象的数据模型既能用来定义数据库的整体逻辑结构，也可以用来提供数据库系统实现的高级描述。基于记录的数据模型基于记录的数据模型可以用来定义数据库的概念模式和外模式。基于记录的数据模型把数据库定义为多种具有固定格式的记录型。每个记录型由固定数量的域或属性构成。每个域或属性具有固定的长度。使用定长记录数据库可以简化数据库的物理级实现。基于记录的数据模型不包含直接表示程序代码的机构。这类数据模型具有独立的语言。用户可以使用这种语言表示数据库查询和更新要求。具有代表性的基于记录的数据模型包括： 关系数据模型：关系数据模型的核心是数学概念关系。一个关系可以视为一个表。每个表具有固定个数的列。每列具有一个名字，称为关系的属性。每一行数据称为一个元组。关系数据模型使用关系表示数据和数据之间的联系。 网络数据模型：网络数据模型的核心是记录和系。记录表示数据。一个记录具有多个数据域。每个数据域表示一个数据项。数据之间的联系由系表示。系可以视为一个指针。 层次数据模型：层次数据模型类似于网络数据模型。层次数据模型也使用记录和系表示数据和数据之间的联系。层次数据模型与网络数据模型的不同在于记录不能被组织成为任意的图，必须组织成树的集合。本节的详细内容请参考前面的“数据库类型（模型）”。物理数据模型物理数据模型是在逻辑数据模型的基础上，考虑各种具体的技术实现因素，进行数据库体系结构设计，真正实现数据在数据库中的存放。物理数据模型的内容包括确定所有的表和列，定义外键用于确定表之间的关系，基于用户的需求可能进行发范式化等内容。在物理实现上的考虑，可能会导致物理数据模型和逻辑数据模型有较大的不同。物理数据模型的目标是指定如何用数据库模式来实现逻辑数据模型，以及真正的保存数据。比较知名的物理数据模型有： 一体化模型； 框架存储器模型。数据库模式和实例数据库一词包括了两方面的意义： 模式； 实例；数据库模式是一个数据库的基于特定数据模型的结构定义。类似于程序设计语言中的数据类型，是一个数据库的框架。在任意一个特定的时刻，数据库中存储的数据称为一个数据库实例。数据库实例与程序设计语言中的变量值的概念对应。数据库模式是相对稳定的，很少变化。数据库实例是动态的，随数据库更新操作而变化。数据库语言每个数据库系统都为用户提供一个数据库语言。用户可以使用这个语言定义和操纵数据库。数据库语言包括两个子语言：（1）数据定义子语言：数据定义子语言用来定义数据库模式，简记作 DDL。DDL 包括数据库模式定义和数据库存储结构与存取方法定义两方面。数据定义子语言的处理程序也相应地分为两部分：数据库模式定义处理程序、存储结构和存取方法定义处理程序。 数据库模式定义处理程序数据库模式定义处理程序接收用 DDL 表示的数据库模式定义，吧其变换为内部表示形式，存储到数据库系统中称为数据字典的特殊文件中。 存储结构和存取方法定义处理程序存储结构和存取方法定义处理程序接收用 DDL 表示的数据库的存储结构和存取方法定义，在存储设备上创建相关的数据库文件，建立起物理数据库。数据定义子语言也包括数据库模式的删除与修改功能。（2）数据操纵子语言：数据操纵子语言用来表示用户对数据库的操作请求。一般地，数据操纵语言能够表示如下的数据操作： 查询数据库中的信息； 向数据库插入新的信息； 从数据库删除信息； 修改数据库中的信息。数据操纵语言分为两类： 过程性语言：过程性语言要求用户既说明需要数据库中的什么数据，也说明怎样搜索这些数据。 非过程性语言：非过程性语言只要求用户说明需要数据库中的什么数据，不需要说明怎样搜索这些数据。非过程性语言容易学习和使用，但是，非过程性语言产生处理程序代码比过程性语言产生的代码效率低。这个问题可以通过各种查询优化技术来解决。数据操纵语言的主要部分是查询数据库中的信息。我们称这部分为数据查询语言。人们常把数据操纵语言称为查询语言。在很多数据库中，这两个子语言（定义子语言、操纵子语言）被合并为一个语言。SQL 语言是一个集数据定义和数据操纵子语言为一体的典型数据库语言。目前关系数据库产品都提供 SQL 语言作为标准数据库语言。数据库语言与数据模型密切相关。基于不同数据模型的数据库系统的语言也不相同。数据库管理系统的结构数据库管理系统分为多个程序模块。每个模块实现数据库系统的一种功能。一般情况下，数据库系统建立在操作系统基础上。数据库的设计与实现必须考虑与操作系统接口的问题。详细结构 数据定义语言编译执行模块该模块首先接收数据定义语言语句，进行语法检查等预处理，并调用安全性检查模块进行安全性检查，然后处理数据定义语言语句。如果语句是建立数据库模式请求，则形成元数据，写入数据字典；如果是撤销数据库模式请求，则从数据字典中删除相应数据库模式的元数据；如果是修改数据库模式请求，则修改数据字典的相应元数据。 查询预处理模块：该模块接收用户的查询请求（存取数据库或更新数据库），进行语法检查，并调用安全性检查模块进行安全性检查，调用完整性约束模块进行完整性约束验证。 查询优化处理模块：该模块加工处理用户的查询请求，产生一个优化的查询执行计划。如果查询来自复杂用户，则根据查询执行计划的要求，调用数据操作模块提供的各种数据操作算法，完成用户查询的处理。如果查询来自应用程序，则把查询执行计划返回到数据操纵语言的预编译模块. 数据操纵语言预编译模块该模块调用查询预处理和查询优化处理模块，对应用程序中出现的查询进行优化，并调用宿主语言编译程序产生应用程序的目标代码。目标代码执行时，根据查询执行计划的要求调用数据操作模块提供的各种数据操作算法，完成用户查询的处理。 记录管理模块：该模块调用并发控制模块、系统恢复模块、缓冲处理模块、记录存储模块、存取方法模块和数据存取模块等，实现并发控制和系统恢复、I/O 缓冲处理、数据记录的存储和存取等功能。记录管理模块还要管理各种存取方法，如 B-树索引、HASH 方法等。简化结构DBMS 的主要组成如下图：最上方的查询和更新（还有模式更新）是 DBMS 的输入。查询和更新有两种生成方式： 通过通用的查询接口，用户输入相应语句进行操作； 通过应用程序的接口。其中，对数据的插入、修改和删除等操作统称为更新。模式更新：所谓数据库的模式，就是指数据的逻辑结构（请参看“数据库的体系结构”）。模式更新命令一般只能由数据库管理员使用。查询处理程序：查询处理程序不仅负责查询，也负责发出更新数据或模式的请求。查询处理程序的功能是：接受一个操作的请求后，找到一个最优的执行方式，然后向存储管理程序发出命令，使其执行。存储管理程序的功能是从数据库中获得上层想要查询的数据，并根据上层的更新请求更新相应的信息。存储管理程序：在简单的数据库系统中，存储管理程序可能就是底层操作系统的文件系统；但有时为了提高效率，DBMS 往往直接控制磁盘存储器。存储管理程序包括两个部分： 文件管理程序：文件管理程序跟踪文件在磁盘上的位置，并负责取出一个或几个数据块，数据块中含有缓冲区管理程序所要求的文件。 缓冲区管理程序。缓冲区管理程序控制着主存的使用。它通过文件管理系统从磁盘取得数据块，并选择主存的一个页面来存放它。如果有另一个数据块想要使用这个页面，就把原来的数据块写回磁盘。假如事务管理程序发出请求，缓冲区管理程序也会把数据块写回磁盘。事务管理程序：事务管理程序负责系统的完整性。它必须保证同时运行的若干个数据库操作不互相冲突，保证系统在出现故障时不丢失数据。事务管理程序和查询处理程序互相配合，因为它必须知道当前将要操作的数据，以免出现冲突。为了避免发生冲突，还可能需要延迟日志文件，记录等每一次数据的更新，这样即使系统出现故障，也能有效可靠地进行恢复。典型的 DBMS 允许用户吧一个或多个数据库操作（查询/更新）组成“事务”。可以认为，事务是一组按顺序进行的操作单位。数据库系统常常允许多个事务并发地执行，事务管理程序的任务就是保证这些事务全都能正确执行。那么这个“正确执行”的标准到底是什么呢？一般来说，满足下列四个特性，就可以任务事务正确执行了。这四个特性是： 原子性：整个事务要么都执行，要么都不执行，不能出现执行了一半的情况。 一致性：数据库通常有个”一致状态“的概念，通俗地说，就是数据符合我们的所有期望何限定性条件。 隔离性：当两个或更多的事务并发执行时，它们的作用效果必须相互独立，不能相互影响。也就是说，事务并发执行的效果应该和普通串行执行的效果完全一样。 持久性：事务一经完成，即使系统出现故障，也要保证事务的结构不能丢失。如何实现事务，才能使其具有上述四个特性呢？加锁、日志文件、事务提交等是常用的技术。下面对这几种技术作一简介。 （1）加锁造成事务之间的相互干扰的主要原因是多个事务同时读写数据库中的统一数据项。因此，多数事务管理程序能对事务要访问的数据项加锁。一个事务对数据项加锁后，其他的事务就不能访问它了，直到该数据项解锁为止。 日志文件事务管理程序记录了一个日志文件，包括每个事务的开始、每个事务所引起的数据库的更新和每个事务的结束。日志文件是记录在非易失性存储器上的，即使掉电，日志也能完好保存。对所有的操作进行记录是保证持久性的重要手段。 事务提交事务一般以“试验”的方式完成，就是说，在试验过程中，计算对数据库要做的更新，但并不真正地更新数据库本身。事务即将完成时，也就是事务提交的时候，更新的内容已经复制到了日志文件中，然后再把更新的内容写入数据库。这样，即使在这两步之间系统出现故障，通过查看日志文件，就能知道系统恢复之后需要进行哪些数据库更新操作。如果在这两步之前系统出现故障，我们可以重新执行该事务，确保不会发生错误。客户程序/服务程序体系结构现代的软件往往采用客户程序/服务程序体系结构。按照这种结构，在系统运行时，由一个进程（客户程序）发出请求，而由另一个进程（服务程序）去执行。从系统配置上，服务程序通常安装在功能强大的服务器上，而客户程序就放在相对简单的 PC 机（客户机）上。数据库系统通常就是按这种体系结构，把上图各组成部分的分成一个服务进程和一个或多个客户进程。按照客户程序/服务程序的划分方式，DBMS 的核心部分都属于服务程序，而客户程序主要是与用户相互配合并将查询或其他命令传送给服务程序的查询接口。对于关系数据库系统，通常用 SQL 语言表达从客户程序到服务程序的各种请求，然后由服务程序给出回答，用表即关系的形式传给客户程序。如果有很多用户同时使用数据库的话，服务程序也可能会成为“瓶颈”。从这个角度考虑，也可使客户程序多分担一部分工作，以减轻服务程序的负担，从而使整个系统处于更好的运行状态。数据库系统运行过程下面通过介绍应用程序查询数据库数据的全过程让读者大致了解数据库系统运行的过程。在应用程序运行时，数据库管理系统将开辟一个数据库系统缓冲区，用户数据的传输和格式的转换。数据库系统三成结构的描述放在数据字典（DD）中。查询语句的具体执行过程如下：（1）当计算机执行该语句时，启动数据库管理系统 DBMS。（2）DBMS 首先对该语句进行语法检查，然后从数据字典 DD 中找出该应用程序对应的外模式（相当于关系数据库中的视图），检查是否存在锁要查询的关系，并进行权限检查，即检查该操作是否在合法的授权范围内。如有问题，则返回出错信息。（3）在决定执行该语句后，DBMS 从 DD 中调出相应的模式描述，并从外模式映像到模式，从而确定锁需要的逻辑数据。（4）DBMS 从 DD 调出相应的内模式描述，并从模式映像到内模式，从而确定应读入的物理数据和具体的地址信息。在查询过程中，DBMS 的查询处理程序将根据 DD 中的信息进行查询优化，并把查询命令转换成一串单记录（元组）的读出操作序列。随后 DBMS 执行读出操作序列。（5）DBMS 在查看内模式决定从哪个文件、勇什么方式读取哪个物理记录之后，向操作系统发出从指定地址读取物理记录的命令，同时再系统缓冲区记下运行记录。当物理记录全部读完时，转到（12）。（6）OS 执行读出的命令，按指定地址从数据库中把记录读入 OS 的系统缓冲区，随后读入数据库（DB）的系统缓冲区。（7）DBMS 根据查询命令和数据字典的内容把系统缓冲区中的记录转换成应用程序所要求的记录格式。（8）DBMS 把数据记录从系统缓冲区传送到应用程序的用户工作区。（9）DBMS 把执行成功与否的状态信息返回给应用程序。（10）DBMS 把系统缓冲区中的运行记录计入运行日志，以备以后查询或发生意外时用于系统恢复。（11）DBMS 在系统缓冲区中查找下一记录，若找到就转到（7），否则转到（5）。（12）查询语句执行完毕，应用程序做后续处理。从上述执行过程可以看出，在数据库系统中，数据库管理系统处于中心位置，而对数据库的操作则要以数据字典中的内容为依据。关系数据库关系数据库应用数学方法来处理数据库中的数据。关系数据模型是关系数据库系统的基础。关系数据库模型由三部分构成： 关系数据结构； 关系完整性）； 关系运算（关系操作集合）。关系数据库构成前面已经提到了关系数据库由三部分构成。具体讲解如下。关系数据结构关系是关系数据模型的核心。关系是一个数学概念。当人们把关系的概念引入到数据库系统作为数据模型的数据结构时，这一概念既有所限定也有所扩充。关系模型的数据结构非常简单，只包含单一的数据结构—-关系。在用户看来，关系模型中数据的逻辑结构是一张扁平的二维表。关系模型的数据结构虽然简单却能够表达丰富的语义，描述出现实世界的实体以及实体间的各种联系。也就是说，在关系模现实世界的实体以及实体间的各种联系均用单一的结构类型即关系来表示。一般来说，笛卡尔积是没有实际语义的，只有它的某个子集才有实际含义。关系和关系模式是关系数据库中密切相关但又有所不同的概念。关系模式描述了关系的数据结构和语义约束，不是集合；而关系是一个数据集合。关系模式是相对稳定的；而关系是随时间变化的，是某一时刻现实世界状态的真是反映，是关系模式在某一时刻的“当前值”。我们称一个关系模式的任何一个“当前值”为该关系模式的关系实例。若关系中的某一属性组的值能位移地标识一个元组，则程该属性为候选码；若一个关系有多个候选码，则选定其中一个为主妈；候选码的诸属性称为主属性。不包含在任何候选码中的属性称为非主属性或非码属性。在最简单的情况下，候选码只包含一个属性；在最极端的情况下，关系模式的所有属性是这个关系模式的候选码，称为全码。关系可以有三种类型： 基本关系（又称为基本表或基表）；基本表是实际存在的表，它是实际存储数据的逻辑表示。 查询表：其为查询结果对应的表。 视图表：视图表是由基本表或其他视图表导出的表，是虚表，不对应实际存储的数据。 基本表具有以下 6 条性质： 列是同质的，级每一列中的分量是同一类型的数据，来自同一个域。 不同的列克出资同一个域，称其中的每一列为一个属性，不同的属性要给予不同的属性名。 列的顺序无所谓，即列的次序可以任意交换的，因此很多数据库产品总是在最后插入列。 任意两个元组的候选码不能相同。 行的顺序无所谓，即行的次序可以任意交换（不过有些需要排序）。 分量必须取原子值（不过对象-关系型数据库有所改变），即每一个分量都必须是不可分的数据项。关系模型要求关系必须是规范化的，即要求关系必须满足一定的规范条件。这些规范条件中最基本的一条就是，关系的每一个分量必须是一个不可分的数据项。规范化的关系称为范式（具体见后面章节）。完整性约束规则关系需要一个或一组属性作为键以标识关系中元组的唯一性。关系模型的完整性约束如下： 实体完整性约束：对于实体完整性规则说明如下：（1）实体完整性规则是针对基本关系（基本表）而言。一个基本表通常对应现实世界的一个实体集。（2）现实世界中的实体是可区分的，即它们具有某种唯一性标识。（3）相应地，关系模型中以主码作为唯一标识。（4）主码中的属性即主属性不能取空值。如果主属性取空值，就说明存在某个不可标识的实体，即存在不可区分的实体，这与第（2）点相矛盾，因此这个规则称为实体完整性 关联（参照）完整性约束：不仅两个或两个以上的关系间可以存在引用关系，同一关系内部属性间也可能存在引用关系。需要指出的是，外码并不一定要与相应的主码同名。不过，在实际应用当中，为了便于识别，当外码与相应的主码属于不同关系时，往往给它们取相同的名字。参照完整性规则就是定义外码与主码之间的引用规则。 用户定义的完整性任何关系数据库都应该支持实体完整性和参照完整性。这是关系模型所必须的。除此之外，不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性就是针对某一具体关系数据库的约束条件。它反映某一具体应用所涉及的数据必须满足的语义要求（如某个非主属性也不能为空）。关系模型应提供定义和检验这类完整性的机制，以便用统一的系统的方法处理它们，而不要由应用程序承担这一功能。关系运算（操作）早期的关系运算能力通常用代数方式或逻辑方式来表示，分别称为关系代数和关系演算。关系代数式用对关系的运算来表达查询要求的。关系演算是用谓词来表达查询要求的。关系演算又可按谓词变元的基本对象是元组变量还是域变量分为元组关系演算和域关系演算。关系数据语言的分类关系代数、元组关系演算和域关系演算三种语言在表达能力上是完全等价的。而且它们均是抽象语言，这些抽象的语言与具体的 RDBMS 中实现的实际语言并不完全一样。但它们能用作评估实际系统中查询语言能力的标准或基础。实际的查询语言除了提供关系代数或关系演算的功能外，还提供了许多附加功能，如关系赋值等另外还有一种介于关系代数和关系演算之间的语言 SQL。SQL 不仅具有丰富的查询功能，而且具有数据定义和数据控制功能，是集查询、DDL、DML 和 DCL 于一体的关系数据语言。它充分体现了关系数据语言的特点和优点，是关系数据库的标准语言。因此，关系数据语言可以分为三类：这些关系数据语言的共同特点是：语言具有完备的表达能力，是非过程化的集合操作语言，功能强，能够嵌入高级语言中使用。关系代数关系代数式一种抽象的查询语言，它用对关系的运算来表达查询。任何一种运算都是将一定的运算符作用于一定的运算对象上，得到预期的运算结构。所以运算对象、运算符、运算结构是运算的三大要素。关系代数的运算对象是关系，运算结构亦为关系。关系代数用到的运算符包括四类： 集合运算符； 专门的关系运算符； 算术比较符； 逻辑运算符。关系代数的运算按运算符的不同可分为传统的集合运算和专门的关系运算两类。其中传统的集合运算将关系看成元组的集合，其运算时从关系的“水平”方向即行的角度来进行。而专门的关系运算不仅涉及行而且涉及列。比较运算符和逻辑运算符是用来辅助专门的关系运算符进行操作的。关系代数包括并、差、投影、笛卡尔积和选择五个基本操作，另外还有一些经常使用的附加操作，比如交、连接、商等操作。这些附加操作可以用五个基本操作表示。传统的集合运算传统的集合运算是二目运算，包括并、差、交、笛卡尔积四种运算。专门的关系运算专门的关系运算包括选择、投影、连接、除运算等。 选择：选择运算实际上是从关系 R 中选取使逻辑表达式 F 为真的元组。这是从汗的角度进行的运算。 投影：关系 R 上的投影是从 R 中选择出若干属性列组成新的关系。可见，投影操作时从列的角度进行的运算。 连接：一般的连接操作时从行的角度进行运算。但自然连接还需要取消重复咧，所以是同时从行和列的角度进行运算。 除操作（商运算）：除操作时同时从行和列角度进行运算。元组关系演算关系演算是以数理逻辑中的谓词演算为基础的。按谓词变元的不同，关系演算可分为元组关系演算和域关系演算。域关系演算关系运算的安全性由于计算机不能处理无限关系，也不能进行无穷验证，所以我们不希望关系运算导致无限关系和无穷验证。直观地说，如果一个关系运算不产生无限关系和无穷验证，则这个关系运算系统是安全的。从关系代数操作的定义可以看出，任何一个有限关系上的关系代数操作结构不会导致无限关系和无穷验证。所以，关系代数系统是安全的。然而，元组关系演算系统和域关系演算系统可能产生无限关系和无穷验证。关系运算的等价性如果两个表达式锁表达的关系相同，我们称这两个表达式为等价表达式。我们使用如下方法证明关系代数、元组关系演算、域关系演算的等价性： 证明每个关系代数表达式都有一个等价的安全元组演算表达式与之对应； 证明每个安全元组演算表达式都有一个等价的安全域关系演算表达式与之对应； 证明每个安全的域关系演算表达式都有一个等价的关系代数表达式与之对应。关系数据库查询语言前面已经讲述了关系代数、元组关系演算和域关系演算的相关知识，而且证明了这三种关系运算系统在表达能力上是等价的。E.F.Codd 提出了考察关系数据库查询语言的标准，即与元组关系演算的表达能力等价的查询语言是完备的。由于关系代数、元组关系演算和域关系演算的表达能力相同，所以绝大多数关系数据库查询语言都是以这三种关系运算系统为基础建立起来的。如： IBM 英国科学中设计的 ISBL 是一种纯关系代数查询语言； INGRES 关系数据库系统的 QUEL 语言是一种近似于元组关系演算的查询语言； IBM 公司研制的 QBE 语言是一种域关系演算语言； 目前使用最广泛的 SQL 语言是一种既由关系代数特点又有关系演算特点的查询语言。数据库语言一般都允许两种使用方式： 一种方式是交互使用：即，用户通过计算机终端设备直接向数据库系统输入数据库语言语句，请求数据库系统的服务； 嵌入方式：把数据库语言嵌入到某个程序设计语言中，作为这个程序设计的子程序使用。这个程序设计语言称为宿主语言。应用程序员可以在宿主语言程序的任何地方使用数据库语言语句，向数据库系统提出操作要求。 接口式：在用编程语言编写代码时，引用一个或多个数据库连接通用的接口库，使程序能通过对这些接口库函数或对象的调用来传入 SQL 语句，并间接执行 SQL 语句，这种方式被称为接口式，也称为 API 式。提供的接口库有 ODBC、JDBC、OCI 等。关系数据库标准语言 SQL和许多流行的编程语言（例如，C++、Java、Visual Basic 和 C#）不同，SQL 用于处理数据集，而且是非过程语言。也就是说，在其他编程语言中被认为理所当然的特性，如流控制语句、循环语句等，在 SQL 中完全没有，非过程化语言在本质上提交一个命令，具有询问和查询类型特性。 SQL 是由单个命令组成的非过程化语言。其中数据库自身做许多工作以决定如何获得信息。另一个方面，过程化语言包含命令块。这些命令块是有区别的步骤序列，通常每个后继的步骤都依赖于该序列中的前一个命令的结构。SQL 概述SQL 实现了数据存储、数据检索及数据操作功能，它与数据库管理系统（DBMS）紧紧地地联系在一起，既不能存在于 DBMS 之外，也不能在 DBMS 外执行。我们要做的就是将一个查询提交到 DBMS，然后再某些客户端程序中得到结构，这些结构可以是从数据库得到的真实数据，也可以是一项任务的状态结构（如，插入或删除记录）。和编程风格的变量操作不同，插入数据、更新数据和检索数据都是基于集的过程。SQL 语句操作于数据集，虽然在 SQL 程序员看来，完成一项操作可能要花费很长的时间，但这些操作却是不包含任何留控制。当然，在某些过程语言（通常是 C 语言）中会实现执行 SQL 查询的引擎。大多数情况下，不管它多短多简单或者多长多复杂，一个 SQL 程序就是作为一个整体来执行一条或多条语句。SQL 的特点为了解决 SQL 程序不足所引发的问题，数据库供应商提供了许多自己的 SQL 函数和程序扩展插件。SQL 是用于对存放在数据库中的数据进行组织、管理和检索的工具，是关系数据库的高级语言。具有以下显著特点： 综合统一：数据库系统的主要功能是通过数据库支持的数据语言来实现的。非关系数据库（层次模型、网状模型）的数据语言一般都分为： 模式数据定义语言（模式 DDL）； 外模式数据定义语言（外模式 DDL 或子模式 DDL）； 数据存储有关的描述语言（DSDL）； 数据操纵语言（DML）。它们分别用于定义模式、外模式、内模式和进行数据存取与处置。当用户数据库投入运行后，如果需要修改模式，必须停止现有数据库的运行，转储数据，修改模式并编译后再重装数据库，十分麻烦。*SQL 则集数据定义语言 DDL、数据操纵语言 DML、数据控制语言 DCL 的功能于一体，语言风格统一，可以独立完成数据库生命周期中的全部活动，包括： 定义关系模式，插入数据，建立数据库； 对数据库中的数据进行查询和更新； 数据库重构和维护； 数据库安全性、完整性控制等一系列操作。这就为数据库应用系统的开发提供了良好的环境。特别是用户在数据库系统投入运行后，还可根据需要随时地逐步地修改模式，并不影响数据库的运行，从而是系统具有良好可扩展性。另外，*在关系模型中实体和实体间的联系均用关系表示，这种数据结构的单一性带来了数据操作符的统一性，查找、插入、删除、更新等每一种操作都只需一种操作符，从而克服了非关系系统由于信息表示方式的多样性带来的操作复杂性。SQL 语言包含如下三种自语言完成关系数据库需要的几乎所有的操作： 数据定义语言（DDL）； 数据操作语言（DML）； 数据查询语言（DQL）。DDL 用来定义数据库结构，包括创建和删除表、定义视图、索引以及约束条件等等。DML用来实现数据的修改，而 DQL用来检索数据。由于 SQL 是使用关系模型来创建数据库的标准语言，这就使得关系数据库具有很好的可移植性，可以移植到任何不同的环境。用户掌握 SQL 后，经过很小的调整，就可以使用任何关系数据库。可见，DQL 集数据查询、数据操作、数据定义和数据控制功能于一身，充分体现了关系数据语言的优越性，是一种功能强大、通用性号又简单易学的语言。 高度非过程化非关系数据模型的数据操纵语言是“面向过程”的语言，用“过程化”语言完成某项请求，必须指定存取路径。而用 DQL 进行数据操作，只要提出“做什么”，而无须指明“怎么做”，因此无需了解存取路径。存取路径的选择以及 DQL 的操作过程由系统自动完成。这不但大大减轻了用户负担，而且有利于提高数据独立性。 面向集合的操作方式非关系数据模型采用的是面向记录的操作方式，操作对象是一条记录。例如查询所有平均成绩在 80 分以上的学生姓名，用户必须一条一条地把满足条件的学生记录找出来（通常要说明具体处理过程，即按照哪条路径，如何循环等）。而SQL采用集合操作方式，不仅操作对象、查找结构可以是元组的集合，而且一次插入、删除、更新操作的对象也可以是元祖的集合。 以同一种语法结构提供多种使用方式SQL 既是独立的语言，有时嵌入式语言。作为独立的语言，它能够独立当用于联机交互的使用方式，用户可以在终端键盘上直接键入 SQL 命令对数据库进行操作；作为嵌入式语言，SQL 语句能够嵌入到高级语言程序中，供程序员设计程序时使用。而在两种不同的使用方式下，SQL 的语法结构基本上是一致的。这种以统一的语法结构提供多种不同使用方式的做法，提供了吉大的灵活性与方便性。 语言简洁，易学易用SQL 功能极强，但由于涉及巧妙，语言时分简洁，完成核心功能只用了 9 个动词，如下表所示：DQL 基本概念支持 SQL 的 RDBMS 同样支持关系数据库三级模式结构，如下图：其中外模式对应于视图和部分基本表，模式对应于基本表，内模式对应于存储文件。用户可以用 SQL 对基本表和视图进行查询或其他操作，基本表和视图一样，都是关系。 基本表：基本表是本身独立存在的表，在 SQL 中一个关系就对应一个基本表。一个（或多个）基本表对应一个存储文件，一个表可以带若干索引，索引也存放在存储文件中。 存储文件：存储文件的逻辑结构组成了关系数据库的内模式。存储文件的物理结构是任意的，对用户是透明的。 视图：视图是从一个或几个基本表导出的表。它本身不独立存储在数据库中，即数据库中只存放视图的定义而不存放视图对应的数据。这些数据仍存放在导出视图的基本表中，因此视图是一个虚表。视图在概念上与基本表等同，用户可以在视图上再定义视图。SQL 各供应商间差异虽然各 SQL 语句涉及到的基本概念和基本功能是基本相同的，但各个 RDBMS 产品在实现标准 SQL 时各有差别，与 SQL 标准的符合程度也不相同，一般在 85% 以上。因此，具体使用某个 RDBMS 产品时，还应参阅系统提供的有关手册。各个 RDBMS 产品各有差别是因为，SQL 的以下内容是留给供应商实现的： 语义和语法差异； 为处理技术打开一个数据库：ODBC、OLEDB、JDBC 和其他接口并不是 SQL 标准的一部分，尽管 SQL 标准已将 CLI（呼叫级接口）定义为 ISO/IEC 9075-3:2003/Cor1:2005 的一部分。 动态和嵌入的 SQL 实现会因提供商的不同而有所差异； 排序顺序：已排序的查询结果是如何呈现呢？这依赖于是否使用了 ASCII 或 EBCDIC 字符。虽然 UNICODE 标准解决了这一问题，仍然存在大量的旧有数据和应用程序。 不同的数据类型扩展：自定义结构、混合数据类型、对象等； 数据库目录表中的差异：由于这仅在完全一致性级别标准下回提到，在核心一致性下工作的供应商没有理由放弃自己的专有结构。数据类型在关系模型中一个很重要的概念是域。每一个属性来自一个域，它的取值必须是域中的值。在 SQL 中域的概念用数据类型来实现。定义表的各个属性时需要指明其数据类型及长度。SQL 提供了一些主要数据类型，要注意的是，不同的 RDBMS 中支持的数据类型不完全相同（具体参考相应产品说明）。一个属性选用哪种数据类型要根据实际情况来决定，一般要从两个方面考虑，一是取值范围，二是要做哪些运算。例如，对于年龄属性，可以采用 CHAR(3) 作为数据类型，但考虑到要在年龄上做算术运算（如求平均年龄），所以要采用整数作为数据类型，因为 CHAR(n) 数据类型不能进行算术运算。整数又有长整数和短整数两种，因为一个人的年龄在百岁左右，所以选用短整数作为年龄的数据类型。数据定义关系数据库系统支持三级模式结构：模式、外模式和内模式。这三种模式中的基本对象有表、视图和索引。因此 SQL 的数据定义功能包括模式定义、表定义、视图和索引的定义，如下表所示：SQL 通常不提供修改模式定义、修改视图定义和修改索引定义的操作。用户如果想修改这些对象，只能先将它们删除掉，然后再重建。数据定义语句（DDL）用来创建、删除或者更改一个数据模式对象的记过，是对数据库重要元数据(Meta Data)的管理。这里的元数据指的是前述数据意义的数据。DDL 语言就是通过对元数据的操作来管理数据库模式的各种结构的。在每一条 DDL 语句执行前后，系统都将隐式提交当前事务。在使用 DML 子语句修饰 DDL 语句的执行语句中，通常系统会自动提交 DML 语句的内容。创建数据库创建数据库用 CREATE DATABASE 命令，创建数据库由很多个参数可以自定义也可以使用默认值。在创建数据库前需要确定数据库的存储空间和数据库的日志模式等。不同的 DBMS 系统对数据库概念是不一致的。具体详细的用法其参考相应产品的帮助手册。模式的定义与删除 定义模式在 SQL 中，模式定义语句如下：CREATE SCHEMA &lt;模式名&gt; AUTHORIZATION &lt;用户名&gt;如果没有指定 ，那么 隐含为 。要创建模式，调用该命令的用户必须拥有 DBA 权限，或者获得了 DBA 授予的 CREATE SCHEMA 的权限。定义模式实际上定义了一个命名空间，在这个空间中可以进一步定义该模式包含的数据库对象，例如基本表、视图、索引等（创建语句见前面表格“SQL 的数据定义语句”）。目前在 CREATE SCHEMA 中可以接受 CREATE TABLE,CREATE VIEW 和 GRANT 子句。 删除模式在 SQL 中，删除模式语句如下：DROP SCHEMA &lt;模式名&gt; &lt;CASCADE | RESTRICT&gt;其中 CASCADE 和 RESTRICT 两者必选其一。 CASCADE选择了 CASCADE（级联），表示在删除模式的同时把该模式中所有的数据库对象全部一起删除。 RESTRICT选择了 RESTRICT（限制），表示如果该模式中已经定义了下属的数据库对象（如表、视图等），则拒绝该删除语句的执行。只有当模式中没有任何下属的对象时才能执行 DROP SCHEMA 语句。模式与表每一个基本表都属于某一个模式，一个模式包含多个基本表。当定义基本表同时定义它所属的模式一般可以有三种方法： 在表名中明显地给出模式名，例如 在创建模式语句中同时创建表，如[例3]所示。 设置所属的模式，这样在创建表时表名中不必给出模式名。当用户创建基本表（吉他数据库对象也一样）时候若没有指定模式，系统根据搜索路径来确定该对象所属的模式。搜索路径包含一组模式列表，RDBMS 会使用模式列表中第一个存在的模式作为数据库对象模式名。若搜索路径中模式名都不存在，系统将给出错误。基本表的定义、删除与修改 定义基本表创建了一个模式，就建立了一个数据库的命名空间，一个框架。在这个空间中首先要定义的是该模式包含的数据库基本表。SQL 语言使用 CREATE TABLE 语句定义基本表，其基本格式如下：CREATE TABLE &lt;表名&gt;(&lt;列名&gt; &lt;数据类型&gt; [列级完整性约束条件] [,&lt;列名&gt; &lt;数据类型&gt; [列级完整性约束条件] ... [,表级完整性约束条件]);建表的同时通常还可以定义与该表有关的完整性约束条件，这些完整性约束条件被存入系统的数据字典中，当用户操作表中数据时由 RDBMS 自动检查该操作是否违背这些完整性约束条件。如果完整性约束条件涉及到该表的多个属性列，则必须定义在表级上，否则既可以定义在列级也可以定义在表级。 修改基本表随着应用环境和应用需求的变化，有时需要修改已建立好的基本表，DQL 语言用 ALTER TABLE语句修改基本表，其一般格式为：ALTER TABLE &lt;表名&gt;[ ADD &lt;新列名&gt; &lt;数据类型&gt; [ 完整性约束 ]][ DROP &lt;完整性约束名&gt; ][ ALTER COLUMN &lt;列名&gt; &lt;数据类型&gt; ];其中 是要修改的基本表，ADD 子句用于增加新列和新的完整性约束条件，DROP 子句用于删除指定的完整性约束条件，ALTER COLUMN 子句用于修改原有的列定义，包括修改列名和数据类型。 删除基本表当某个基本表不再需要时，可以使用 DROP TABLE语句删除它。其一般格式为：DROP TABLE &lt;表名&gt; [RESTRICT | CASCADE]; RESTRICT缺省自动选择 RESTRICT。选择 RESTRICT 则该表的删除是有限制条件的。欲删除的基本表不能被其他表的约束所引用（如 CHECK，FOREIGN KEY 等约束），不能有视图，不能有触发器，不能有存储过程或函数等。如果存在这些依赖该表的对象，则此表不能删除。 CASCADE选择 CASCADE 则该表的删除没有限制条件。在删除基本表的同时，相关的依赖对象，例如视图，都将被一起删除。同样，对于其他的 SQL 语句，不同的数据库产品在处理策略上会与标准有所差别。索引的建立与删除建立索引是加快查询速度的有效手段。用户可以根据应用环境的需要，在基本表建立一个或多个索引，以提供多种存取路径，加快查找速度。一般来说，建立与删除索引由数据库管理员 DBA 或表的属主(owner)负责完成。系统在存取数据时会自动选择合适的索引作为存取路径，用户不必也不能显式地选择索引。 建立索引在 SQL 语言中，建立索引使用 CREATE INDEX 语句，其一般格式为：CREATE [ UNIQUE ][ CLUSTER ] INDEX &lt;索引名&gt;ON &lt;表名&gt;( &lt;列名&gt; [ &lt;次序&gt; ][,&lt;列名&gt; [ &lt;次序&gt; ]]...);其中， 是要建索引的基本表的名字。索引可以建立在该表的一列或多列上，各列名之间用逗号分隔。每个 后面还可以用 指定表索引值得排列次序，可选 ASC（升序）或 DESC（降序），缺省值为 ASC。UNIQUE表明此索引的每一个索引值只对应唯一的数据记录。CLUSTER表示要建立的索引是聚簇索引。所谓聚簇索引是指索引项的顺序与表中记录的物理顺序一致的索引组织。用户可以在最经常查询的列上建立聚簇索引以提高查询效率。显然在一个基本表上最多只能建立一个聚簇索引。建立聚簇索引后，更新该索引列上的数据时，往往导致表中记录的物理顺序变更，代价较大，因此对于经常更新的列不宜建立聚簇索引。用户使用 CREATE INDEX 语句定义索引时，可以定义索引是位移索引、非唯一索引或聚簇索引。至于某一个索引是采用 B+ 树，还是 HASH 索引则由具体的 RDBMS 来决定。 删除索引索引一经建立，就由系统使用和维护它，不需用户干预。建立索引是为了减少查询操作的时间，但如果数据增删改频繁，系统会花费许多时间来维护索引，从而降低查询效率。这是，可以删除一些不必要的索引。在 SQL 中，删除索引使用 DROP INDEX语句，其一般格式为：DROP INDEX &lt;索引名&gt;;删除索引时，系统会同时从数据字典中删去有关该索引的描述。在 RDBMS 中索引一般采用 B+ 树、HASH 索引来实现。B+ 树索引具有动态平衡的优点。HASH 索引具有查找速度快的特点。索引是关系数据库的内部实现技术，属于内模式的范畴。视图定义、删除、更新 定义视图定义视图用 CREATE VIEW 语句。视图是对表定义的查询，自己不存储数据，是逻辑上的表，它可以组合多个表的数据，供不同应用需要。例如： 删除视图删除视图用 DROP VIEW 命令。对视图的删除并不影响实际储存的数据。例如：DROP VIEW clerk; 更新视图更新视图有 3 种意义上的更新： 将视图定义的查询语句进行修改，使用 REPLACE VIEW命令； 使用 ALTER VIEW 命令重新编译视图或者修改视图的各种约束； 对视图中的数据进行更新，由于视图可以定义在多个关系的基础上，对于视图的选取属性不一定是关系的全部属性，所以对于数据插入操作，没有选取出的关系属性将出现空值，这有时会出现许多异常，所以视图中数据的更新当且仅当定义在单个关系上才被允许。简单（单表）查询数据操作语句（DML）用来改变表中的数据或者查询数据表中的数据，但是不该表表或其他对象的结果。而数据库查询是数据库的核心操作。SQL 提供了 SELECT 语句进行数据库的查询，该语句具有灵活的使用方式和丰富的功能。其一般格式为：SELECT [ALL | DISTINCT] &lt;目标列表达式&gt; [,&lt;目标列表达式&gt;]...FROM &lt;表名或视图名&gt; [,&lt;表名或视图名&gt; ]...[ WHERE &lt;条件表达式&gt; ][ GROUP BY &lt;列名 1&gt; [ HAVING &lt;条件表达式&gt; ]][ ORDER BY &lt;列名 2&gt; [ ASC | DESC]];整个 SELECT 语句的含义是，根据 WHERE 子句的条件表达式，从 FROM 子句指定的基本表或视图中找出满足条件的元组，再按 SELECT 子句中的目标列表达式，选出元组中的属性值形成结果表。 GROUP BY如果有 GROUP BY 子句，则将结果按 &lt;列名 1&gt; 的值进行分组，该属性列值相等的元组为一个组。通常会在每组中作用聚集函数 。 HAVING如果 GROUP BY 子句带 HAVING 短语，则只有满足指定条件的组才予以输出。 ORDER BY如果有 ORDER BY 子句，则结果表还要按 &lt;列名 2&gt; 的值得升序或降序排序。SELECT 语句既可以完成简单的单表查询，也可以完成复杂的连接查询和嵌套查询。单表查询—选择列单表查询是指仅涉及一个表的查询。 查询指定列很多情况下，用户只对表中的一部分属性列表感兴趣，这时可以通过在 SELECT 子句中的 &lt;目标列表达式&gt; 中指定要查询的属性列。 查询全部咧将表中的所有属性列都选出来，可以有两种方法。一种方法就是在 SELECT 关键字后面列出所有列名。如果列的显示顺序与其在基表中的顺序相同，也可以简单地将&lt;目标列表达式&gt; 指定为 *。 查询经过计算的值SELECT 子句的 &lt;目标列表达式&gt; 不仅可以是表中的属性列，也可以是表达式。&lt;目标列表达式&gt; 不仅可以是算术表达式，还可以是字符串常量、函数等。用户可以通过指定别名来改变查询结果的列标题，这对于含算术表达式、常量、函数名的目标列表达式尤为有用。例如对于上例，可以定义如下列别名：单表查询—选择元组 消除取值重复的行两个本来并不完全相同的元组，投影到指定的某些列上后，可能变成相同的行了，可以用 DISTINCT 取消它们。 查询满足条件的元组查询满足指定条件的元组可以通过 WHERE 子句实现。WHERE 子句常用的常用条件如下表所示： 比较大小用于比较的运算符一般包括：=（等于），&gt;，&lt;，&gt;=，&lt;=，!=或&lt;&gt;（不等于），!&gt;（不大于），!&lt;RDBMS 执行该查询的一种可能过程是：对 Student 表进行全表扫描，取出一个元组，检查该元组在 Sdept 列的值是否等于 ‘CS’。如果相等，则取出 Sname 列的值形成一个新的元组输出，否则跳过该元组，取下一个元组。如果全校有数万个学生，计算机系的学生人数是全校学生的 5% 左右，可以在 Student 表的 Sdept 列上建立索引，系统会利用该索引找出 Sdept = ‘CS’ 的元组，从中取出 Sname 列值形成结果关系。这就避免了对 Student 表的全表扫描，加快查询速度。注意：如果学生较少，索引查找不一定能提高查询效率，系统仍会使用全表扫描。这由查询优化器按照某些规则或估计执行代价来做出选择。 确定范围谓词 BETWEEN…AND… 和 NOT BETWEEN…AND…可以用来查找属性在（或不在）指定范围内的元组。 确定集合谓词 IN 可以用来查找属性值属于指定集合的元组。 字符匹配谓词 LIKE 可以用来进行字符串的匹配。其一般语法格式如下：[NOT]LIKE '&lt;匹配串&gt;'[ESCAPE' &lt;换码字符&gt;']其含义是查找指定的属性列值与 &lt;匹配串&gt; 相匹配的元组。&lt;匹配串&gt; 可以是一个完整的字符串，也可以含有通配符 % 和 _。其中： %百分号代表任意长度（长度可以为 0）的字符串。 _下划线代表单个字符。 涉及空值得查询 多重条件查询逻辑运算符 AND 和 OR 可用来联结多个查询条件。AND 优先级高于 OR，但用户可以用括号改变优先级。ORDER BY 子句用户可以用 ORDER BY 子句对查询结果按照一个或多个属性咧的升序（ASC）或降序（DESC）排列，缺省值为升序。对于空值，若按升序排，含空值的元组将最后显示；若按降序拍，空值的元组将最先显示。聚集函数为了进一步方便用户，增强检索功能，SQL 提供了许多聚集函数，主要有：如果指定 DISTINCT 短语，则表示在计算时要取消指定列中的重复值。如果不指定 DISTINCT 短语或指定 ALL 短语（ALL 为缺省值），则表示不取消重复值。GROUP BY 子句GROUP BY 子句将查询结果按某一列或多列的值分组，值相等的为一组。对查询结果分组的目的是为了细化聚集函数的作用对象。如果未对查询结果分组，聚集函数将作用于整个查询结果。分组后聚集函数将作用于没一个组，即每一组都有一个函数值。如果分组后还要求按一定的条件对这些组进行筛选，最终只输出满足执行条件的组，则可以使用 HAVING 短语指定筛选条件。WHERE 子句与 HAVING 短语的区别在于作用对象不同。WHERE 子句作用于基本表或视图，从中选择满足条件的元组。HAVING 短语作用于组，从中选择满足条件的组。视图查询视图定义后，用户就可以像对基本表一样对视图进行查询了。RDBMS 执行对视图的查询时，首先进行有效性查询。检查查询中设计的表、视图等是否存在。如果存在，则从数据字典中取出视图的定义，把定义中的子查询和用户的查询结合起来，转换成等价的对基本表的查询，然后再执行修正了的查询。这一转换过程称为视图消解。目前多数关系数据库系统对行列子集视图的查询均能进行正确转换。但对非行列式子集视图的查询（如例 11）就不一定了，因策这些查询应该直接对基本表进行。连接查询若一个查询同时涉及两个以上的表，则称之为连接查询。连接查询是关系数据库中最主要的查询，包括等值连接查询、自然连接查询、非等值连接查询、自身连接查询、外连接查询和符合条件连接查询等。关系代数的强大表达能力来自于它能够通过并、交、差、自然连接、笛卡尔积等运算将两个或两个以上的关系连接起来，从而完成复杂的查询任务。并、交、差在 SQL 中各自有相应的关键字来表示，至于连接和笛卡尔积，不需要有额外的关键字，仅仅使用普遍的 SELECT-FROM-WHERE 语句，就可以方便的表示。等值与非等值连接查询连接查询的 WHERE 子句中用来连接两个表的条件称为连接条件或连接谓词，其一般格式为：[ &lt;表名 1&gt;.] &lt;列名 1&gt; &lt;比较运算符&gt; [ &lt;表名 2&gt;. ]&lt;列名 2&gt;其中比较运算符主要有：=、&gt;、&lt;、&gt;=、&lt;=、!=等。此外连接谓词还可以使用下面形式：[ &lt;表名 1&gt;. ]&lt;列名 1&gt; BETWEEN [&lt;表名 2&gt;.]&lt;列名 2&gt; AND [&lt;表名 2&gt;.]&lt;列名 3&gt;当连接运算符为 = 时，称为等值连接。使用其他运算符称为非等值连接。连接谓词中的列名称为连接字段。连接条件中的各字段类型必须是可比的（如数据类型），但名字不必相同。本例中，SELECT 子句与 WHERE 子句中的属性名前都加上了表名前缀，者是为了避免混淆。如果属性名在参加连接的各表中是唯一的，则可以省略表名前缀。自然连接查询自然连接(Natural join)是一种特殊的等值连接，它要求两个关系中进行比较的分量必须是相同的属性组，并且在结果中把重复的属性列去掉。而等值连接并不去掉重复的属性列。上节例子改造如下，就变成了自然连接：自身连接查询连接操作不仅可以在两个表之间进行，也可以是一个表与其自己进行连接，称为表的自身连接。内连接查询全外连接查询外联接。外联接可以是左向外联接、右向外联接或完整外部联接。在 FROM子句中指定外联接时，可以由下列几组关键字中的一组指定： 1）LEFT JOIN或LEFT OUTER JOIN左向外联接的结果集包括 LEFT OUTER子句中指定的左表的所有行，而不仅仅是联接列所匹配的行。如果左表的某行在右表中没有匹配行，则在相关联的结果集行中右表的所有选择列表列均为空值。 2）RIGHT JOIN 或 RIGHT OUTER JOIN右向外联接是左向外联接的反向联接。将返回右表的所有行。如果右表的某行在左表中没有匹配行，则将为左表返回空值。 3）FULL JOIN 或 FULL OUTER JOIN完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。左外连接查询在通常的连接操作中，只有满足连接条件的元组才能作为结果输出。如“等值与非等值连接查询”一节中的图中结果表中没有 200215123 和 200215125 两个学生的信息，原因在于他们没有选课，在 SC 表中没有响应的元组，造成 Student 中这些元组在连接时被舍弃了。有时想以 Student 表为主体列出每个学生的基本情况及其选课情况。若某个学生没有选课，仍把舍弃的 Student 元组保存在结果关系中，而在 SC 表的属性上填空值（Null），这时就需要使用外连接。右连接查询概念：恰与左连接相反，返回右表中的所有行，如果右表中行在左表中没有匹配行，则结果中左表中的列返回空值。select * from T_student s right join T_class c on s.classId = c.classId交叉连接（CROSS JOIN）概念：不带 WHERE 条件子句，它将会返回被连接的两个表的笛卡尔积，返回结果的行数等于两个表行数的乘积（例如：T_student和T_class，返回 4*4=16 条记录），如果带 where，返回或显示的是匹配的行数。 不带 where：select *from T_student cross join T_class ‘等于 select *from T_student, T_class 带 where：有where子句，往往会先生成两个表行数乘积的数据表，然后才根据where条件从中选择select * from T_student s cross join T_class c where s.classId = c.classId 　(注:cross join后加条件只能用where,不能用on)查询结果跟等值连接的查询结果是一样。Union 查询形成并集要是用 Union 来连接结果集（也可以由于一个表），需要满足 4 个限定条件： 子结果集要具有相同的结构。 字结果集的列数必须相同。 子结果集对应的数据类型必须可以兼容。 每个子结果集不能包含 order by 和 compute 子句。语法格式为：select_statement union [all] select_statementall代表最终的结果集中将包含所有的行，而不能删除重复行。实例如下：SELECT Name FROM Person_1 　　UNION 　　SELECT Name FROM Person_2注意到重复记录，孙权与周瑜仅仅显示了一个。下面来将UNION替换成UNION ALL看看是什么结果：SELECT Name FROM Person_1 　　UNION ALL 　　SELECT Name FROM Person_2Except 查询形成差集Except可以对两个或多个结果集进行连接，形成“差集”（前者-后者）。其限定条件为： 子结果集要具有相同的结构。 子结果集的列数必须相同。 子结果集对应的数据类型必须可以兼容。 每个子结果集不能包含 order by 和 compute 子句。其语法形式为：select_statement except select_statement该语句将自动删除重复行。实例如下：SELECT Name FROM Person_1 　　EXCEPT 　　SELECT Name FROM Person_2InterSect 查询形成交集InterSect可以对两个或多个结果集进行连接，形成“交集”。其限制条件为： 子结果集要具有相同的结构。 子结果集的列数必须相同。 子结果集对应的数据类型必须可以兼容。 每个子结果集不能包含 order by 或 compute 子句。其语法形式为：select_statement intersect select_statement实例如下：SELECT Name FROM Person_1 　　INTERSECT 　　SELECT Name FROM Person_2嵌套查询在 SQL 语言中，一个 SELECT-FROM-WHERE 语句称为一个查询块。将一个查询块嵌套在另一个查询块的 WHERE 子句或 HAVING 短语的条件中的查询称为嵌套查询。例如：SQL 语言允许多层嵌套查询。即一个子查询中还可以嵌套其他子查询。需要特别指出的是：子查询的 SELECT 语句中不能使用 ORDER BY 子句，ORDER BY 子句只能对最终查询结果排序。嵌套查询使我们可以用多个简单查询构成复杂的查询，从而增强 SQL 的查询能力。以层层嵌套的方式来构造程序正是 SQL 中“结构化”的含义所在。带有 IN 谓词的子查询在嵌套查询中，子查询的结果往往是一个集合，所以谓词 IN 是嵌套查询中最经常使用的谓词。可见，实现同一个查询可以有多种方法，当然不同的方法其执行效率可能会有差别，甚至差别很大。这就是数据库编程人员应该掌握的数据库性能优化技术。有些嵌套查询可以用连接运算代替，有些事不能替代的。对于可以用连接运算代替嵌套查询的，到底采用哪种方法得看效率和个人习惯。带有比较运算符的子查询带有比较运算符的子查询是指父查询与子查询之间用比较运算符进行连接。当用户能确切知道内存查询返回的是单值时，可以用比较运算符。求解相关子查询不能像求解不相关子查询那样一次将子查询求解出，然后求解父查询。内存查询由于与外层查询有关，因此必须反复求值。带有 ANY（SOME）或 ALL 谓词的子查询子查询返回单值可以用比较运算符，但返回多值时要用 ANY（有的系统用 SOME）或 ALL 谓词修饰符。而使用 ANY 或 ALL 谓词时则必须同时使用比较运算符。其语义为：带有 EXISTS 谓词的子查询EXISTS 代表存在谓词，带有 EXISTS 谓词的子查询不返回任何数据，只产生逻辑 true 或 false。可以利用 EXISTS 来判断属于、子集、集合相等、是否有交集等。使用存在谓词 EXISTS 后，若内层查询结果非空，则外层的 WHERE 子句返回真值，否则返回假值。由 EXISTS 引出的子查询，其目标列表表达式通常都用*，因为带 EXISTS 的子查询值返回逻辑值，给出列名无实际意义。与 EXISTS 谓词相对应的是 NOT EXISTS 谓词。使用存在谓词 NOT EXISTS 后，若内层查询结果为空，则外层的 WHERE 子句返回真真，否则返回假值。由于带 EXISTS 谓词的相关子查询只关心内层查询是否有返回值，并不需要查具体值，因此其效率并不一定低于不相关子查询，有时是高效的方法。数据更新数据更新操作有 3 种：向表中添加若干行数据、修改表中的数据和删除表中的若干行数据。在 SQL 中有相应的三类语句。插入数据SQL 的数据插入语句 INSERT 通常有两种形式。一种是插入一个元组，另一种是插入子查询结果。后者可以一次插入多个元组。 插入元组插入元组的 INSERT 语句的格式为：INSERTINTO &lt;表名&gt; [(&lt;属性列 1&gt;[,&lt;属性列 2&gt;...])]VALUES(&lt;常量 1&gt;[,&lt;常量 2&gt;]...);其功能是将新元组插入指定表中。其中新元组的属性列 1 的值为常量 1，属性列 2 的值为常量 2，…。INTO 子句中没有出现的属性咧，新元组在这些列取空值。但必须注意的是，在表定义时说明了 NOT NULL 的属性列不能取空值，否则会出错。如果 INTO 子句中没有指明任何属性列名，则新插入的元组必须在每个属性列上均有值。 插入子查询结果子查询不仅可以嵌套在 SELECT 语句中，用以构造父查询的条件，也可以嵌套在 INSERT 语句中，用以生成要插入的批量数据。插入子查询结果的 INSERT 语句的格式为：INSERTINTO &lt;表名&gt; [(&lt;属性列 1&gt; [,&lt;属性列 2&gt;...])]子查询;修改数据修改操作又称为更新操作，其语句的一般格式为：UPDATE &lt;表名&gt;SET &lt;列名&gt;=&lt;表达式&gt;[,&lt;列名&gt;=&lt;表达式&gt;]...[WHERE &lt;条件&gt;];其功能是修改指定表中满足 WHERE 子句条件的元组。其中 SET 子句给出&lt;表达式&gt;的值用于取代相应的属性列值。如果省略 WHERE 子句，则表示要修改表中所有元组。 修改某一个元组的值 修改多个元组的值 带子查询的修改语句删除数据删除语句的一般格式为：DELETEFROM &lt;表名&gt;[WHERE &lt;条件&gt;];DELETE 语句的功能是从指定表中删除满足 WHERE 子句条件的所有元组。如果省略 WHERE 子句，表示删除表中全部元组，但表的定义仍在字典中。也就是说，DELETE 语句删除的是表中的数据，而不是关于表的定义。 删除某一个元组的值 删除多个元组的值 带子查询的删除语句对某个基本表中数据的增、删、改操作有可能会破坏参照完整性（要求通过定义的外关键字和主关键字之间的的引用规则来约束两个关系之间的联系。这条规则要求“不引用不存在的实体”）。更新视图更新视图是指通过视图来插入（INSERT）、删除（DELETE）和修改（UPDATE）数据。由于视图是不实际存储数据的虚表，因此对视图的更新，最终要转换为对基本表的更新。像查询视图那样，对视图的更新操作也是通过视图消解，转换为对基本表的更新操作。为防止用户通过视图对数据进行增加、删除、修改时，有意无意地对不属于视图范围内的基本表数据进行操作，可在定义视图时加上 WITH CHECK OPTION 子句。这样在仕途上增删改数据时，RDBMS 会检查视图定义中的条件，若不满足条件，则拒绝执行该操作。在关系数据库中，并不是所有的视图都是可更新的，因为有些视图的更新不能位移地有意义地转换成对相应基本表的更新。一般地，行列子集视图是可更新的。除行列子集视图外，还有些视图理论上是可更新的，但它们的确切特征还是尚待研究的课题。还有些视图从理论上就是不可更新的。目前各个关系数据库系统一般都只允许对行列子集视图进行更新，而且各个系统对视图的更新还有更进一步的规定，由于各系统实现方法上的差异，这些规定也不仅相同。应该指出的是，不可更新和不允许更新的视图是两个不同的概念。前者是指理论上已证明其是不可更新的视图。后者指实际系统中不支持其更新，但它本身可能是可更新的视图。查询优化查询优化一般可分为代数优化和物理优化。 代数优化代数优化是指关系代数表达式的优化。 物理优化物理优化则是指存取路径和底层操作算法的选择。优化技术：主要由四种查询优化技术，即启发式关系代数优化方法、启发式关系演算优化方法、基于复杂性的查询优化方法和语义优化方法。本文没有讲到的方法可以自行查询资料。查询处理在进行查询优化之前需要对查询处理的基本过程有一个基本的了解，才能对每一个处理过程进行优化，以达到最好的优化效果。查询处理的任务是把用户提交给 RDBMS 的查询语句转换为高效的执行计划。查询处理步骤RDBMS 查询处理可分为 4 个阶段：查询Fenix、查询检查、查询优化和查询执行。 查询分析首先，对查询语句进行扫描、词法分析和语法分析。从查询语句中识别出语言符号，如 SQL 关键字、属性名和关系名等，进行预压检查和语法分析，即判断查询语句是否符合 SQL 语法规则。 查询检查根据数据字典对合法的查询语句进行语义检查，即检查语句中的数据库对象，如属性名、关系名、是否存在和是否有效。还要根据数据指点中的用户权限和完整性约束定义对用户的存取权限进行检查。如果该用户没有响应的访问权限或违反了完整性约束，就拒绝执行该查询。检查通过后便把 SQL 查询语句转换成等价的关系代数表达式。RDBMS 一般都用查询树，也称为语法分析树，来表示扩展的关系代数表达式。这个过程中要把数据库对象的外码名称转换为内部表示。 查询优化每个查询都会有许多可供选择的执行策略和操作算法，查询优化的层次一般可分为代数优化和物理优化。代数优化是指关系代数表达式的优化，即按照一定的规则，该表代数表达式中的操作的次序和组合，使查询执行更高效；物理优化则是指存取路径和底层操作算法的选择。选择的依据可以是基于规则的，也可以是基于代价的，还可以基于语义的。实际的 RDBMS 中的查询优化器都综合运用了这些优化技术，以获得最好的查询优化效果。 查询执行依据优化器得到的执行策略生成查询计划由代码生成器生成执行这个查询计划的代码。实现查询操作的算法示例以下以选择操作和连接操作的实现算法（实际为算法思想）为例，介绍查询操作的实现技术。其实，每一种操作有多重执行这个操作的算法，这里仅仅介绍最主要的几个算法。 选择操作的实现SELECT 语句功能十分强大，有许多选项，因此实现的算法和优化策略也很复杂。不失一般性，下面以简单的连接操作为例介绍典型的实现方法。 简单的全表扫描方法对查询的基本表顺序扫描，逐一检查每个元组是否满足选择操作，把满足条件的元组作为结果输出。对于小表，这种方法简单有效。对于大表顺序扫描十分费时，效率很低。 索引（或散列）扫描方法如果选择条件中的属性上有索引（例如 B+ 树索引或 Hash 索引），可以用索引扫描方法。通过索引先找到满足条件的元组主码或元组指针，再通过元组指针直接在查询的基本表中找到元组。 连接操作连接操作时查询处理中最耗时的操作之一。不失一般性，这里只讨论等值连接（或自然连接）最常用的算法。 嵌套循环方法这是最简单可行的算法。对外层循环(Student)的每一个元组(s)，检索内层循环(SC)中的每一个元组(sc)，并检查者两个元组在连接属性(sno)上是否相等。如果满足连接条件，则串联后作为结果输出，直到外层循环表中的元组处理完为止。 排序-合并方法这也是常用的算法，尤其适合连接的诸表已经排好序的情况。用排序-合并连接方法的步骤是： 索引连接方法用索引连接方法的步骤是： HASH Join 方法把连接属性作为 hash 码，用统一 hash 函数把 R 和 S 中元组散列到统一个 hash 文件中。 （1）第一步，划分阶段，对包含较少元组的表（比如 R）进行一遍处理，把它的元组按 hash 函数分散到 hash 表的桶中； （2）第二步，试探阶段，也称为连接阶段，对另一个表（S)进行一遍处理，把 S 的元组散列到适当的 hash 桶中，并把元组与桶中所有来自 R 并与之相匹配的元组连接起来。关系数据库的查询优化综述关系系统的查询优化既是 RDBMS 实现的关键技术又是关系系统的优点所在。它减轻了用户选择存取路径的负担。用户只要提出“干什么”，不必指出“怎么干”。对比一下非关系系统中的情况：用户使用过程化语言表达查询要求，执行何种记录级的操作，以及操作的序列是由用户而不是由系统来决定的。因此用户必须了解存取路径，系统要提供用户选择存取路径的手段，查询效率由用户的存取策略决定。如果用户做了不当的选择，系统是无法对此加以改进的。这就要求用户有较高的数据库技术和程序设计水平。查询优化概述查询优化的优点不仅在于用户不必考虑如何最好地表达查询以获得较好的效率，而且在于系统可以比用户程序的“优化”做得更好。这是因为：（1）优化器可以从数据字典中获取许多统计信息，例如每个关系表中的元组树、关系中每个属性值得分布情况、哪些属性上已经建立了索引等。优化器可以根据这些信息做出正确的估算，选择高校的执行计划，而用户程序则难以获得这些信息。（2）如果数据库的物理统计信息改变了，系统可以自动对查询进行重新优化以选择相适应的执行计划。在非关系系统中必须重写程序，而重写程序在实际应用中往往是不太可能的。（3）优化器可以考虑数百种不同的执行计划，而程序员一般只能考虑有限的几种可能性。（4）优化器中包括了很多复杂的优化技术，这些优化技术往往只有最好的程序员才能掌握。系统的自动化优化相当于使得所有人都拥有了这些优化技术。目前 RDBMS 通过某种代价模型计算出各种查询执行策略的执行代价，然后选取代价最小的执行方案。在集中式数据库中，查询的执行开销主要包括磁盘存取块数（I/O 代价），处理机时间（CPU 代价），查询的内存开销。在分布式数据库中还要加上通信代价。一般地，集中式数据库中 I/O 代价是最主要的。查询优化的总目标是：选择有效的策略，求得给定关系表达式的值，使得查询代价最小（实际上是较小）。一个实例启发式关系代数优化方法在很多数据库管理系统中，查询处理的第一步是把查询变换为与关系代数对应的内部表示，如查询树，一个查询可以变换为一个等价的关系代数表达式。关系代数等价变换规则启发式代数优化规则物理优化代数优化改变查询语句中操作的次序和组合，不涉及底层的存取路径。对每一种操作有多重执行这个操作的算法，有多条存取路径。因此对于一个查询语句有许多存取方案，它们的执行效率不同，有的会相差很大。因此，仅仅进行代数优化是不够的。物理优化就是要选择高效合理的操作算法或存取路径，求得优化的查询计划，达到查询优化的目标。选择的方法可以是： 基于规则的启发式优化：启发式规则是指那些那些在大多数情况下都适用，但不是在每种情况下都是适用的规则。 基于代价估算的优化：优化器估算不同执行策略的代价，并选出具有最小代价的执行计划。 两者结合的优化方法：查询优化器通常会把这两种技术结合在一起使用。因为可能的执行策略很多，要穷尽所有的策略进行代价估算往往是不可行的，会造成查询优化本身付出的代价大于获得的益处。谓词，常常先使用启发式规则，选取若干较优的候选方案，减少代价估算的工作量；然后分别计算这些候选方案的执行代价，较快地选出最终的优化方案。基于启发式规则的存取路径选择优化 选择操作的启发式规则有： 对于小关系，使用全表顺序扫描，即使选择列上有索引。对于大关系，启发式规则有： 对于选择条件是主码 = 值的查询，查询结果最多是一个元组，可以选择主码索引。一般的 RDBMS 会自动建立主码索引。 对于选择条件是非主属性 = 值得查询，并且选择列上有索引，则要估算查询结果的元组数目，如果比例较少可以使用索引扫描方法，否则还是使用全表扫描。 对于选择条件是属性上的非等值查询或者范围查询，并且选择列上有索引，处理同上。 对于用 AND 连接的合取选择条件，如果有涉及这些属性的组合索引，则优先采用组合索引扫描方法；如果某些属性上有一般的索引，则可以用前面介绍过的索引扫描方法（参见“实现查询操作的算法示例”），否则使用全表扫描。 对于用 OR 连接的析取选择条件，一般使用全表顺序扫描。 连接操作的启发式规则有： 如果 2 个表都已经按照连接属性排序，则选用排序-合并方法。 如果一个表在连接属性上有索引，则可以选用索引连接方法。 如果上面 2 个规则都不适用，其中一个表较小，则可以选用 Hash Join 方法。 最后可以选用嵌套循环方法，并选择其中较小的表，确切地讲是占用的块数较少的表，作为外表（外循环的表）。理由如下：上面列出了一些主要的启发式规则，在实际的 RDBMS 中启发式规则要多得多。基于代价的优化数据库的完整性数据库运行时，应防止输入或输出不符合语义的错误数据，而始终保持其中数据的正确性。这就是通常所说的数据库的完整性。数据库的完整性可分为系统自身规定的完整性（如实体完整性、引用完整性等），用户自定义完整性。数据完整性和安全性的概念辨析： 数据完整性数据完整性是为了防止数据库中存在不符合语义的数据，也就是防止数据库中存在不正确的数据。完整性检查和控制的防范对象是不合语义的、不正确的数据，防止它们进入数据库。 数据安全性数据的安全性是保护数据库数据防止恶意的破坏和非法的存取。安全性控制的防范对象是非法用户和非法操作，防止他们对数据库非法存取。为维护数据库的完整性，DBMS 必须能够： 提供定义完整性约束条件的机制完整性约束条件也称为完整性规则，是数据库中的数据必须满足的语义约束条件。SQL 标准使用了一系列概念来描述完整性，包括关系模型的实体完整性、参照完整性和用户定义完整性。这些完整性一般由 SQL 的 DDL 语句来实现。它们作为数据库模式的一部分存入数据字典中。 提供完整性检查的方法DBMS 中检查数据是否满足完整性约束条件的机制称为完整性检查。一般在 INSERT、UPDATE、DELETE 语句执行后开始检查，也可以在事务提交时检查。检查这些操作执行后数据库中的数据是否违背了完整性约束条件。 违约处理DBMS 若发现用户的操作违背了完整性约束条件，就采取一定的动作，如拒绝（NO ACTION）执行该操作，或级连（CASCADE）执行其他操作，进行违约处理以保证数据的完整性。完整性控制数据库中的完整性控制可以由应用程序编写程序来实现数据自己的完整性，也可以通过数据库自带完整性约束来实现。用完整性约束来实现数据完整性比用应用程序来进行完整性控制更可靠更高效。完整性约束是用一些股则来限制在一个表中某（些）列，是一种保证数据库数据一致性和有效性的一种手段。完整性约束语句一般出现在创建表（视图）或修改表（视图）语句中，用于影响列的定义和某些条件的定义。完整性控制按照完整性约束是否具有修复数据能力分为两大类： （1）声明型完整性约束声明型完整性约束是指通过使用声明性的约束子句在 DDL 语句中声明了约束，一旦违反约束的数据操作发生后，只需由系统简单地对该数据操作进行禁止。声明型完整性约束主要分为： 域完整性约束： 非控制约束（NOT NULL） CHECK 约束 参照完整性约束： 主键约束 唯一性约束（候选键约束） 外键约束等 全局约束。 （2）处理型完整性约束：处理型完整性约束是指在约束的定义过程中，不仅声明了某个约束，而且这个约束的具体规则及处理行为系统并没有实现，需要数月本身用代码来实现。实现后的约束具有很多的灵活性，而不是简单地对数据操作做禁止与允许处理。从维护数据完整性的意义上看，处理型的完整性约束是应用程序维护数据完整性的一种特例（不过还是有些不同）。不同的是在维护数据完整性的时候约束是系统强制执行的，而应用程序是由用户自定义执行的。常用的处理型完整性主要是触发器。处理型完整性约束同声明型完整性约束相比，能够实现更为复杂的检查和操作，从而保证数据库数据的一致性。但是，因为触发器很容易造成级联调用，而且实现相同约束效率要比声明型约束差，应合理利用而不能滥用。实体完整性关系模型的实体完整性在 CREATE TABLE中用 PRIMARY KEY 定义。对单属性构成的码有两种说明方法： 列级约束条件； 定义为表级约束条件。对多个属性构成的码只有一种说明方法，即定义为表级约束条件。实体完整性检查和违约处理用 PRIMARY KEY 短语定义了关系的主码后，每当用户程序对基本表插入一条记录或者对主码列进行更新操作时，RDBMS 将利用实体性完整性规则自动进行检查，包括： 检查主码值是否唯一，如果不唯一则拒绝插入或修改。 检查主码的各个属性是否为空，只要有一个为空就拒绝插入或修改。从而保证了实体完整性。检查记录中主码值是否唯一的方法：参照完整性关系模型的参照完整性在 CREATE TABLE中用FOREIGN KEY短语定义哪些列为外码，用 REFERENCES 短语指明这些外码参照哪些表的主码。参照完整性检查和违约处理一个参照完整性将两个表中的相应元组联系起来了。因此，对被参照表和参照表进行增删改操作时有可能破坏参照完整性，必须进行检查。当上述的不一致发生时，系统可以采用以下的策略加以处理。 拒绝执行：不允许操作执行。该策略一般设置为默认策略。 级连操作：当删除或修改被参照表的一个元组造成了与参照表的不一致，则删除或修改参照表中的所有造成不一致的元组。 设置为空值：当删除或修改被参照表的一个元组时造成了不一致，则将参照表中的所有造成不一致的元组的对应属性设置为空值。不过不是所有的外码都可以接受空值（比如学号）。因此对于参照完整性时，除了应该定义外码，还应定义外码是否允许空值。一般地，当对参照表和被参照表的操作违反了参照完整性，系统选用默认策略，即拒绝执行。如果想让系统采用其他的策略则必须在创建表的时候显式地加以说明。可以对 DELETE 和 UPDATE 采用不同的策略。如，对删除操作违反一致性时拒绝执行；对更新操作则采取级连更新的策略。断言约束断言，在数据库中用 assertion 谓词来实现。其实，有关的域完整性约束和参照完整性约束都是一种特殊的断言约束。这些约束都容易检测和表达，所以在很多的数据库中比价适用。但是，还有许多数据完整性约束并不那么容易检测和表达，但是确实又是在现实中存在的，我们可以断言来进行处理。断言是数据库模式（schema）级的约束，一旦涉及的关系发生变化时系统将自动检测。断言的语法为：CREATE ASSERTION &lt;name&gt; CHECK (&lt;condition&gt;);断言一旦建立，那么在整个数据库中，任何有违背断言的数据操作即将被禁止。这样很方便使数据库按照应用系统的业务规则做数据间的平衡关系，但是如果这种平衡关系设计得太复杂，将为系统在做出是否违背断言的规则检测时，变得相当的吃力，这是也大大滴损耗了数据库的许多宝贵资源。因此，应慎用断言。用户定义的完整性用户定义完整性就是针对某一具体应用的数据必须满足的语义要求。目前的 RDBMS 都提供了定义和检验这类完整性的机制，使用了和实体完整性，参照完整性相同的技术和方法来处理它们，而不必由应用程序承担这一功能。属性上的约束条件的定义在 CREATE TABLE 中定义属性的同时可以根据应用要求，定义属性上的约束条件，即属性值限制，包括： 列值非空（NOT NULL 短语） 列值位移（UNIQUE 短语） 检查列值是否满足一个布尔表达式（CHECK 短语） 例子 不允许取空值 列值唯一 用 CHECK 短语指定列值应该满足的条件属性上的约束条件检查和违约处理当往表中插入元组或修改属性的值时，RDBMS 就检查属性上的约束条件是否被满足，如果不满足则操作被拒绝执行。元组上的约束条件的定义与属性上约束条件的定义类似，在 CREATE TABLE 语句中可以用 CHECK 短语定义元组上的约束条件，即元组级的限制。同属性值限制相比，元组级的限制可以设置不同属性之间的取值的相互约束条件。元组上的约束条件检查和违约处理当往表中插入元组或修改属性的值时，RDBMS 就检查元组上的约束条件是否被满足，如果不满足则操作被拒绝执行。完整性约束命名子句前面讲解的完整性约束条件都在 CREATE TABLE语句中定义。SQL 还在 CREATE TABLE 语句中提供了完整性约束命名子句 CONSTRAINT，用来对完整性约束条件命名。从而可以灵活地增加、删除一个完整性约束条件。完整性约束命名子句CONSTRAINT &lt;完整性约束条件&gt; [PRIMARY KEY 短语|FOREIGN KEY 短语|CHECK 短语]修改表中的完整性限制可以使用 ALTER TABLE 语句修改（更新）表中的完整性限制。域中的完整性限制SQL 支持域的概念，并可以用 CREATE DOMAIN语句建立一个域以及该域应该满足的完整性约束条件。触发器在很多情况下，当一个完整性约束被违背时，数据库管理系统除了终止事务外，还需要执行一些其他操作。例如，通知某个用户完整性约束被违背，又例如，每当雇员的差旅费超过了某一限制时，需要通知经理来处理。为了在数据库完整性约束被违背时能够及时地执行必要的操作，数据库工作者提出了触发器技术。触发器概述约束有其执行模式，每当约束的元素（比如属性，元组）发生变化时，就按其执行模式调用相应的约束。由于约束的实现设计到对相应事件的检验进行“触发”，因此，人们很自然地会想到，能否由数据库编程人员而不是由系统来选择出发事件。这种方法可为用户提供某些附加的选项，以便有针对性地出发数据库操作，而不是被动地防止出现约束的违例。为此，SQL3 的推荐标准包括“触发”。说到触发很容易联想到约束，但触发程序（实现触发机制的程序）要明确指定触发事件，并明确指定基于条件真假而要做的动作。如果说约束还有一定被动性的话，那么触发就完全是主动性元素。触发有时也称为事件-条件-动作规则或 ECA 规则。触发与约束在以下三个方面有所不同：（1）当数据库编程人员所指定的某个或某些事件发生时才对触发程序进行测试。允许的事件通常为对特定关系的插入、删除或修改。另一种允许的事件为事务结束。（2）不是直接阻止事件的发生，而是由处罚程序对条件进行测试。如果条件不满足则什么也不做，否则，为响应该事件就会进行与该触发相关的处理。（3）如果出发条件得到满足，就由 DBMS 执行与该触发相关的动作。于是，该动作可能阻止事件的发生或撤销时间（如删除插入的元组）。实际上，动作可能是数据库操作的任何序列，甚至可能是与触发事件毫不相干的操作。SQL3 的触发语句在时间、条件和动作部分给用户许多不同的选项。其主要特点如下： 动作可以在触发事件之前、之后执行，甚至可以不通过触发事件而执行； 动作可以引用在触发该动作的事件中插入、删除或修改的元组的旧值或新值； 修改事件可以指定特定的属性或属性集； 条件可以用 WHEN 子句来执行，而只有在对规则进行触发并且当触发事件发生时条件满足的情况下动作才会执行； 编程人员可以对规定执行的动作进行如下选择： 对每个更新的元组都执行一次； 对在一个数据库操作中发生变化的所有元组执行一次。 触发器组成触发器是存储在数据库里的过程，当数据库某事件发生时，这个过程就会被 DBMS 在后台自动运行。与过程或函数不同的是：触发器不接受参数，除了能完成声明型约束不能完成的数据完整性控制的功能外，触发器还可以做许多事，包括审计表中信息被修改时记录修改者的行为，自动为其他程序发信号等。一个触发器由 4 个部分组成： 触发器侦测的操作事件（如，删除记录等）； 操作事件的对象（如，列、表等） 触发时是否执行触发器执行体的先决条件（如，数据修改时新值不等于旧值等）； 触发器执行体（与自定义存储过程一样的业务逻辑处理）。触发器分类根据触发器侦测的操作事件和操作事件的对象不同，可将触发器分为以下类型： DML 触发器：由 DML 数据操作语句触发的触发器，是最常用的一种触发器； 系统触发器：由对数据库或模式对象的操作而触发的触发器，分数据库级和模式级两种类型； 替代触发器：由对视图对象进行数据更新操作而触发的触发器。DML 触发器DML 触发器是数据库系统传统意义上的触发器，一般由三类数据操作事件触发：数据插入（Insert）、数据修改（Update）、数据删除（Delete）。 语法： 对上述语法的说明： 举例：系统触发器系统触发器主要用于对数据库和模式对象的操作事件进行侦测，主要侦测的具体事例有： 数据库级：数据库的启动、关闭、登录、退出、服务器出错； 模式级：创建对象、修改对象、删除对象。下面从语法方面进行简单阐述和说明。 语法： 对语法的说明： 举例：替代触发器替代触发器主要用于侦测视图数据的操作事件。对于可修改数据的视图才有必要定义一个替代触发器。替代触发器只能再行级上触发，不能上升到语句级，只能被创建在视图上，不能加 BEFORE/AFTER 选项，在对视图进行 INSERT 或 UPDATE 操作时候，系统将自动检查替代触发器是否执行。 语法： 对语法的说明：除使用 instead of 和指定 view_name 外，其他说明与 DML 触发器意义一致。 举例：删除触发器触发程序举例触发程序可分为元组级（又称为行级）触发程序和语句级触发程序两类。两者的差别是： 形式上：前者有 FOR EACH ROW 子句，而后者没有。 执行上：对于产生多个触发事件（更新多个元组）的一个 SQL 更新语句，前者对每个元组都执行一次，而后者只对整个语句执行一次。 应用时：前者可直接引用旧元组或新元组，而后者只能引用旧元组的集合（删除的元组或修改的元组的旧版本）和新元组的集合（插入的元组或修改的元组的新版本）。下面是一个引用元组集的例子。其他实例：层次与网状数据库系统层次与网状数据库系统是最早出现的数据库系统，被称为第一代数据库系统，正逐渐被关系数据库系统取代，但目前在美国等一些国家里，由于历史的原因，这两类数据库系统的用户仍然很多。层次数据库系统层次数据系统是基于层次数据模型的数据库系统。下面简单介绍层次数据库的数据定义、数据操纵、存储结构等内容。层次数据模型中的数据结构层次数据模型具有两个主要的数据结构概念，即记录和父子联系。一个记录是一组数据域的集合。每个数据域可以存储一个数据值。具有相同结构的记录集合构成一个记录型，一个记录型具有一个名字。记录型的数据结构由一组命名的数据域或数据项定义。每个数据域具有一个数据类型，如整数、字符串等。M:N 联系的表示层次数据模型只能直接表示两个记录之间的 1:N 联系，在显示世界中，M:N（多对多）联系也是非常重要的联系。如果记录型 R 和 S 之间存在一个 M:N 父子联系型，则每个 R 型记录对应于多个 S 型记录，反之，每个 S 型记录也对应于多个 R 型记录。下面，介绍两种使用层次数据模型表示 M:N 联系的方法。数据操作完整性约束IMS 概述网状数据库系统网状数据模型是一种比层次数据模型更具普遍性的数据模型，取消了层次数据模型的树形数据结构的限制，允许没有父节点的节点存在，允许一个节点有多个父节点，允许两个节点之间有多重联系（称之为复合联系）。因此网状数据模型可以更直接地描述现实世界。层次数据模型是网状数据模型的一个特例。数据结构网状数据模型的数据结构是层次数据结构的扩充。在层次数据结构中，每个子记录有且仅有一个父记录。在网状数据结构中，一个子记录可以有任意数量的父记录，包括没有父记录的情况。网状数据模型具有两个基本数据结构：记录和系。一个记录是一组数据域的集合。每个数据域可以存储一个数据值。具有相同结构的记录集合构成一个记录型，一个记录型具有一个名字。记录型的数据结构由一组命名的数据域或数据项定义。每个数据域具有一个数据类型，如整数、字符串等。记录是记录型的实例。在网状模型中，记录型描述的是现实世界的实体，数据项描述实体的属性，每个记录型具有一个或一组数据项作为键，唯一地标识记录。关系和层次数据模型只允许简单数据项，网状数据模型支持两类复杂数据项，即向量和重复组，向量是一个记录中由多个相同类型的数据值构成的数据项。重复组是一个记录中由多种类型的多个数据值构成的一个数据项。上面的各种数据项称为实数据项，因为它们是实际存储在记录中的数据项。虚数据项是由实数据项定义或推导出的数据项。虚数据项不在记录中存储。例如，我们可以在 STUDENT 记录型上定义一个虚数据项 AGE，并写一个从这个记录型的数据项 BIRTHDAYE 计算 AGE 的过程。一个数据库应用通常具有大量的记录型。不同记录型的记录一般都相互关联。为了描述这些关联，网状数据模型提供了一种结构—-系。数据操作完整性约束三个特殊的系型网状数据模型具有三个特殊系型，即系统系型、多成员系型和递归系型。M:N 联系的表示数据库设计人们在总结信息资源开发、管理和服务的各种手段时，认为最有效的是数据库技术。什么是数据库设计呢？广义地讲，数据库设计是数据库及其应用系统的设计，即设计整个的数据库应用系统。狭义地讲，是设计数据库本身，即设计数据库的各级模式并建立数据库，这是数据库应用系统设计的一部分。这里重点讲狭义的数据库设计。数据库设计是指对于一个给定的应用环境，构造（设计）优化的数据库逻辑模式和物理结构，并据此建立数据库及其应用系统，使之能够有效地存储和管理数据，满足用户的应用需求，包括信息管理要求和数据操作要求。其中信息管理要求是指在数据库中应该存储和管理哪些对象；数据操作要求是指对数据对象需要进行哪些操作，如查询、曾、删、该、统计等操作。概述设计与使用数据库刺痛的过程是把现实世界的数据经过人为的加工和计算机的处理，又为现实世界提供信息的过程。在给定的 DBMS、操作系统和硬件环境下，表达用户的需求，并将其装换为有效的数据库结构，构成较好的数据库模式，这个过程称为数据库设计。要设计一个好的数据库必须用系统的观点分析和处理问题。数据库及其应用系统开发的全过程可分为两大阶段：数据库系统的分析与设计阶段；数据库系统的实施、运行与维护阶段。在数据库设计中面临的主要困难和问题有： 同时具备数据库知识与应用业务知识的人很少。懂计算机与数据库的人一般都缺乏应用业务知识和实际经验，而熟悉应用业务的人又往往不懂计算机和数据库。 项目初期往往不能确定应用业务的数据库系统的目标。 缺乏完善的设计工具和设计方法。 需求的不确定性。用户总是在系统的开发过程中不断提出新的要求，甚至在数据库建立之后还会要求修改数据库结构或增加新的应用。 应用业务系统千差万别，很难找到一种适合所有业务的工具和方法，这就增加了研究数据库的自动生成工具的难度。因此，研制适合一切应用业务的全自动数据库生成工具几乎是不可能的。完善的数据库系统应具备如下特点： 功能强大； 能准确地表示业务数据； 使用方便，易于维护； 便于检索和修改数据； 在合理的时间内响应最终用户的操作； 为以后改进数据库结构留下空间； 维护数据库的工作较少； 具备有效的安全机制来确保数据安全； 冗余数据最少或不存在； 便于进行数据的备份和恢复； 数据库结构对最终用户透明。数据库设计问题数据库设计所要解决的问题是：对于一个给定的应用领域，设计优化的数据库逻辑和物理结构，使之满足用户的信息管理要求和数据操作要求，有效地支持各种应用系统的开发和运行。数据库设计的目标是为用户和各种应用系统提供一个高效率的运行环境。效率包括两个方面：一是数据库的存取效率，二是存储空间的利用率。数据库设计可以视为以下的优化问题：约束条件： 计算机软硬件环境； 数据库管理系统的能力； 用户的操作要求与信息要求； 完整性和安全性约束。 目标函数： 数据设计问题：数据库设计的任务数据库的生命周期可分为两个重要的极端：一是数据库的设计阶段，二是数据库的实施和运行阶段。其中数据库的设计阶段是数据库整个生命周期中工作量比较大的一个阶段，其质量对整个数据库系统的影响很大。数据库设计的主要任务是：根据一个单位的信息需求、处理需求和数据库的支撑环境（包括 DBMS，操作系统和硬件），设计出数据模式（包括外模式、逻辑（概念）模式和内模式）以及典型的应用程序。其中信息需求表示一个单位所需要的数据及其结构。处理需求表示一个单位需要经常进行的数据处理，例如工资计算、成绩统计等。前者表达了对数据库的内容及结构的要求，也就是静态要求；后者表达了基于数据库的数据处理要求，也就是动态要求。DBMS、操作系统和硬件是建立数据库的软、硬件基础，也是其制约因素。信息需求主要是定义所设计的数据库将要用到的所有信息，描述实体、属性、联系的性质。描述数据之间的联系。处理要求则定义锁设计的数据库将要进行的数据处理，描述操作的优先次序、操作执行的频率和场合，描述操作与数据之间的联系。当然，信息需求和处理需求的区分不是绝对的，只不过侧重点不同而已。信息需求要反映处理的需求，处理需求自然包括其所需要的数据。数据库设计方法：数据库设计有两种不同的方法：瞄向数据的设计方法、面向过程的设计方法。 面向数据的设计方法：面向数据的设计方法以信息需求为主，兼顾处理需求。用这种方法设计的数据库，可以比较好地反映数据的内在联系，不但可以满足当前应用的需要，还可以满足潜在的应用的需求。在实际应用中，数据库一般由许多用户共享，还可能不断有新的用户加入，除了常规的处理要求外，还有许多即兴的访问。对于这类数据库，最好采用面向数据的设计方法，使数据库比较合理地模拟一个单位。一个单位的数据重视相对稳定的，而处理测试则是相对变动的。为了设计一个相对稳定的数据库，一般采用面向数据的设计方法。 面向过程的设计方法：面向过程的设计方法以处理需求为主，兼顾信息需求。用此方法设计的数据库，可能在使用的初始阶段比较好地满足应用的需要，获得好的性能，但随着应用的发展和变化，往往会导致数据库的较大的表动或者不得不重新设计。面向过程的设计方法主要用于处理要求比较明确、固定的应用系统，例如酒店管理。数据库的设计成果：数据库设计的成果有两个：一是数据模式。二是以数据库为基础的典型应用程序。应用程序是随着应用而不断发展的，在有些数据库系统中（如情报检索），实现很难编出所需的全部应用程序或事务。因此，数据库设计的最基本的成果是数据模式。不过，数据模式的设计必须适应数据处理的要求，以保证大多数常用的数据处理能够方便、快速地进行。数据库设计特点数据库设计的很多阶段都可以和软件工程的各阶段对应起来，软件工程的某些方法和工具同样也适合于数据库工程，但数据库设计还有很多自己的特点。 从数据结构即数据模型开始，并以数据模型为核心展开。这是数据库设计的一个主要特点。 静态结构设计与动态行为设计分离：静态结构设计是指数据库的模式结构设计，包括概念结构、逻辑结构和物理结构的设计。动态行为设计是指应用程序设计，包括功能组织、流程控制等方面的设计。传统的软件工程往往注重处理过程的设计，不太注重数据结构的设计，在结构程序设计中只要可能就尽量推迟数据结构的设计，而数据库设计正好与之相反，需要把主要精力放在数据结构的设计上，如数据库的表结构、视图等。 试探性：数据库设计比较复杂，又缺少完善的设计模型和统一的过程，设计的过程往往是试探性的过程，因此设计的结果往往不是唯一的。有时多种方案并存，供设计者选择，而且这种选择并不是完全客观的，有时多少取决于用户的偏爱和观点。 反复性：由于数据库设计是一种试探性的过程，这就是决定了数据库的设计是一个反复推敲和修改的过程，而不可能“一气呵成”。 多步性：传统的数据库设计采用直观设计法或单步设计法，它由设计者通过对用户的调查访问，确认需求，熟悉用户应用问题的语义，结合结构限制于 DBMS 功能，凭设计人员的经验进行分析、选择、综合与抽象之后，建立数据模型，并用 DDL 写出模式。由于这种设计方法要求设计人员有比较丰富的经验和熟练的技巧，不易为一般人所掌握，且因缺乏工程规范支持和科学根据，现已抛弃不用。新的数据库设计是分步（阶段）进行的，前一阶段的设计结果可作为后一阶段设计的依据，后一阶段也可向前一阶段反馈其要求，反复修改，逐步完善。数据库建设的基本规律：“三分技术，七分管理，十二分基础数据”是数据库设计的特点之一。在数据建设中不仅涉及技术，还涉及管理。要建设好一个数据库应用系统，开发技术固然重要，但是相比之下则管理更加重要。这里的管理不仅仅包括数据库建设作为一个大型的工程项目本身的项目管理，而且包括该企业（即应用部门）的业务管理。在数据库建设的长期实践中深刻认识到一个企业数据库建设的过程是企业管理模式的改革和提高的过程。只有把企业管理创新做好，才能实现技术创新，才能建设好一个数据库应用系统。十二分基础数据则强调了数据的收集、整理、组织和不断更新是数据库建设中的重要环节。人们往往忽视基础数据在数据库建设中的地位和作用。基础数据的收集、入库是数据库建立初期工作量最大、最繁琐、最细致的工作。在以后数据库运行过程中更需要不断地把新的数据加到数据库中，使数据库称为一个“活库”，否则就成了“死库”。数据库一旦成了“死库”，系统也就失去了应用价值，原来的投掷也就失败了。结构（数据）设计和行为（处理）设计相结合：数据库设计应该和应用系统设计相结合。也就是说，整个设计过程中把数据库结构设计和数据的处理设计密切结合起来。但是早期的数据库应用系统开发过程中，常常把数据库设计和应用系统的设计分离开来，如下图。传统的软件工程忽视对应用中数据语义的分析和抽象。例如结构化设计和逐步求精的方法着重于处理过程的特性，只要有可能就尽量推迟数据结构设计的决策。这种方法对于数据库应用系统的设计显然是不妥的。早期的数据库设计致力于数据模型和数据库建模方法的研究，着重结构特性的设计而忽视了行为的设计对结构设计的影响，这种方法也是不妥的。数据库设计方法大型数据库设计是涉及多学科的综合性技术，又是一项庞大的工程项目。它要求从事数据库设计的专业人员具备多方面的技术和知识。主要包括： 计算机的基础知识； 软件工程的原理和方法； 程序设计的方法和技巧； 数据库的基本知识； 数据库设计技术； 应用领域的知识。早期数据库设计主要采用手工与经验相结合的方法，那时数据库设计是一种技艺。谓词，提出了各种通用的数据库设计方法。能够有效地指导数据库设计，使数据库设计更加合理的原则称为数据库设计方法学。目前已有的数据库设计方法可分为四类： 直观设计法：直观设计法又称单步逻辑设计法，它依赖于设计者的知识、经验和技巧，缺乏工程规范的支持和科学依据，设计质量也不稳定。为此，数据库专家在美国新奥尔良市专门讨论了数据库设计问题，提出了数据库设计规范，把数据库设计分为：需求分析阶段、概念结构设计阶段、逻辑结构设计阶段和物理结构设计阶段四个阶段。目前，常用的规范设计方法大多起源于新奥尔良方法。 规范设计法； 计算机辅助设计法； 自动化设计法。 基于 3NF 的数据库设计方法其基本思想是在需求分析的基础上，识别并确认数据库模式中的全部属性和属性间的依赖，将它们组织成一个单一的关系模式，然后再分析模式中不符合 3NF 的约束条件，用投影和连接的办法将其分解，使其达到 3NF 条件。其具体涉及步骤分为五个阶段，如下图所示：（1）设计企业模式，使用上述得到的 3NF 关系模式画出企业模式。具体包括： 分析应用环境，并设定环境中所使用的种种资料。 确定每一种报表各自所包含的数据元素。 确定数据元素之间的关系，如确定主键和一般的数据元素。 对每一组或若干组数据元素推导出 3NF 的关系模式。 在 3NF 关系模式的基础上画出数据库的企业模式。（2）设计数据库逻辑模式。 根据上一步得到的企业模式选定数据模型，从而得到试用于某个 DBMS 的逻辑模式。 根据逻辑模式导出各种报表与事务处理所使用的外模式。（3）设计数据库物理模式（存储模式）。根据数据库的逻辑模式和给定的计算机系统设计物理模式。（4）评价物理模式。 对物理模式估算空间利用情况，并推算输入/输出的概率。 必要时根据物理模式调整各种报表与实务处理的外模式。 对外模式进行存取时间的估算。（5）数据库实现。 LRA 方法数据库设计的 LRA 方法即逻辑记录存取法。它从用户的信息要求和处理要求出发，分三个阶段完成数据库的设计。 （1）需求分析：向现有和潜在的用户了解和收集有关的信息内容和处理要求，并将它们文本化。 （2）逻辑设计：逻辑设计又分信息结构设计（ISD）和信息结构改进（ISR）两步。前者主要是分析各种用户的信息要求，确定实体、属性及实体之间的联系，并综合成一个厨师的数据库信息结构。信息结构改进的主要任务是根据设计的厨师信息结构、处理要求和 DBMS 的特点，设计 DBMS 能处理的模式。它分三步完成： 首先定义局部信息结构，并将局部信息结构合并成全局信息结构； 然后分别将全局信息结构和局部信息结构转换为 DBMS 所能支持的逻辑数据库结构和局部逻辑数据库结构； 最后根据数据传送量、应用的处理拼读、逻辑记录存取数等因素，改进逻辑数据库结构。 （3）物理涉及：LRA 方法的物理涉及与其他方法的物理涉及类似。LRA 方法的特点是：提供一种定量估算的方法，使得能够对数据库逻辑结构的性能进行分析，在可供选择的若干个结构中选择一个处理效率较高的结构，或者据此对现有的逻辑结构进行改进。谓词，LRA 使用逻辑记录存取数表示在一个应用程序执行过程中对一个记录类型所要查找的记录的个数，记做 LRA 数。根据所有应用程序的 LRA 数及它们在单位时间内要执行的次数，就可以知道哪些应用程序可能要求的 I/O 次数最多，哪些应用程序在性能上起着主导地位，从而决定如何改进逻辑结构以提高处理效率。 基于实体联系（E-R）的数据库设计方法E-R 方法主要用于逻辑设计。其基本思想是在需求分析的基础上，用 E-R 图构造一个纯粹反映现实世界实体之间内在联系的企业模式，然后再将此企业模式转换成选定的 DBMS 上的概念模式。E-R 方法简单易用，又克服了单步逻辑设计方法的一些缺点。因此成为比较流行的方法之一。但由于它主要用于逻辑设计，故 E-R 方法往往成为其他设计方法的一种工具。 基于视图概念的数据库设计方法此方法先从分析各个应用的数据着手，为每个应用建立各自的视图，然后再把这些视图汇总起来合并成整个数据库的概念模式。合并时必须注意解决下列问题： 消除命名冲突； 消除冗余的实体和联系； 进行模式重构。在消除了命名冲突和冗余后，需要对整个汇总模式进行调整使其满足全部完整性约束条件。 面向对象的关系数据库设计方法面向对象的数据库设计（即数据模式）思想与面向对象数据库管理系统（OODBMS）理论不能混为一谈。前者是数据库用户定义数据库模式的思路，而后者是数据库管理程序的思路。用户使用面向对象方法学可以定义任何一种 DBMS 数据库，即网络型、层次型、关系型等。对象的数据库设计从对象模型触发，属于实体主导型设计。数据库设计（模式）是否支持应用系统的对象模型是判断是否是面向对象数据库系统的基本出发点。应用系统对象模型向数据库模式的映射是面向对象数据库设计的核心和关键，其实质就是向数据库表的变换过程。有关变换规则简单归纳如下：（1）一个对象类可以映射为一个以上的库表，当类间有一对多关系时，一个表也可以对应多个类。（2）关系（一对一、一对多、多对多等）的映射可能有多种情况，但一般映射为一个表，也可以在对象类表间定义相应的外键。对于条件关系的映射，一个表至少应有三个属性。（3）单一继承的泛化关系可以对超类、子类分别映射表，也可以不定义父类表而让子类表拥有父类属性，反之，也可以不定义子类表而让父类拥有全部子类属性。（4）多重继承的超类和子类分别映射表，对多次多重继承的泛化关系也映射一个表。（5）对映射后的库表进行冗余控制调整，使其达到合理的关系范式。面向对象关系数据库设计效果可归纳为： 数据库结构清晰，便于实现 OOP； 数据库对象具有独立性，便于维护； 需求变更时程序与数据库重用率高，修改少。. 计算机辅助数据库设计方法计算机辅助数据库设计是数据库设计趋向自动化的一个重要步骤，它的基本思想并不是完全由机器代替人，而是提供一个交互式过程，人机结合，相互渗透，帮助设计者更快更好地进行设计工作。在数据库设计过程中，目前还没有全自动设计方法，只能使用计算机进行局部辅助设计，而且一般立足于不同的设计规程和模型化工具，如关系数据库模式的辅助设计工具的应用。许多自动化工具，如 Oracle Designer，已经具有如下一些稳定的特性： 确定业务和用户需求的功能； 对业务处理建模的功能； 对数据流建模的功能； 对实体机器相互关系建模的功能； 生成创建数据库对象的 DDL 语句的功能； 对数据库设计周期的支持； 业务处理二次工程； 数据库和应用软件的版本控制； 文档和用户反馈信息报告的生成。 敏捷数据库设计方法今年来，一种新的软件开发方法学—敏捷方法学呗逐步应用于数据库设计。它提出了在可控制方式下的进化设计。迭代式开发是它的一个重要特点，即整个项目生命周期中运行多个完整的软件生命周期循环。敏捷过程在每次迭代中都会度过一个完整的生命周期且迭代时间较短。敏捷方法的一些原则包括： 拥有不同技能和背景的人能够紧密合作； 每个项目组成员都有自己的数据库实例； 开发人员的数据库经常集成到共享主数据库； 数据库包含计划和测试数据； 所有的变化要求数据库重构； 每个数据库重构都可以通过编写 SQL DDL（对于计划变化）和 DML（对于数据迁移）来自动完成； 自动地更新所有开发人员的数据库； 清晰地分离所有的数据库获取代码等。敏捷数据库设计方法保持多个数据库在一个系统中，而且不需要专职的 DBA。可以通过开发一些简单工具帮助解决数据库进化过程中大量的重复性工作。目前，敏捷方法在数据库设计中的应用尚有一些没有解决的问题，如集成数据库和 24X7 小时实施等，还有待进行进一步的研究工作。此外，其他的设计方法还有属性分析法、实体分析法及基于抽象语义规范的设计法等。在实际的设计过程中，各种方法可以结合起来使用，例如，在基于视图概念的设计方法中可用 E-R 方法来表示各个视图。数据库设计的基本步骤按照规范设计的方法，考虑数据库及其应用系统开发全过程，将数据库设计分为以下 6 个阶段（如图）： 需求分析； 概念结构设计； 逻辑结构设计； 物理结构设计； 数据库实施； 数据库运行和维护。在数据库设计过程中，需求分析和概念设计可以独立于任何数据库管理系统进行。逻辑设计和物理设计与选用的 DBMS 密切相关。数据库设计开始之前，首先必须选定参加设计的人员，包括系统分析人员、数据库设计人员、应用开发人员、数据库管理员和用户代表。系统分析和数据库设计人员是数据库设计的核心人员，他们将自始至终参与数据库设计，他们的水平决定了数据库系统的质量。用户和数据管理员在数据库设计中举足轻重的，他们主要参加需求分析和数据库的运行与维护，他们的积极参与（不仅仅是配合）不但能加速数据库设计，而且也是决定数据库设计质量的重要因素。应用开发人员（包括程序员和操作员）分别负责编制程序和准备软硬件环境，他们在系统实施阶段参与进来。如果所设计的数据库应用系统比较复杂，还应该考虑是否需要使用数据库设计工具以及选用何种工具，以提高数据库设计质量并减少设计工作量。分步设计法：分步设计法遵循自顶向下、逐步求精的原则，将数据库设计过程分解为若干相互独立又相互依存的阶段，每一阶段采用不同的技术与工具，解决不同的问题，从而将问题局部化，减少了局部问题对整体设计的影响。目前，此方法已在数据库设计中得到了广泛应用并获得了较好的效果。在分步设计法中，通常将数据库的设计分为需求分析、概念结构设计、逻辑结构设计和数据库物理设计四个阶段。在数据库设计的整个过程中，需求分析和概念设计可以独立于任何的数据库管理系统（DBMS），而逻辑设计和物理设计则与具体的数据库管理系统密切相关。 需求分析阶段进行数据库设计首先必须准确了解与分析用户需求（包括数据与处理）。需求分析师整个设计过程的基础，是最困难、最耗费时间的异步。作为“地基”的需求分析是否做得充分与准确，决定了在其上构建数据库大厦的速度与质量。需求分析做得不好，甚至会导致整个数据库设计返工重做。需求分析说明书：需求分析是指收集和分析用户对系统的信息需求和处理需求，得到设计系统所必需的需求信息，建立系统说明文档。其目标通过调查研究，了解用户的数据要求和处理要求，并按一定格式整理形成需求说明书。需求说明书是需求分析阶段的成果，也是今后的设计的依据。它包括数据库锁涉及的数据、数据的热证、使用频率和数据量的估计，如数据名、属性及其类型、主关键字属性、保密要求、完整性约束条件、更改要求、使用频率、数据量估计等。这些关于数据的数据称为元数据。在设计大型数据库时，这些数据通常由数据字典来管理。用数据字典管理元数据有利于避免数据的重复或重名以保持数据的一致性及提供各种统计数据，因而有利于提高数据库设计的质量，同时可以减轻设计者的负担。需求分析的目标：需求分析的目标是给出应用领域中数据项、数据项之间的关系和数据操作任务的详细定义，为数据库的概念设计、逻辑设计和物理设计奠定基础，为优化数据库的逻辑结构和物理结构提供可靠依据。设计人员应与用户密切合作，用户则应积极参与，从而使设计人员对用户需求全面、准确的理解。 概念结构设计阶段概念结构设计是数据库设计的第二阶段，是整个数据库设计的关键，它通过对用户需求进行综合、归纳与抽象，形成一个独立于具体 DBMS 的概念模型。概念结构设计的目标：概念结构设计目标是对需求说明书提供的所有数据和处理哟求进行抽象与综合处理，按一定的方法构造反映用户环境的数据及其相互联系的概念模型，即用户的数据模型或企业的数据模型。概念数据模型：这种概念数据模型与 DBMS 无关，是面向现实世界的、极易为用户所理解的数据模型。为保证所设计的概念数据模型的正确，完全地反映用户的数据及其相互关系，便于进行所要求的各种处理，在本阶段设计中刻吸收用户参与和评议设计，从而有利于保证数据库的设计与用户的需求相吻合。该模型是准确描述应用领域的信息模式，支持用户的各种应用，这样既容易转换为数据库逻辑模式，又容易为用户理解。数据库概念模式是独立于任何数据库管理系统，面向现实世界的数据模型，不能直接用于数据库的实现。但是，这种模式易于为用户理解，而且涉及人员可以致力于模拟现实世界，而不必过早地纠缠于 DBMS 锁规定的各种细节。在进行概念结构设计时，可先设计各个应用的视图，即各个应用所看到的数据及其结构，然后再进行视图集成，以形成一个单一的概念数据模型。这样形成的初步数据模型还要经过数据库设计者和用户的审查与修改，最后形成所需的概念数据模型。 逻辑结构设计阶段在逻辑设计阶段，将第二阶段锁得到的数据库概念模式，转换成以 DBMS 的逻辑数据模型表示的```逻辑模式``，同时将概念设计阶段得到的应用视图转换成外部模式`即特定 DBMS 下的应用视图。数据库逻辑设计的目标是：进一步落实需求说明，并满足用户的完整性和安全性要求，能在逻辑级上高效率地支持各种数据库事务的运行。数据库的逻辑设计不仅涉及数据模型的转换问题，而且涉及进一步深入解决数据模式设计中一些技术问题，例如数据模式的规范化、满足 DBMS 各种限制等。数据库逻辑设计的结果以数据定义语言（DDL）表示。由于 SQL 语言是综合性语言，DDL 就相当于 SQL 中的定义关系模式部分。 物理设计阶段物理设计是为逻辑数据模型选取一个最适合应用环境的物理结构（包括存储结构和存取方法）。物理设计阶段的任务是把逻辑设计阶段得到的满足用户需求的已确定的逻辑模型在物理上加以实现，其主要的内容是根据 DBMS 提供的各种手段，设计数据的存储形式和存取路径，如文件结构、索引的设计等，即设计数据库的内模式或存储模式。数据库的内模式对数据库的性能影响很大，应根据处理需求及 DBMS、操作系统和硬件的性能进行精心设计。实际上，数据库设计的基本过程与任何复杂系统开发一样，在每一阶段设计基本完成后，都要进行认真的检查，看看是否满足应用需求，是否符合前面已执行步骤的要求和满足后续步骤的需要，并分析设计结果的合理性。在每一步设计中，都可能发现前面步骤的遗漏或处理的不当之处，此时，往往需要返回去重新处理并修改设计和有关文档。所以，数据库设计过程通常是一个反复修改、反复设计的迭代过程。 数据库实施阶段在数据库实施阶段，设计人员运用 DBMS 提供的数据库语言（如 SQL）及其宿主语言，根据逻辑设计和物理设计的结果建立数据库，编制与调试应用程序，组织数据入库，并进行试运行。 数据库运行和维护阶段数据库应用系统经过试运行后即可投入正式运行。在数据库系统运行过程中必须不断地对其进行评价、调整与修改。小结：设计一个完善的数据库应用系统是不可能一蹴而就的，它往往是上述 6 个阶段的不断反复。需要指出的是，这个设计步骤既是数据库设计的过程，也包括了数据库应用系统的设计过程。在设计过程中把数据库的设计和对数据库中数据处理的设计紧密结合起来。将这两个方面的需求分析、抽象、设计、实现在各个阶段同时进行，相互参照，相互补充，以完善两方面的设计。事实上，如果不了解应用环境对数据的处理要求，或没有考虑如何去实现这些处理要求，是不可能设计一个良好的数据库结构的。按照这个原则，设计过程各个阶段的设计描述，可用下图概括地给出。图中的有关处理特性的设计描述中，其设计原理、采用的设计方法、工具等在软件工程和信息系统设计的课程中有详细介绍，这里不再讨论。数据库设计过程中的各级模式按照上一节的设计过程，数据库设计的不同阶段形成数据库的各级模式，如下图所示。 需求分析阶段，综合各个用户的应用需求； 在概念设计阶段形成独立于机器特点，独立于各个 DBMS 产品的概念模式，可以使用 E-R 图； 在逻辑设计阶段将 E-R 图转换成具体的数据库产品支持的数据模型，如关系模型，形成数据库逻辑模式；然后根据用户处理的要求、安全性的考虑，在基本表的基础上再建立必要的视图，形成数据的外模式； 在物理设计阶段，根据 DBMS 特点和处理的需要，进行物理存储安排，建立索引，形成数据库内模式。需求分析需求分析是数据库设计过程的第一步，是整个数据库设计的依据和基础。需求分析做得不好，就会导致整个数据库设计重新返工。需求分析的任务需求分析的任务是通过详细调查现实世界要处理的对象（组织、部门、企业等），充分了解原系统（手工系统或计算机系统）工作概况，明确用户的各种需求，然后在此基础上确定新系统的功能。新系统必须充分考虑今后可能的扩充和改变，不能仅仅按当前用用需求来设计数据库。需求分析人员既要对数据库技术有一定的了解，又要对单位的情况比较熟悉，一般由数据库人员和本单位的有关工作人员合作进行。需求分析的结果整理成需求设计说明书，这是数据库技术人员和应用单位的工作人员取得共识的基础，必须得到单位有关管理人员的确认。目前，需求分析说明书一般用自然的语言表达，是非形式化的。在需求分析说明书中，已经确认了数据库中应包含的数据及其有关的特性，例如数据名、属性及其类型、键码、使用频率、更新要求、数据量估计、保密要求、共享范围以及语义约束等。这些数据是关于数据的数据，即元数据。在设计大型数据库时，用人工管理这些元数据是困难的，也不便于查询和使用。一般用专用软件包或 DBMS 来管理这些数据，称为数据字典。数据字典不同于数据目录： 数据目录主要是面向系统的，它是 DBMS 的一个组成部分； 数据字典是面向数据库实现人员和用户的，它是用 DBMS 或专用软件实现的一个应用系统。用数据字典管理元数据，不但可以减少设计者的负担，也有利于保持数据的一致性（例如避免重复或重名）并可提供各种统计数据，因而可以提高数据库设计的质量。为了便于在后续阶段用计算机处理需求说明，需求说明有时转换成形式化和半形式化的描述形式，例如需求描述语言、框图、信息流图等。但是数据库的需求是多方面的，数据的语义是丰富多彩的，要完全形式化描述数据库设计的需求说明，至少在目前还难以做到，还得辅以非形式化的说明。确定用户的最终需求是一件很困难的事，这是因为： 一方面用户缺少计算机知识，开始时无法确定计算机究竟能为自己做什么、不能做什么，因此往往不能准确地表达自己的需求，所提出的需求往往不断地变化。 另一方面，设计人员缺少用户的专业知识，不易理解用户的真正需求，甚至误解用户的需求。因此设计人员必须不断深入地与用户交流，才能逐步确定用户的实际需求。一般需求分析分为应用领域的调查、定义数据库支持的信息与应用、定义数据库操作任务、定义数据字典、预测未来的改变等几步。需求分析几个步骤： 应用领域的调查应用领域的调查分为两个阶段： 对应用领域的组织结构、业务流程和数据流程进行调查，对现行系统的功能和所需信息有一个明确的认识； 在第一阶段的基础上进行应用领域的分析，抽象应用领域的逻辑模型，最后把逻辑模型用数据流图来表示。数据流图可以表示现行系统的信息流动和加工处理等详细情况，是现行系统的一种逻辑抽象表示，它独立于系统的实现。下表是数据流图使用的符号及其说明：调查的重点是“数据”和“处理”，通过调查、收集与分析，或得用户对数据库如下要求： 信息要求：信息要求是指用户需要从数据库中获得信息的内容与性质。由信息要求可以导出数据要求，即在数据库中需要存储哪些数据。 处理要求：处理要求是指用户要完成什么处理功能，对处理的响应时间有什么要求，处理方式是批处理还是联机处理。 安全性与完整性要求。 定义信息与应用定义数据库系统支持的信息的目的是确定最终数据库需要存储哪些信息。信息定义应用领域的逻辑模型为基础。信息定义分为以下两步：（1）考察数据流图中每个存储信息，确定其是否应该而且可能由数据库存储，如果应该而且可能，则列入数据库需要存储的信息范围。（2）对于上面产生的每个需要由数据库存储的信息，进行严格定义，内容包括：信息名、内容定义、产生该信息的应用和引用该信息的应用。信息定义集合可用表 7.2(a) 的形式表示。例如图 7.3 中的“统计结果”需要由数据库存储，则其信息定义集合表示为表 7.2（b）。定义数据库系统支持的应用的目的是确定最终的数据库支持哪些应用系统。由应用领域调查所产生的逻辑模型是定义数据库系统支持的应用的基础。利用这个逻辑模型，按照下列步骤来完成应用的定义：（1）考察数据流图中的每个数据处理应用，确定正在设计的数据库是否应该而且可能支持这个应用。如果应该而且可能支持，即把这个功能列入数据库系统支持的应用范围。（2）对于上面产生的每个数据库系统应该支持的应用，进行严格的定义，内容包括应用名、处理功能、输入信息和输出信息。数据库应用定义集合可以用表 7.3（a）的形式表示。例如图 7.3 中的“统计处理”应用，可以用表 7.3(b) 来表示。 定义操作任务数据库操作任务对应于最终数据库系统的事务。一个应用包括一个或多个数据库操作任务。每个数据库操作任务可属于多个应用。数据库操作任务的定义是对应用定义集合中每个应用逐步求精的过程。在逐步求精的过程中，划分出数据库操作任务，完成数据库操作任务的定义。划分数据库操作任务的规则如下： 每个数据库操作任务必须是某个应用的组成部分； 每个数据库操作任务必须是一个独立的计算机执行单位，具有相对独立的功能； 每个数据库操作任务内的所有数据库操作必须具有原子性，即当该任务成功地运行结束时，所有操作对数据库的影响必须同时存在；当任务失败时，所有操作对数据库的影响必须全部清除。 每个数据库操作任务必须具有明确的输入和输出数据项集合定义，每个数据项必须是详细说明的原子数据项。根据上述规则，我们可以对应用定义结合中的每个应用进行逐步求精，得到一个数据库操作任务集合。然后，我们对每个操作任务进行定义，定义的内容如下：然后，用图表的方式来表示每个数据库操纵任务的定义，这种图表称为数据库输入处理输出图，简称为 DBIPO 图。 定义数据项数据项的定义是数据库设计的最基本而且最重要的工作。数据项定义以数据库操作任务定义为基础，详细过程如下： 从 DBIPO 图中提取出所有原子数据项； 把有联系的数据项组合起来形成数据组； 以数据组为单位，写出数据项的如下定义： 语义定义：名字、实际意义等； 完整性约束定义：数据类型、数据长度、小数位数、值约束、空值约束以及其他比较复杂的完整性约束等。 根据用户和实际领域的信息模型需要补充其他数据项及其定义； 形成数据定义字典，包括上面数据项定义的所有内容。 预测未来的改变预测现行系统的未来改变是为了使数据库具有较高的适应性。现行系统的未来改变信息是其他数据库设计阶段的参考信息。使用这些信息，我们可以始终考虑如何使最终数据库尽量适应未来变化，减少将来为适应改变而引起的数据库修改或重新设计。现行系统未来改变的预测需要与用户进行讨论，讨论的内容一般包括以下几个方面： 应用领域中已有的，但数据库系统目前尚未支持的应用； 应用领域中各种应用功能的可能扩充、减少和改变； 应用领域的上述改变对数据库支持的信息和应用范围、数据项定义、数据项之间的联系和数据操作任务的影响。然后，根据上面的讨论的结果形成现行系统未来改变预测的说明书。实体联系（ER）模型实体联系模型简称为ER 模型。实体是 ER 模型的基本对象。实体和属性实体是 ER 模型的基本对象。实体是现实世界中各种事物的抽象。实体是可以物理存在的事物，也可以是抽象的概念。每个实体都有一组特征或性质，称为实体的属性。实体属性的一组特定值确定了一个特定的实体。实体的属性值是数据库存储的主要数据。某些属性可以划分为多个具有独立意义的子属性。例如，地址属性可以划分为邮政编码、省份等子属性，这类属性称为复合属性。复合属性具有层次结构，如下图：复合属性的用途： 准确模拟现实世界的符合信息结构； 当用户既需要把符合属性作为一个整体使用也需要单独使用各子属性时，属性的符合结构十分重要。多数实体属性多数单值属性，即对于同一实体只能取一个值，如人的年龄。在某些情况下，实体的一些属性可能取多个值，这样的属性称为多值属性，例如有的人具有多个学位。实体属性之间可能具有某种关系，如人的年龄和生日属性具有相互依赖关系。从当前日期和生日属性的值可以确定年龄属性的值，即年龄属性的值可以由其他属性导出，这样的属性称为导出属性。导出属性的值不仅可以从另外的属性导出，也可以从有关的其他实体中导出，比如，一个公司实体的雇员数属性的值可以通过累积该公司所有雇员数得到。实体的有些属性可能没有适当值可设置，这些属性通常被设置一个称为空值的特征值。实体型、键属性和属性的值域 实体型一个数据库通常存储很多类似的实体，例如大学中老师很多，属性是类似的，但具体到每个老师的属性值大多是不同的。这些类似的实体抽象为一个实体型。实体型是一个具有相同属性的实体集合，由一个实体型和一组属性来定义。实体型的定义称为实体模式，描述了一组实体的公共信息结构。实体型所表示的实体集合中的任一实体称为该实体型的实例，简称实体。在任意时刻，一个实体型的所有实体的集合称为该实体型的外延。同一个实体型的不同实体是现实世界中不同的对象。 键在 ER 模型中每个实体型具有一个由一个或多个属性组成的键，用来区别不同的实体。对于同一个实体型的不同实体，键的值必须相异。比如，大学的名字属性是键。由一个属性构成的键称为简单键。由多个属性构成的键称为复合键。键是实体型的一个重要完整性约束，规定了不同的实体在键上不能取相同的值。一个实体型可以具有多个键。实体型的每个简单属性都具有一个值域，说明这个属性的可能取值范围。数据库实例实体间的联系一个数据库通常都包含很多实体型。不同实体型的实体之间可能具有某种联系，这种联系称为实体间的联系。例如，在大学数据库中，一个教研室必属于一个系，一个学生必属于一个系等。 联系型和联系实例 联系型的结构约束联系型通常都具有结构约束。结构约束分为两类：实体对应约束和实体关联约束。一个联系型的实体对应约束规定了该联系型锁关联的实体间的对应关系。实体对应约束包括三种：一对一约束、一对多约束、多对多约束。实体对应约束：实体关联约束： 联系型的属性弱实体实际领域中经常存在一些实体型，没有自己的键盘，这样的实体型称为弱实体想。弱实体型的实体称为弱实体。弱实体型的不同实体的属性值可能完全相同，难以区别。为了区别弱实体，弱实体型需要与一般实体型相关联。设联系型 R 关联弱实体型 A 和一般实体型 B。弱实体型 A 的不同实体可以通过与 B 的有关实体相结合来加以区别。B 称为实体型 A 的识别实体型。R 称为弱实体型 A 的识别联系。识别联系型对于弱实体型必须具有全域关联约束。一个弱实体型可以具有多个识别实体型和多个识别联系。弱实体型必须具有一个或多个属性，使得这些属性可以与识别实体型的键相结合形成相应弱实体型的键，这样的弱实体属性称为弱实体型的部分键。给定一个弱实体型，我们可以使用它的识别实体型的键和它的部分键识别不同的弱实体。例如，在上边的例子中，孩子名是弱实体型孩子的部分键。实体联系图（ER 图）扩展的实体联系模型扩展的实体联系模型是 ER 模型的扩充，简称 EER 模型。EER 模型包括了 ER 模型的所有概念。此外，它还包括子类、超类、演绎、归纳、范畴、属性层次等概念。子类、超类、演绎和归纳 子类和超类 演绎 归纳演绎和归纳的性质由属性谓词定义的子类：演绎和归纳的约束条件：多层演绎和共享子类：范畴与范畴化EER 图概念数据库设计概念数据库设计又称为概念结构设计，其任务包括两个方面：概念数据库模式设计和事务设计。 概念数据库模式设计任务：概念数据库模式设计的任务是以需求分析阶段所识别的数据项和应用领域的未来改变信息位基础，使用高级数据模型建立概念数据库模式。 事务设计的任务：事务设计的任务是考察需求分析阶段提出的数据库操作任务，形成数据库事务的高级说明。概念数据库模式设计概述概念数据库模式设计的任务是以需求分析阶段所识别的数据项和应用领域的未来改变信息位基础，使用高级数据模型建立概念数据库模式。概念数据库模式设计目标： 准确描述应用领域的信息模式，支持用户的各种应用； 既易于转换为逻辑数据库模式，又容易为用户理解。概念数据库模式独立于任何数据库管理系统，不能直接用于数据库的实现。但是这种独立性是非常重要的，其原因如下：（1）概念数据库模式设计的过程是彻底理解应用领域的信息结构、语义、信息的相互联系和各种约束的过程。这个过程应该独立于任何数据库管理系统。不然，特定数据库管理系统的局限性将给概念设计带来不应有的影响。（2）概念数据库模式是数据库内容的静态描述。尽量当选择不同的数据库管理系统或改变逻辑与物理设计阶段的设计决策时，不需要改变概念数据模式。（3）概念数据库模式的正确理解对于用户和应用程序设计者是非常关键的。独立于数据库管理系统的高级数据模型比特定的数据库管理系统的数据模型更一般化，具有更强的表达能力。使用这种数据模型进行概念设计能有助于正确理解概念数据库模式。（4）用图形方式表示的概念数据库模式直观易懂，有利于数据库设计者、用户和系统分析员之间的信息交流。高级数据模型通常都具有图形表达能力。概念数据模型的特点：在概念设计阶段一般都适用语义数据模型或概念数据模型。这类数据模型具有如下特点： 具有很强的表达能力，能够方便地表达各种类型的数据、数据间的联系和各种约束； 简单易懂，概念清晰，容易适用； 组成模型的概念少，概念定义严格，无多义性，不同概念的语义不重叠； 具有适用图形表示概念模式的能力。有很多可用于概念数据库设计的高级数据模型，比较流行的有实体联系模型和扩展的实体联系模型。概念数据模型的作用： 提供能够识别和理解系统要求的框架； 为数据库提供一个说明性结构，作为设计数据库逻辑结构即逻辑模型的基础。数据结构设计的策略主要有：自底向上、自顶向下、有里向外和混合策略。概念设计的基本方法要进行数据库的概念设计，首先必须选择适当的数据模型。用于概念设计的数据模型要具有如下的特点： 有足够的表达能力，可以很方便地表示各种类型的数据及其相互间的联系和约束； 简明易懂，容易适用，能为非计算机专业人员所接受； 组成模型的概念少，定义严格，无多义性； 具有适用图形表示概念模式的能力。目前有很多可供选择的高级数据模型，例如各种语义数据模型，面向对象数据模型等。应用得最广泛的是实体-联系（E-R）模型。ER 模型除了具有上述的特点外，还可以用 ER 图表示数据模式，便于理解与交流。用 ER 模型设计数据模式，首先必须根据需求分析说明书，确认实体集、联系和属性。实体集、联系和属性的划分不是绝对的。实体集本来是一个无所不包的概念，属性和联系都可以看成是实体集。引入属性和联系的概念，是为了更清晰、明确地表示现实世界中各种食物彼此之间的联系。概念设计所产生的模式要求比较自然地反映现实世界。因此，实体集、属性和联系的划分实质上反映了数据库设计者和用户对现实世界的理解和观察。它既是对客观世界的描述，又反映出设计者的观点甚至偏爱。所以对于同一个单位，不同的设计者会设计出不同的数据模式。数据库概念设计方法主要有两种，一种是集中式设计方法，另一种是视图综合设计方法。 集中式模式设计法在这种方式中，首先将需求说明综合成一个统一的需求说明，即合并在需求分析阶段得到的各种应用的需求，一般由一个权威组织或授权的数据库管理员 DBS 进行此项综合工作。然后，在此基础上设计一个单位的全局数据模式，以满足所有应用的要求。再根据全局数据模式为各个用户组或应用定义数据库逻辑设计模式。这种方法强调统一，对各用户组合应用可能照顾不够，一般用于小的、不太复杂的单位。如果一个单位很大、很复杂，综合需求说明是很困难的工作。而且在综合过程中，难免要牺牲某些用户的要求。 视图综合设计法视图综合设计法不要求综合成一个统一的需求说明，而是以各部分的需求说明为基础，分别设计各自的局部模式。这些局部模式实际上相当于各部分的视图，然后再以这些视图为基础，集成为一个全局模式。在视图集成过程中，可能会发现一些冲突，须对视图做适当的修改。由于集成和修改是 ER 模型表示的模式上进行，一般可用计算机辅助设计工具来进行，修改后的视图可以作为逻辑设计的基础。两种方法的比较：从表面上看，集中式模式设计法修改的是局部需求说明，而视图综合设计法修改的是视图，两者似乎无多大差别。但两者的设计思想是有区别的；视图集成法是以局部需求说明作为设计的基础，在集成时尽管对视图要做必要的修改，但视图是设计的基础，全局模式是视图的集成；集中式模式设计法是在同一需求说明的基础上，设计全局模式，在设计数据库逻辑模式，全局模式是设计的基础。这两种方法的不同仅在于应用需求合成的方式与阶段不同、视图继承法比较适合于大型数据库的设计，可以多组并行进行，可以免除综合需求说明的麻烦。概念设计的策略给定一组需求说明，概念设计的任务是建立一个满足给定需求的概念数据库模式。目前存在很多种完成这项任务的策略。多数策略遵循逐步求解的原则，即一个满足某些需求的简单模式开始，逐步加以完善，最后形成满足所有需求的概念数据库模式。 自顶向下的策略：从一个包含高级抽象概念结构的模式触发，对这些高级抽象概念结构逐步求精，形成最终的概念数据库模式。例如，我们可以首先建立一个包含介个较高级实体型的模式，然后逐步把它们分解为低级的实体型和联系型，把一个实体型分解为子类的演绎过程是一个自顶向下的设计策略。即首先定义全局概念结构的框架，然后逐步细化，如下图所示： 自底向上的策略从包含基本概念结构的模式触发，逐步组合这些基本概念结构，形成最终的概念数据库模式。例如，我们可以首先说明属性，然后分组这些属性，形成实体型和联系型。前面介绍的由子类形成超类的归纳过程就是一个自底向上的设计策略。即首先定义各局部应用的概念结构，然后将它们集成起来，得到全局概念结构，如下图所示：它通常分为两步：第一步是抽象数据并设计局部视图；第二步是集成局部视图，得到全局的概念结构。 逐步扩张策略首先定义最重要的黑心概念结构，然后向外扩充，以滚雪球的方式逐步生成其他概念结构，直至总体概念结构，如下图所示： 混合策略：首先使用自顶向下的策略把应用需求划分为多个需求子集合；然后，对于每个需求子集合，使用自底向上的策略设计局部模式；最后，组合局部模式，形成最后的概念数据库模式。即将自顶向下和自底向上相结合，用自顶向下策略设计一个全局概念结构的框架，以它为骨架集成由自底向上策略中设计的各局部概念结构。数据抽象概念结构是对现实世界的一种抽象。所谓抽象是对实际的人、物、事和概念进行人为处理，抽取所关心的共同特性，负略非本质的细节，并把这些特性用各种概念精确地加以描述，这些概念组成了某种模型。一般有三种抽象： 分类：定义某一类概念作为现实世界中一组对象的类型，这些对象具有某些共同的特性和行为。它抽象了对象值和型之间的“is member of”的语义。在 ER 模型中，实体型就是这种抽象。 聚集：定义某一类型的组成成分。它抽象了对象内部类型和成分之间“is part of”的语义。在 ER 模型中若干属性的聚集组成了实体型，就是这种抽象，如下图所示：更复杂的聚集如下图，即某一类型的成分仍是一个聚集。 概括：定义类型之间的一种子集联系。它抽象了类型之间“is subset of”的语义。例如，学生是一个实体型，本科生、研究生也是实体型。本科生、研究生均是学生的子集。把学生成为超类，本科生、研究生成为学生的子类。扩展 ER 模型支持概况，允许定义超类实体型和子类实体型，并用竖边的矩形框表示子类，用直线加小圆圈表示超类-子类的联系。概括有一个很重要的性质：继承性。子类继承了学生类型的属性。当然，子类可以增加自己的某些特殊属性。概念结构设计的第一步就是利用上面介绍的抽象机制对需求分析阶段收集到数据进行分析、组织（聚集），形成实体、实体的属性，标识实体的码，确定实体之间的联系类型（1:1,1:n，m:n）。局部视图设计局部概念模式（试图）可以由用户独立完成，也可以由数据库设计者协助完成。 试图设计的任务 第一项任务根据局部需求分析的结果使用适当的概念设计策略，产生局部实体。局部实体应该是局部应用领域中的对象，能够满足局部应用的需求。局部实体的差生包括确定局部实体的属性和键。在局部概念模式设计过程中，我们可能遇到这样一些对象：它们既可以抽象为实体也可以抽象为属性或实体间联系。对于这样的对象，我们应该使用最易于用户理解的概念模型结构来表示。需要注意的是，每个对象必须由一种而且及仅由一种概念模型结构表示。在设计局部实体时，我们还需要确定哪些属性是单值属性、哪些是多值属性、哪些是导出属性和哪些是复合属性。 第二项任务：局部概念设计的第二项任务是根据局部需求分析的结果确定局部实体间的联系及其结构约束。局部实体间的联系要准确地描述局部应用领域中各对象之间的关系。同时，局部实体间的联系也要满足局部应用的各种要求。 第三项任务：深入分析局部实体之间的关系，应用演绎或归纳过程，确定局部实体间的超类/子类来袭、共享子类和范畴。同时，还需要确定他们的正交和完全性约束。 视图设计步骤在实体分析法中，局部视图设计的第一步是确定其所属的范围，即它所对应的用户组，然后对每个用户组建立一个仅由实体、联系及它们的标识码组成的局部信息结构（局部数据模式）框架，最后再加入有关的描述信息，形成完整的局部视图（局部数据模式）。这样做的目的是为了集中精力处理好用户数据需求的主要方面，避免因无关紧要的描述细节而影响局部信息结构的正确性。整个过程可分为以下几个步骤： 确定局部视图的范围； 识别实体及其标识； 确定实体间的联系； 分配实体及联系的属性。 确定局部视图的范围需求说明书中标明的用户视图范围可以作为确定局部视图的基本依据，但它通常与子模式范围相对应，有时因为过大而不利于局部信息结构的构造，故可根据情况修改，但也不宜分得过小，过小会造成局部视图的数量太大及大量的数据冗余和不一致性。给以后的视图集成带来很大的困难。局部视图范围确定的基本原则是： 各个局部视图支持的功能域之间的联系应最少； 实体个数矢量：一个局部视图所包含的实体数量反映了该局部视图的复杂性，按照信息论中“7±2”观点，人们在同一时刻可同时顾及的事情一般在 5~9 之间，以 6 或 7 最为适当。因此，一个局部视图内的实体数不宜超过 9 个，否则就会过于复杂，不便于人们理解和管理。 识别实体及其标识在需求分析中，人们已经初步地识别了各类实体、实体间的联系及描述其性质的数据元素，这些统称为数据对象，它们是进一步设计的基本素材。这一步的任务就是在确定的视图范围内，识别哪些数据对象作为局部视图的基本实体及其标识，并定义有关数据对象在 ER 模型中的地位。数据对象的分类：为了确定数据对象在局部 ER 数据模型中的地位，首先必须对所有已识别的数据对象加以适当的分类，以便于根据它们所属的对象类来确定它们在相应局部 ER 模型中的身份。数据对象分类的原则是同一类中的对象在概念上应该具有共性。例如，高校中的教师这个概念是指在职的教学人员，因此，教授、副教授、讲师和助教均可归入教师这一类，但他们在概念上并不完全相同，除了共享之外，还各有其特殊之处，如教授、副教授有研究方向、知道研究生等描述项，他们的职称也不一样。因此数据对象存在分类层次问题，谓词可运用面向对象数据模型中子类与超类的概念。识别实体与属性：建立局部 E-R 数据模型，还须识别每个对象类在局部 E-R 模型中的地位：实体、属性或联系。实体和属性之间在形式上的界限并不明显，常常是现实世界对它们已有的大体的自然区分，随应用环境的不同而不同。在给定的应用环境中区分实体和属性的总的原则是：要在此应用环境中显得合理，且同一个对象在同一局部视图内只能做一种成分，不能既是实体又是属性。此外，为了对已给定的需求目标，更合理地确认局部 E-R 模型中的实体和属性，以便在逻辑设计阶段从 E-R 模型得到更接近于规范的关系模式，可按下述一般规则来区分实体与属性： 描述信息原则：在 E-R 模型中的实体均有描述信息，而属性则没有。据此，可将一个需要描述信息的对象类作为实体，而将只需有一个标识的对象类归为属性。例如，仓库这个对象类在某些事务处理中需要用到仓库的面积、地点、管理员姓名等描述信息，则宜将其归入实体。但如人的年龄、物品的重量等对象类，在一般应用中都不需要描述信息，所以他们在通常情况下都作为属性。 多值性原则：所谓多值性是指若一个描述项存在多个值描述其描述对象，则即使该描述项本身没有描述信息也应化为实体。例如加工种类与其描述的工件之间就符合多值性原则，因为每个工件实体可能需要多个工种的加工，尽管工种除了工种名外不需要其他的描述，但还是讲工种作为实体为好。需要注意的是，这一原则最好与存在性原则结合起来使用，如果将被描述对象删除后，描述项没有再存在的意义，则即使此描述项是多值得也不宜作为实体。例如零件的颜色可以是多值得，但颜色离开了其描述的对象就没有单独存在的意义，因此还是作为属性为宜。 存在性原则： 多对一联系性：属性不再与其描述对象以外的其他对象类发生联系。相反，如果一个对象的某个描述项与另一个对象类存在着多对一联系，则此描述项即使本身没有描述信息，也应将其作为实体。例如在前面所讲的工件与加工种类的例子中，如果还有一个车间实体，且加工种类与车间之间存在多对一的联系，则将加工种类华为实体更合理。 组合标识判别原则：若一个对象类的标识是由其他对象类的标识组成的，该对象一般应定义为联系。相反，如果组成某对象类标识的各成分不是其他实体的标识，且作为实体在应用的上下关系中很自然，则可以定义为实体。例如，一个工厂生产的零件须由名称及规格组成组合标识，在一般应用中应将零件作为实体较为适宜。实体与属性的识别过程是个相互作用的反复过程，随着实体的确认，属性也将趋于明朗，反之亦然。在此过程中根据应用需求对已经识别的实体和属性做适当指派，发现问题再来调整，在标识过程中必须遵循前面所讲的总原则。对象的命名：在需求分析中得到的数据对象通常都是有名称的，但由于这些名称未经规范化，常常存在诸如同名异义、异名同义等许多命名上的冲突、不一致性及语义不清等问题，是造成数据不一致性及数据冗余的一个重要原因。此外，数据对象原有的名称有的过于冗长，给使用带来很大不便。谓词，需要按一定的规范对每一类数据对象重新命名，给它制定一个简洁明了且唯一的名字，避免异名同义和异义同名存在。命名规范一般包含以下原则和规定： 数据对象名应清晰明了便于记忆，并尽可能采用用户熟悉的名字； 名字要反映数据对象的主要特点并力求简洁，以利于减少冲突和方便使用； 遵守缩写规则。缩写规则包括一般缩写规则和系统中专用名称的缩写规定，对于较大的复杂系统应编制缩写字典，便于参照。凡有缩写规定的不得使用全称，以免混淆。 规定统一的命名约定并加以遵守。例如对属性的命名可以采用如下形式的约定：实体名·分类词—修饰词其中，分类词指单位内通用的数据项名，如名称、号码、小计、总计、合计、单位等。每个单位应有一个标准的分类词表，加于分类前面的实体名和后面的修饰词可用以说明该分类词在特定的上下文中具有的特殊含义。例如，合同上的数据项日期可命名为：合同·日期—年月指定命名约定的基本原则是简明一致、避免混淆，具体可根据单位内数据对象的复杂程度自行制定。在完成了实体与属性的识别后，必须按照命名规范仔细地审核没类数据对象的名字，纠正不符合规范的命名，务必使每个对象名符合规范要求。确定实体的标识：实体的标识能够唯一地标识一个实体的属性或属性组，也就是该实体的关键字。确定实体标识在实体识别与规范化命名之后进行，首先确定每个实体的候选关键字。一个实体可能有若干候选关键字，选择其中对有关用户最熟悉的一个候选关键字作为主关键字（或主码），并将每个实体的候选关键字、主关键字记入数据字典。 确定实体间的联系实际上，识别联系的主要任务是在需求分析阶段完成的。这里的工作一是从局部视图的角度进行一次审核，检查有无遗漏之处，二是确切地定义每一种联系。在现实世界中，诸多形式的联系大致可分为三类：存在性联系、功能性联系和事件联系。存在性联系如学校有教师、教师有学生、工厂有产品等；功能性联系如教师讲授课程、教师参与科研等；事件联系如学生借书、产品发运等。根据上述分类仔细检查在给定的局部视图范围内是否有未识别的联系，在确认所有的联系都已识别并无遗漏之后，还须对联系进行正确的定义。定义联系就是对联系语义的仔细分析，识别联系的类型，确定实体在联系中的参与度。二元联系的类型与定义：二元联系是指两个实体类之间的联系。根据参与联系的两个实体类值之间的对应关系分为一对一、一对多及多对多 3 种类型。对每一种联系类型，要确定实体在联系中的参与度，并以 m:n 的形式标在 E-R 图上要说明的实体旁，若 m&gt;0 ，表明该实体参与联系是强制性的，若 m=0 则是非强制性的。下面分别讨论上述三类联系的定义，以及另一种二元联系实体类内部的联系。 一对一联系这是一种最简单的联系类型。若对于实体集 A 中的每一个实体，实体集 B 中至多有一个实体与之联系，反之亦然，则称实体集 A 与实体集 B 具有一对一联系，记为 1:1 。按照实体参与联系的强制性情况，又可分为以下 3 种情况：（1）两类实体都是强制性的。加入规定每个工程师一定要负责一项工程，每项工程也一定要有一位工程师负责，便属于此种情况。如果工程师的辨识为职工号，工程标识为工程号，对于工程师与工程间的 1:1 联系，可用职工号或工程号作为标识。（2）其中仅有一类实体是强制性的。若规定每项工程必须由一名工程师负责，但并不是所有工程师都必须负责一项工程（因为可能没有那么多的工程），此时，每一项工程一定对应着唯一的负责联系，所以工程号可用做联系的标识。（3）两类实体均为非强制性的。如工程师不一定安排负责管理工程，有的工程项目暂时可以不安排工程师负责管理，这种情况标识凡分到工程项目的工程师与工程项目之间总存在语义对应联系，因此职工号或工程号均可宣威负责联系的标识，定了其中一个为标识，另一个就作为候选关键字。 一对多联系：若对于实体集 A 中的每一个实体，实体集 B 中有 n 个实体（n&gt;=0）与之联系，反之，对于实体集 B 中的每一个实体，实体集 A 中之多有一个实体与之联系，则称实体集 A 与实体集 B 有一对多的联系，记为 1:n 。亿专业与学生间的关系为例：如规定一个专业可以管理许多学生，每个学生只能属于一个专业，这种联系就是一对多联系。对这种联系我们只需关系“多”端实体的强制性，分两种情况进行讨论：（1）“多”端的实体是强制性的。此时，每个学生必须归属某个专业，即每个学生都有一个确定的专业，但每个专业都不唯一地对应一个学生，故可以选择学号作为联系的标识。（2）“多”端的实体是非强制性的。对本例而言是指有些学生（如新生）不属于任何专业的情况。此时实际上仅标识已经分配专业的学生与专业之间的联系，对这些学生中的每一个都有一个确定的专业，因此，应以学号为联系的标识，而专业代号作为联系的一般属性。 多对多联系若对于实体集 A 中的每一个实体，实体集 B 中有 n 个实体（n&gt;=0）与之联系，反过来，对实体集 B 中每一个实体，实体集 A 中也有 m 个实体（m&gt;=0）与之联系，则称实体集 A 与实体集 B 具有多对多联系，记为 m:n。教师与学生这两个实体类间的教与学的联系就是多对多的联系。这是，只有&lt;教师、学生&gt;对才能确定一个特定的教学联系。因此，一般情况下可以以两个关联实体的标识拼凑作为联系的标识。但这种方法对某些情况就不能构成有效的联系标识。当一个实体值在同一个联系上可能存在多个不同的联系值时，就会出现这种情况。如教师与其讲授的课程之间的联系，同一个教师可讲授几门不同的课程，也可以多次讲授同一门课程，这是一种特殊的多对多联系，这种情况可用下图所示的值图表示。值图是表示具体实体及其关联的一种图示法，其中圆点表示具体的实体，连线表示实体间的联系。而通常的 E-R 图只能表示型而不是值，所以称为型图。显然，对于教师与讲授课程间的联系，如在教师档案中要求记录担任教学工作情况，就需要在联系标识中增加表示授课日期的属性，即其合适的联系标识可能为（教师号，课程号，授课日期）。 实体类内部的联系：这种联系发生在同一类实体的不同实体之间，因此称为内部联系或自联系，它也是一种二元联系，其表示方式与前面的二元联系并无不同，要注意仔细区别同一实体类中的不同实体在联系中扮演的不同角色及联系标识的选择。例如在职工类实体中间就存在着管理者与被管理者的联系。多元联系的识别与定义：两个以上的实体类之间的联系称为多元联系。例如在供应商向工程供应零件这类事件中，如果任一供应商可向任一工程供应任一种零件，则为了确定哪个供应商向哪个工程供应了何种零件，就必须定义一个三元联系，因为只有供应商、工程及零件三者一起才能唯一地确定一个联系值。其联系的标识由参与联系的实体类的标识拼接而成，在此例中由供应商、工程、零件 3 个实体类的标识拼接而成。需要注意的是，涉及到多个实体的事件是否属于多元联系完全取决于问题的语义，不可一概而论。例如，如果上例中的问题说明变成每个工程需要订购一定的零件，而任一供应商可向任一工程供应零件。这里有两层意思，一是只有工程确定了才能确定订购的零件，二是只有供应商及工程确定了，才能确定一个供应关系。根据这一情况，应定义两个二元联系，如下图所示：加入问题的说明是任意供应商向任一工程供应零件，但某个供应商向某项工程供应的零件是一定的，则在供应商与工程之间的关系确定后，供应的零件也就确定了。由此可知，只需定义一个二元联系就可以了，如下图所示，其中供应商的零件作为供应联系的一个属性。总之，具体问题应该具体分析，以便使定义的模式确切地表达问题的语义。消除冗余联系：若出现两个或两个以上的联系标识的是同一概念，则存在着冗余的联系，具有冗余联系的 E-R 模型转换为关系模型可能会得到非规范化的联系，因此必须予以消除。出现冗余联系的一种重要原因是存在传递关系。例如，下图中表示了产品与零件之间的“组成”联系，零件与材料之间的“消耗”联系及产品与材料间的“使用”联系。其中，材料与零件间的联系是 1:n。零件与产品之间的组成联系是 n:m，其实由这两个联系必然得出产品与材料之间的使用关系 m:n。因此，图中产品与材料间的联系是冗余的。应将其去掉。 警惕连接陷阱连接陷阱是一种存在语义缺陷的联系结构，它是由于在定义联系过程中对语义的理解出现偏差而造成的，因而无法由它得到需要的信息。连接陷阱可分为扇形陷阱、断层陷阱和深层的扇形陷阱 3 种情况。扇形陷阱：两个实体类间的一对多联系。由一个实体值引出多个同一类型的联系值，其值图是一种扇形结构。下图（a）是这种结构的一个例子，图（b）是一个值图。从（b）值图可以看出，从这种联系结构无法获得哪个职工属于哪个专科的信息，其原因是将专科与职工之间的联系通过医院来连接了。如采用下图（a）所示的联系结构，图（b）是它的值图。新的结构能较自然地表示了医院、专科及职工之间的层次关联。假定任一医院的职工无例外地分属于医院的各个专科的话，该结构可以确定一个职工所属的专科或医院，但如果允许某些职工直属医院而不属于任何专科，那么这种结构还是不合适的。断层陷阱：断层陷阱是指型图所含的传递联系掩盖了某些特定的直接联系的现象。例如上图（a）的联系结构虽然隐含了医院与职工的联系（传递联系），但却没有提供部分职工直属于医院的联系路径，因而出现了断层陷阱。解决办法是设置一个虚构的专科或增加一个联系，如在本例中增加一个医院-职工联系。增加虚构实体和现实世界不符，因此可考虑增加一个联系，但增加新的联系在某些情况也可能带来新的麻烦，见下面的内容。深层的扇形陷阱：举一个“教师指导学生参加课题”的例子，若每个学生可在多位教师指导下参加多个课题研究，每位老师可知道多名学生，但现在只允许一名教师指导一名学生参加一个课题，不允许多名教师指导同一名学生参加某个课题。对此可先建立一个由两个多对多的二元联系组成模式，如下图所示：利用联系的分解法则将其分解为下图所示的结构，它是以学生为中心的双扇形结构。下图是上图对应的值图，从该联系结构无法得到哪位教师指导哪个学生参加何课题的信息，这表明存在扇形缺陷。下图是对上例的一种改进，在其中增加了一个教师与课题的联系。该联系结构能确切地提供“教师 1 指导学生 1 参与课题 1”及“教师 2 指导学生 2 参与课题 1”的信息，但从此图无法确定教师 1 指导学生 2 参与了哪一个课题。对教师 2 和学生 1 也是如此，因为参加课题 1 或 2 均是正确的语义。之所以如此，原因在于新增加的教师与课题间的多对多联系带来了两个新的双扇形结构，即=以教师为中心的及以课题为中心的双扇形结构。增加的新联系虽然消除了原来的陷阱，却产生了新的陷阱。对这类问题的有效解决办法是将三个实体间的联系定义成一个单一的三元关系，它的 E-R 模型如下图所示。现在，每一个联系值唯一地确定了另一个联系值，从中可获得哪位教师指导某学生参加哪一课题的确定信息。可见问题的实质是对于应该定义成三元关系的问题千万不能用二元联系代替。 分配实体及联系的属性在需求分析中收集的数据对象集内，除去已识别的实体、联系及标识外，剩下的主要是非标识属性。问题的实质就是将这些非标识属性恰当地分配给有关实体或联系。不过分配这些属性时，应避免使用用户不易理解的属性间的函数依赖关系有关准则，而应该从用户需求的概念上去识别框架中实体或联系必须有的描述属性，并按下述两条原则分配属性。非空值原则：所谓非空值原则是指当一个属性的分配在几个实体或联系中可以选择时，应避免使属性值出现空值的分配方案。例如在前面曾经讲过的工程师负责工程的模式中，其联系是一对一且两个实体类均属非强制性的情况，现有一个属性项“施工期限”，按依赖关系考虑可加给工程师、工程或负责联系三者中的任何一个，因为工程师与工程在这里是一对一的联系，工程师定了，工程的施工期限也就定了。但有的工程师可能没有分配到负责工程的任务，若把施工期限作为工程师的属性，在此情况下便会出现空值；若作为工程的属性，则工程可能还未纳入计划，也会出现空值，可见将“施工期限”分配给负责联系最为适宜。增加一个新的实体或联系：在分配属性过程中，有时会出现有的数据项在框架模式中似乎找不到适合依附的实体或联系。对于这种情况，常常可通过在原模式中增加一个新的实体或联系加以解决。例如，图 1-13 表示了一个病区/病人模式，这是一个一对多，且“多”端为强制性的联系，在所有明显的属性均已分配完后，尚有属性项手术名及手术号待分配。这里手术名依赖于手术号，一个病人可能接受多种手术，一个病区可能接纳不同种手术的病人。在此情况下，手术号与手术名两个属性项不论作为哪个实体或联系的属性均不合适，谓词可以在原来的模式中增加一个新的实体—手术，再加一个病人与手术的联系就可以了，如图 1-14 所示。按照上述属性分配原则建立的模式将有利于转换成规范化的关系模式。视图集成视图集成就是要将反映各用户组数据的局部数据模式综合成单位中某个确定范围内的单一数据视图，即全局数据模式，又称模式汇总。该全局数据模式是未来数据库结构的基础，因此视图集成是数据库设计过程中一个十分重要的步骤，也是一项较为复杂和困难的任务。当所有局部视图设计完毕后，就可开始视图集成了。整体 E-R 图包含了每个局部 E-R 图的信息，它合理地表示了一个简单而又完整的数据库概念模型。视图集成的原理和策略：视图集成的实质是所有局部视图的统一与合并，在此过程中主要使用了 3 个基本概念：等同、聚合和普遍化。基于这 3 个概念，有 3 种相应的基本集成方法。 等同：等同又称一致性合并，是指如果两个或多个数据对象具有相同的语义，则把它们归并为同一个对象，以消除不一致性，而不管它们的名字原来是否相同；同样，如果两个对象有相同的名字，但表示不同的对象，则应通过改名把它们区分开来。等同包括简单数据对象间的等同、多个数据对象的聚合与另外介个数据对象聚合之间的等同。等同的数据对象其语法表示形式不一定相同，它与通常所说的同义异名是一个概念。识别等同时还要注意鉴别同名异义和语义相同但值域不同两种情况。同名异义虽有相同的表示形式，但语义却不同。等同貌似简单，但在实践中要做出判断却并不容易，须做仔细分析，主要依靠对有关数据对象类值域的分析比较。 聚合：聚合表示和数据对象间的一种组成关系，例如数据对象学生可看成是学号、姓名、性别、年龄等数据元素的聚合。聚合集成主要用于实体的属性分配，有关的思想和方法请参看前面的实体分析法。 普遍化：普遍化是对某一概念范围内具有共性对象的一种抽象。在视图集成中，它用于对现实世界中的事物进行归类。虽然普遍化和聚合均表示事物的层次结构，且同一个数据对象可能同时参与普遍化和聚合两种联系,但它们是两个截然不同的概念。聚合是将若干不同类型的数据对象组合成一个高级对象的过程，而普遍化是按公共属性的值对事物进行抽象和归类的过程。综合地运用上述三种方法可有效地进行视图的集成。视图集成从策略上可分成两类：二元集成和 n（n&gt;2）元集成： 二元集成： 平衡式； 阶梯式。 n（n&gt;2）元集成： 一次集成； 多次集成。 二元集成： 平衡式集成：这种集成方式是把整个集成过程分成若干层次，在每层中进行亮亮集成，其结果进入下一层集成，集成的对数逐层减少，最后得到统一的视图。有人证明，只要选择恰当的集成初始序列，就有可能使这种集成的分析比较次数达到最少。两个分别具有 N 和 M 个对象的视图，其集成结果，在不考虑聚合和分解引起的增减的情况下，可能有 N+M-X 个对象，其中 X 为视图间对象的重叠度，若两个视图中有 i 个对象等同，则 X = i-1.为了最大限度地减少在后面的集成中涉及的对象数，选择初始集成序列时应使没对集成视图的 X 值尽可能地大，若在每个集成层次上均彼此原则进行，则就可能使总的集成效率达到最高。只有当配对的是关系极为密切的视图，即对应于事务处理中联系最紧密的功能域时，才能使配对视图中的 X 值为最大。由此可见，确定视图初始集成序列中的分组原则与划定局部范围的原则是一致的，因而有关的方法也是可参照使用的。 阶梯式集成：阶梯式集成是一种流水线作业形式的集成方式，它无须考虑视图的初始序列，当然也不保证 X 值为最大，但省去了进行处理的麻烦，且这种方案适合同已经存在的局部集成模式进行综合。数据库的应用范围常常随着单位的发展而需要逐步扩展，扩展的每一种功能所设计的数据，通常与已经集成的数据模式关联最为密切，而阶梯式集成为这种情况提供了最为适宜的策略。由以上可知，二元集成是一种较简单且行之有效的策略。它的优点在于可使每个集成步骤上的分析比较过程简单化和一致化，因而使用较广泛。它的主要缺点是集成操作的总次数较多，且在最后必须分析检查是否满足总体性能，必要时须做调整。n 元集成： 一次集成：此法一次集成 n 个视图。其优点是能充分地考虑全局需求，不必到最后再来分析调整，且集成操作次数少。缺点是集成效率将随着视图数及视图中对象数的增加而明显降低，因为集成过程中基本操作是等同性检查，一次集成 n 个视图，为了判别一个视图中单个数据对象的等同性，必须与其他 n-1 个视图中的每个数据对象进行比较，所以只有当 n 较小时，这种策略才有意义。 多次集成：此法先用与平衡式二元集成相同的机理，将待集成的视图分成若干组，每组的视图数可以是两个或多个，但个数不能太多，然后按组集成，形成若干中间视图，再对这些中间视图进行分组、集成，最后得到全局视图。它的优点是：具有平衡式二元集成法效率较高的优点，集成操作的总次数较少；齐次，其分层的集成过程在概念上正好与大多数具有层次功能结构的事务单位相吻合。事务管理人员可凭借其丰富的事务知识有效地进行低层次集成，单位中高级管理人员具有的综合知识及全局观点，有利于运用聚合或普遍化感念进行高层次上的集成。此策略的效果同样取决于初始集成序列的划分。它的缺点是一致性差。 视图集成的方法和步骤局部视图集成是一个相当困难的工作，往往必须凭设计者的经验与技巧才能很好地完成。尽管如此，集成的方法很多，它因所用的概念设计数据模型、集成策略、集成过程的输入/输出量及识别和解决冲突的方法的不同而各有其独特的执行过程，但总的来说都分成两个阶段：预集成阶段和集成极端。预集成阶段： 确定总的集成策略，包括视图集成的优先次序，一次集成的视图数及初始集成序列等； 检查集成过程要用到的信息是否齐全； 揭示和解决冲突，为下阶段的视图归并奠定基础。 集成阶段： 集成阶段的主要任务是归并和重构局部视图，最后得到统一的全局视图。全局视图须满足下述要求： 完整性和正确性：整体视图应包含各局部视图所表达的所有语义，正确地表达与所有局部视图应用相关的数据观点； 最小化：原则上，现实世界统一概念只在一个地方表示。 可理解性：即应选择最易为设计者和用户理解的模式结构。一个视图的基本框架主要由实体和联系组成，所以集成主要是实体与联系的集成，整个集成过程也就是这两类基本集成过程的反复交替执行的过程。 等同的识别和冲突的发现与解决冲突的表示及处理策略 同名异义：为了发现不同视图间的同名异义问题，可以先列出所有同名数据对象，然后诸一判别其语义。对同名异义冲突通常采用换名加以解决，既可对同名者之一换名，也可对两者都给以重新命名。识别语义的主要方法是进行值域分析。 异名同义：识别异名同义比较困难，一般由设计者对所有对象一个不漏地逐一鉴别（最好开始设计局部视图时约定命名规则和常用名称）。它同样采用换名的方法解决。若归并时视图将它们合并为一个对象，则可以把其中之一的名称作为合并后的对象名；若集成后，它们仍以两个不同的对象存在，则可对其一换名，当然，若原名都不合适，则可以对两者都重新命名。 同名不同层次：如果两个对象同名，但其中之一是作为一个视图中的实体，而另一个是另一视图中的属性，则在集成时就会发生同名不同层次的冲突。解决这种冲突的办法的两个，一是将属性转换为实体，而是将实体变换成属性。例如，设一局部视图中有一部分实体 DEPT，而在另一与之集成的视图中有职工实体 EMP，且 EMP 有属性 DEPT，于是发生了同名不同层次的冲突。此时，可将 EMP 的 DEPT 属性去掉，另设一个实体 DEPT 与 EMP 建立联系，这时再与另一视图集成就容易多了。再如，设一局部视图中有一名为 STOR 的仓库实体，其中含有一属性部门号（DEPT-NO）；在另一局部视图中有一单位实体 DEPT，其中仅含有一个属性 DEPT-NO。对这类同名不同层次的冲突，可将 DEPT 实体变换为其所在视图中与 DEPT 相关的另一实体的属性，然后再进行集成。必须注意的是，实体变换为属性时通常要满足一些特定的条件，比如该实体通常只有一个与同名属性具有共同特征的属性，且一定存在一个与该实体存在联系的另外的实体。 同名同义联系测度冲突：虽同名同义，但对象联系刻度不同。所谓联系测度是指实体的联系是一对一、一对多还是多对多。若同名同义对象的在一个局部视图中为一对多联系，在另一局部视图中为多对多联系，则在集成时将发生联系测度冲突。一般而言，一对多包含一朵一，多对多包含一对多。所以解决这种冲突的方法往往取较高刻度为集成后的相应的测度。 约束冲突：不同视图可能有不同的约束，例如，对于“选课”这个联系，大学生和研究生对选课的最少门数和最多门熟可能不一样。 数据特征不相容：如果一同名同义属性在一局部视图中刻作为关键字属性，但在另一局部视图中不具有关键字属性特征；或者，如果一组属性在不同视图中具有相反的相互依赖关系。这联众情况均会发生数据特征不相容冲突。对于第一种不相容冲突，集成时往往需要重新选择关键字；关于第二种不相容冲突，解决的策略则依赖于实际应用环境。例如，假设在两个不同局部视图中都含有课程和教室属性，其中之一存在课程决定教室的属性依赖关系，而在另一局部视图中课程与教室的依赖关系刚好相反。当将这两个属性集成到一个实体中时，其原有的这种对应联系将不存在。此时，若这种联系的丢失不产生影响，则集成可正常进行。但如同第一种冲突，有时可能要重新指定关键字，而且，有时第二种冲突也可鞥具有第一种冲突的特征，本例就可能是这种情况。不相容冲突因不同的环境而可能有多种不同的形式，应根据具体情况采用不同策略加以灵活处理。等价数据对象类之间的映射：另一类貌似不等同但通过适当映射可转化为等同的数据对象，称为等价的数据对象类。通常有两种等价情况：（1）用不同的名称和值域描述统一种食物。例如，出生日期（日期型）与年龄（整型）、职工号（字符型）与工作证号（整型）等。（2）用不同的度量单位度量同一事物。对于“重量”“长度”等度量属性都可能出现这一情况。如对于一个物品的重量单位在一个视图中定义为吨，而在另外的视图中定义为公斤。这两种情况实质是用不同的形式来描述统一事务或概念，这种描述统一事物或概念的数据对象类称为等价数据对象类。这些等价数据对象之间可以按一定的规则映射，如出生日期与年龄之间，吨与公斤之间都可按公式进行相互转换，对那些没有确定的规则可循的等价数据对象类之间的映射可用对照表加以实现。等价数据对象类是由于各个用户组对数据对象的观点不同而造成的。它们可以通过映射转化为等同数据类，然后再按等同数据对象进行集成。因此，在集成前应仔细识别所有等价数据对象类，并确切说明它们之间的映射。定义数据对象类的值域：一个数据对象类所有可能的实例的集合称为该对象类的值域或简称为域。数据对象类的值域是分析该数据对象类语义的重要依据，是识别各个视图中数据对象类在所讨论的概念上是等同的、有共性或不相干的主要依据。因此仔细定义每个数据对象的值域是识别来自不同视图的数据对象类是否等同的主要手段。例如 Dom(A) 表示对象类 A 的值域，各对象类在值域上存在四种相关情况。 域等同； 域包含（子集关系）； 域重叠（有交集）； 域分离（无交集）。对所有数据对象按上述四种值域相关情况归类后，便可用不同的方法对实体类进行集成。 实体类的集成下面按照前面定义的四种值域相关情况，采用二元集成策略，对视图中的实体类进行集成。为了方便起见，用大写字母，如 A、B 等表示实体类，用 Attrs(A) 表示实体类 A 的属性。 域等同：A 和 B 是来自不同视图的两个实体，如果它们的值域等同，则集成过程就是建立一个单一的实体类，设为 C，作为全局模式中的实体类，其属性 Attrs(C) 为 A 和 B 的属性的并集，值域等同于 A 或 B 的值。因此，在这种情况下，集成操作就变成了求并操作，可表示为： 域包含： 域重叠： 域分离： 联系类的集成联系类集成是通过语义分析来归并和调整来自不同视图的联系结构。联系的语义主要由里阿尼的元数、实体在联系中角色和参与度，以及联系的值域等表示。根据待集成联系类的元数和实体在联系中所起角色的异同，可将联系类的集成分成三种类型： 元素和角色均相同的联系类的集成； 不同角色的联系类的集成； 不同元数的联系类的集成。其中每一种类型又可按实体的参与度或值域等语义因素分为八种情况。下面对它们逐一进行讨论。元素和角色均相同的联系类的集成 实体的参与度相同： 实体的参与度不同：不同角色的联系类的集成 域包含： 域分离：在这种情况下，参与两个不同视图中联系类的实体虽然相同，但它们表示的却是通常意义上互不相干的两件事。集成时，它们会变成全局模式中两个实体类间的两个联系。 域重叠：不同元数的联系类的集成不同元数的两个联系类之间有三种可能的情况：（1）元数较少的联系类可从元数较多的哪个联系类导出。（2）两个联系类在施加某些语义限制后可以兼容。（3）不属于以上两种情况。对应地有三类集成处理：可归并的、有条件可归并的和不可归并的。 可归并的不同元数的联系类： 有条件可归并的联系类： 不可归并的联系类： 新老数据模式的集成当需要对已经建立的数据库系统进行扩充、修改、以扩大其应用范围，满足企业业务上发展的需要时，就会出现新老数据模式的集成问题。现有的数据库系统的情况可能是： 由若干面向单项应用的独立数据库组成； 支持一定范围内多项应用的综合数据库。不论哪一种情况，均可应用前面所讲的方法进行集成处理，但其具体内容稍有不同。原有系统为多个独立数据库时的集成这种情况下的集成包括单个数据库的集成和扩充的数据模式的集成。由于这些独立的数据库仅仅各自反映单个用户组的需求，而且很可能是在不同时期由不同的设计人员设计的，因而这些数据库之间及其和扩充的数据模式之间。必然地存在许多冲突和冗余。把它们集成为一个能支持所有应用，并能保证数据的一致性、完整性及最小冗余的全局模式后，原有的应用程序很可能都不能运行。因此，事前需要有周密的计划，原则是既要满足新的需要，同时尽可能地保持原来的数据模式，以便将原有的应用程序稍做改动后仍能运行。原有系统为单一的综合数据库时的集成这时原有的数据模式已是经过集成的数据模式，再和扩充部分集成时，应尽量地向原模式靠拢，以使得原数据库支持的应用程序基本不变。进行新老数据模式集成时，首先必须理解原有数据模式。如果原有数据库未留下概念设计的文档，那么就得从分析模式入手，这一过程不但十分困难和繁琐，而且容易出错或遗漏。因此，对于比较复杂的数据模式，最好先将逻辑模式翻译成相应的 E-R 图，将其与用户交互，确认新的需求，根据用户意见，对 E-R 模式进行调整，形成新的用户视图，然后再按前面所述的方法集成。可见，新老数据模式的集成比全新的视图集成受到的限制更多，因此，在某种意义上来说更加困难。事务的设计数据库设计的目的是支持各种事务的运行，在数据库设计的过程中，需要考虑所有事务的特点和要求。这样才能保证所设计的数据库包含各种事务所需要的信息。事务的各种特点和性能要求在物理数据库设计中也是非常重要的。当然，在概念数据库设计阶段，我们不可能知道所有的事务。但是，数据库系统的重要事务常常是可以预先知道的。数据库设计应该以这些事务为依据。所以，事务的设计通常是与数据库设计同时进行的。在概念数据库设计阶段，事务设计的任务是定义事务的功能。在概念级定义事务功能的方法是说明事务的输入信息、输出信息和功能。使用这种方法，事务的定义可以独立于任何数据库管理系统。事务可以分为三类： 数据查询型事务：这类事务查询数据库中的数据，进行各种数据处理。 数据更新型事务：这类事务用于增加、修改和删除数据库中的数据。 混合型事务：这类事务既具有查询功能也具有更新功能。逻辑结构（数据库）设计概念结构````独立于任何一种数据模型的信息结构。逻辑结构设计的任务就是把概念结构设计阶段设计好的基本 E-R 图转换为与选用的 DBMS 产品所支持的数据模型相符合的逻辑结构。可见逻辑数据库设计依赖于逻辑数据模型（有关系模型、层状模型和网状模型）和数据库管理系统。从理论上讲，设计逻辑结构应该选择最适于相应概念结构的数据模型，然后对支持这种数据模型的各种 DBMS 进行比较，从中选出最合适的 DBMS。但实际情况往往是已给定了某种 DBMS，设计人员没有选择的余地。逻辑数据库设计的目标： 满足用户的完整性和安全性要求； 动态关系至少具有第三规范形式，静态关系至少具有第一范式； 能够在逻辑级上高效率地支持各种数据库事务的运行； 存储空间利用率高。目前 DBMS 产品一般支持关系、网状、层次三种模型中的某一种。对莫一种数据模型，各个机器系统又有许多不同的限制，提供不同的环境与工具。所以设计逻辑结构时一般要分 3 步进行： 将概念结构转换为一般的关系、网状、层次模型； 将装换来的关系、网状、层次模型向特定 DBMS 支持下的数据模型转换； 对数据模型进行优化。对于关系数据库的逻辑设计阶段的步骤如下： 形成初始关系数据库模式； 关系模式规范化； 关系模式优化； 定义关系上的完整性和安全性约束； 子模式定义； 性能估计。形成初始关系数据库模式初始关系数据库模式是指直接由概念数据库模式生成的关系数据库模式。初始关系数据库模式生成的目的是把概念数据库模式的实体、实体间联系等模型结构变换为关系模式。 普通实体型的转换 弱实体的变换 多值属性的变换 带有非原子属性的实体的转换 实体间联系的变换 1:1 联系的变换： 1:N 联系的变换： M:N 联系的变换： n 元联系的变换： 超类/子类联系的变换 扩充 E-R 模型向关系模型的转换扩充 E-R 模型是基本 E-R 模型的扩充。它主要扩充了两点： 一是一个实体集可能是另一个实体集中的某个属性，即一个实体可以附属于另一个实体集； 二是增加了一种叫 is-a 的特殊联系，这种联系建立了两个实体间的继承关系，通过这种联系可以构成实体集之间的普通化/特殊化层次结构。下面讨论这些扩充部分的转换，这些转换方法也可推广到其他具有这些概念的数据模型。 1）一个实体集同时是另一个实体集的属性： 2）两个实体集间 ISA 联系的转换 3）一个超集具有多个子集时的转换 范畴和共享子类的变换 一般关系模型向特定的关系模型的转换 确定函数依赖集通过前面的变化，概念数据库模式中的所有模型结构都已经变换为关系模式，形成了初始关系数据库模式。最后，我们需要对初始关系数据库模式中的每个关系模式进行深入地分析，与用户协商，确定每个初始关系的函数依赖集，使用关系数据库设计理论，对关系模式进行规范化处理。逻辑模式的规范化和优化从 E/R 图转换而来的关系模式还只是逻辑模式的雏形，要称为逻辑模式，还需要进行下列及步的处理： 规范化； 适应 DBMS 限制条件的要求； 对性能，存储空间等的优化； 用 DBMS 锁提供的 DDL 定义逻辑模式。下面主要讨论对性能、存储空间等的优化。（1）数据库性能的优化： 减少连接运算： 减小关系的大小和数据量： 尽可能使用快照：（2）节省存储空间的措施 节省每个属性所占的空间： 采用假属性减少重复数据所占存储空间：另外，数据库逻辑设计的结果不是唯一的。为了进一步提高数据库应用系统的性能，还应该根据应用需要是当地修改、调整数据模型的结构，这就是数据模型的优化、关系数据模型的优化通常以规范化理论为指导，方法（至于涉及到的理论和细节请参考前面相关内容的表述）为： 确定数据依赖：根据数据依赖的概念分析和表示数据项之间的联系相关内容，写出每个数据项之间的数据依赖。按需求分析阶段所得到的语义，分别写出每个关系模式内部各属性之间的数据依赖以及不同关系模式属性之间的数据依赖。 数据依赖极小化处理：对于各个关系模式之间的数据依赖进行极小化处理，消除冗余的联系。 范式分析：按照数据依赖的理论对关系模式逐一进行分析，考察是否存在部分函数依赖、传递函数依赖、多值依赖等，确定个关系模式分别属于第几范式。 模式合并或分解：按照需求分析阶段得到的处理要求，分析对于这样的应用环境，这些模式是否合适，确定是否要对默写模式进行合并或分解。 模式分解：对关系模式进行必要的分解，提高数据操作的效率和存储空间的利用率。常用的两种分解方法是水平分解和处置分解。规范化评论为数据库设计人员判断关系模式优劣提供了理论标准，可用来预测模式可能出现的问题，使数据库设计工作有了严格的理论依据。设计用户子模式将概念模式转换为全局逻辑模型后，还应该根据局部应用需求，结合具体 DBMS 的特点，设计用户的外模式。目前关系数据库管理系统一般都提供了视图概念，可以利用这一功能设计更符合局部用户需要的用户外模式。定义数据库全局模式主要是从系统的时间效率、空间效率、易维护等角度出发。由于用户外模式与模式是相对独立的，因此在定义用户外模式时可以注意考虑用户习惯于方便。包括： 使用更符合用户习惯的别名： 可以对不同级别的用户定义不同的视图，以保证系统的安全性。 简化用户对系统的使用：如果某些局部应用中经常要使用某些很复杂的查询，为了方便用户，可以将这些复杂查询定义为视图，用户每次只对定义好的视图进行查询，大大简化了用户的使用。评审设计评审设计的主要内容是对概念模式的质量和性能进行评价，以便改进。 模式的评价： 数据模式的改进：数据库的物理设计数据库在物理设备上的存储结构与存取方法称为数据库的物理结构，它依赖于选定的数据库管理系统。为一个给定的逻辑数据模型选取一个最适合应用要求的物理结构的过程，就是数据库的物理设计。物理数据库设计的任务是在数据库逻辑设计的基础上，为每个关系模式选择合适的存储结构和存取路径。和逻辑模式不一样，它不直接面向用户。一般的用户不一定也不需要了解数据库存储模式的细节。所以数据库存储模式的设计可以不必考虑用户理解是否方便。数据库物理设计的目标有两个： 提高数据库的性能； 有效地利用存储空间。在这两个目标中，第一个目标更为重要，因为性能仍然是当今数据库系统的薄弱环节。总之，数据库物理设计是利用已确定的逻辑结构及 DBMS 提供的方法、技术、以较优的存储结构、数据存取路径、合理的数据存储位置及存储分配，设计出一个高效的、可实现的物理数据库结构。显然，数据库的物理设计是完全依赖于给定的硬件环境和数据库产品的。数据库的物理设计分为如下 4 个步骤： 分析影响数据库物理设计的因素； 为关系模式选择存取方法； 设计关系、索引等数据库文件的物理存储结构； 对物理结构进行评价，评价的重点是时间和空间效率。每个数据库管理系统都提供很多种存储结构和存取方法供数据库设计者选择。物理数据库设计与数据库管理系统密切相关。如果评价结果满足原设计要求，则可进入到物理实施阶段，否则，就需要重新设计或修改物理结构，有时甚至要返回逻辑设计阶段修改数据模型。由于不同的 DBMS 提供的硬件环境和存储结构、存取方法、以及提供给数据库设计者的系统参数、变化范围有所不同，因此，为了设计出一个较好的存储模式，设计者必须了解一下几方面的问题，做到心中有数。（1）了解并熟悉应用要求，包括各个用户对应的数据视图，即数据库的外模式（子模式），分清哪些是主要的应用，了解各个应用的使用方式，数据量和处理频率等，以便对时间和空间进行平衡，并保证优先满足应用的时间要求。（2）熟悉使用的 DBMS 的性能，包括 DBMS 的功能，提供的物理环境、存储结构、存取方法和可利用的工具。（3）了解存放数据的外存设备的特性，如物理存储区域的划分原则，物理块的大小等有关规定及 I/O 特性等。设计方法与内容在进行物理设计时，设计人员可能用到的数据库产品是多种多样的。不同的数据库产品所提供的物理环境、存储结构和存取方法有很大差别，能供设计人员使用的设计变量、参数范围也大不相同，因此没有通用的物理设计方法可遵循，只能给出一般的设计内容和原则。数据库物理设计包括数据存储结构的设计、集簇的设计、存取路径的设计和确定系统配置几个方面。 数据存储结构的设计： 集簇的设计： 存取路径的设计： 确定系统配置：影响物理设计的因素给定一个数据库逻辑模式和一个数据库管理系统，有大量的数据库物理设计策略可供选择。我们希望选择优化的数据库物理设计策略，使得各种事务的响应时间最小、事务吞吐率最大。要做出这样的选择，我们必须在选择存储结构和存取方法之前，对数据库系统支持的事务进行详细分析，获得选择优化数据库物理设计策略所需要的参数。对于数据库查询事务，我们需要得到如下信息： 要查询的关系； 查询条件（即选择条件）所涉及的属性； 连接条件所涉及的属性； 查询的投影属性。对于数据更新事务，我们需要得到如下信息： 要更新的关系； 每个关系上的更新操作的类型； 删除和修改操作条件所涉及的属性； 修改操作要更改的属性值。上述这些信息是我们确定关系的存取方法的依据。除此之外，我们还需要知道每个事务在各关系上运行的频率，某些事务可能具有严格的性能要求。例如，某个事务必须在 20 秒内结束。这种时间约束对于存取方法的选择具有重大的影响。我们需要了解每个事务的时间约束。如果一个关系的更新频率很高，这个关系上定义的索引等存取方法的数量应该尽量减少。这是因为更新一个关系时，我们必须对这个关系上的所有存取方法作相应的修改。值得注意的是，在进行数据库物理设计时，我们通常并不知道所有的事务。上述信息可能不完全。所以，以后可能需要修改根据上述信息设计的物理结构，以适应新事务的要求。存取方法的选择数据库系统是多用户共享的系统，对同一个关系要建立多条存取路径才能满足多用户的多种应用要求。物理设计的任务之一就是要确定选择哪些存取方法，即建立哪些存取路径。存取方法设计的目标是：提供访问每个记录类型或关系的存取方法，使得主要应用能对它们做最有效的访问，它包括文件结构和索引选择两个方面。 数据库访问类型虽然对数据库的访问要求是多种多样的，但就文件结构的选择而言，大致可分为三种类型： 访问文件的全部或相当多的记录：属于这类访问的应用一般要访问 20%~100% 的记录。 访问某一特定记录： 访问某些记录、 文件类型的选择有些 DBMS 是以操作系统的文件管理系统为其物理层的基础。但更多的 DBMS 是独立设计其物理层，其原因是：（1）DBMS 为了实现其功能，需要在文件目录、文件描述块、物理块等部分增加一些信息，传统的文件系统无此功能。（2）数据库中的文件为所有用户共享，要求其结构能兼顾多方面的要求，提供多种访问途径，提供并发控制、故障恢复和保密等方面的手段，而传统文件则无法满足这些要求。（3）传统文件系统主要面向批处理，在数据库系统中，往往要求及时访问、动态修改、要求文件结构能够适应数据的动态变化，提供快速访问路径。（4）若以操作系统中的文件系统为 DBMS 物理层的基础，则因 DBMS 对操作系统的依赖性，不利于 DBMS 的移植。何况，有些操作系统，如 UNIX，仅提供字符流的存取功能，不提供各种文件结构，只能靠 DBMS 本身来实现。（5）数据文件的数据量变化大，传统文件无法适应这样的变化。因此，DBMS 的文件结构虽然继承了文件系统的某些技术，但又与传统文件系统有区别。数据库物理设计不是设计和实现新的文件结构，而是在 DBMS 所提供的各种文件结构范围内，根据应用的要求和数据的特征，选择适当的文件结构。各个 DBMS 提供的文件结构和访问方法虽然有所不同，但常用的一般有以下几种： 直接文件（HASH）：在这种文件中，通过记录的关键字映射成记录的地址，直接访问该记录，与记录在文件中的文职及文件的大小无关，因此是随机的。郑重文件不但查找方便，插入、删除、修改也很方便。关于关键字到地址的转换用各种散列函数实现。直接文件虽然能快速随机地查找文件中的某些记录，但由于某些原因，在目前数据库系统中很少作为通用的访问方法，仅用于需要快速随机查询的场合，如数据字典的查询。影响直接文件在数据库系统中使用的原因主要有：（1）关键字所映射的地址空间并不取决于实际的数据量，而取决于关键字所映射的地址范围，因而往往造成存储空间的极大浪费。（2）不同的关键字可能映射到同一地址，对应每个映射地址有一个桶。当桶装满了，就会溢出，这时就要进行溢出处理，增加了访问的开销，若出现严重的溢出情况，就会使想能恶化。（3）只能通过关键字直接访问，访问方法比较单一，适用于上述第二种类型的某些访问，对于其他类型的访问就非常不便。（4）不便于处理变长记录。（5）对于通用的 DBMS 很难找到合适的、通用的散列函数。 堆文件：在这种文件结构中，记录按其插入的先后次序存放。记录可以存放在一个邻接的存储区中，也可以存放在多个不相邻接的存储区中，甚至可以存放在一个个物理上不相邻接的物理块中国，通过指针或逻辑地址到物理地址的映射表等机制连成一体。这种文件结构的优点是：建立容易，插入也很方便。缺点是：一般之鞥女采用顺序的扫描方式进行搜索。适宜于第一种类型的访问，对于其余两种类型的访问，效率很低，其次，删除、修改困难，一般在删除时只做删除标志，并不立即进行物理上的删除，以避免引起大量记录的移动，而是在积累了一定数量的删除记录后，再集中清理，一般小文件都用堆文件，因为对于小文件不值得提供其他复杂的访问机制，尤其当内存缓冲区较大时，有些小文件可直接调入内存处理，速度很快。对于大文件，堆文件主要用于第一种类型的访问。 索引文件：实际上，索引文件是在前述的堆文件上增加了索引。索引相当于一个映射机构，把某一键值转换为记录的地址。它与散列法的区别在于：索引法在有了记录后，才有索引项，才占有存储空间，因而不会浪费存储空间。当然，索引本身也要占用一定的空间，但索引键比记录本身要小得多，为此付出的代价是可以接受的。此外，索引键的选择也比较灵活，可以是单属性，也可以是多个属性的组合，而且还可根据需要建立多种或多级索引。索引文件按其是否根据索引键排序而分为顺序文件和非顺序文件。在堆文件的基础上加上索引后，既可利用原来的堆文件处理大量的记录，又可以利用索引访问个别记录，较好地满足了前述三种类型访问的需要，因而在数据库系统中得到了广泛应用，尤其是 B 树动态索引用得最多。 索引的选择原则上讲，索引选择可以采用穷举法，对每种可能的方案进行代价估算，从中选择最佳的方案，但实际上这是行不通的，其原因如下：（1）数据库中文件之间的相关性。例如，关系数据库中的连接操作涉及多个文件，在计算连接操作的代价时，往往在其他关系参与连接操作的方法有关，因而各个文件往往不能孤立地进行设计。（2）可能出现组合爆炸问题，难以进行计算。即使对于由五个文件组成的数据库，每个文件只有五个属性的话，如果在单个属性上建立索引，其存取结构的可能方案就有10的11次方之多。实际的数据库文件一般远远不止五个，每个文件的属性也不止五个，而且有可能需要在多个属性上建立索引，这样的求解空间显然太大了。（3）访问路径与 DBMS 的优化策略有关。一个事务究竟如何之赐你个，不仅取决于数据库设计者提供的访问路径，还取决于 DBMS 的优化策略。若设计者所认为的事务执行方式与 DBMS 实际执行事务的方式不同，就会出现设计结果与实际情况的偏差。（4）代价估算比较困难。首先因为代价模型与系统有关，很难形成一套通用的代价估算公式；其次，代价估算与数据库本身特性有关，为了获得必须的设计参数，必须对数据库进行统计分析，而在数据库设计阶段，对数据特性的了解往往是不充分的。（5）设计目标较为复杂。鉴于上述原因，很难进行比价精确、优化的数据库物理设计，目前常用的是一种简化了的设计方法，其思想和基本方法如下所述。有人分析了各种连接方法后认为，在一定条件的限制下，某些连接方法是可分离的，换句话说参与连接的各个关系的代价可以独立地估算，对于像嵌套循环法进行两个关系连接等不可分离的连接方法，即使按分离的方法处理，也不会引起显著的误差。因此，在进行数据库物理设计时，可以分别设计各个文件，从而避免了前面提到的组合爆炸问题，大大缩减了求解空间。该理论课称为可分离理论。按照可分离理论，根据处理要求，对记录在文件中的存放方式—有序或无序或按某一属性（或属性组）进行集簇等，做出初步的抉择，将在运行中进行适当调整，而不必穷军各种可能，从而把问题归结为一个文件要建立哪些索引。而且经过简单分析后，可确定在有些属性上不需要建立索引，当然也不需要进行代价分析和比较了，不需要建立索引的属性有： 在查找条件中不出现或很少出现的属性； 属性值很少的属性：因为对于这种情况，如果在其上建立属性，则在每个索引项后面会附有大量的 tid（元组标识符—此块号和记录在块中的地址组成），顺序索引集的溢出块将会很多，用索引去检索，不如直接进行顺序扫描。建立索引的一般原则为：（1）如果某个（或某些）属性经常作为查询条件，则考虑在这个（或这些）属性上建立索引。（2）如果某个（或某些）属性经常作为表的连接条件，则考虑在这个（或这些）属性上建立索引。（3）如果某个属性经常作为分组的依据列，则考虑在这个（或这些）属性上建立索引。（4）为经常进行连接操作的表建立索引。一个表可以建立多个索引，但只能建立一个聚簇索引。注意事项：索引一般可以提高查询性能，但会降低数据的修改性能。因为在修改数据时，系统要同时对索引进行维护，使索引与数据保持一致。维护索引要占用相当多的时间，而且存放索引信息也会占用空间资源。因此在决定是否建立索引时，要权衡数据库的操作，如果查询多，并且对查询的性能要求比较高，则可以考虑多建一些索引。如果数据更改较多，并且对更改的效率要求比较高，则应该考虑少建一些索引。总结：在手工设计时，一般按启发式规则选择索引。即使在数据库的计算机辅助设计工具中，也是先用启发式规则限制选择范围，在用简化的代价比较法选择索引。下面介绍用启发式规则选择索引的一般步骤：（1）凡是满足下列条件之一的属性或表，不宜建立索引： 不出现或很少出现在查询条件中的属性。 属性值很少的属性。例如属性“性别”只有两个值，若在其上建立索引，则平均起来，每个属性值对应一半的元组，用索引检索，还不如顺序扫描。 属性值分布严重不均的属性或表。因为更新时有关的索引需要做相应的修改。 过长的属性。例如超过 30 个字节。因为在过长的属性上建立索引，索引所占的存储空间较大，而索引级数也随之增加，有诸多不利之处。如果实在需要在其上建立索引，必须采取索引树荫属性压缩措施。 太小的表。例如小于留个物理块的表。因为采用顺序扫描最多也不过六次 I/O，不值得采用索引。（2）凡符合下列条件之一，可以考虑在有关属性上建立索引，下面所指的查询都是常用的或重要的查询。 主键码和外键码上一般都建有索引，这有利于主键码位移性检查和引用完整性约束检查；主键码和外键码通常都是连接条件中的公共属性，建立索引，可显著提高连接查询的效率。 对于以读为主或只读的表，只要需要，存储空间又允许，可以多建索引。 对于等值查询（即查询条件以等号为比较符），如果满足条件的元组是少量的，例如小于 5%，且存储空间允许，可以考虑在有关属性上建立索引。 对于范围查询（即查询条件以&lt;、&gt;等为比较符），可以在有关的属性上建立索引。 有些可以从索引直接得到结果，不必访问数据块。对于这种查询，在有关属性上建立索引是有利的。上述选择索引的规则仅仅是原则性的。也许有些索引既有建立的理由，又有不宜建立的理由，这只能由设计者权衡。好在数据库在运行以后，还可以调整。有些索引一时难以决定是否建立，可以等到运行时通过实验来确定。 聚簇存取方法的选择为了提高某个属性（或属性组）的查询速度，把这个或这些属性（称为聚簇码）上具有相同值的元组集中存放在连续的物理块称为聚簇。聚簇方法是把经常进行连接操作的多个关系的记录以连接属性为中心分类存储。聚簇方法可以提高连接操作的效率。聚簇功能不但适用于单个关系，也适用于经常进行连接操作的多个关系。即把多个连接关系的元组按连接属性值聚集存放，聚簇中的连接属性称为聚簇码。这就相当于把多个关系按“预连接”的形式存放，从而大大提高连接操作的效率。一个数据库可建立多个聚簇，一个关系只能加入一个聚簇。选择聚簇存取方法，即确定需要建立多少个聚簇，每个聚簇包含哪些关系。下面先设计候选聚簇，一般来说： 对经常在一起进行连接操作的关系可以建立聚簇； 如果一个关系的一组属性经常出现在相等比较条件中，则该单个关系问题可建立聚簇； 如果一个关系的一个（或一组）属性上的值重复率很高，则此单个关系可建立集簇。即对应每个集簇码值的平均元组数不太少。太少了，集簇的效果不明显。然后检查候选聚簇中的关系，取消其中不必要的关系： 从聚簇中删除经常进行全表扫描的关系； 从聚簇中删除更新操作远多于连接操作的关系； 不同的聚簇中可能包含相同的关系。一个关系可以在某一个聚簇中，但不能同时加入多个聚簇。要从这多个聚簇方案（包括不建立聚簇）中选择一个较优的，即在这个聚簇上运行各种事务的总代价最小。必须强调的是，聚簇只能提高某些应用的性能，而且建立与维护聚簇的开销是相当大的。对已有关系建立聚簇，将导致关系中元祖移动其物理存储位置，并使此关系上原有的索引无效，必须重建。当一个元祖的聚簇码值改变时，该元组的存储位置也要做相应移动，聚簇码值要相对稳定，以减少修改聚簇码值所引起的维护开销。因此，当通过聚簇码进行访问或连接是该关系的主要应用，与聚簇码无关的其他访问很少或者是次要的，这时可以使用聚簇。尤其当 SQL 语句中包含有与聚簇码有关的 ORDERBY，GROUP BY，UNION，DISTINCT 等子句或短语时，使用聚簇特别有利，可以省去对结果集的排序操作；否则很可能会适得其反。 HASH 存取方法的选择有些数据库管理系统提供了 HASH 存取方法。选择 HASH 存取方法的规则如下：如果一个关系的属性主要出现在等值连接条件中或主要出现在相等比较选择条件中，而且满足下列两个条件之一，则此关系可以选择 HASH 存取方法： 如果一个关系的大小可预知，而且不便； 如果关系的大小动态变化，而且数据库管理系统提供了动态 HASH 存取方法。物理存储结构设计物理存储结构设计的目的是确定如何在磁盘存储器上存储关系、索引和聚簇，使得空间利用率最大化，数据操作引起的系统开销最小化。确定数据库物理结构主要指确定数据的存放位置和存储结构，包括：确定关系、索引、聚簇、日志、备份等的存储安排和存储结构，确定系统配置等。确定数据的存放位置和存储结构要综合考虑存取时间、存储空间利用率和维护代价 3 个方面的因素。这 3 个方面常常是相互矛盾的，因而需要进行权衡，选择一个折中方案。确定数据的存放位置：为了提高系统性能，应该根据应用情况将数据的易变部分，经常存取部分和存取效率低部分分开存放。例如，目前许多计算机有多个磁盘或磁盘阵列，因此可以将表和索引放在不同的磁盘上，在查询时，由于磁盘驱动器并行工作，可以提高物理 I/O 读写的效率；也可以将比较大的表分放在两个磁盘上，以加快存取速度，这在多用户环境下特别有效；还可以将日志文件与数据库对象（表、索引等）放在不同的磁盘上，以改进系统的性能。由于各个系统所能提供的对数据进行物理安排的手段、方法差异很大，因此设计人员应子了解给定的 RDBMS 提供的方法和参数，针对应用环境的要求，对数据进行适当的物理安排。确定系统配置：DBMS 产品一般都提供了一些系统配置变量、存储分配参数，供设计人员和 DBA 对数据库进行物理优化。初始情况下，系统都为这些变量赋予合理的默认值。但是这些值不一定适合每一种应用环境，在进行物理设计时，需要重新对这些变量赋值，以改善系统的性能。系统配置变量很多，例如，同时使用数据库的用户数，同时打开的数据库对象数，内存分配参数，缓冲区分配参数（使用的缓冲区长度、个数），存储分配参数，物理块的大小，物理装填因子，时间片大小，数据库的大小，锁的数目等。这些参数影响存取时间和存储空间的分配，在物理设计时就要根据应用环境满足这些参数值，以使系统性能最佳。在物理设计时对系统配置变量的调整只是初步的，在系统运行时还要根据系统实际运行情况做进一步的调整，以期切实改进系统性能。磁盘空间管理：由于物理存储结构的设计包含的方面非常广泛，而且不同的数据库管理系统对磁盘空间管理的策略差别很大，所以下面以分区的设计来简单介绍物理存储结构设计。数据库系统一般有多个磁盘驱动器，有些系统还带有磁盘阵列。数据在多个磁盘组上的分布也是数据库物理设计的内容之一，这就是所谓分区设计。下面是分区设计的一般原则。 减少访盘冲突，提高 I/O 的并行性多个事务并发访问统一磁盘组时，会因访盘冲突而等待。如果事务访问的数据分布在不同的磁盘组上，则可并行地执行 I/O，从而提高数据库的效率。从减少访盘冲突、提高 I/O 并行性的观点来看，一个关系最好不要放在一个磁盘组上。而是水平分割成多个部分，分布到多个磁盘组上。分割在表面上看似乎与聚集是矛盾的，实际上聚集是把聚集（聚簇）属性相同的元组在同一磁盘上存放，以减少 I/O 次数；分割是将整个关系分布到不同的磁盘组上，利用并行 I/O 提高性能。然而两者是相辅相成的。分割的策略决定与查询的特征，可以按属性值分割，也可以不按属性值分割，例如按元组的输入次序轮流存放到各个磁盘组上。 分散热点数据，均衡 I/O 负责实践证明，数据库中的数据被访问的频率是很不均与的。经常访问的数据，称为热点数据。热点数据最好分散存放在各个磁盘组上，以均衡各个磁盘组的负荷，充分发挥多个磁盘组并行操作的优势。 保证关键数据的快速访问，缓解系统的瓶颈在数据库系统中，有些数据，例如数据目录，是每次访问的“必经之地”。其访问速度影响整个系统的性能。还有些数据从应用的必须来说，对性能的要求特别高，例如某些实时控制数据，这些数据要优先分配到快速磁盘上。有时甚至为减少访盘冲突，宁可闲置一些存储空间，将某一磁盘组供其专用。ORACLE 磁盘空间管理方法：ORACLE 中的最基本数据单位是存储记录。存储记录是与一个关系元组有关的数据项集合，除了用户数据以外，存储记录还包括必要的指针、记录长度和其他的系统所需要的管理信息。物理存储块是磁盘读写的基本单位。每个物理存储块可以存储多个记录。由一个或多个连续的物理存储块组成的存储空间称为数据域。与关系、索引、聚集等数据库对象相对应的存储结构称为数据段，由一个或多个数据域构成。构成数据段的数据域可以具有相同或不同的长度。数据段存储在数据库文件中。一个数据库文件可以包含多个数据快中的数据。一个数据段可以属于多个数据库文件。一个数据库文件对应一个操作系统文件。一个或多个数据库文件形成一个数据库分区。数据库分区是物理数据库的逻辑划分。一个物理数据库可以包括一个或多个数据库分区。一个数据库分区只能属于一个物理数据库。评价物理设计与性能预测数据库物理设计过程中想哟啊对时间效率、空间效率、维护代价和用户要求进行权衡，其结果可以产生某种方案。数据库设计人员必须对这些方案进行细致的评价，从中选择一个较优的方案作为数据库的物理结构。评价物理数据库的方法完全依赖于所选用的 DBMS，主要是从定量估算各种方案的存储空间、存取时间和维护代价入手，对估算结果进行权衡、比较，选择出一个较优的合理的物理结构。如果该结构不符合用户需求，则需要修改设计。估算代价是非常复杂的，目前数据库物理设计主要还是采用启发式的方法，即根据一般的原则和设计要求，运用 DBMS 提供的各种手段，设计出初步方案，通过基准程序测试进行调整。评价物理结构设计完全依赖于具体的 DBMS，主要考虑操作开销，即为使用户获得及时、准确的数据所需的开销和计算机的资源开销。具体可分为以下几类： 查询和响应时间：响应时间是从查询开始到查询结果开始显示锁经历的时间。一个设计得好的应用程序可以减少 CPU 时间和 I/O 时间。 更新事务的开销：主要是修改索引、重写物理块或问价，以及写校验等方面的开销。 生成报告的开销：主要包括索引、重组、排序和显示结果的开销。 主存储空间的开销：包括程序和数据所占用的空间。一般对数据库设计者来说，可以对缓冲区做适当的控制，包括控制缓冲区个数和大小。 辅助存储空间的开销：辅助存储空间分为数据块和索引块两种，设计者可以控制索引块的大小、索引块的充满度等。实际上，数据块设计者只能对 I/O 服务和辅助空间进行有效控制。对于其他的方面则只能进行有限的控制或者根本不能控制。数据库实施与维护数据库的物理设计完成之后，既可以进入数据库的实施阶段，设计人员用 DBMS 提供的数据定义语言和其他应用程序将数据库逻辑设计和物理设计结果严格描述出来，称为 DBMS 可以接受的源代码，再经过调试产生目标模式，然后就可以组织数据入库了。数据库实施阶段的两项重要工作就是数据的载入和应用程序的编码与调试。数据库实施根据数据库的逻辑设计和物理设计结果，在计算机系统上建立实际的数据库结构装入数据、进行测试和试运行的过程称为数据库的实施。 建立实际数据库结构用护体的数据库管理系统提供的数据定义语言把数据库逻辑设计和物理设计的结果严格描述出来，作为 DBMS 可以接受的源模式，通过 DBMS 编译成目标模式，执行之后实际的数据库结构就建立起来了。 装入实验数据，调试应用程序实验数据可以是实际的数据，也可以是随机的数据。但测试数据应尽可能充分反映现实世界的各种情况，这样才能确定应用程序的功能是否满足设计要求。 装入实际数据数据库系统的数据量通常都很大，所以，一般都是通过系统提供的使用程序或专门的录入程序来完成装入数据的工作。其实，在装入数据之前往往还有大量的数据整理工作。这是由于数据库作为共享资源，面对的是不同的用户、不同的应用，因此数据来自各个方面，难免在数据的结构、格式与新设计的数据库系统有相当的差距。 进入试运行当有部分数据装入数据库以后，就可以对数据库系统进行联调，这个过程称为数据库的试运行。在试运行阶段，除了对应用程序做进一步调试之外，重点是执行对数据库的各种操作，实际测量系统的性能指标，检查是否达到设计要求。若发现问题，则应回过来修改物理结构、甚至修改逻辑结构。数据加载数据是数据库系统最基础最重要的资源。数据加载是在数据库结构建立后，将试运行数据或实际运行数据载入数据库的过程。数据加载是数据库实施阶段最主要的工作。 数据加载的准备数据加载前的准备工作是十分重要的数据库系统建设的基础工作。数据的可靠和正确是数据库系统应用的基本要求，“进去是一堆垃圾，出来还是一堆垃圾”是对数据库系统建设的重要警训。由于数据库存储的数据量一般都很大，且分散在众多的组织和部门中的各种文件和凭证上，还有可能提前准备和进行必要的转换。数据的准备和转换工作细致且繁杂，是一项十分机械且耗费时间和人力的工作，必须制定详细的极化和时间表，并进行数据加载前的组织工作和人员培训。 数据加载的方法数据的加载有两种不同的形式：一种是数据的手工录入和加载，即从原始的凭证上录入相应数据，经验检查合格后写入数据库；另一种是已经存放在文件系统或原有数据库中的数据，需要进行转换。转换的方法也有两种：一种是数据库管理系统已经提供必要的转换手段，即有转换程序，可利用转换程序进行数据的转换；另一种是需要数据库管理员自己编织转换程序来实现数据的转换。而后一种可能是经常使用的方法。数据输入的自动化方法编制好或由系统提供输入程序，其主要功能包括：原始数据的输入、抽取、校验、分类、转换和综合，最后提供符合数据库结构要求且正确无误的数据，并把这些数据存入数据库中。输入程序可能是一类复杂的程序，因为其适应的数据种类和应完成的任务较为繁杂，需要编写许多应用程序才能完成任务。且输入程序的设计还必须在数据库物理设计时开始着手进行，即进行并行开发，这样才能相互配合，并能及时开始输入工作。 数据加载正确性保证由于要如可的数据在原来系统中的格式结构与新系统中的不完全一样，有的差别可能还比较大，不仅向计算机内输入数据时发生错误，转换过程也有可能出错。因此在源数据入库之前要采用多种方法对它们进行正确性检查，以防止不正确的数据入库，这部分的工作在整个数据输入子系统中是非常重要的。当然，不同的数据对象应有不同的检查力度。有的数据应在输入过程中进行多次检查，每次检查所采用的方法和检查的重点是不相同的，这样才能尽可能地保证入库后的正确性和可用性。数据加载的正确性是保证数据库数据正确的重要措施，也是最基础性的工作，一旦数据垃圾进入数据库中，则以后的数据加工都将毫无意义。另外，在设计数据输入子系统时还要注意原有系统的特点。例如对于原有系统是人工数据处理系统的情况，尽管新系统的数据结构可能与原系统有很大差别，在设计数据输入子系统时，还是要金陵让用户以原系统结构相近的形式输入源数据，这不仅可使用户鞥呢方便地处理手工文件，更重要的是能减少用户出错的机会，保证数据输入的质量。现有的 DBMS 一般都提供将市场上比较流行的 DBMS 产品的数据转换到本系统的工具，对于原有系统是数据库系统的情况，就可以利用新系统数据库的数据转换工具，先将原系统中的表转换到新系统中相同结构的临时表中，再将这些表中的数据分类、转换、综合成符合新系统中数据结构的数据，然后插入到新系统相应的表中。在数据库结构设计过程中，对数据库应用程序的设计是同时进行的，因此在组织数据入库的同时还要调试应用程序。 程序排错方法程序排错是程序测试后开始的工作，它确定测试中锁发现错误的性质和位置并修改错误。排错方法有多种，但在理论和方法上还不成熟。简单排错法人工转储、打印并人工检查、确定错误的性质和位置。借助排错工具，插入打印语句，设置断点，跟踪语句的执行，确定程序执行正确与否。简单排错方法属于类排错方法，其有效性较低，且依赖于测试人员的经验和水平。归纳排错法从特殊到一般的归纳对问题进行分析和思考，其过程可归纳为：通过实例运行结果，寻找线索，从线索（一个或多个测试实例的执行结果所反映的错误征兆）和线索之间的联系出发作归纳分析，从而确定错误。其步骤可归纳如下： 寻找适当数据:通过实例运行，查找与错误征兆有关的信息，并集中为线索。主要内容是列出程序已经正确做了什么的全部信息。 组织数据：列出错误征兆数据结构，如可列出表格。表中记载的信息包括：列出错误征兆、观察到征兆的位置、发生征兆的时间、征兆的范围和数量。 研究线索，给出猜想：利用线索及线索间的关系，给出一个或多个引起错误的猜想。 证明猜想：将猜想线索做分析对比。使全部的错误征兆和线索都得到解释，否则猜想失败。演绎排错法从一般推测触发，使用逐步求精方法去获得错误的性质和位置，其步骤可归纳为： 列出猜测构造数据：写出全部想到的原因/推测，它们可能是不完全的、是猜测性的，通过猜测收集构造有用数据。 清除原因：通过已有数据的分析，寻找矛盾，消除全部可能的原因，若全清除，则需要考虑新的原因，设计和运行新的测试。若还剩有未消除原因，则选择可能性最大的原因。 原因求精：定义和完善未清除原因，做定义和补充、求精。反向搜索排错法或称回溯法，从程序产生不争取的结果出，沿逻辑路径反向搜索，知道发现程序错误为止。测试拍错发从测试实例发现的错误征兆出发，对实例做某些修改，再做测试，通过两次测试结果比价，通常可找到有用的排错信息。在确定错误的性质和位置时，应考虑到某些心理因素和吸收必要的经验，以利于提高工作效率和质量。 通过思考分析错误征兆可找出大部分产生的原因； 当遇到难以立即解决的困难时，应立即停止，从而使自己走出困境； 分析错误产生的原因时可以采用工具，但工具必须配合思考才能有效； 盲目的试验对于发现错误是作用不大的。以上这些经验在进行程序拍错时可以借鉴。在修改已经发现的错误时可参考以下经验： 错误往往具有密集性，当在某程序段出现了错误时应注意邻近搜索； 修改错误时是修改错误而不应是修改征兆； 修改后的程序还可能出错，必须进行回归测试； 应该修改源代码而不是修改目标代码； 错误修改本身也是编码，应使用可用的程序设计方法。 测试与排错的关系测试与排错是相互联系但又是性质和目的不同的两类活动，它们之间存在差别，了解和区别这种差别有利于对程序进行整体的调试。 实施的时间不同：测试应在排错之前进行，排错一般只有在发现错误征兆后才能有效地进行； 根本目的不同：测试的根本目的是证明程序存在错误，而排错是将错误的程序修改成正确的程序；测试的目的主要是去揭露程序中隐含的错误，而排错则是去改正程序中已发现的错误。 出发条件不同：测试是从已知条件出发，使用预定的方法，并有事先期望的测试结果，但其结果是不可预测的。而排错则是从未知初始条件出发，即在错误的性质、位置和范围未知的情况下进行，其结果亦不可预测。 安排计划不同：测试可以事先安排计划，指定日程表，使其按计划进行，而排错的方法、时间和结果都难以事先确定。 性质不同：测试的性质有些类似于程序正确性证明，而排错的方法是基于推理和归纳的。 测试的进行是一种严格的、机械的且是强制性的方法和过程，一般其结果是可以预测的。 行为人不同： 一般的测试可以也应该由专门的测试人员来完成，而排错一般则要依靠程序人员来完成。 完善性不同：软件测试已经建立了较完整的方法和理论，而排错则具有很大的任意性，在很大程度上还要依靠程序人员的经验、个人的能力和认真态度。了解程序测试与程序拍错的关系和区别，将有利于程序正确性保证措施的实施，即计划的指定和人员的组织，切实和有效地提高程序的质量。数据库试运行将原有系统的一小部分数据输入数据库后，就可以开始对数据库系统进行联合调试了，这称为数据库的试运行，数据库的试运行是数据库正式运行前必须完成的工作。 数据库试运行的准备建立数据库结构后，由数据录入和转换程序将数据加载到数据库中，并建立起对数据进行加工的应用程序。有了数据和程序的准备，数据库系统才能具备试运行的条件。 数据库试运行的任务数据库在试运行阶段应实施的工作内容包括： 运行应用程序，执行数据库的各种操作，进一步验证和测试应用程序的功能。 做数据库应用系统的性能测试，分析是否达到在数据库物理设计中所预测的性能指标。前者为综合性地在试运行中对系统的功能做进一步的验证；后者更着重性能指标的验证，要通过系统的试运行分析系统在总体上是否达到了设计要求。试运行的结果经分析和总结后，可能有两种结果：一种是符合设计要求，另一种是不完全符合设计要求，特别是性能指标的要求。若是后者则必须回到屋里设计阶段进行修改，如调整物理结构、修改系统参数等，有时甚至返回到逻辑设计阶段，即调整逻辑结构。上述情况之所以会产生的原因，往往是在性能预测中，会对实际可能产生的复杂情况难以事先准确估计，一般只是近似的估计或在估计中忽略了某些看来是次要的因素，致使其粗糙和失真，与实际系统运行相比存在一定的差距，要避免上述可能的失误，经验是十分重要的。 数据库试运行的实施数据库试运行是为数据库运行提供条件，发现和改进系统，并使系统达到可运行的水平。其实施方式可以是满负荷运行，即数据全部加载后试运行，也可以是分期分批输入数据，先输入小批量数据做调试用，待运行负荷要求后再大批量输入数据，逐步增加数据量，最后加载全部数据。后者是常采用的方法。由于数据库系统的建立，特别是大型复杂的数据库系统的建立，包括试运行都是一项复杂的工作，即使是试运行也可能有反复，而不能一次成功。试运行期间可能出现的问题是多样的。诸如，软件和硬件的错误，操作的错误等，为了保证试运行的进行，必须做好数据库的转储以利于恢复。在数据库试运行阶段，由于系统还不稳定，硬、软件故障随时都可能发生。而系统的操作人员对新系统还不熟悉，误操作也不可避免，因此应首先调试运行 DBMS 的恢复功能，一旦故障发生，能使数据库尽快恢复，尽量减少对数据库的破坏。数据库运行与维护数据库试运行合格后，数据库开发工作就基本完成，即可投入正式运行了。但是，由于应用环境在不断变化，数据库运行过程中物理存储也会不断变化。对数据库设计进行评价、调整、修改等维护工作是一个长期的任务，也是设计工作的继续和提高。在数据库运行阶段，对数据库经常性的维护工作主要是由 DBA 来完成的，它包括： 数据库的转储和恢复 数据库的安全性、完整性控制：在数据库运行过程中，由于应用环境的变化，对安全性的要求也会发生变化，加入有的数据原来是机密的，现在是可以公开查询了，而新加入的数据又可能是机密了。而系统中用户的密级也会改变。这些都需要 DBA 根据实际情况修改原有的安全性控制。同样，数据库的完整性约束条件也会变化，也需要 DBA 不断修正，以满足用户要求。 数据库性能的监督、分析和改进：在数据库运行过程中，监督系统运行，对检测数据进行分析，找出改进系统性能的方法是 DBA 的又一重要任务。目前有些 DBMS 产品提供了检测系统性能参数的工具，DBA 可以利用这些工具方便地得到系统运行过程中一系列性能参数的值，DBA 应仔细分析这些数据，判断当前系统运行状况是否是最佳，应当做哪些改进，例如调整系统物理参数，或对数据库进行重组织或重构等。 数据库的重组织与重构造：关系数据理论针对一个具体问题，应该如何构造一个适合于它的数据模式，即应该构造几个关系模式，每个关系由哪些属性组成等。这是数据库设计的问题，确切地讲是数据库逻辑设计问题。实际上设计任何一种数据库应用系统，不论是层次的、网状的还是关系的，都会遇到如何构造合适的数据模式即逻辑结构的问题。由于关系模型有严格的数学理论基础，并且可以向别的数据模型转换，因此，人们就以关系模型为背景来讨论这个问题，形成了数据库逻辑设计的一个有力工具—关系数据库的规范化理论。规范化理论虽然是以关系模型为背景，但是它对于一般的数据库逻辑设计同样具有理论上的意义。非规范化关系模式的问题关系数据库是由一组关系组成的，所以关系数据库的设计归根到底是如何构造关系，即如何把具体的客观事物划分为几个关系，而每个关系又由哪些属性组成。在我们构造关系时，经常会发现数据冗余和更新异常等现象，这是由关系中各属性之间的相互依赖性和独立性造成的。关系模型的形式化定义一个关系模式应当是一个五元组：R(U,D,DOM,F)这里： 关系名 R，它是符号化的元组定义； 一组属性 U； 属性组 U 中属性锁来自的域 D； 属性到域的映射 DOM； 属性组 U 上的一组数据依赖 F。由于第3、4点对模式设计关系不大，因此可暂且把关系模式看作是一个三元组：R&lt;U,F&gt;当且仅当 U 上的一个关系 r 满足 F 时，r 称为关系模式 R&lt;U,F&gt;的一个关系。关系作为一张二维表，对他有一个最起码的要求：每一个分量必须是不可分的数据项。满足了这个条件的关系模式就属于第一范式（1NF）。在模式设计中，面对同一个问题具有多个解决方案和模式设计，哪个“更好”呢？这属于函数依赖和规范化问题。非规范化造成的问题但是，这个关系模式存在以下问题： 数据冗余太大：比如，每一个系主任姓名重复出现，重复次数与该系所有学生的所有可能成绩出现次数相同，如表 6.1 所示。这将浪费大量的存储空间。 更新异常：由于数据冗余，当更新数据库中的数据时，系统要付出很大的代价来维护数据库的完整性，否则会面临数据不一致的危险。比如，某系更换系主任后，必须修改与该系学生有关的每一个元组。 插入异常：如果一个系刚成立，尚无学生，就无法把这个系及其系主任的信息存入数据库。 删除异常：如果某个系的学生全部毕业了，在删除该系学生信息的同时，把这个系及其主任的信息也丢掉了。鉴于存在以上种种问题，我们可以得出这样的结论：Student 模式不是一个好的模式。一个“好”的模式应当不会发生插入异常、删除异常、更新异常，数据冗余应尽可能少。要想设计一个“好”模式就需要规范化理论支持。问题的根源 完全依赖与部分依赖： 传递依赖：函数依赖为了便于了解函数依赖的概念，先看一个具体的关系实例。函数依赖的严格定义：关系的键码之前说过键码的概念，本节从函数依赖的角度给出严格的定义。键码定义：键码的确定过程：超键妈函数依赖规则三个函数依赖规则： 分解/合并规则： 平凡依赖规则： 传递规则：计算属性的封闭集（或闭包）计算过程：例子：规范化关系数据库理论的意图是消除数据库中发生的异常。而规范化是消除异常的有效方法。范式 第一范式： 第二范式：概念解读例子：模式分解：分解实例：一个关系模式 R 不属于 2NF，就会产生插入、删除异常，修改复杂等问题。 第三范式：例 1：例 2：一个关系模式 R 不属于 3NF，就会产生插入、删除异常，修改复杂等问题。 BC 范式（BCNF）例子：小结：由 BCNF 的定义可以得到结论，一个满足 BCNF 的关系模式有： 所有非主属性对每一个码都是完全函数依赖； 所有的主属性对每一个不包含它的码，也是完全函数依赖； 没有任何属性完全函数依赖于非码的任何一组属性。3NF 和 BCNF 是在函数依赖的条件下对模式分解所能达到的分离程度的测度。一个模式中的关系模式如果都属于 BCNF，那么在函数依赖范畴内，它已实现了彻底的分离，已消除了插入和删除的异常。3NF 的“不彻底”表现在可能存在主属性对码的部分依赖和传递依赖。分解的原则模式分解例子：模式分解的两个原则：从上面例子可以看出，对模式的分解显然不是随意的。主要涉及两个原则： 无损连接： 保持依赖：所以，在实际应用中，对模式分解的要求并不一定要达到 BC 范式，有时达到第三范式就足够了。分解的方法 模式分级的两个规则： 公共属性共享： 相关属性合一： 模式分解的三种方法： 方法一：部分依赖归子集；完全依赖随键码例子： 方法二：基本依赖为基础，中间属性做桥梁 方法三：找违例自成一体，舍其右全集归一；若发现仍有违例，再回首如法炮制模式分解为 BC 范式的方法：例子：小结：关系模式规范化小结多值依赖属性独立性带来的冗余多值依赖的定义定义：例子：第四范式如果把多值依赖用于新的关系分解算法中，那么由多值依赖引起的冗余是可以清除的。在第四范式（4NF）里，随着违背 BC 范式的所有函数依赖的清除，所有的“非平凡”多值依赖也都清除了。定义：定义解读实例：分解成第四范式例子：小结：第五范式当实体是第四范式的并且在实体的候选码中没有连接依赖时，此实体就是第五范式（也叫做工程连接范式）的。当我们使用规范化规则分解实体时，应该能够重新构造原始实体。重构造的实体应该保持连接以保证无数据丢失和不产生多余的（往往是不正确的）数据，就叫做无损连接。如果一个实体不能被分解成更小的几个实体，而且每个实体有不丢失数据的、来自原始实体的不同码，则此实体就是第五范式的实体。如果数据在分解后丢失了，则就不可能是无损连接，如果所有被分解的实体使用原始实体中的某个候选码作为其码，那么这些实体的连接后的结果是一个无损连接。注意：第三范式之上的范式在很大程度上是理论上研究的问题，作为实践，第三范式是产品数据库的规范化的终点。" }, { "title": "操作系统基础", "url": "/2016/11/OS-basic.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2016-11-05 18:04:05 +0800", "snippet": " 操作系统是应用软件的运行环境，只要深入了解操作系统才能进一步优化应用程序，并充分利用操作系统提供的便利性和高效性，而且操作系统中采用的一些策略在开发应用程序时也是可以借鉴的。 概述 计算机发展史 操作系统资源管理 操作系统的基础抽象 虚拟计算机 操作系统的作用与功能 ...", "content": " 操作系统是应用软件的运行环境，只要深入了解操作系统才能进一步优化应用程序，并充分利用操作系统提供的便利性和高效性，而且操作系统中采用的一些策略在开发应用程序时也是可以借鉴的。 概述 计算机发展史 操作系统资源管理 操作系统的基础抽象 虚拟计算机 操作系统的作用与功能 操作系统的主要特性 处理器（进程和线程）管理 程序的顺序执行 进程 进程的特点 进程的状态和转换 进程描述 进程切换与模式切换 进程控制 线程 处理器调度 调度时机 分级调度 调度算法的评价及准则 调度算法分类 调度机制 调度算法 批处理系统中的调度算法 交互式系统中的调度 实时系统调度 多处理机调度算法 进程间关系 进程的交互 临界资源 进程同步机制 经典同步问题 管程（进程高级同步） 进程通信 信号通信机制 管道通信机制 共享主存通信机制 消息传递机制 消息缓冲队列通信机制 死锁 死锁原因 资源分配图 解决死锁问题的基本方法 死锁的预防 死锁避免 死锁检测与解除 综合的死锁策略 内存管理 概述 内存管理需求 存储管理功能 用户程序 连续分配存储管理方式 单道程序的连续分配 固定分区分配方式 动态分区 可重定位分区（紧缩） 伙伴系统 空闲内存管理 基于位图的存储管理 基于链表的存储管理 内存不足的存储管理技术 移动技术（主存紧凑） 对换技术 覆盖技术 基本分页存储管理 存储空间划分（分页） 地址映射（页表） 快表（TLB） 页表结构（或组织方式） 基本分段存储管理方式 分段存储管理方式的引入 段的特点 分段系统的基本原理 段页式存储管理方式 基本原理 地址转换 管理算法 虚拟存储器 虚拟存储器的引入（局部性原理） 虚拟存储器的实现方法 虚拟存储器的特征 请求分页存储管理方式 请求分页中的硬件支持 请求分页的基本原理 请求分页的内存分配 调页策略 页面置换算法 缺页中断率 最佳置换算法 先进先出(FIFO)页面置换算法 最近最久未使用(LRU)置换算法 LRU 近似页置换 最少使用置换算法 页面缓冲算法 工作集替换算法 分页系统颠簸 系统颠簸的原因 颠簸防止 请求分段存储管理方式 请求分段中的硬件支持 共享段 分段保护 请求段页式虚拟存储管理 设备管理 I/O 系统概述 I/O 设备类型 设备与控制器之间的接口 设备控制器 内存映射 I/O I/O 通道 I/O 数据传输控制方式 程序直接控制方式 中断驱动 I/O 控制方式 DMA 控制方式 通道方式 缓冲管理 缓冲引入的原因 单缓冲 双缓冲 循环缓冲 缓冲池 I/O 软件 I/O软件的设计目标和原则 中断处理程序 设备驱动 设备独立性软件 用户层的 I/O 软件 设备分配 设备分配中的数据结构 设备分配时应考虑的因素 独占设备的分配程序 SPOOLing 技术 磁盘存储器的管理 磁盘性能概述 磁盘访问时间 坏扇区的处理 稳定存储器 磁盘调度 先来先服务 最短寻道时间优先 扫描(SCAN)算法 循环扫描(CSCAN)算法 NStepSCAN 和 FSCAN 调度算法 磁盘 I/O 速度的提高 磁盘高速缓存 提高磁盘I/O速度的其它方法 廉价磁盘冗余阵列 文件管理 文件 文件概述 文件命名 文件类型 文件操作 文件的逻辑结构 文件逻辑结构的类型 堆 顺序文件 索引文件 索引顺序文件 直接文件 哈希(Hash)文件 外存分配方式 连续分配 链接分配 索引分配 混合索引分配方式 目录管理 文件控制块 索引结点 目录结构 目录查询技术 文件存储空间的管理 空闲表法 空闲链表法 位示图法 成组链接法 文件共享 基于索引结点的共享方式 利用符号链实现文件共享 磁盘容错技术 第一级容错技术SFT-Ⅰ 第二级容错技术 SFT-II 基于集群技术的容错功能 数据一致性控制 事务 检查点 并发控制 重复数据的数据一致性问题 虚拟文件系统 操作系统接口 系统调用 系统态和用户态 系统调用的基本概念 系统调用的实现 中断和陷入硬件机构 系统调用的处理步骤 系统调用处理子程序的处理过程 计算机软件大致可以分为两类，即系统软件和应用软件。系统软甲负责管理计算机本身的运作，而应用软件则负责完成用户所需要的各种功能。最基本的系统软件是操作系统，它负责管理计算机的所有资源并提供一个可以在其上编写应用程序的平台。概述下面先给出计算机系统层次图：上图中的微体系结构是用于解释执行机器语言指令的，一条机器语言指令可能对应一段微程序（详细请参考“计算机组成原理”CPU相关章节）。所谓操作系统，一般是指在内核态（或称为管态）下运行的软件，它受到硬件的保护，用户不能随便去篡改它的内容。不过，要想在操作系统和其他系统软件之间画上一条清晰的边界，是比较困难的。因为有些运行在用户态的程序也可以视为操作系统的一部分，至少跟它是密切相关的。从自顶向下的观点出发，操作系统可以认为是一台虚拟机（相对于裸机而言）；从自底向上的观点而言，操作系统可以视为资源管理器（如计算机硬件资源和软件资源等）。资源管理主要包括两种形式的资源共享： 时间上的资源共享：它是指，各个程序或用户轮流使用该资源。这是资源的重复利用和分时利用的特性。 空间上的资源共享：它是指，每个程序不是轮流去使用资源，而是把资源划分为若干份，然后分配给各个程序。这是资源的局部同时可用的特性，利用该特性可以虚拟出多台同样的逻辑设备。计算机发展史 第一代计算机：真空管和插接板最早的机器使用的是机械继电器，速度非常慢，周期时间的计量单位是秒。后来这些继电器被真空管所取代。不过真空管体积过大，运算速度也不快。在计算机出现的早期，每台机器都由一个专门的小组来设计、制造、编程、操作和维护。编程全部采用机器语言。后来，出现了穿孔卡片，这时不再使用插接板，而是将程序写在卡片上，然后读入计算机，但其他过程则依然如此。 第二代计算机：晶体管和批处理系统集体管的使用使得计算机已经比较可靠，这时第一次出现了设计人员、生产人员、操作员、程序员和维护人员的分开。不过还是非常昂贵。运行一个作业时，程序员首先将程序写在纸上（用 FORTRAN 或汇编语言），然后用穿孔机制成卡片，并将这些卡片交给操作员，然后就可以去做其他任何事情了，之后等计算结果出来之后再回来从输出室取走计算结果。不过这样浪费大量的计算机时间（操作员读卡片、手动装入 FORTRAN 编译器，而此时计算机并没有真正进行计算任务），于是批处理系统应运而生。从上图可知，批处理系统使得主机从输入和输出中某种程度的解放出来了。因为输入和输出通常是比较慢的，如果联机输入和输出的话，必然浪费具有更快速度的主机时间。只有使输入、输出与主机运算达到并行才能尽可能的提高主机利用率。 第三代计算机：集成电路和多道程序此时出现了多道程序和假脱机技术。多道程序技术的目的是，解决在输入输出时 CPU 等待的情形，使得 CPU 此时也能做执行其他的程序。而假脱机技术则是，不再需要像批处理系统那样将磁带（输入磁带和输出磁带）搬来搬去了（详见前面的图）。第三代操作系统相当适合于大型的科学计算和大规模的商务数据处理，但从本质上说，它们仍旧是批处理系统，程序员一旦提交作业，就失去了控制权，如果程序有错误，只能等到运行完之后才能修正，交互性非常差。程序员们都希望能有快速的响应时间，这种需求导致了分时系统的出现。它实际上是多道程序的一个变体，不同之处在于每个用户都有一个联机的终端。需要指出的是，多道程序技术需要用到特殊的硬件机制（这也促使硬件技术的发展）。 第四代计算机：个人计算机随着大规模和超大规模集成电路的普及，计算机越来越便宜，于是出现了个人计算机，进而出现了通用或专用的操作系统。后来还出现了网络操作系统和分布式操作系统。网络操作系统与单处理器的操作系统本质上没有区别。它们需要一个网络接口控制器以及相应的底层驱动软件，此外还需要一些程序来进行远程登录和远程文件访问，但这些并没有改变操作系统的本质结构。真正的分布式操作系统并不仅仅是在单处理器系统的基础上增添一小段代码。事实上，分布式系统与集中式系统有本质的区别。它需要更复杂的处理器调度算法来获得最好的并行性能。另外网络中的通信延迟往往导致不完整、过时甚至错误的信息，而分布式算法必须在这种环境下运行。而单处理器系统中，操作系统能够掌握整个系统的所有信息。多道程序设计操作系统的形成离不开多道程序设计。实现多道程序设计必须妥善地解决以下三个问题： 存储保护与程序浮动 处理器的管理与分配 资源的管理与调度。中断和通道技术的出现以及大容量存储器的诞生使得实现多道程序系统已不存在问题。操作系统资源管理操作系统的主要目标可归结为： 方便用户使用 扩充机器功能 管理各类资源 提高系统效率 构筑开放环境由于计算机系统的硬件相对不足导致各应用程序之间对资源的共享和争用。 必须要解决资源数量不足和合理分配资源这两个问题。 提供相应的资源使用接口，屏蔽直接使用资源的复杂性和不安全性。而解决以上问题的最好方法是通过共享硬件资源的方式来实现虚拟机抽象。所利用的资源管理技术如下：三种资源管理技术：资源复用、资源虚化和资源抽象。 （1）资源复用由于多道程序设计，必须要求资源复用。通过适当资源复用可以创建虚拟资源和虚拟机，以解决物理资源数量不足的问题。物理资源的复用有两种基本方法：空分复用共享和时分复用共享空分复用共享表明资源可以进一步分割成更多和更小的单位供进程使用；时分复用共享表明资源可以被一个一个进程单独占用一个时间片，而下一时间片将分配给下一个进程。进程能够空分复用主存资源，不同的进程映像装入不同的主存区域，拥有各自的地址空间，且通过硬件存储保护机制进行隔离。操作系统必须跟踪当前执行进程，确定其执行时间；而时分复用共享使得处理器可以执行已装入不同地址空间中的程序代码。这种共享硬件的技术称之为“多道程序设计”。 （2）资源虚化虚化又称虚拟性。虚化的本质是对资源进行转化、模拟或整合，把一个资源转变成逻辑上的多个对应物，创建无须共享的多个独占资源的假象，以达到多用户共享一套计算机物理资源的目的。空分复用与虚化两者相比较，空分复用所分割的是实际存在的物理资源，而虚化则是实现假想的虚拟同类资源。虚化技术可以解决单类资源绝对不足（如，主存不足时可以使用磁盘来虚拟主存）和不能复用资源（如虚拟打印机技术）的共享问题。虚拟设备技术如同多台外部设备同时联机操作，该技术被称为 SPOOLing 技术。从本质上讲，SPOOLing 技术、窗口技术（虚拟屏幕终端）、时分信道多路复用技术都建立在时分复用共享的基础上；虚拟存储器则是通过虚拟存储技术把物理上的多级存储器（主存和辅助存储器）映射为逻辑上的、单一的（虚拟）存储器，它与频分信道多路复用技术一样都是建立在空分复用共享基础之上的例子。 （3） 资源抽象资源复用和资源虚化的主要目标是解决物理资源（单类资源相对或绝对）数量不足的问题。而资源抽象则是解决物理资源易用性问题。资源抽象是指通过创建软件来屏蔽硬件资源的物理特性和接口细节，简化对硬件资源的操作、控制和使用，即不考虑物理细节而对资源执行操作。比如使用设备的一些系统调用、更高级的文件系统（对磁盘的抽象）。 （4） 组合使用抽象和虚化技术对于某一类资源，操作系统往往同时实施抽象和虚化技术。如打印机，既使用了系统调用，又使用了虚化技术 SPOOLing。操作系统的基础抽象计算机系统的物理资源可被分为两大类：计算类（处理器和主存）、存储与接口类（辅存和其他外部设备等）。为了方便对物理资源的管理和使用，现代操作系统对资源进行了三种最基础的抽象：进程抽象、虚存抽象和文件抽象。 进程抽象进程是对于进入主存的当前运行程序在处理器上操作的状态集的一个抽象，它是并发和并行操作的基础。实际上，若干进程透明地时分复用共享一个（或多个）处理器，操作系统内核的主要任务之一是将处理器“虚化”，制造一种每个运行进程都独自拥有一个处理器的假象。由于进程执行依赖于主存和设备上的信息资源，所以还需要后面的几种资源抽象进行配合。 虚存抽象虚存抽象的目的是让用户认为它正在独占和使用整个主存，从而不需要考虑程序如何在主存中存放的细节，也不用直接操作物理地址，而是使用虚拟地址（逻辑地址）来使用主存（操作系统会将虚拟地址转化为物理地址）。 文件抽象Unix 类系统把磁盘、外部设备都抽象成文件，如此就可像操作普通文件一样操作设备了。从而屏蔽了诸多设备的不同细节，提供了友好的统一接口。虚拟计算机虚拟计算机是一台抽象计算机，它在硬件基础上由软件来实现，处于不同层次的用户将用到不同的虚拟机，并且和物理机器一样，具有指令集（如系统调用、函数库等）及可用的存储空间。下面讲解一下操作系统虚拟机。 虚拟处理器虚拟计算机的虚拟处理器是由物理处理器实现的，利用处理器调度技术，虚拟处理器每次分得时间片后可供进程执行时使用（时分复用）。 虚拟主存虚拟主存利用虚拟存储技术供进程作为物理地址空间使用（空分复用）。 虚拟辅存磁盘被抽象成命名文件，运行在虚拟机上的进程通过文件管理系统来使用和共享磁盘。磁盘的部分空间可以作为主存空间的扩充，存放进程映像副本（空分复用）。 虚拟设备外部设备也被抽象为命名文件，运行在虚拟机上的进程通过设备管理来使用设备，根据外部设备自身物理特性的不同，有些类型设备基于空分复用共享，有些类型的设备基于时分复用共享。总之，虚拟机是由操作系统通过共享硬件资源的方式来实现的，它定义进程运行的逻辑计算环境。操作系统的作用与功能操作系统在计算机系统中起到 3 个方面的作用。 提供用户接口和服务 扩展机器功能和提供虚拟机 管理和控制计算机资源概括地说，操作系统既是“管理员”，又是“服务员”。 对内作为“管理员”，做好计算机系统软硬件资源的管理、控制与调度，提高系统效率和资源利用率。 对外作为“服务员”，是用户与硬件之间的接口和人机界面，为用户提供尽可能友善的运行环境和最佳服务，所以，资源管理和调度是操作系统的重要任务。从资源管理的观点来看，操作系统具有 6 项主要功能。 处理器管理：对处理器的管理和调度最终归结为对进程和线程的管理和调度，包括： 进程控制和管理； 进程同步和互斥； 进程通信； 进程死锁； 线程控制和管理； 处理器调度，又可分为高级调度、中级调度和低级调度。 存储管理： 主存分配 地址转换与存储保护； 主存共享； 存储扩充：用辅存逻辑上扩充主存。 设备管理： 提供设备中断机制； 提供缓冲区管理； 提供设备独立性，实现逻辑设备到物理设备之间的映射； 设备的分配和回收； 实现共享型设备的驱动调度； 实现虚拟设备。 文件管理： 提供文件的逻辑组织方法； 提供文件的物理组织方法； 提供文件的存取和使用方法； 实现文件的目录管理； 实现文件的共享和安全性控制； 实现文件的存储空间管理。 网络与通信管理： 网络资源管理； 数据通信管理； 网络管理。 用户接口：为了使用户能够灵活、方便地使用计算机硬件和系统所提供的服务，操作系统向用户提供一组使用其功能的手段，称为用户接口，包括两大类：程序接口和操作接口。操作系统的主要特性操作系统具有并发性（两个或两个以上活动或事件在同一时间间隔内发生）、共享性、异步性（又称为“随机性”，导致“走走停停”）。其中共享性是指，计算机系统中的资源可以被多个并发执行的程序共同使用，而不是被某个程序独占。并发性必然会产生资源共享的需要。资源共享方式有以下两种： 通明资源共享操作系统采用复用、虚化和抽象技术创建虚拟机使用户感觉就是独占设备一般。透明资源共享机制必须妥善处理资源隔离和授权访问。处理器（进程和线程）管理进程可被调度在一个处理器上交替地执行，或在多个处理器上并行执行。不同类型的操作系统可能采取不同的调度策略，交替执行和并行执行都是并发的类型。为了提高并发粒度和降低并发开销，现代操作系统引进线程的感念，此时进程仍然是资源分配和管理的单位，线程则成为处理器调度的基本单位。程序的顺序执行我们把一个具有独立功能的程序独占处理机，直到最后结束的过程称为程序的顺序执行。程序顺序（并发）执行时的特征 顺序（间断）性 （失去）封闭性：程序运行时独占全机资源。 （不）可再现性：程序的最终结果与执行速度及执行的时刻无关。进程进程是执行中的程序。进程不只是程序代码，程序代码有时称为“程序区（或文本段）”，进程还包括当前活动，通过程序计数器的值和处理器寄存器的内容来表示。另外，进程还包括进程堆栈段和数据段（包含全局变量）。如果说程序是提供计算机操作的一组工作流程的话，进程就是具体的工作过程，按照同样的工作流程，针对不同的原料，可以同时开始多个工作过程，得到多种不同的成品。进程和程序时两个完全不同的概念，但又有密切联系，它们之间的主要区别如下： 程序是静态概念，本身可以作为一种软件资源长期保存，而进程是程序的一次执行过程，是动态的概念。 进程是一个能独立运行的单位，能与其他进程并发执行。进程是作为资源申请和调度单位存在的；通常程序不能作为一个独立运行的单位而并发执行。 程序和进程不存在一一对应的关系。 各个进程在并发执行过程中会产生相互制约的关系，造成各自前进速度的不可预测性，而程序本身是静态的，不存在这种异步特征。进程的特点从进程与程序的区别可以看出，进程具有如下特征： 动态性 并发性 独立性：进程是一个能独立运行的基本单位，同时也是系统中独立获得资源和独立调度的基本单位。 异步性：进度之间需要协调运行。 结构特征（进程映像）：进程实体是由程序段、数据段及进程控制块组成。进程的状态和转换进程是具有生命周期的，根据进程在执行过程中不同情况需要定义不同的状态。三态模型： 运行态：进程正占用处理器。 就绪态：只缺处理器资源。 等待（阻塞）态：正在等待某个时间完成或资源空闲而不具备运行条件五态模型在很多系统中，增加两个进程状态：新建态和终止态。 新建态：对应于进程被创建时的状态。又是将根据系统性能的要求或主存容量的限制推迟新建态进程的提交。创建进程需要两个步骤：①为新进程分配所需资源，建立必要的管理信息；②设置此进程为就绪态，等待被调度执行。 终止态：处于终止态的进程不再被调度执行，下一步将被系统撤销，最终从系统中消失。类似地，进程终止也要通过两个步骤实现：①等待操作系统或相关进程进行善后处理（如抽取信息）；②回收被占用的资源并由系统删除进程。进程终止通常由下列条件引起： 正常退出（自愿的）； 出错退出（自愿的）； 严重错误（非自愿的）； 被其他进程杀死（非自愿的）。 具有挂起功能的进程状态很多系统引入了挂起状态。所谓挂起状态，实际上就是一种静止状态。一个进程被挂起之后，不管它是否在就绪状态，系统都不分配给它处理机。引起挂起状态的原因： 终端用户的请求 父进程请求考察子进程的活动 系统负荷的需要：资源紧缺，挂起不重要的进程。 操作系统的需要：检查和统计运行中的资源使用情况。挂起状态又引入了两个新状态：挂起就绪态和挂起等待态。挂起就绪态表明进程具备运行条件，但目前在辅存中，只有当进程被兑换到主存时才能被调度执行；挂起等待态则表明进程正在等待某一事件发生且进程在辅存中。引进挂起状态后，进程状态可分为新建态、活动就绪态、运行、活动阻塞、静止就绪、静止阻塞和终止状态。进程描述进程的活动包括占用处理器执行程序以及对相关数据进行操作，因而，程序和数据是进程必需的组成部分，两者描述的是进程的静态特征；进程的动态特性则由以下的数据结构来描述：进程控制块；进程程序块（即程序区）；进程核心栈（核心态与用户态切换时用）；进程数据块（用户数据和用户栈）。 进程控制块（PCB）：不同的操作系统中的 PCB 不尽相同。可以按照功能大概分成 4 个组成部分：进程标识符、处理机状态（现场信息）、进程调度信息、进程控制信息。 进程标识符： 进程内部标识符：操作系统给予的位移数字标识符； 进程外部标识符：由创建者提供，便于用户访问该进程。为了描述进程的家族关系，还应设置父进程标识及子进程标识。此外，还可设置用户标识、用以标识拥有该进程的用户。 处理机状态：处理机状态信息主要由处理机的各种寄存器中的内容组成。用于保护和恢复现场从断点继续执行。处理机的寄存器包括通用寄存器、指令计数器、程序状态字 PSW、用户栈指针。 进程调度信息：PCB 中还存放一些与进程调度和进程对换有关的信息。 进程状态：指明进程当前状态。 进程优先级； 进程调度所需要的其他信息：　　它们与所采用的进程调度算法有关； 事件或阻塞原因。 进程控制信息： 程序和数据的首地址； 进程同步和通信机制； 资源清单：除 CPU 之外的其他已获得资源清单。 链接指针：给出了本进程 PCB 所在队列的下一个进程 PCB 的首地址。 当系统创建一个新进程时，就为它建立一个 PCB；当进程终止后，系统回收其 PCB，该进程在系统中就不存在了。所以，PCB 是进程存在的唯一标志。进程控制块的组织方式：系统中有许多处于不同状态的进程，同时阻塞的原因也可能各不相同，所以需要不同的队列将它们组织起来，以便对所有进程进行有效管理。这就需要适当的方式将 PCB 组织起来。有三种通用的队列组织方式：线性方式、链接方式和索引方式。 线性方式：把所有进程的 PCB 都放在一个线性表中。该线性表是静态分配空间。为了采用某种调度算法，必须扫描整个线性表，从而降低了调度效率。 链接方式：根据不同的进程状态和阻塞原因或其他某种特定需求分成不同的队列。从而减少了每次扫描的 PCB 数，提高了灵活性和效率。 索引方式：索引方式是线性方式的一种改进，结合了链接方式的优点。可以认为索引方式是用静态链表的方式来实现的链接方式。进程切换与模式切换 进程上下文切换中断和异常是激活操作系统的仅有方法，它暂停当前运行进程的执行，把处理器切换至核心态，内核获得处理器的控制权之后，如果需要就可以实现进程切换。所以，进程切换必定在核心态而非用户态发生。这种切换通过核心栈来完成。内核在下列情况会发生上下文切换：进程在运行过程中执行系统调用、产生中断或异常时，操作系统从当前运行进程那里获得控制权，此后，进程切换可以在任何时刻发生。在执行进程上下文切换时，保存老进程的上下文且装入被保护的新进程的上下文，以便新进程运行。进程切换的实现步骤如下： 处理器模式切换与进程上下文切换有关的是 CPU 模式切换，用户态和核心态之间的相互切换（称为“模式切换”），此时仍然在同一个进程中进行。仍在自己的上下文中执行。模式切换的步骤如下：模式切换不同于进程切换，它不一定会引起进程状态的转换，在大多数情况下，也不一定引起进程切换，在完成系统调用服务或中断处理之后，可通过逆向模式切换来恢复被中断进程的运行。CPU 上所执行进程在任何时刻必定处于三个活动范围之内：进程控制系统中的进程不断地产生和消亡，进程生命周期的动态变化过程由进程管理程序来控制，对于进程的控制和管理包括：创建进程、阻塞进程、唤醒进程、挂起进程、激活进程、终止进程和撤销进程等，这些功能均由系统中的原语来实现。原语在核心态执行，是完成系统特定功能的不可分割的过程，它具有原子操作性，其程序段不允许被中断，或者说原语不能并发执行。系统对进程的控制如果不适用原语，就会造成状态的不确定性，不能达到进程控制的目的。原语可分为两类： 机器指令级的其特点是执行期间不允许中断，是一个不可分割的基本单位。 功能级的其特点是作为原语的程序段不允许并发执行。需要注意的是：阻塞原语是进程自己阻塞自己；唤醒是被系统进程或事件完成进程唤醒；进程的挂起或解挂都是被动的线程如果说操作系统中引入进程的目的是为了使多个程序并发执行，以便改善资源利用率和提高系统效率，那么，在进程之后再引入线程的概念，则是为了减少程序并发执行（进程切换）时所付出的时空开销，使得并发粒度更细，并发性更好。此时，进程成为了独立分配资源的基本单位，无须频繁地切换；而线程则作为系统（处理机）调度和分派的基本单位，会被频繁地调度和切换。进一步产生了多线程进程。线程和进程的比较如下：线程的组成部分有：线程的状态：线程和进程一样，也有自己的状态。线程有 3 种基本状态，即执行、阻塞和就绪，但没有挂起（由于线程不是资源的拥有单位，挂起状态对于线程是没有意义的）。进程中可能有多个线程，至于单个线程是否要阻塞整个进程取决于系统实现。有的系统只有所有的线程都阻塞之后才阻塞整个进程（这种方式更能体现多线程的优越性）。线程切换：针对线程的 3 种基本状态，存在 5 种基本操作来转换线程的状态。 派生：线程在进程中派生出来，也可再派生线程。 调度； 阻塞； 激活； 结束。 多线程程序设计的优点 线程的组织 多线程实现多线程的实现分为三类：用户级线程（ULT）、内核级线程（KLT）或者混合方式。 用户级线程：其由用户应用程序建立，并由用户应用程序负责调度和管理，操作系统内核不知道有用户级线程的存在。ULT 的优点：ULT 的缺点： 内核级线程：内核级线程中所有线程的创建、调度和管理全部由操作系统内核负责完成，一个应用程序可按多线程方式编写程序，其他交给内核处理。多线程技术利用线程库提供一整套有关线程的过程调用或系统调用来支持多线程运行，有的操作系统直接支持多线程，有的语言则提供线程库。因而，线程库可分为用户空间线程库和内核空间库。线程库实际上是多线程应用程序的开发和运行环境。多线程模型许多系统都提供对用户和内核线程的支持，从而有不同的多线程模型。以下是 3 种常用类型： 多对一模型该模型将许多用户线程映射到一个内核线程。详情请参看“用户级线程”。 一对一模型（参见“内核级线程”） 多对多模型多对多模型多路复用了许多用户线程到同样数量或更小数量的内核线程上。开发人员可创建任意多的必要用户线程，并且相应内核线程能在多处理器系统上并行执行。而且，当一个线程执行阻塞系统调用时，内核能调用另一个线程来执行。为了防止无限制的创建线程，可使用线程池。处理器调度某些进程花费了绝大多数时间在计算上（注意，某些 I/O 活动可以看做是计算），称之为“计算密集型进程”；而有些进程则在等待 I/O 上花费了绝大多数时间，称之为“I/O 密集型进程”。如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持始终忙碌。调度时机CPU 调度决策可以在如下四种环境下发生：分级调度一个批处理型作业，从进入系统并驻留在外存的后备队列上开始，直至作业运行完毕，可能要经历以下三级调度：作业调度、对换和进程调度。 高级调度其又称为作业调度、长程调度。用于选择把外存上处于后备队列中的哪些作业调入内存，并为它们创建进程、分配必要的资源，然后，再将新创建的进程排在就绪队列上，准备执行。高级调度控制多道程序的道数，被选择进入主存的作业越多，每个作业所获得的 CPU 时间就越少，所以有时为了满足某种特定需求，需要限制道数。每当有作业执行完毕并撤离时，作业调度会选择一个或多个作业补充进入主存。此外，如果 CPU 的空闲时间超过一定的阈值，系统也会引出作业调度选择后备作业。可见，高级调度负责作业的调入和撤离，与交换（对换或中级调度）有着很大的区别。 中级调度中级调度又称为“平衡调度、中程调度”，根据主存资源决定主存中所能容纳的进程数目，并根据进程的当前状态来决定辅助存储器和主存中的进程的对换。当主存资源紧缺时，会把暂时不能运行的进程换出主存，此时这个进程处于“挂起”状态，不参与低级调度；当进程具备运行条件且主存资源有空闲时，再将进程重新调回主存工作，起到短期均衡系统负载的作用，充分提高主存的利用率和系统吞吐率。 低级调度低级调度又称为进程调度/线程调度、短程调度和微观调度，其主要功能是：根据某种原则决定就绪队列中的哪个进程/内核级线程获得处理器，并将处理器出让给它还用。低级调度是操作系统最为核心的部分，执行十分频繁，其调度策略的优劣将直接影响整个系统的性能，因而，这部分代码要求精心设计，并常驻内存。进程调度可分为如下两种方式： 非抢占方式：不允许进程抢占已经分配出去的处理机。该方式的优点是实现简单、系统开销小，适用于大多数的批处理系统环境。但它很难满足紧急任务的要求。因而可能造成难以预料的后果。显然，在要求比较严格的实时系统中，不宜采用这种调度方式。 抢占方式：抢占方式允许调度程序根据某种原则暂停某个正在执行的进程，将处理机收回，重新分配给另一个进程。抢占的原则有优先权原则、短作业（或进程）优先原则、时间片原则等。各级调度的关系：调度算法的评价及准则在操作系统的设计中，如何选择作业调度及进程调度的方式和算法取决于操作系统的类型和目标。显然，根据不同的目标，会有不同的调度算法。面向用户的准则： 公平性 周转时间短：周转时间是指，作业被提交给系统开始，到作业终止为止的这段时间间隔。 响应时间快：响应时间指的是，从用户提交一个作业请求开始，直至系统首次产生响应（如屏幕显示提示信息）为止的时间。 截止时间保证截止时间是指，某任务必须开始执行的最晚时间，或必须完成的最晚时间。面向系统的准则：这是为了提高整个系统的效率。 系统的吞吐量：吞吐量是指，在单位时间内系统所完成的作业数，它与批处理作业的平均长度有密切关系。 处理机的利用率 各类资源的平衡利用。 尽量保持系统所有部分尽可能忙碌调度算法分类不同的环境需要不同的调度算法。调度机制从概念上来看，调度机制由 3 个逻辑功能程序模块组成： 队列管理程序 上下文切换程序 分派程序：转入上下文，开始执行获得 CPU 的进程。调度算法在操作系统中，存在多种调度算法，有的算法仅适用于作业调度，有的算法仅适用于进程/线程调度，但大多数调度算法对两者都适用。有的调度算法适合批处理系统或其他特定的系统，但一些算法既适合批处理系统也适合交互式系统等。批处理系统中的调度算法 先来先服务（FCFS）易于理解和实现，但没有考虑作业的特点和用户的实际需要，所以无法满足用户的大部分需求，也不能充分利用系统资源。不过，它是其他算法的基础，当各种条件都一样时，此时，就需要先来先服务原则来保证公平性。 最短作业优先（SJF）该算法一般是非抢占式的，所以这里的最短作业指的是，调度的当时是最短（虽然有时很难估计时间）的。而不是在该作业运行期间（如，后面又来了一个更短的作业）。 最短剩余时间优先：SRTF 和最短作业优先一样，有时该时间是很难预先知道的。 高响应比优先：HRN 调度算法为了克服短作业优先算法的缺点，采用了一种折中的方法，既让短作业优先，又考虑到系统内等待时间过长的作业。交互式系统中的调度下面的调度算法也可以用于批处理系统的调度器中，尽管三级调度不大可行，但两级调度是可行的。 时间片轮转调度：时间片设得太短会导致过多的进程切换开销；而设得太长有可能引起对短交互请求的响应变差。一般设为 20-50 ms。 优先级调度：优先级可以是静态的，也可以是动态的，系统和用户均可指定优先级。优先级调度可以是抢占式的，也可以是非抢占式的。不过，可能造成高优先级的进程无限制执行下去，而低优先级的进程处于饥饿状态，所以优先级标准和如何变化将会影响用户体验和系统性能。 多级反馈队列调度算法不论哪一种算法都无法满足不同的需要。为此，可以将不同的需求分到不同的队列中，而且不同的队列具有不同的优先级，不同队列中可以根据具体的需求采用最适合该队列的调度算法。而且进程根据不同的运行情况会被动态的分配到不同的队列中。此种算法称为“多级反馈队列调度算法 MLFQ ”或 “反馈循环队列”。可见，该算法中，同一个进程随着占用 CPU 的次数的增加，优先级在不断递减。MLFQ 调度算法具有较好的性能，能满足各类应用的需要。但仍会导致“饥饿”问题。例如，一个耗时很长的作业，最终将进入优先级最低的队列，然后，系统不断的进入新的作业，那么，该长作业就很难得到再运行的机会。为此，可以允许使用高响应比来提升优先级（通常只允许降低优先级）。 彩票调度算法其基本思想是：为进程/线程发放针对各种资源（如 CPU 时间）的彩票，当调度程序需要作出决策时，随机选择一张彩票，彩票的持有者将获得相应的系统资源。对于 CPU 调度，系统可能每秒钟抽取彩票 50 次，中奖者每次可以获得 20 ms 的运行时间。一般情况下，所有进程都是平等的，不过某些进程需要更多机会，所以需要得到额外的彩票以增加中奖的机会。进程拥有多少彩票份额，就能获得多少资源。合作进程如果愿意，可以交换彩票，以便相应进程得到更多的机会。可见，彩票调度法很灵活，而且反应非常迅速，因为中奖机会与其持有的彩票数成正比。 公平分享调度该算法考虑了进程的拥有者。主要应对不同作业拥有的进程数是不一样的情况，如果不考虑拥有者，则拥有更多进程的作业显然获得 CPU 时间更多。实时系统调度实时系统通常分为硬实时系统和软实时系统。前者意味着存在必须满足的时间限制；后者意味着偶尔超过时间限制是可以容忍的。实时系统根据响应的事件可进一步分为周期性（每隔一段固定时间发生）和非周期性（在不可预知的时间发生）。一个系统更可能必须响应多个周期的事件流。根据每个事件需要多长的处理时间，系统可能根本来不及处理所有事件。实时调度算法可以是静态的或动态的。前者在系统启动之前完成所有的调度决策；后者在运行时做出调度决策。如果使用静态调度算法，必须预先知道足够多的需要做的工作和必须满足的约束的时间信息。 单比率调度算法对于周期性事件，单比率调度是视周期长度而定的抢占式策略：周期越短，优先级越高。 限期调度算法当一个事件发生时，对应的实时进程就被加入就绪队列，此队列按照截止期限排序。对于周期性事件，截止期限即事件下一次发生的时间。系统检测队首截止期限是否比当前运行者早，以决定是否剥夺当前运行的进程资源。 最少裕度法多处理机调度算法多处理机调度的设计要点有 3 个：为进程分配处理机、在单个处理机上是否使用多道程序设计技术和实际指派进程的方法。 负载共享调度算法：进程并不被指派到特定的处理机上，系统维护全局性进程就绪队列，当处理机空闲时，就选择进程的一个线程去运行。可见，该算法没有考虑同一个进程的多个线程的同步和切换问题，因为具有同步和互斥等关系的线程很难被按照一定顺序执行，也不能保证被切换的进程在原有的处理机上再次执行，从而增加了切换开销。具体的负载共性调度算法有：先来先服务、最少线程数优先和剥夺式最少线程数优先等。 群调度算法其基本思想是：给予一对一原则，一群相关线程被同时调度到一组处理机上运行。紧密相关线程的并行执行能够减少同步阻塞，从而减少进程切换，降低调度代价。当进程的相关线程数小于处理机数时会造成处理机资源空闲。 专用处理机调度算法将同属于一个进程的一组线程同时分派到一组处理机上运行。是群调度的一种极端方式。不过该方式也会使有些处理机因线程等待事件阻塞时空闲。然而，对于数目很大的处理机群而言，个别处理机的使用率只是代价的一小部分，对整体影响不大。 动态调度算法针对能够动态改变线程数的应用程序。其基本思想是：由操作系统和应用进程共同作出调度决策，操作系统负责在应用进程之间分配处理机；应用进程所分配的处理机上执行可运行线程的子集，这些处理机如何分配到具体的线程完全是应用进程的任务，可借助于运行时库函数完成。 注意：多处理机调度不宜采用复杂的调度算法，复杂的调度算法意味着过多的时间开销，然后这些开销乘以期间空闲的处理机数，将使开销被放大。进程间关系由于多道程序技术、多处理技术、分布式处理技术等导致了进程并发，并且并发会在不同的上下文中出现： 多个应用程序； 同一个应用程序内部； 操作系统自身内部。支持并发进程必需解决进程间的同步、互斥和通信问题。并发在单处理机上表现为进程的交替执行，在多处理机上表现为重叠执行。并发必然要求资源共享，共享的资源包括全局数据、硬件软件资源等，而且对共享资源的访问或读写顺序不同可能得到的结果也不同。所以，需要操作系统控制好进程对资源的互斥访问和顺序访问。并发带来的困难： 全局资源的共享充满了危险，不同进程使用的时机不同，资源被使用的前后状态也不同。 操作系统很难对资源进行最优化分配，可能导致死锁。 定位程序设计错误是非常困难的。这是因为结果通常是不确定的和不可再现的。操作系统需要为并发做的工作如下： 记录各个活跃进程的状态，为进程的同步、互斥等管理工作收集信息。 为每个活跃进程分配和释放各种资源。 必须保护每个进程的数据和物理资源。 保证一个进程的功能和输出结果与执行速度无关。进程的交互实际情况并不总是像上表中给出的那么清晰，多个进程可能既表现出竞争，又表现出合作。临界资源竞争进程面临三个控制问题（互斥、死锁和饥饿）。首先是互斥的要求。这涉及到不可共享或同时访问的资源的互斥访问问题。该类资源称之为临界资源。不论硬件临界资源，还是软件临界资源，多个进程必需互斥对其进行访问。每个进程中访问临界资源的那段代码称为临界区。所以，若能保证各进程互斥地进入临界区，便可实现各进程对临界资源的互斥访问。为此，必须在临界区前面增加一段用于检查临界资源是否在使用的代码，该段代码称为“进入区”；相应地，在临界区后面再加一段用于设置刚用完临界资源的状态，以便临界资源被其他进程使用的代码，该代码称为“退出区”，其他部分代码称为“剩余区”。进程同步机制进程同步是指有协作关系的进程之间不断地调整它们之间的相对速度或执行过程，以保证临界资源的合理利用和进程的顺利执行。实现进程同步的机制称为进程同步机制。 同步机制应遵循的规则：为实现进程互斥地进入自己的临界区，可用软件或硬件方法。不过所有同步机构都应遵循下列准则： 空闲让进； 忙则等待； 有限等待； 让权等待：当进程不能进入自己的临界区时，应立即释放处理机。 实现临界区管理的设施硬件设施： 关中断：在多处理机环境下，很难有效工作。 专用机器指令：用于保证两个动作的原子性。 如比较和交换指令（使用了忙等待或者自旋等待）。 忙等待或自旋等待指的是这样一种技术：进程在得到临界区访问权之前，它只能继续执行测试变量的指令来得到访问权，除此之外不能做其他事情。软件算法实现互斥 锁机制：实现互斥的一种软件方法是采用锁机制，即提供一对上锁和开锁原语，以及一个锁变量 w 或者是锁位。进入临界区之前不断地检测 w 的状态，若没有上锁则进入临界区，否则继续测试 w 的状态；进入后上锁，退出时开锁。 信号量机制信号量机制是一种广义的锁机制或者成为计数锁的同步机制，既能解决互斥，又能解决同步。后来发展成了 P 操作（原语）和 V 操作（原语）。P 操作用于检测和申请临界资源，V 操作用于释放临界资源。信号量也叫信号灯，是在信号量同步机制中用于实现进程的同步和互斥的有效数据结构。可以为每类资源设置一个信号量。信号量有多种类型的数据结构，如整型信号量，记录型信号量、AND 型信号量及信号量集等。信号量类型举例： 整型信号量：它是信号量的最简单的类型，也是各种信号量类型中必须包含的类型。整型信号量的数值表示当前系统中可用的该类临界资源的数量。如， 记录型信号量 AND 型信号量AND 同步机制的基本思想是将进程在整个运行过程中需要的所有资源，一次性全部分配给进程，待进程使用完成后再一起释放。只要有一个资源尚未分配给进程，其他所有可能分配的资源也不能分配给它。AND 型信号量集机制可描述如下： 信号量集如果某进程一次需要 N 个某类资源时，就要进行 N 次 wait 操作，这使系统的效率较低，有可能造成死锁。信号量实现互斥：经典同步问题 生产–消费者问题 问题的描述： 问题的分析： 算法程序： 注意事项： 读者–写者问题 问题的提出： 问题的分析： 算法程序： 注意事项： 哲学家进餐问题 问题的提出： 问题的分析： 算法程序： 其他算法： 理发师问题 问题提出： 问题分析： 算法程序：管程（进程高级同步）虽然 PV 操作可以解决进程间的同步互斥问题，但用于同步互斥的共享变量及信号量的操作被分散于各个进程中，它是否能达到同步互斥的功能还需要依靠程序员的正确编写。PV 同步机制的缺点： 易读性差：因为要了解对于一组共享变量及信号量的操作是否正确，则必须通读整个系统或者并发程序。 不利于修改和维护：因为程序的局部性很差，所以任一组变量或一段代码的修改都可能影响全局。 正确性难以保证：因为操作系统或并发程序通常很大，要保证这样一个复杂的系统没有逻辑错误是很难的。为了克服 PV 同步机制的缺点，提出了管程的概念。 管程定义：管程是一种抽象数据类型。它将描述共享资源的数据（私有数据）及操作这些数据的一组过程或方法（公有，当需要通过”管程名.方法名”的方式调用，不过也有内部函数，只允许管程方法使用，对外部隐藏）封装在一个具有名字的对象中。该对象可以引用外部方法或变量。可见管程是用于管理资源的公用数据结构（而进程是占有资源的私有数据结构），管程和调用它的进程不能同时工作（而进程之间可以并发），而且管程是语言或操作系统的成分，不必创建和撤销。 管程组成： 名称：即，管程名称。对不同类的共享资源可能有不同管程，而且也需要引用管程名来调用其中的方法。 数据结构说明：局部于管程的共享变量说明，也是该管程所管理的共享资源的清单。 对该数据结构进行操作的一组过程/函数 初始化语句：规定数据结构中数据的初始值。 管程的属性： 共享性：通过调用管程的过程或方法进行共享。 安全性：管程内变量（私有变量）只允许管程的过程访问。 互斥性：任一时刻最多只有一个调用者能真正引入管程，其他进程将在管程入口处等待。 易用性：进入管程的互斥由编译器负责，从而减轻了写管程的程序员工作。 管程基本形式：具体例子： 条件变量：前面提到的管程（并不完整）实现了临界资源的正常进入和退出，但没有考虑临界区内因为某种原因必须中途暂时退出的情况。也就是说，还需要一种方法使得进程在临界区内其他资源不能满足而无法继续运行时被阻塞，等条件满足之后再次运行。而条件变量同步机制，以及在其上操作的仅有的两个同步原语 wait 和 signal 的引入就是为了解决这一问题。当进程中途等待资源时将被加入资源等待队列（称为紧急等待队列），该队列由相应的条件变量维护，资源等待队列可以有多个，每种资源一个队列。紧急等待队列的优先级应当高于入口等待队列的优先级。 当一个管程过程发现无法继续执行下去时，它将在相应的条件变量上执行 wait ，这个操作引起调用进程阻塞；当然，这是允许先前被挡在管程之外的一个进程进入管程。 另一个进程可以通过对其伙伴在等待的同一个条件变量上执行 signal 操作来唤醒等待进程。 wait 和 signal 是两条原语，在执行时不允许被中断。它们分别表示把某个进程加入等待使用资源的条件变量的等待队列，从等待资源的条件变量的等待队列上释放一个进程。 当执行 wait 之后，相应的进程被置成等待状态，同时开放管程，允许其他进程调用管程中的过程或方法。 当执行 signal 之后，指定条件变量上的一个进程被释放。某个进程（P）在管程内运行时可能中途释放某个条件变量（及时尽早释放临界资源和条件变量的原则），这将唤醒等待该条件变量的等待队列队首进程（Q），按照条件变量机制，该被唤醒的进程将再次进入管程（P 仍在管程内），很显然是不允许。可采用两种方法来防止这种现象的出现。 进程 P 释放管程转为等待直至进程 Q 退出管程，或者进程 Q 等待另一条件（中途又被阻塞）； 进程 Q 等待直至进程 P 退出管程（类似“非剥夺式”），或者进程 P 等待另一个条件（被阻塞）； 规定唤醒为管程中最后一个可执行的操作（即，最后统一释放所有的条件变量，统一唤醒）。霍尔采用了第一种办法，而汉森选择了第三种方法，进程执行 signal 操作后立即退出管程，因而，进程 Q 马上被恢复执行。注意事项：虽然条件变量也是一种信号量，但它并不是 P、V 操作中所论述的纯粹计数信号量，不能像信号量那样积累供以后使用，仅仅起到维护等待进程队列的作用。当一个条件变量上不存在等待条件变量的进程时，signal 操作发出的信号将丢失，等于做了一次空操作。wait 操作一般应在 signal 操作之前发出，这一规则大大简化了实现。 管程实现互斥和同步 互斥：进入管程的互斥由编译器负责，写管程的人无需关心。 同步：管程实现同步，需设置：具体例子： 生产者消费者问题： 哲学家用餐问题： 读者写者问题：除了前面说过的进程同步互斥机制外，有些操作系统还支持原子事务。对于事务的细节可以参考数据库原理。而且消息传递机制（参本文后面章节）也可以解决进程互斥和同步问题。进程通信进程之间互相交换信息的工作成为进程通信。通信分为两大类：低级通信和高级通信。 低级通信将进程间控制信息的交换称为低级通信，如信号量通信机制、信号通信机制。 高级通信：进程之间大批量数据的交换称为高级通信。通信方式列举： 信号通信机制； 信号量通信机制； 管道通信机制； 消息传递通信机制； 共享主存通信机制； 网络进程通信机制。信号通信机制信号是一种软终端，是传递短消息的简单通信机制，通过发送指定信号来通知进程某个异步事件发生，以迫使进程执行信号处理程序（在用户态下执行）。信号处理完毕后，被中断进程将恢复执行。一般地，分成操作系统标准信号和应用进程定义信号，这种机制模拟硬中断，但部分优先级，简单且有效，但不能传送数据，故能力较弱。管道通信机制管道是指用于连接一个读进程和一个写进程，以实现它们之间通信的一个共享文件（又名“pipe 文件”）。向管道（共享文件）提供输入的发送进程（写进程），以字符流的形式将大量的数据送入管道；而接收管道输出的接收进程（“读进程”），则从管道接收（读）数据。由于发送进程和接收进程是利用管道进行通信的，故称为管道通信。管道通信必须提供以下能力： 互斥：即当一个进程正在对 pipe 执行读/写操作时，其他进程必需等待。 同步：同步是指，当写（输入）进程把一定数量的数据写入 pipe，便去等待，直到读（输出）进程取走数据后，再把它唤醒；当读进程读一空 pipe 时，也应睡眠等待，直至写进程将数据写入管道后才将之唤醒。管道是一种功能机制很强的通信机制，但仅用于连接具有共同祖先的进程，使用时需要临时建立，难以提供全局服务。为了克服这些缺点， UNIX 推出管道的一个变种，称为有名管道或FIFO 通信机制，用来在不同的地址空间之间进行通信，特别为服务器通过网络与多个客户进行交互而设计。共享主存通信机制共享存储通信有两种方式： 基于共享数据结构的通信方式：公用数据结构的设置及对进程间同步的处理，都是程序员的职责，而操作系统只需提供共享存储器。因此，通信效率低，只适用于传递相对少量的数据。 基于共享存储区的通信方式：进程在通信钱，先向系统申请获得共享存储区中的一个分区，并指定该分区的关键字：若系统已经给其他进程分配了这样的分区，则将该分区的描述符返回给申请者，然后，由申请者把获得的共享存储区连接到本进程上；此后，便可以像读写普通存储器一样访问该公用存储分区。实际上，很多系统可以通过系统调用来操控共享分区。消息传递机制不论单机系统、多机系统还是计算机网络，消息传递机制都是应用最为广泛的一种进程间通信的机制。在消息传递系统中，进程间的数据交换是以格式化的消息（Message）为单位的；在计算机网络中，又把 Message 称为报文。程序员直接利用系统提供的一组通信命令进行通信。操作系统隐藏了实现通信的细节，提高了透明性，因而获得了较为广泛的使用。因实现方式不同可分为直接通信方式和间接通信方式。 直接通信方式：这种通信固定在一对进程之间。 间接通信方式：又称为“信箱通信”方式。信箱是一种数据结构，逻辑上可分为信箱头和信箱体两部分。 信箱头包含信箱体的结构信息以及多进程共享信箱体时的同步互斥信息。 信箱体由多个格子构成，它实际上就是一个有界缓冲器。信箱通信的同步、互斥方式与生产者消费者问题的方式类似。它一般是进程之间的双向通信。消息传递的复杂性在于：地址空间的隔离，发送进程无法将消息直接复制到接收进程的地址空间中，这项工作只能由操作系统来完成。为此，消息传递机制至少需要提供两条原语 send 和 receive。为了实现异步通信，必须采用简洁的通信方式。简洁通信解除了发送进程和接收进程之间的直接联系，在消息的使用上加大了灵活性。一个进程可以分别与多个进程共享信箱。于是，一个进程可以同时和多个进程通信，一对一关系允许在两个进程间建立不受干扰的专用通信链接；多对一关系对客户服务器间的交互非常有用；一个进程为其他进程提供服务，这时的信箱又称为端口，端口通常划归接收进程所有并由接收进程创建，服务进程被撤销时，其端口也随之消失。当然还有多对多关系的公用信箱。 信箱的设置：信箱可以在用户空间或系统空间开辟。 用户空间信箱：创建者进程撤销时，信箱也随之消失，这时必须通知所有使用者。 系统空间设置公用信箱：可以充分利用预留空间（如果在系统空间内分别开辟私有空间则很难确定分配多大，当然可以延迟到接收时分配）。 通信进程的同步两个进程间的消息通信就隐含着某种程度的同步，当发送进程执行 send 发出消息后，本身执行可分为两种情况： 同步的（阻塞型），等待接收进程回答消息后才继续进行； 异步的（非阻塞型），将消息传送到接收进程的信箱中，允许继续运行，直到某个时刻需要接收进程送来回答消息（如信箱已满）时，才查询和处理。对于接收进程而言，执行 receive 后也可以是阻塞型和非阻塞型，前者指直到消息交付完成（一有消息就要停下来接收消息）它都处于等待消息的状态；后者则不要求接收进程等待，当他需要消息时，再接收并处理消息。 消息传递机制解决进程的互斥和同步问题 解决进程互斥问题 解决同步问题：生产者消费者问题的一种解法消息缓冲队列通信机制死锁死锁的规范定义如下：如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么，该进程集合就出现了死锁。在多道程序设计环境下，多个进程可能竞争一定数量的资源。一个进程申请资源，如果该资源不可用，那么进程进入等待（阻塞）状态。如果所申请的资源被其他等待进程占有，那么该等待进程有可能无法改变状态，这就出现了死锁。死锁可分为资源死锁和调度死锁（外界强加优先权解决死锁）。可见死锁与资源有关。资源分类： 可抢占资源：可抢占资源可从拥有它的进程处抢占而没有任何副作用。 不可抢占资源：不可抢占资源是无法在不导致相关计算失败的情况下将其从占有它的进程处剥夺（如刻盘时）。总的来说，死锁与不可抢占资源有关，有关可抢占资源的潜在死锁通常可以通过在进程间重新分配资源而化解。资源的另一种分类：资源通常可分为两类：可重用的和可消耗的。 可重用资源：可重用资源是指一次只能供一个进程安全地使用，并且不会由于使用而耗尽的资源。进程得到资源单元，后来又释放这些单元，供其他进程再次使用。可重用资源的例子包括处理器、I/O 通道、内外存、设备以及诸如文件、数据库和信号量之类的共享数据结构。 可消耗资源：可消耗资源是指可以被创建（生产）和销毁（消耗）的资源。通常对某种类型可消耗资源的数目没有限制，一个无阻塞的生产进程可以创建任意数目的这类资源。当消费进程得到一个资源时，该资源就不再存在了。可消耗资源的例子有中断、信号、消息和 I/O 缓冲区中的信息。死锁原因系统产生死锁的根本原因可归结为以下两点： 资源竞争：大多数情况下，引起死锁的资源竞争是指对于不可剥夺性资源的竞争。另外一种因资源竞争而死锁的资源是一些临时性资源（也称为消耗性资源，如消息），如因为各个进程都在等待其他进程发送消息然后自己才发送消息的情况。 进程推进顺序不当 死锁产生的必要条件 互斥条件 占有且申请条件 不可抢占条件 环路等待条件资源分配图总而言之，如果资源分配图没有环，那么系统就不处于死锁状态。另一方面，如果有环，那么系统可能会也可能不会处于死锁状态（因为还有其他必要条件）。在处理死锁问题时，这一点很重要。解决死锁问题的基本方法 死锁的预防：采取某种策略，限制并发进程对资源的请求，从而保证死锁的必要条件在系统执行的任何时间都得不到满足。 死锁的避免：在分配资源时，根据资源的使用情况提前做出预测，给定一个合适、安全的进程推进顺序，从而避免死锁的发生。 死锁的检测：允许系统发生死锁。系统设有专门的机构，当死锁发生时，该机构能够检测到死锁的发生，并能确定参与死锁的进程及相关资源。 死锁的解除：这是与死锁检测相配套的措施。用于将进程从死锁状态中解脱出来。由于操作系统的并发与共享以及随机性等特点，通过预防和避免死锁的手段达到排除死锁的目的十分困难，需要相当大的系统开销，对资源的利用也不够充分。死锁的检测与解除则相反，不必花费多少执行时间就能发现死锁并从死锁中恢复出来。因此，实际操作系统很多都采用了后两种方法。 鸵鸟算法：大多数操作系统（如 UNIX、Windows），处理死锁的办法仅仅是忽略它，其假设前提是大多数用户宁可在极偶然的情况下发生死锁，也不愿接受只能创建一个进程、只能打开一个文件等限制。要解决死锁问题的代价通常很大，而且常常会给进程带来许多不便的限制，于是我们不得不在方便性和正确性之间做出令人不愉快的权衡，要充分考虑哪一个、对谁最重要。在这些条件下，很难找到通用的解决办法。死锁的预防死锁的必要条件中，“互斥条件”对于可分配的资源要互斥使用，这是由资源的固有特性决定的，不可改变（当然有些资源可以使用 SPOOLing 技术或其他抽象虚化技术变成逻辑上的多个资源）。因此，只有通过打破后三个条件，使它们中的一条不成立，来达到预防死锁的目的。 摒弃占有且申请条件可采用资源的静态预分配或释放已占资源策略。 资源的静态预分配：在进程运行之前，一次性地向系统申请它所需的全部资源。系统要么满足所有要求，要么不分配任何资源。这种方法存在一些缺点： 释放已占资源策略：仅当进程没有占用资源（先释放已有资源）时才允许它去申请资源。这种方法允许进程在开始时只申请磁盘文件等可重用资源。该方法仍然有资源利用率低，可能发生饥饿（对于需要多个常用资源的进程）等缺点。 折中策略：先释放已有资源再一次性申请所需所有资源，系统要么一次性满足，要么不分配任何所需资源。 摒弃不可抢占条件我们采取的策略是隐式抢占。约定如果一个进程已经有了某些资源又要申请另外的资源，而被申请的资源不满足时，该进程必须等待，同时释放已占有的资源，以后再进行申请。至于释放资源又有两种方式： ①占有资源的进程若要申请新的资源，必须主动释放已占用资源（剥夺式），若仍需要占用此资源，应该向系统重新提出申请，从而破坏了不剥夺条件，但会造成进程重复地申请和释放资源。 ②资源管理程序为进程分配新资源时，若有则分配之，否则将剥夺此进程所占有的全部资源，并让进程进入等待资源的状态，资源充足后再唤醒他重新申请所有所需资源。 它所释放的资源可以重新被分配给其他进程，这就相当于该进程占有的资源被隐式地抢占了，不过这种预防死锁的方法实现起来较为困难。 摒弃环路条件采用层次分配策略，将系统中的所有资源排列到不同的层次中，一个进程得到某层的一个资源后，只能再申请较高一层的资源；当进程释放某层的一个资源时，必须先释放所占用的较高层次资源；当进程获得某层的一个资源后，如果想申请同层的另一个资源，必须先释放此层中的已占用资源。层次分配策略的一个变种是按序分配策略。把系统的所有资源按顺序编号，规定进程请求所需资源的顺序必须按照资源的编号依次进行，使进程在申请、占有时不会形成环路。这些预防死锁的策略与前面两种策略相比，资源利用率和系统吞吐量都有较为明显的改善。但也存在缺点： 限制了新类型设备的增加； 作业使用各类资源的顺序与系统规定的顺序不同时，造成资源的浪费； 为了解决前面两个问题，会增加复杂性； 按规定次序申请的方法必然会限制用户自然、简单地编程。死锁避免死锁的预防是排除死锁的静态策略，它使产生死锁的 4 个必要条件不能同时具备，从而对进程申请资源的活动加以限制，以保证死锁不会发生。死锁的避免是一种排除死锁的动态策略，能支持更多的进程并发执行，它不是对进程随意强加限制，而是对进程所发出的每一个申请资源的活动加以动态地检查，并根据检查结果决定是否进行资源分配，即在资源分配过程中预测是否会出现死锁，如不会死锁，则分配资源；若有发生死锁的可能，则加以避免。这种方法的关键是确保资源分配的安全性。 安全状态安全状态是指系统中的所有进程能够按照某种次序分配资源，并且依次运行完毕，则进程序列就是安全序列。如果存在这样一个安全序列（只要一个就行），则系统是安全的，称此时系统处于安全状态。如果系统不存在这样一个序列，则称系统是不安全的。安全状态不是死锁状态，相反，死锁状态是不安全状态；然而，并不是所有的不安全状态都是死锁状态。可见，死锁避免策略并不能确切地预测死锁，它仅仅是预料死锁的可能性并确保永远不会出现这种可能性。避免死锁的方法： 进程启动拒绝：如果一个进程的请求会导致死锁，则不启动此进程； 资源分配拒绝：如果一个进程增加的资源请求会导致死锁，则不允许此分配（“银行家算法”）。 资源分配图算法前面提到的“资源分配拒绝”方法中具体有：资源分配图算法和银行家算法等。资源分配图除了申请边和分配边外，可引入一新类型的边，称为需求边。这种边类似申请边，但是用虚线表示，如果需求被肯定，那么需求边就可以转化为分配边。 银行家算法对于每种资源类型有多个实例的资源分配系统，资源分配图算法就不适用了。此时，可用银行家算法，但其效率要比资源分配图方案差。银行家算法又称“资源分配拒绝”法，其基本事项是： 系统中的所有进程放入进程集合，在安全状态下系统收到进程的资源请求后，先把资源试探性地分配给它。 然后，根据还剩余的资源，找出剩余资源能满足最大需求量的进程，以便释放出更多的该类资源。这时，把这个进程从进程集合中删除（又少了一个竞争者），归还（试探性的，并非真正归还）该进程的所有其他资源（增加了剩余资源）。反复执行上述步骤直到无法满足任何进程资源需求或进程集合为空截止。 最后，检查进程集合，若为空则表明本次申请可行，系统处于安全状态，可以真正实施本次分配；否则，只要进程集合非空，系统便处于不安全状态，本次资源分配暂不实施，让申请资源的进程等待。为了实现银行家算法，必须要有若干数据结构。这些数据结构对资源分配系统的状态进行了编码。设 n 为系统进程的个数，m 为资源类型的种类。需要如下数据结构： 可利用资源向量 Available ：它是长度为 m 的向量（含有 m 个元素的数组）表示每种资源的现有的实例的数量。每一个元素代表一类可利用的资源数目。其初始值是系统中所配置的该类全部可用资源的数目。其数值随该类资源的分配和回收而动态地改变。 最大需求矩阵 Max最大需求矩阵是一个 nXm 的矩阵，它定义了系统中 n 个进程中的每一个进程 对 m 类资源的最大需求。 分配矩阵 Allocation ：分配矩阵也叫做占有矩阵，是一个 nXm 的矩阵，它定义了系统中每一进程已占有的每一类资源数。 需求矩阵 Need ：需求矩阵也叫做申请矩阵，是一个 nXm 的矩阵，用以表示每一个进程尚需的各类资源数。银行家算法的实现： 进程申请资源的情况 银行家算法的描述 安全性算法安全算法步骤：银行家算法粗略代码：上述代码说明：银行家算法实例：死锁检测与解除死锁的预防和避免都是对资源的分配加以限制，操作系统解决死锁问题的另一条途径是死锁检测方法。死锁检测方法与死锁预防和避免策略不同，这种方法对资源分配不加限制，只要有剩余的资源，就可把资源分配给申请的进程，允许系统有死锁发生，这样做的结果可能会造成死锁，关键是当死锁发生时系统能够尽快检测到，以便及时解除死锁，使系统恢复正常运行。因此，采用这种方法必须解决 3 个问题： 何时检测死锁的发生（启动检测程序的频率）； 如何判断系统是否出现了死锁； 当发现死锁发生时如何解除死锁。 死锁的检测 （1）利用资源分配图：具体可参看“资源分配图”一节，这里只介绍如何利用资源分配图来检测死锁是否发生。资源分配图的简化：利用资源分配图进行死锁检测的目的是为了确定当前状态是否发生死锁。如果满足下列条件，那么一个连续、可重用资源图就能够通过进程 P 化简。 进程没有被阻塞； 进程没有请求边； 有分配边指向 P。总之，只要进程 P 只有入度（有向图中的概念）就可以在资源分配图中“删除”P ，同时消除指向 P 的所有分配边（指向 P 的边），于是释放了资源，那么其他进程的资源请求就可能重新得到满足。只要存在这样的 P（任意进程），就可以按照这种方式化简，直到不存在这样的 P 进程（不能完全简化）或资源图中没有进程（完全简化）为止。死锁定理：通过资源分配图可以很直观地看出系统中的进程使用资源情况。显然，如果图中不出现封闭的环路，则系统中不会存在死锁。如果系统出现由各有向边组成的环路，则是否产生死锁，还需进一步分析。如果环路可以通过化简取消，则系统一定不产生死锁；如果环路通过化简方式扔不能取消，即不能再进行简化，则系统一定会产生死锁。这就是著名的死锁定理。资源分配图死锁检测实例：下面介绍特殊的资源分配图。其中的每种资源类型只有单个实例。其死锁检测算法使用了资源分配图的变种，称为等待图。 （2）死锁检测算法死锁检测算法实例：死锁检测时机：另一个不太昂贵的方法是在一个不频繁的时间间隔里调用检测算法，如每小时一次，或当 CPU 使用率低于 40% 时（死锁最终会使系统性能下降，并造成 CPU 使用率下降）。如果在不定的时间点调用检测算法，那么资源图可能会有许多环。通常不能确定死锁进程中是哪些引起了死锁。 死锁解除当死锁检测算法确定死锁已经存在，那么可以采取多种措施。一种措施是通知操作员死锁已发生，以便操作人员人工处理死锁。另一种措施是让系统从死锁状态中自动恢复过来。打破死锁有两个方法： 简单地终止一个或多个进程以打破循环等待； 从一个或多个死锁进程那里抢占一个或多个资源。下面是这两种方法的具体描述： 进程终止 终止所有死锁进程； 一次只终止一个进程直到取消死锁循环为止。 资源抢占如果要求使用抢占资源来处理死锁，那么有三个问题需要处理： 选择一个牺牲品； 回滚：逐步回滚（到安全状态）或完全回滚（只能重新启动进程）。 饥饿：如何保证资源不会总是从同一个进程中抢占。总之，常用的死锁解除方法有：资源剥夺法、进程回退法、进程撤销法和系统重启法等。具体方法描述小结如下：选择剥夺资源或杀死进程的原则：尽管检测死锁是否出现和发现死锁后实现恢复的代价大于防止和避免死锁所花费的代价，但由于死锁不是经常出现的，因而这样做还是值得的。检测策略的代价依赖于死锁出现的频率，而恢复的代价是指处理器时间的损失。综合的死锁策略从上表可见，所有解决死锁的策略都各有其优缺点。与其将操作系统机制设计为只采用其中一种策略，还不如在不同情况下使用不同的策略更有效。内存管理存储管理是操作系统的重要组成部分。计算机系统的主要用途是执行程序。在执行时，这些程序及数据所访问的数据必须在内存里，至少部分是如此（CPU 只能直接访问寄存器、高速缓存和主存），因此，存储管理的优劣直接影响系统性能。在多道程序设计和分时系统的环境下，内存通常相对较小，不足以永久地容纳所有数据和程序，因此计算机系统必须提供次级存储以支持内存。现代计算机系统采用硬盘作为信息（程序和数据）的主要在线存储媒介。文件系统为在线存储和访问驻留在硬盘上的数据提供了一种机制。如此就形成了存储器的层次。存储器的层次：可执行程序必须被保存在主存储中，与设备相交换的信息也依托于主存地址空间。由于处理器在执行指令时的主存访问时间远大于其处理时间（CPU 时间），所以，寄存器和高速缓存被引入来加快指令的执行。由于程序在执行和处理数据时往往存在顺序性和局部性，执行时并不需要将其全部调入主存，仅调入当前使用的一部分，其他部分待需要时再逐步调入。如此就可以在磁盘上建立磁盘高速缓存以扩充主存器的存储空间，计算程序和所处理的数据可装入磁盘高速缓存，操作系统自动实现主存储器和磁盘高速缓存之间的程序和数据的调入和调出，从而向用户提供比实际主存容量大得多的存储空间。概述主存空间一般分为两部分：一部分是系统区，用于存放操作系统内核程序和数据结构等；另一部分是用户区，用于存放应用程序和数据。所以通常说的主存管理主要是对用户区的管理。存储管理所研究的主要内容包括 3 个方面： 取：“取”是指研究应将哪道程序（或程序的一部分）从辅存调入主存，一般有请调和预调之分。前者是需要时再调入；后者是采用某种策略，预测并调入即将使用的某道程序（或程序的一部分）到主存。 放：“放”是研究将“取”来的程序（或程序的一部分）按何种方式存放在主存的什么地方。“放”是存储器管理的基础。目前“放”的技术归结为两类：一类是连续的，即运行的程序必须存放在主存的一片连续空间中；另一类是不连续的，即运行的程序可以放在主存的多个不相邻的块中。 替换：“替换”是研究应将哪道程序（或程序的一部分）暂时从主存移到辅存以腾出主存空间供其他程序（或程序的一部分）占用。内存管理需求内存管理一般有 5 点需求：重定位、存储保护、共享、逻辑组织、物理组织。 重定位：在多道程序设计系统中，通常情况下，应用程序员并不能事先知道主存中已经有几道程序以及占用了那部分内存，那么操作系统必须能把程序员使用的逻辑地址重定位到内存地址空间中。而且在进程运行过程可能会被交换，这也需要重定位。 存储保护：主存中驻留了多个进程，每个进程都应该受到保护，以免被其他进程有意或无意地干涉。由于重定位的存在，存储保护必须在运行时检查进程产生的所有内存访问，以确保它们只访问分配给自己的存储空间或有权访问的其他共享空间。需要注意的是，内存保护的需求必须有处理器（硬件）来满足，而不是由操作系统（软件）满足。 共享：节约主存空间，提高主存利用率和效率。 逻辑组织：是逻辑空间的组织满足用户编程和数据组织的需要，提高易用性。 物理组织：将主存用较好的物理方式组织起来，以尽可能提高主存利用率和效率。存储管理功能前面说到的需求似乎抽象一些。本节将需求具体化为内存管理应具有的一些功能： 分配和回收：进程可请求对主存区的独占式使用（至少用户感觉是这样），主存区的请求和释放即主存空间的分配和回收操作由存储管理来完成。 抽象和映射主存储器被抽象成这样：使用户认为分配给它的地址空间是从 0 开始的一个无限大和连续的空间。好像用户独占主存一样（多道程序设计系统使用起来和单道系统一样）。 隔离和共享使用户无法感知其他程序的存在，同时也要满足用户对其他程序提供的信息共享的需要。即使用户没有明确的需要，系统也会为了提高主存利用率（使用一个副本总比使用多个副本要节约空间）而对程序间相同的部分进行共享。 存储扩充物理主存容量不应限制应用程序的大小，主存和辅助存储器被抽象为虚拟主存，允许用户的虚拟地址空间大于主存物理地址空间，存储管理自动在不同的存储层次中移动信息。后面的章节将围绕如何实现这些功能而展开。而且几乎每一种内存管理方法都要实现这些功能。用户程序内存管理主要是对主存中的用户区进行管理，而用户区是用来安放用户程序的，所以要想充分利用用户区，还得充分了解用户程序结构特点和处理过程。 用户程序的处理过程系统对用户程序的处理分为以下几个阶段： 编译：由编译器的编译程序将用户源代码编译成若干个目标模块。每个目标模块都有自己的独立逻辑地址空间。有些库函数、系统调用或其他引入的文件有可能系统已经编译好了。 链接：由链接程序将编译后形成的目标代码以及它们所需的库函数链接在一起，形成一个装入模块。 装入：由装入程序将装入模块装入内存。 执行：由调度程序分配处理机执行。重要概念： 逻辑地址：逻辑地址是一个操作数在逻辑地址空间中的地址（CPU 所生成的地址，程序计数器 PC 值）。逻辑地址空间是程序及数据所构成的空间，所有单独编译的模块都是从 0 开始编址的。可见，逻辑地址是可以重叠的（实际上他们处于不同的作用域内，其实可以通过模块名加以区分）。逻辑地址只是同一个模块中的相对地址，其绝对地址取决于模块装入和位置和方式，此时的逻辑地址又被称为虚拟地址。linux 中 fork 出的子进程与父进程的逻辑地址空间相同，所以，它们的同名变量（没有被覆盖重定义的情况下）打印出的地址（逻辑地址）相同，但是，它们的物理地址（堆栈段）实际上是不同的（然而，代码段和静态区段的物理地址相同，这是由其全局性决定的）。 物理地址：物理地址是指模块装入内存后的真实地址，即加载到内存地址寄存器中的地址，是主存中的绝对地址，不允许没有空间共享的两个不同模块的物理地址在相同时刻有重叠。 重定位：重定位是指将一个操作数的逻辑地址转换为物理地址。可见用户程序处理的是逻辑地址，而看不到真正的物理地址。 目标程序装入内存的方式对用户程序处理过程中的每一个环节都可能有不同的方式。而程序只有装入内存后才能运行。装入方式分为：绝对装入方式、可重定位装入方式和动态运行时装入方式。 绝对装入方式：如果在编译时就知道进程将在内存中的驻留地址，那么就可以生成绝对代码。如果将来开始地址发生变化，那么就必须重新编译代码。通常情况是在程序中采用符号地址，然后在编译或汇编时，将这些符号地址再转化为绝对地址。MS-DOS 的 .COM 格式程序就是在编译时捆绑成绝对代码的。 可重定位装入方式：在程序执行之前，由操作系统重定位装入程序完成。一般用于多道程序环境中。重定位程序根据装入程序的内存起始地址，直接用“起始地址 + 逻辑地址”的方式得到正确的内存地址。 动态运行时装入方式：该方式是在程序执行期间进行的。程序执行期间可能会发生移动或换入换出（每次换入的位置可能不同），即在执行过程中在主存中的位置发生改变。在这种情况下，静态重定位不能解决问题，需要用动态重定位。采用运行时动态装入时，一个子程序只有在调用时才被加载，所有子程序都以可重定位的形式保存在磁盘上。主程序装入内存并执行，当一个子程序需要调用另一个子程序时，调用子程序首先检查另一个子程序是否已加载。如果没有，可重定位的链接程序将被用用来加载所需要的子程序，并更新程序的地址表以反映这一变化。之后，控制权传递给新加载的子程序。该方式的优点是不用的子程序绝不会被装入内存。如果大多数代码需要用来处理异常情况（如错误处理）或程序中含有很多分支处理子程序（只有满足条件的分支才会被执行）。对这种情况，虽然总体上程序比较大，但是所使用的部分（即加载的部分）可能小很多。上述两种动态装入不需要操作系统提供特别的支持。利用这种方法来设计程序主要是用户的责任。不过，操作系统可以帮助程序员，如提供子程序库以实现动态加载或链接。一般说来，动态重定位需要有专门的硬件机构来完成，通常采用一个重定位寄存器，每次进行存储访问时，将取出的逻辑地址加上重定位寄存器的内容，形成正确的内存地址。 目标程序链接链接程序的功能是将经过编译或汇编后得到的一组目标模块以及它们所需的库函数或外来模块装配成一个完整的装入模块。实现链接的方法有：静态链接、装入时动态链接和运行时动态链接。 静态链接：静态链接之后形成一个完整的准入模块，又称为执行文件，通常不再拆开，运行时可直接装入内存。在多道程序环境下，不同的执行文件中可能具有相同的模块，如相同的库函数调用，这实际上造成了多个副本，浪费空间。而且一般需要整体装入（需要更大的连续空间），必须以一个整体的形式进行，本来可以将其中不常用的一部分换出即可。 装入时动态链接：用户源程序经编译后得到目标模块，在装入内存时边装入边链接，即在装入一个目标模块时，若发生一个外部模块调用，装入程序将去寻找相应的外部目标模块，并将它装入内存。装入时进行的链接虽然可以将整个模块装入内存的任何地方，但装入模块的结构是静态的，在程序执行期间装入模块时不可改变的，因为无法预知本次要运行哪个模块，只能将所有可能要运行的模块，在装入时全部链接在一起。这种方法可以在当某个模块更新之后不需要重新链接成一整个执行文件，便于局部更新。 运行时动态链接：在这种链接方式中，可将某些目标模块的链接推迟到执行时才进行，即在执行过程中，若发现一个被调用模块尚未装入内存时，由 OS 去找该模块，将它装入内存，并把它链接到调用模块上。这一特点（其实，装入时动态链接也具有本段的性质）通常用于系统库，如语言子程序库。没有这一点，系统上的所有程序都需要一份其语言库的拷贝（或至少那些被程序所引用的子程序）。这一要求将浪费磁盘和主存空间。如果用运行时动态链接，二进制映像中对每个库程序的引用都有一个存根。存根是一小段代码，用来指出如何定位适当的内存驻留库程序，或如果该程序不在内存时应如何装入库。它与装入时动态链接的区别在于其是和动态装入（或加载）配套使用的。两种动态链接都可用于库更新，使用该库的所有程序会自动使用新的版本。没有动态链接，所有这些程序如果要使用新的库。为了避免使程序错用新的、不兼容版本的库，程序和库（同时存在多个版本）可以包括版本信息。与动态装入（或加载）不一样，动态链接通常需要操作系统的帮助。如果内存中进程是彼此保护的（共享的子程序或库函数段只需要装入一次即可被其他所有调用者共享），那么只有操作系统才可以检查所需子程序是否在其他进程内存空间内（被链接到锁调用进程的空间内），或是允许多个进程访问用一内存地址。无存储器抽象的内存管理最简单的存储器抽象就是根本没有抽象，直接操纵物理地址空间。每一个程序都直接访问物理内存。使用多道程序设计时需要使用静态链接、绝对装入或静态重定位的方式。而且要事先知道各道程序所需空间。这种直接引用物理地址对于大型计算机、小型计算机、台式计算机和笔记本电脑来说已经成为很久远的记忆了，但是缺少内存抽象的情况在嵌入式系统和智能卡系统中是很常见的。现在，像洗衣机和微波炉这样的设备都已经完全被（ROM 形式的）软件控制，在这些情况下，软件都采用访问绝对内存地址的寻址方式。这样能够正常工作是因为，所有运行的程序都是可以事先确定的，用户不可能在洗衣机上自由地运行他们自己的软件。虽然高端的嵌入式系统（如手机）有复杂的操作系统，但是一般的简单嵌入式系统并非如此。在某些情况下可以用一种简单的操作系统，它只是一个被链接到应用程序的库，该库为程序提供 I/O 和其他任务所需要的系统调用。注意：本博客提到的存储管理都是基于有抽象的存储器管理。连续分配存储管理方式连续分配是指为一个用户程序分配一个连续的内存空间，包括单道程序的连续分配和多道程序的连续分配。连续分配方式又称为分区分配方式，包括固定分区、动态分区和动态重定位分区 3 种。单道程序的连续分配单道程序的连续分配是一种最简单的存储分配方式。只能用于单用户、单任务的操作系统。在这种存储管理方式下，内存分为系统区和用户区两个分区。为了避免用户程序执行时访问操作系统所占空间，应将用户程序的执行严格控制在用户区域（即存储保护），保护措施主要是由硬件实现。硬件提供界地址寄存器和越界检查机构。将操作系统所在空间的下界存放在界地址寄存器中，用户程序执行时，每访问一次主存，越界检查机构便将访问主存的地址和界地址寄存器的值进行比较，若出界则报地址错。固定分区分配方式固定分区管理方式的基本思想是：主存空间被划分成数目固定不变的分区，各分区的大小固定不变（各分区的大小可以相等也可以不等），每个分区只装入一个作业，若多个分区中都装有作业，则它们可以并发执行，这是支持多道程序设计的最简单的存储管理技术。固定分区存储管理又称为定长分区或静态分区模式。在这种管理方式下，操作系统启动时系统操作员根据当天作业情况借助操作系统命令划分与确定好分区的大小和个数（一旦确定下来，可以并发的程序道数也就被限制了），即使如此，在有比较多作业且无法一次性装下所有作业的情况下，划分出的分区不一定适合所有作业，可能出现空闲分区过小或过大的情形，这样可能出现： 小作业不能有效地利用分区空间； 作业需要排队进入主存区； 分区无法容纳整个作业时，还需要使用覆盖、换入换出等技术加以补救，不但加重了用户的负担（覆盖需要程序员的手动规划和编写方案），而且极不方便。在程序运行期间，整个系统中的分区不再变化。因此，为一个作业分配空间时，应先根据一定的分区分配策略，为作业选择一个分区，然后再分配。作业进入分区排队策略：动态分区为了克服固定分区的一些缺点，出现了动态分区方法（不过已经被其他更好的方法所取代）。对于动态分区，分区长度和数目是可变的。当进程被装入内存时，系统会给它分配一块和它所需容量完全相等的内存空间，不多不少。动态分区方法在开始时是很好的，随着进程的退出和进入（退出和进入的顺序是很难预知的，当然可以根据空闲区的大小从等待队列中选择较为合适的作业进入，但是，进程配对、退出、进入的随机性很强），它最终会导致内存中出现许多小的碎片（即外部碎片），可能任何碎片都无法被进程使用，即使所有碎片总和能够容下进程，不经过紧缩（请参考“可重定位分区”）处理也无法利用。空闲区块的分配方法： 首次适应分配第一个足够大的空闲块，查找可以从头开始，也可以从上次首次适应结束时开始，一旦找到足够大的空闲区就可以停止查找。 最佳适应分配最小的足够的空闲区，必须查找整个列表，除非列表按大小排序。这种方法将会出现最小的剩余空闲区。 最差适应分配最大的空闲区。同样查找整个列表，除非列表按大小排序。这种方法将产生最大剩余空闲区，该空闲区可能比最佳适应产生的较小剩余空闲区更为有用。 快速匹配法它的基本思路是：对于一些常用的或特殊的请求大小，为它们分别设置各自的链表分别进行管理，如此分类管理减少了查找等的开销。不过，在一个进程终止或被换出（回收）时，查找合并相邻空闲区是非常费时的。评价这些算法好坏的标准有两条：算法本身的时间复杂度（排序和查找）、空间利用率。模拟结果显示，首次适配和最佳适配在执行时间和利用空间方面都好于最差适配。首次适配和最佳适配在利用空间方面相差不大，但是首次适配要快些。不过，正如前面所说，这些算法都有外部碎片问题。动态分区的内存回收：回收分区的主要工作是首先检查是否有相邻的空闲区，如果有则合并，使之成为一个连续的空闲区。避免形成许多离散的小分区。可重定位分区（紧缩） 紧缩（紧凑）在连续分配方式中，必须把一个系统程序或用户程序装入到连续的内存空间中，如果系统中存在若干个小的分区，每个小分区都不能满足装入程序的需要，该程序就不能装入内存，但各空闲分区之和大于要装入的程序。在这种情况下，要想装入作业，可采用的方法是：将内存的作业进行移动，使它们相邻，使原来许多分散的小分区可以拼接成大的分区，称为“紧缩”。由于经过紧缩的用户程序在内存中的位置发生了变化，若不对程序中的数据地址进行修改变换，程序无法执行，因此必须进行重定位（运行时动态重定位）。 动态重定位分区分配算法该算法与动态分区分配算法基本相同，差别仅在于这种分配算法中增加了“紧缩”功能。通常，若找不到足够大的空闲区来满足用户的需要，则进行“紧缩”或“交换”（根据开销进行选择。开销包括已经做了的工作类型及其工作量、剩余的工作量与交换所需开销），然后寻找合适的内存空间。伙伴系统固定分区和动态分区方案都有缺陷。固定分区方案限制了活动进程的数目，并且如果可用分区的大小与进程大小非常不匹配，则内存空间的利用率非常低。动态分区的维护特别复杂，并且引入了进行紧缩的额外开销。一种更有吸引力的折中方案是伙伴系统。分配算法： 确定允许的最小分区和最大分区，所有分区都是 2 的整数幂； 比较请求的大小和空闲分区集合中最佳分区的大小关系： 最佳分区为允许的最小分区，则直接分配，否则 请求大小 &lt; 最佳分区的 1/2，则将最佳分区均分为二，直到分离出新的最佳分区（这个只是计算过程，实际上最后分成两部分，一个大分区和一个不能再分的最佳分区）不满足再分条件为止，然后将其分配出去； 否则将最佳分区整个分配出去。 “不能再分的分区”的条件：已经到了允许的最小分区或是再分就不能最佳适应请求分区的大小了。内存回收：回收内存时候要在空闲区集合中查找其伙伴，如果存在伙伴则合并（合并之后可能出现新的伙伴），直到没有伙伴为止。为了实现伙伴系统算法，需要位图（标志已分配的分区）和空闲链表作为辅助工具，伙伴系统分配和合并操作速度快，但可能出现较大的内部碎片（因为最佳分区可能选择不当）。而且，在当前的操作系统中，基于分页和分段机制的虚拟内存更先进。然而，伙伴系统在并行系统中有很多应用，它是为并行程序分配和释放内存的一种有效算法。空闲内存管理在动态分配内存时，操作系统必须对其进行管理。一般而言，有两种方式跟踪内存使用情况：位图和空闲链表。基于位图的存储管理使用位图方法时，内存可能被划分（相等的）成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲，1 表示占用（或者相反）。一块内存区和其对应的位图如下图所示：分配单元的大小是一个重要的设计因素。分配单元越小，位图越大。如果分配单元过大，那么在最后一个分配单元中就会有一定数量的内存被浪费了。因为内存的大小和分配单元的大小决定了位图的大小，所以它提供了一种简单的利用一块固定大小的内存，区就能对内存使用情况进行记录的方法。这种方法的主要问题是，在决定把某个占 k 个分配单元的进程调用内存时，存储管理必须搜索位图，在位图中找出有 k 个连续 0 的串。这是很耗时的操作。基于链表的存储管理动态分区可以使用两张表来管理内存，它们是：已分配区表和未分配区表。如此，对内存的管理就变成了对表格的曾删查改（实际上并不是真的清除了内存中的内容，只是将允许该进程访问该内存区块，原有的内容实际上还是存在的，只不过后面将被覆盖，所以，程序员最好对每个变量都初始化，当然一般编译器会默认初始化，否则，未初始化变量中的内容是无法预知的）。由于分区的数目不定，采用链表来管理空闲区可能更好。用链指针把所有空闲分区链接起来，每个主存空闲区的开头单元存放本空闲区长度及下一个空闲区起始地址指针，系统设置指向空闲区链的头指针。在使用时，沿链查找并取一个长度能满足要求的空闲区给进程，再修改链表（已分配表和未分配区表）；归还时，把此空闲区链入空闲区链表的相应位置即可。空闲区链表管理比空闲区表格管理要复杂，但其优点是链表自身并不占用存储单元（至少不需要预先占用一大块连续的空间）。为了提高链表查找效率，可以将进程（即，已分配空间链表）和空闲区使用不同的链表（甚至可以精简链表项，将一部分表项存储在对应的空闲区存储空间内）。无论空闲区表管理还是空闲区链表管理，表格和链表中的空闲区项都可按一定规则排列。例如，按空闲区大小、空闲区地址等，以方便空闲区的查找和回收。具体的查找回收算法请参考“动态分区”一节中相关内容。内存不足的存储管理技术这里说的内存不足有两种情况： 绝对不足：整个内存过小，不满足单道程序的大内存要求； 相对不足：空闲内存或分配给该进程的内存不足。 运行不足：分配给进程的内存空间开始是足够的，后面由于进程数据等的增长导致运行期间进程内存不足。移动技术（主存紧凑）当在未分配区表中找不到足够大的空闲区来装入新进程时，可采用移动技术（运行时动态重定位）把已在主存中的进程分区（即已经分配出去的空间，进程链表可以表征）连接到一起，使分散的空闲区汇集成片，这就是移动技术，也叫做主存紧凑。这种技术有两种方法可选： 把所有当前占用的分区移动到主存的一端，直到所有空闲分区集中在一起。 把占用分区移动到主存的一端，但当产生足够大小的空闲分区时就停止移动。使用移动技术的移动时机： 当一道程序正在与设备交换数据时往往不能移动，系统应设法减少移动（因为块设备在与主存交换信息时，通道或 DMA 不用 CPU 参与，总是按确定的主存绝对地址完成信息传输，即使移动了，它也会按照原来的地址存取数据，从而导致错误和对移动到该区域的进程造成破坏）； 进程撤销之后释放分区时，如果它不与空闲区邻接，立即实施移动，于是，系统始终保持只有一个空闲区； 进程装入分区时，若空闲区的总和够用，但没有一个空闲区能容纳此进程时，实施移动。移动操作也为进程运行过程中动态扩充主存空间提供了方便。当进程在执行过程中要求增加主存分配区时，只需适当移动临近的占用分区（可能要移动好几个进程或者换出某个进程）就可增加其所占有的连续区的长度，移动后的基值和经扩大的限长值都要做相应修改。对换技术对换技术广泛应用于分时系统的调度中，以解决主存容量不足的问题，使分时用户获得快速响应时间；也可用于批处理系统，以平衡系统负载。如果当前一个或多个驻留进程都处于阻塞态，此时选择其中的一个或几个进程，将其暂时移出主存，腾出空间给其他进程使用，同时把磁盘中的某个进程换入主存，让其投入运行，这种互换称为对换。交换技术的应用场景：该技术可用于同时为很多用户服务的分时系统，如此可以改善响应时间和大部分的用户体验。这种交换策略的变种被用在基于优先权的调度算法中。如果一个更优先级进程来了且需要服务，内存管理可以交换出低优先级和低代价的进程，以便可以装入和执行更高优先级的进程。当更高优先级进程执行完后，低优先级进程可以交换回内存以继续执行。交换需要的技术支持： 配套的装入方式：通常一个交换出的进程需要交换回它原来所占有的内存空间。这一限制是由地址捆绑（逻辑地址到物理地址的转化）方式决定的。如果捆绑是在汇编时或加载时决定的。，那么就不可以移动到不同的位置。如果捆绑在运行时确定，由于物理地址是在运行时才确定的，那么进程可以移动到不同的地址空间。 快速磁盘及交换处理过程：交换需要备份存储。备份存储通常是快速磁盘。这必须足够大，以便容纳所有用户的内存映像拷贝，它也必须提供对这些内存映像的直接访问。系统有一个就绪队列，它包括在备份存储或在内存中准备运行的所有进程。当 CPU 调度程序决定执行进程时，它调用派遣程序来检查队列中的下一个进程是否在内存中。如果不在内存中且没有空闲内存空间，派遣程序检查队列中的下一进程是否在内存中。如果不在内存中且没有空闲内存空间，派遣程序将一个已在内存中的进程交换出去，并换入索要的进程。然后，它重新装载寄存器，并将控制权转交给所选择的进程。对换决策： 进程选择：首先要解决的是选择哪个进程换出，选择标准如下： 进程阻塞的原因是不同的，换出时需要考虑其阻塞原因（因为这涉及到可不可以换出，换出的代价如何）； 进程的工作类型，这涉及到进程变化部分的多少（假设变化很少，一般磁盘本来就存在一个副本，只需保存变化的信息即可）； 换出的进程（最后只换出一个进程）空间足够用于新进程； 换入换出的时间开销要远小于该进程剩余的执行时间以及新进程需要执行的时间； 待换出的阻塞态进程阻塞时间够长（以便防止频繁的换入换出），优先级较低； 交换的本身时间消耗（与待换出的进程空间大小有关）要尽量少； 有些时候不一定要把整个进程都换出去，这就需要决定具体换出进程的那一部分，尽量换出信息变动频率小的部分； 如果进程 I/O 是以异步的方式访问用户内存的 I/O 缓冲区的，那么该进程就不能够被换出（可能导致 I/O 数据损失和新进程数据遭到破坏，因为 I/O 一般直接使用绝对物理地址进行操作）。对这个问题有两种解决方法：（1）不能换出有待处理的 I/O 进程；（2）I/O 操作的执行只能使用操作系统缓冲，而且不剥夺正在使用的缓冲区，仅当换入进程后，才执行操作系统缓冲与进程内存之间的数据转移。假设一个被对换的进程映像占用 k 个磁盘块，那么，一次进程对换的所有开销是 2k 个磁盘块输入/输出的时间，在加上进程重新请求主存资源所造成的时间延迟。 信息备份：决定备份那些信息，如何备份。开始时，进程从可执行文件被装入主存，其未曾修改的部分（如代码段）在主存与磁盘中始终保持一致，这些信息不必保存，当进程换回主存时，只需简单地从最初的可执行文件再加载一次；数据区和堆栈是进程运行时所创建和修改的，操作系统可通过文件系统把这些可变信息作为特殊文件保存。 对换空间：尽量加快对换空间的访问速度。有些系统从降低开销的角度考虑，开辟一块特殊的磁盘区域作为对换空间，它包含连续的柱面和磁道，可通过底层磁盘读写实现高效访问。此时，交换不需要或只需要很少磁头移动，因此较普通的磁盘访问要快。 对换时机：提高整机效率。 在批处理系统中，当进程要求动态扩充主存空间且得不到满足时可触发对换； 在分时系统中，对换可与调度结合，每个时间片结束或执行 I/O 操作时实施（CPU 空闲时），调度程序启动一个被换出的进程换入（预换入）。这样，轮到它执行时立即可以启动。 普通交换使用不多。交换需要很多时间，而且提供很少的时间片执行时间（导致相对时间开销过大），因此这不是一种有效内存管理解决方案。然而，一些交换的变种却在许多系统中得以使用。UNIX 中，交换通常不执行，但当有许多进程运行且内存空间吃紧时，交换开始启动。如果系统负荷降低，那么交换就暂停。对换与移动技术的比较：对换技术比移动技术更有效，移动不能保证得到一个满足请求的空闲区，而利用对换技术总可按需换出若干驻留的阻塞进程，且对换仅涉及少量进程，只需更少的主存访问。与移动不同的是，对换要访问磁盘，这是一个 I/O 集中型操作，会影响对用户的响应时间，但系统可让对换与计算型进程并行工作，不会造成系统性能的显著下降。覆盖技术移动和对换技术解决的是因其他程序存在而导致主存不足的问题，这种主存短缺只是暂时的；如果程序的长度超出了物理主存的总和，或超出了固定分区的大小，则出现主存永久性短缺，大程序无法运行，前述的两种方法无能为力，解决方法之一是采用覆盖技术。覆盖的思想是：在任何时候只在内存中保留所需的指令和数据。当需要其他指令时，他们会装入到刚刚不再需要的指令所占用的内存空间内。覆盖驱动程序根据需要将它们读入内存。为了构造覆盖，需要使用特殊的重定位和链接算法。覆盖的实现技术：把用户空间分成固定区和一个或多个覆盖区，把控制或不可覆盖部分（如主函数）放在固定区，其余按调用结构及先后关系分段并存放在磁盘上，运行时一次调入覆盖区。系统必须提供覆盖控制程序及相应的系统调用，当进程装入运行时，由系统根据用户给出的覆盖结构进程覆盖处理，程序员必须指明同时驻留在主存的是哪些程序段，哪些是被覆盖的程序段，这种声明可从程序调用结构中获得。覆盖技术的评价：与动态加载（或装入）一样，覆盖不需要操作系统提供特别支持。用户通过简单文件结构，将文件读入内存，并执行所读指令就可以完全实现覆盖。操作系统只不过注意到I/O 操作比平常多些而已。另一方面，程序员必须适当地设计和编写覆盖结构。这并不简单，需要对程序结构、代码、数据结构有完全了解。由于程序比较大时才需要使用覆盖，而此时获取对程序的足够且完整的理解可能比较困难。由于这些原因，覆盖的使用通常局限于微处理机和只有有限物理内存且缺乏更先进硬件支持的其他系统。基本分页存储管理用分区方式管理存储器，每道程序要求占用主存的一个或多个连续存储区域，导致主存中产生“碎片”。虽然可通过“紧凑”方法将许多碎片拼接成可用的大块空间，但必须为之付出很大开销。如果允许将一个进程直接分散地装入到许多不相邻接的分区中，则无须再进行“紧凑”。基于这一思想产生了离散分配方式。如果离散分配的基本单位是页，则称为分页存储管理方式；如果离散分配的基本单位是段，则称为分段存储管理方式。在分页存储管理方式中，如果不具备页面对换功能，则称为基本的分页存储管理方式，或称为纯分页存储管理方式，它不具有支持实现虚拟存储器的功能，它要求把每个作业全部装入内存后才能运行。存储空间划分（分页）分页存储管理是将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页，并从 0 开始为各页加以编号。相应地，也把内存空间分成与页面相同大小的若干个物理存储块，称为（物理）块或页框或帧，也同样从 0 开始为它们加以编号。不过，页面编号占的位数要多于页框的编号位数，因为逻辑空间一般大于物理空间。在系统需要执行一个进程时，它将检查该进程所需要的页数。因此，如果进程需要 n 页，那么内存中至少有 n 个空余帧（请求分页机制除外）。如果有，那么就可分配给新进程，装入一帧就把相应的帧号放入进程的页表对应项目中。在为进程分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为页内碎片。页面大小在分页系统中的页面其大小应适中。 若页面太小： 虽然可使内存碎片减小，从而减少了内存碎片的总空间，有利于提高内存利用率； 也会使每个进程占用较多的页面，从而导致进程的页表过长，占用大量内存； 还会降低页面换进换出的效率。 如果选择的页面较大： 虽然可以减少页表的长度； 提高了页面的换进换出的速度； 却又会使也内碎片增大。 因此，页面的大小应选择适中，且页面大小应是 2 的幂，通常为 512 B ~ 8 KB。假设进程的大小是随机性的，那么可以推测每个进程平均可能有半页的内部碎片。地址映射（页表）逻辑地址（它是一个自相对于程序开始处的位置）由两部分组成： 页号：即页面编号，用于查询安放在物理地址空间中对应的物理块号； 页内位移：即相对于本页起始位置的偏移量，用于表述具体指令或数据在页面中的具体位置，从而确定在相应物理块中的具体物理位置。逻辑地址空间的总大小（即逻辑地址的位数 = 页号位数 + 页内位移的位数）由地址总线的位数决定（一般而言，32 位地址总线最大支持的文件大小为 4G）。一页的大小由页内位移所占的位数决定，逻辑空间能容纳的页数最大值由页号所占的位数决定。采用分页存储管理时，逻辑地址是连续的，用户在编制程序时仍使用相对地址，不必考虑如何分页，由硬件地址装换机构和操作系统的管理需要来决定页面的尺寸，从而确定主存分块大小。进程在主存中的每个页框内的地址是连续的，但同属一个进程的页框之间的地址可以不连续，进程主存地址由连续到离散的变化为虚拟存储器的实现奠定了基础。 基本概念： 页表逻辑地址到物理地址的转换仍然采用动态地址重定位技术，让程序在执行时动态地进程地址变换。由于程序以页面为单位存储，所以为每个页面设立一个重定位寄存器，这些重定位寄存器的集合称为页表。由于寄存器的硬件代价过高，实际上页表由软件构成，存储在内存中或想联存储器（快表）中。页表是操作系统为进程建立的，是程序页面和主存对应页框的对照表，页表中的每一栏指明程序中的一个页面和分得页框之间的对应关系。使用页表的目的是把页面映射为页框。为了降低系统价格，不用硬件而是在主存中开辟存储区以存放进程页表，系统另外设置专用硬件—–页表基址寄存器，存放当前运行进程的页表的起始地址，以加快地址转换速度。系统应为主存中的进程进行存储分配，并建立页表，指出逻辑地址页号与主存页框号之间的对应关系，页表的长度随进程大小而定。 帧表由于操作系统管理内存，它必须知道物理内存的分配细节：哪些帧已经分配，哪些帧空着，总共有多少帧等等，这些信息常常保存在称为帧表的数据结构中。在帧表中，每个条目对应着一个帧，以标识该帧是空闲还是已被占用，如果占用，是为哪个进程的哪个页所占用。地址变换进程运行前由系统把它的页表基地址送入页表基址寄存器，运行时借助于硬件的地址转换机构，按页面动态地址重定位，当 CPU 获得逻辑地址后，由硬件自动按设定的页面尺寸分成两部分：页号 p 和页内位移 d，先从页表基址寄存器找到页表基地址（页表存放位置，其位置信息一般放在 PCB 中），再用页号 p 作为索引查页表（查找操作由硬件执行），得到对应的页框号，根据关系式： 物理地址 = 页框号（第一个页框的基地址为 0） X 块长 + 页内位移计算出欲访问的主存单元。因此，虽然进程存放在若干不连续的页框中，但在执行过程中总能按正确的物理地址进行存取。注意：在以页号为索引去检索页表前，先将页号与页表长度进行比较，如果页号大于或等于页表长度（从 0 开始编号），则表示本次所访问的地址已超越进程的地址空间。于是，这一错误将被系统发现并产生一地址越界中断。若未出现越界错误，才进行下一步操作。需要补充的是：页表项除了上图中的必要项之外，为了其他需求还会有其他数据项，详见“虚拟存储器管理”，如：快表（TLB）页表可存放在一组寄存器中，地址转换时只要从相应寄存器中取值就可得到页框号，这样做虽然能加快地址转换，但硬件代价太高；页表也可存放在主存中，只需要一个页表基地址寄存器，如此可降低硬件开销，但按照给定的逻辑地址，进行读写操作时，至少访问主存两次： 一次访问页表，经过计算或变换得到物理地址； 另一次根据物理地址访问改地址中的指令或存取数据。这将降低运算速度，比通常执行指令时速度慢一半。在绝大多数情况下，这种延迟是无法忍受的，还不如采用交换机制。为了提高地址变换速度，可在地址变换机构中增设一个具有并行查询能力的特殊高速缓冲寄存器，又称为“联想寄存器”或称为快表（TLB）。用以存放当前访问的那些页表项。此时的地址变换过程有两种形式： 查 TLB 和内存中的页表，两者同时进行；如果在 TLB 中，则内存页表查找立即停止，否则继续查内存页表； 先查 TLB，只有没有命中时，才开始查找内存中的页表。详细装换过程如下：在 CPU 给出有效地址后（未越界的逻辑地址），由地址变换机构自动地将页号 p 送入告诉缓冲寄存器（TLB），并将此页号与高速缓存中的所有页号进行比较（这是并行比较的），若其中有与此相匹配的页号，便表示所要访问的页表项在快表中。于是，可直接从快表中读出该页所对应的物理块号，并送到物理地址寄存器中；如果在快表中未找到对应的页表项，则还须再访问内存中的页表，找到后，把从页表项中读出的物理块号送地址寄存器；同时，再将此页表项存入快表的一个寄存器单元中，即重新修改快表。但如果联想寄存器已满，则 OS 必须找到一个老的且已被认为不再需要或很久之后才需要的页表项，将它换出。由于成本的关系，快表不可能做得很大，通常只存放 16～512 个页表项，这对中小型作业来说，已有可能把全部页表项放在快表中，但对于大型作业，则只能将其一部分页表项放入其中。由于对程序和数据的访问往往带有局限性，因此，据统计，从快表中能找到所需页表项的几率可达 90% 以上。这样，由于增加了地址变换机构而造成的速度损失，可减少到 10% 以下，达到了可接受的程度。页表结构（或组织方式）在原有的内存页表方案之上，引入快表（TLB）可以用来加快虚拟地址到物理地址的转换。不过这不是唯一需要解决的问题，另一个问题是怎样处理巨大的虚拟地址空间。虚拟地址空间比较大时，页表就变得非常大，要占用相当大的内存空间，按照之前的页表连续存放方式（页表大小已经超出了一页的存储空间）来处理是不现实的。至少可以有一下两种方法来解决这一问题： 采用离散方式来解决难以找到一块连续的大内存空间的问题； 只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。 层次化分页 两级页表对于要求连续的内存空间来存放页表的问题，可利用将页表进行分页，并离散地将各个页面分别存放在不同的物理块中的办法来加以解决，同样也要为离散分配的页表再建立一张页表，称为外层页表(Outer Page Table)，在每个页表项中记录了页表页面的物理块号。两层页表结构中逻辑地址结构：如此就可以利用外层页表和页表这两级页表，来实现从进程的逻辑地址到内存中物理地址间的变换。两级页表地址转换：为了地址变换实现上的方便起见，在地址变换机构中同样需要增设一个外层页表寄存器，用于存放外层页表的始址，并利用逻辑地址中的外层页号，作为外层页表的索引，从中找到指定页表分页的始址，再利用 P2 作为指定页表分页的索引，找到指定的页表项，其中即含有该页在内存的物理块号，用该块号和页内地址 d 即可构成访问的内存物理地址。在采用两级页表结构的情况下，对于正在运行的进程，必须将其外层页表调入内存，而对页表则只需调入一页或几页。为了表征某页的页表是否已经调入内存，还应在外层页表项中增设一个状态位S，其值若为 0，表示该页表分页尚未调入内存；否则，说明其分页已在内存中。进程运行时，地址变换机构根据逻辑地址中的 P1，去查找外层页表；若所找到的页表项中的状态位为 0，则产生一中断信号，请求OS将该页表分页调入内存。两级页表地址转换需 3 次访问主存，一次访问页目录、一次访问页表页、一次访问指令或数据。 多级页表随着 64 位地址的出现和普及，二级页表仍不够用，所以，三级、四级页表也已被引入系统。多级页表实际上是对外层页表在进行分页，然后这些分页可以装入到不相邻的物理块中。虽然级别越多，灵活性越大，但页表超过三级会带来更大的复杂性，这样做是否值得令人怀疑。 反置（向）页表（或倒排页表）通常，每个进程都有一个相关页表，该进程所使用的每个页都在页表中有一项（或者每个虚拟页都有一项，不管后者是否有效，即使该页不在内存也要有一项）。这种表示方式比较自然，这是因为进程是通过虚拟地址来引用页的，操作系统必须将这种引用转换成物理内存地址。由于页表是按虚拟地址排序的，操作系统能够计算出所对应条目在页表中的位置，并可以直接使用该值。这种方法的缺点之一是：每个页表可能有很多项目，这些表可能消耗大量物理内存，这些只不过用来跟踪物理内存是如何使用的。换句话说，如果找到跟踪的简便方法，可能减小开销。为了解决这个问题，可以使用反置页表（IPT）。反置页表对于每个真正的内存页或帧才有一个条目。每个条目包含保存在真正内存位置的页虚拟地址，以及拥有该页的进程的信息。因此，整个系统只有一个页表。此表为主存中每个物理块建立一个 IPT 表项并按照块号进行排序，其表项包含：在此页框中的页面页号、页面所属进程的标识符和哈希链指针，用来完成逻辑地址到物理地址的转换，与此相适应，逻辑地址由进程标识符、页号和页内位移 3 个部分组成。反置页表地址转换过程：需要访问主存地址时，地址转换机制用进程标识符与页号作为输入，由哈希函数先映射到哈希表，哈希表项存放的是指向 IPT 表项的指针，此指针要么就是指向匹配的 IPT表项，否则，遍历哈希链直至找到进程标识符与页号均匹配的 IPT 表项，而此表项的序号就是页框号，通过拼接页内位移便可生成物理地址。若在反置页表中未能找到匹配的 IPT 页表项，说明此页不在主存，触发缺页中断，请求操作系统通过页表调入。为了使进程能共享主存中的同一页面，必须扩展 IPT 表的内容，使得每个表项可以记录多个进程。这样做虽然能解决问题，但却增加了复杂性。IPT 能减少页表对主存的占用，然而 IPT 仅包含调入主存的页面，不包含未调入的页面，仍需要为进程建立传统页表，不过此页表不再放在主存中，而是存放在磁盘上。当发生缺页中断时，把所需页面调入主存要多访问一次磁盘，速度会比较慢。由于反向页表是按物理地址排序的，而查找是根据虚拟地址，因此可能需要查找整个表来寻求匹配，这种查找会花费很长时间。为了解决这一问题，可以使用前面提到的哈希表来限制查找一个或少数几个条目。当然，每次访问哈希表也增加了一个对子程序的调用。为了提高速度，可以使用 TLB。如果 TLB 能够记录所有频繁使用的页面，地址转换就可能变得像通常的页表一样快。 共享页分页的另一个优点是可以共享共同代码。这一点对分时环境是特别重要的。当存在大量用户使用共享代码时，节约的时间和空间是可观的。重入代码或纯代码是不能自我改变的代码。如果代码是可重入的，那么它在执行时绝不会改变自己。因此，两个或更多进程可以同时执行代码。每个进程都有自己的寄存器拷贝和保存进程执行所需数据的数据存储拷贝。当然，两个不同进程的数据可以不同。常用程序也可能共享，例如，编辑器、编译器、窗口系统、运行时库、数据库系统等。要共享，代码必须是重入的。共享代码的只读特点不能只通过正确代码来保证，而需要操作系统来强制实现，因为，没有操作系统的帮助，后面的程序不知道共享代码或相同的部分代码的存在，而且即使知道也不能访问（因为存储保护机制，只有操作系统才有权访问其他进程存在区）。一个系统多个进程的内存共享类似于一个任务的多线程地址空间的共享。事实上，共享内存可作为一种进程通信机制，有的操作系统通常共享页来实现共享内存。采用反向页表的系统在实现代码共享方面有一定困难。共享内存通常通过多个虚拟页映射到共同的物理地址来实现的（每个共享进程共用一个页）。这种标准方法在这里并不适合，因为每个物理页只有一个虚拟页的条目，因此一个物理页不能有多个共享虚拟地址。基本分段存储管理方式促使存储管理方式从固定分区到动态分区，从分区方式向分页方式发展的主要原因是要提高主存空间利用率。那么，分段存储管理的引入主要是满足用户（程序员）编程和使用上的要求，其他存储管理技术难以满足这些要求。在分页存储管理中，经链接编址处理得到一维地址结构的可装配目标模块。这是从 0 开始编址的单一连续逻辑地址空间，虽然可以把程序划分成多个页面，但页面与源程序并不存在逻辑关系，也就很难对源程序以模块为单位进行分配、共享和保护。事实上，程序更多是采用分段结构，高级语言往往采用模块化程序设计方法。分段存储管理方式的引入引入分段存储管理方式，主要是为了满足用户和程序员的下述一系列需要： 方便编程：通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从 0 开始编址，并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名（段号）和段内偏移量（段内地址）决定的。如，函数段、类、goto 标签等 信息共享在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。而分页系统中的“页”只是存放信息的物理单位（块），并无完整的意义，不便于实现共享。一个典型的例子是共享库。虽然在页式存储管理中也能够实现共享库，但是要复杂得多，而且它们实际上是通过模拟分段来实现的。 信息保护信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地实现信息保护功能。 不同的段可以使用不同的保护模式。如程序中可以对不同的变量、函数、类等进行不同的保护措施（如不可变常量、私有、公有、只读等），这些保护机制能够帮助程序员发现程序中的错误。 动态增长在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又无法确切地知道数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。如果第 n 个段中的那个函数随后被修改并重新进行了编译，而且新版本比旧版本要长，那么并不会影响到其他的函数，其他的函数不用做任何的修改（因为大家的起始地址都没有变）。而在一维地址中，函数被一个挨一个紧紧地放在一起，中间没有空隙，因此，如果修改了一个函数的长度，将会影响到其他函数的起始地址。这样一来，所有相关的函数调用都要进行修改，以适应这些新的起始地址。如果一个程序包含上百个函数，那么相应的开销可能是相当大的。 动态链接动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主程序所对应的目标程序装入内存并启动运行，当 运行过程中又需要调用某段时，才将该段(目标程序)调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。段的特点在每个段的内部，是一个一维的线性地址序列。从 0 开始，一直到某个最大值。一般来说，每个段的长度是不相等的，而且在执行过程中，段的长度可以动态变化。由于每个段都是一个独立的地址空间，因此它们可以各自独立地增长或缩减，而不会相互影响。如果某个段中的栈需要更多的空间，那么它可以直接往上增长，因为在这个地址空间中，在它的上方没有任何其他东西阻挡。当然，段也有可能会被装满，但这种情况发生的可能性非常小，因为一个段通常是很大的。与动态分区的比较：由于使用大小不等的段，分段类似于动态分区。在没有采用覆盖方案或使用虚拟内存的情况下，为执行一个程序，需要把它的所有段都装入内存。与动态分区不同的是：在分段方案中，一个程序可以占据多个分区，并且这些分区不要求是连续的。分段消除了内部碎片，其和动态分区一样，它会产生外部碎片。不过由于进程被分成多个小块，因此外部碎片也会很小。与分页的比较：分页对程序员来说是透明的，而分段通常是可见的，并且作为组织程序和数据的一种方便手段提供给程序员。一般情况下，程序员或编译器会把程序和数据指定到不同的段。为了实现模块化程序设计的目的，程序或数据可能进一步分成多个段。这种方法最不方便的地方是程序员必须清楚段的最大长度限制。分段系统的基本原理采用大小不等的段的另一个结果是，逻辑地址和物理地址间不再具有简单的对应关系。类似于分页，在简单的分段方案中，每个进程都有一个段表，系统也会维护一个内存中的空闲块列表。每个段表项必须给出相应的段在内存中的起始地址，还必须指明段的长度，以确保不会使用无效地址。分段和分页的实现本质上是不同的，页面是定长的而段不是。分段就是支持前述用户观点的内存管理方案。逻辑地址空间是由一组段组成，每个段都有名称和长度。地址指定了段名称和段内偏移。因此用户通过两个量来指定地址：段名称和段内偏移。为了实现简单，通常用一个短号来代替段名。每个段从 0 开始编号，并采用一段连续的内存空间，各段长度不同。加载内存后，段和段之间可以是不连续的。段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。整个作业的地址空间由于是分成多个段，因而是二维的，亦即，其逻辑地址由段号(段名)和段内地址所组成。通常，在编译用户程序时，编译器会自动根据输入程序来构造段。分段地址结构：在分段存储管理中，地址结构是用户可见的，用户知道逻辑地址是如何划分为段和段内位移，在设计程序时，段的最大长度由地址结构规定，程序中所允许的最多段数会受到限制。分段存储原理：分段存储管理是基于动态分区存储管理的原理实现的。动态分区以整个作业为单位来划分和连续存放，但独立作业之间不一定连续存放。而分段方法是以段为单位来划分和连续存放，为作业各段分配一个连续的主存空间，而各段之间不一定连续。分段的作业地址空间是二维的，与分页管理类似，可以采用动态重定位技术进行地址转换。在进行存储分配时，应为进入主存的作业建立段表，各段在主存中的情况可由段表来记录，它指出主存中各分段的段号、段起始地址和段长度以及存取控制等信息。在撤销进程时，回收所占用的主存空间，并清除此进程的段表。地址转换：段表表项实际上起到基址/限长寄存器的作用，进程运行时通过段表可将逻辑地址转换成物理地址，由于每个用户作业都有自己的段表，地址转换应按各自的段表进行。类似于分页存储管理，也设置一个硬件—–段表基址寄存器，用来存放当前占用处理器的作业段表的起始地址和长度。在地址转换时，将段基址寄存器中的段表长度与逻辑地址中的段号进行比较，若段号超过段表长度则触发越界中断，在利用段表项中的段长与逻辑地址中的段内位移进行比较，检查是否产生越界中断。信息共享：分段系统的一个突出优点，是易于实现段的共享，即允许若干个进程共享一个或多个分段，且对段的保护也十分简单易行。在分页系统中，虽然也能实现程序和数据的共享，但远不如分段系统来得方便。段的共享是指两个以上的作业使用同一个子程序段或数据段，该部分在内存中只包含一个副本，具体的操作是在每个进程的段表中，用相应的表项指向共享段在内存中的起始地址。当用户进程或作业需要共享内存中某段的程序或数据时，只要用户使用相同的名字，就可以在新的段表中填入已经存在段的内存起始地址，并设置访问权限，从而实现段的共享。当共享此段的进程不再需要它时，应将该段释放，取消在该进程中共享段所对应的表项。分段共享和分页共享的比较：假设共享一个文本编辑程序，该程序比较大，需要 40 个页面。则在分页系统中共享时，每个进程都需要在其页表中添加这 40 个页表项，才能共享该文本编辑程序。而在分段系统中，只需要在每个进程段表中添加一项即可。碎片：长程调度程序必须为程序的所有段寻找和分配空间，这与分页相似，只不过段是不同长度的，而页是等长的。因此，与不定长分区方案相似，内存分配是一个动态存储分配问题，这可采用最佳适应或首次适应算法。当所有空闲内存块因太小而不能容纳一个段时，分段就会引起外部碎片。这时，进程可能需要等待直至有更多内存为止，或通过合并来创建一大块内存。由于分段本质上是动态重定向算法，只要需要，就可合并内存。如果 CPU 调度程序因内存分配问题而必须等待一个进程，那么这也可以（或不可以）查找 CPU 队列以便让更小，更低优先级的进程执行。段页式存储管理方式分页式存储管理能有效地提高内存的利用率，分段式存储管理充分考虑程序的逻辑结构，能有效地满足用户的需要。段页式存储管理方式吸取了分页和分段存储管理两种方式的优点，既考虑了程序的逻辑结构，又实现了不连续加载内存的目的。基本原理段页式系统的基本原理，是分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。其地址结构由段号、段内页号以及页内地址三部分组成。段页式存储管理具体涉及到以下主要概念： 采用页式存储管理的方式，将内存划分为一些大小相等的物理块。 逻辑空间采用分段方式，按程序的逻辑关系把进程的地址空间分成若干逻辑段。 段内分页：将每个逻辑段按页式存储管理的方式分为一些大小相等的逻辑页，页大小等于内存块的大小。在每段内，从 0 开始依次编以连续的页号。 逻辑地址结构：见上图。 内存分配：内存以物理块（页框）为单位分配给每个进程。 段表、页表和段表地址寄存器。为了实现从逻辑地址到物理地址的转换，系统要为每个进程或作业建立一张段表，并且还要为该作业中的每一段建立一个页表。这样，作业段表的内容是页表长度和页表地址，为了指出运行作业的段表地址，系统有一个段表地址寄存器，它指出作业的段表长度和段表起始地址。原理小姐：在段页式存储管理系统中，面向物理实现的地址空间是页式划分的，而面向用户的地址空间是段式划分的，也就是说，用户程序被逻辑划分为若干段，每段又划分成若干页面，内存划分成对应大小的块，进程映像是以页为单位进行的，从而逻辑上连续的段存入到分散的内存块中。地址转换在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正从第二次访问所得的地址中，取出指令或数据。显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成物理地址；若未找到匹配表项，则仍须再三次访问内存。由于它的基本原理与分页及分段的情况相似，故在此不再赘述。管理算法在地址转换过程中，软硬件应密切配合。 链接障碍中断：这个模块的功能是实现动态链接，即给每个段一个段号，在相应的段表和现行调用表中为其设置表目，并利用段号改造链接间接字。 缺段中断：这个模块的功能是在系统的现行分段表中建立一个表目，并为调进的段建立一张页表，在其段表的相应表目中登记此页表的起始地址。 缺页中断：发生缺页时进行。这个模块的功能是在内存中查找空闲的存储块，如果找到，则将该页调入内存相应空闲块；如果没找到，则调用交换算法，交换内存中的页到外存，并调进所需页面到内存，然后修改相应的页表表目。段页式存储管理是分段技术和分页技术的结合，因而，它具备了这些技术的综合优点，便于处理变化的数据结构，段可以动态增长；便于共享和检测存取访问权限。但是，它也有缺点，段页式存储管理增加了软件的复杂性和管理开销，也增加了硬件成本，需要更多的硬件支持；此外，各种表格要占用一定的存储空间。虚拟存储器前面所介绍的存储管理称为实存管理，必须为进程分配足够的主存空间，装入其全部信息，否则进程无法运行。把进程的全部信息装入主存后，实际上并非同时使用，有些部分只运行一遍。进程在运行时不用的，或暂时不用的，或某种条件下才用的程序和数据，全部驻留与主存是对宝贵资源的一种浪费，会降低主存利用率，显然这种做法是不合理的。事实上，不必装入进程的全部信息，仅将当前使用部分先装入主存，其余部分存放在磁盘中，待使用时由系统自动将其装进来，这就是虚拟存储技术的基本思路。当进程所访问程序和数据在主存中时，可顺利执行；如果处理器所访问的程序或数据不在主存中，为了继续执行，由系统自动将这部分信息从磁盘装入，这叫做“部分装入”；如果此刻没有足够的空闲物理空间，便把主存中暂时不用的信息移至磁盘，这叫做“部分替换”。如果“部分装入、部分替换”能够实现，那么，当主存空间小于进程的需要量时，进程也能运行；更进一步地，当多个进程的总长超出主存总容量时，也可将进程全部装入主存，实现多道程序运行。这样，不仅能充分地利用主存空间，而且用户编程时不必考虑物理空间的实际容量，允许用户的逻辑地址空间大于主存物理地址空间，对于用户而言，好像计算机系统具有一个容量很大的主存储器，称其为虚拟存储器。虚拟存储器定义：在具有层次结构存储器的计算机系统中，自动实现部分装入和部分替换功能，能从逻辑上为用户提供一个比物理主存容量大得多的，可寻址的“主存储器”。实际上，虚拟存储器对用户隐蔽可用物理存储器的容量和操作细节，虚拟存储器的容量与物理主存大小无关，而受限于计算机的地址结构和可用的磁盘容量（内存容量和外存容量之和）。可见，用户直接把“虚拟存储器”当做了传统的“主存”使用。其运行速度接近于内存速度，而每位的成本却又接近于外存。虚拟存储器的引入（局部性原理） 引入的必要性前面已经谈过常规存储器管理方式及其特征，这里再次简单提一下“实体存储器”的特点： 一次性：在前面所介绍的几种存储管理方式中，都要求将作业全部装入内存后方能运行，即作业在运行前需一次性地全部装入内存，而正是这一特征导致了：(1) 有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部被装入内存，致使该作业无法运行。(2) 有大量作业要求运行，但由于内存容量不足以容纳所有这些作业，只能将少数作业 装入内存让它们先运行，而将其它大量的作业留在外存上等待。出现上述两种情况的原因，都是由于内存容量不够大。一个显而易见的解决方法，是从物理上增加内存容量，但这往往会受到机器自身的限制，而且无疑要增加系统成本，因此这种方法是受到一定限制的。另一种方法是从逻辑上扩充内存容量，这正是虚拟存储技术所要解决的主要问题。此外，还有许多作业在每次运行时，并非其全部程序和数据都要用到。如果一次性地装入其全部程序，也是一种对内存空间的浪费。 驻留性：作业装入内存后，便一直驻留在内存中，直至作业运行结束。尽管运行中的进程会因I/O而长期等待，或有的程序模块在运行过一次后就不再需要(运行)了，但它们都仍将继续占用宝贵的内存资源。由此可以看出，上述的一次性及驻留性，使许多在程序运行中不用或暂不用的程序(数据)占据了大量的内存空间，使得一些需要运行的作业无法装入运行。现在要研究的问题是：一次性及驻留性在程序运行时是否是必需的。 引入的可行性（局部性原理）局部性原理：程序在执行时将呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分；相应地，它所访问的存储空间也局限于某个区域。程序局部性原理的几个表现： 程序执行时，除了少部分的转移和过程调用指令外，在大多数情况下仍是顺序执行的。在高级语言中尤为明显。 过程调用将会使程序的执行轨迹由一部分区域转至另一部分区域，但经研究看出，过程调用的深度在大多数情况下都不超过5。这就是说，程序将会在一段时间内都局限在这些过程的范围内运行。 程序中存在许多循环结构，这些虽然只由少数指令构成，但是它们将多次执行。 程序中还包括许多对数据结构的处理，如对数组进行操作，它们往往都局限于很小的范围内。局部性还表现在下述两个方面： 时间局限性：如果程序中的某条指令一旦执行，则不久以后该指令可能再次执行；如果某数据被访问过，则不久以后该数据可能再次被访问。产生时间局限性的典型原因是由于在程序中存在着大量的循环操作。 空间局限性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，其典型情况便是程序的顺序执行。虚拟存储器就是基于程序局部性原理实现的。虚拟内存将用户逻辑内存与物理内存分开。这在现有物理内存有限的情况下，为程序员提供了巨大的虚拟内存。虚拟内存使编程更加容易，因为程序员不再需要担心有限的物理内存空间或究竟哪些代码需要覆盖；他只需要关注所要解决的问题。采用虚拟内存的系统几乎用不到覆盖。虚拟存储器的实现方法在虚拟存储器中，允许将一个作业分多次调入内存。如果采用连续分配方式时，应将作业装入一个连续的内存区域中。为此，须事先为它一次性地申请足够的内存空间，以便将整个作业先后分多次装入内存。这不仅会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟存储器的实现，都毫无例外地建立在离散分配的存储管理方式的基础上。目前，所有的虚拟存储器都是采用下述方式之一实现的。 请求分页系统这是在分页系统的基础上，增加了请求调页功能和页面置换功能所形成的页式虚拟存储系统。它允许只装入少数页面的程序(及数据)，便启动运行。以后，再通过调页功能及页面置换功能，陆续地把即将要运行的页面调入内存，同时把暂不运行的页面换出到外存上。置换时以页面为单位。为了能实现请求调页和置换功能，系统必须提供必要的硬件支持和相应的软件。所需硬件：（1）请求分页的页表机制；（2）缺页中断机构；（3）地址变换机构。 请求分段系统这是在分段系统的基础上，增加了请求调段及分段置换功能后所形成的段式虚拟存储系统。它允许只装入少数段(而非所有的段)的用户程序和数据，即可启动运行。以后再通过调段功能和段的置换功能将暂不运行的段调出，同时调入即将运行的段。置换是以段为单位进行的。所需硬件支持：（1）请求分段的段表机制；（2）缺段中断机构；（3）地址变换机构。目前，有不少虚拟存储器是建立在段页式系统基础上的，通过增加请求调页和页面置换功能而形成了段页式虚拟存储器系统，而且把实现虚拟存储器所需支持的硬件集成在处理器芯片上。可见，实现虚拟存储技术需要一定物质基础： 需要相当容量的辅存，以便足以存放多用户作业的地址空间； 要有一定容量的主存，以便作为虚拟存储器的高速缓存； 需要地址变换机构和所需要配套表格等。虚拟存储器的特征虚拟存储器具有多次性、对换性和虚拟性三大主要特征。 多次性：多次性是指一个作业被分成多次调入内存运行，亦即在作业运行时没有必要将其全部装入，只需将当前要运行的那部分程序和数据装入内存即可；以后每当要运行到尚未调入的那部分程序时，再将它调入。多次性是虚拟存储器最重要的特征，任何其它的存储管理方式都不具有这一特征。因此，我们也可以认为虚拟存储器是具有多次性特征的存储器系统。 对换性：对换性是指允许在作业的运行过程中进行换进、换出，亦即，在进程运行期间，允许将那些暂不使用的程序和数据，从内存调至外存的对换区(换出)，待以后需要时再将它们从外存调至内存(换进)；甚至还允许将暂时不运行的进程调至外存，待它们重新具备运行条件时再调入内存。换进和换出能有效地提高内存利用率。可见，虚拟存储器具有对换性特征。与对换技术的对比：虚拟存储器与对换技术虽说都是在主存储器和磁盘之间交换信息，但却存在很大区别。对换技术以进程为单位，当其所需主存空间大于当前系统的拥有量时，进程无法被对换进主存工作；而虚拟存储器管理以页或段为单位，即使进程所需主存空间大于当前系统拥有的主存容量，仍然能正常运行，因为系统可将其他进程的一部分页或段换出至磁盘。 虚拟性：虚拟性是指能够从逻辑上扩充内存容量，使用户所看到的内存容量远大于实际内存容量。这是虚拟存储器所表现出来的最重要的特征，也是实现虚拟存储器的最重要的目标。值得说明的是，虚拟性是以多次性和对换性为基础的，或者说，仅当系统允许将作业分多次调入内存，并能将内存中暂时不运行的程序和数据换至盘上时，才有可能实现虚拟存储器；而多次性和对换性又必须建立在离散分配的基础上。 离散性：离散性是指内存分配时采用离散分配方式，没有离散性就不可能实现虚拟存储器。请求分页存储管理方式请求分页系统是建立在基本分页基础上的，为了能支持虚拟存储器功能而增加了请求调页功能和页面置换功能。相应地，每次调入和换出的基本单位都是长度固定的页面。这使得请求分页系统在实现上要比请求分段系统简单（后者在换进和换出时是可变长度的段）。请求分页中的硬件支持为了实现请求分页，系统必须提供一定的硬件支持。除了需要一台具有一定容量的内存及外存的计算机系统外，还需要有页表机制、缺页中断机构以及地址变换机构。 页表机制在请求分页系统中所需要的主要数据结构是页表。其基本作用仍然是将用户地址空间中的逻辑地址变换为内存空间中的物理地址。由于只将应用程序的一部分调入内存，还有一部分仍在盘上，故须在页表中再增加若干项，供程序(数据)在换进、换出时参考。在请求分页系统中的每个页表项如下所示： 状态位P：用于指示该页是否已调入内存，供程序访问时参考。 访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供选择换出页面时参考。 修改位M：该位表示该页在调入内存后是否被修改过。由于内存中的每一页都在外存上保留一份副本，因此，若未被修改，在置换该页时就不需再将该页写回到外存上，以减少系统的开销和启动磁盘的次数；若已被修改，则必须将该页重写到外存上，以保证外存中所保留的始终是最新副本。简言之，M位供置换页面时参考。 外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。 缺页中断机构在请求分页系统中，每当所要访问的页面不在内存时，便产生一缺页中断，请求OS将所缺之页调入内存。它与一般的中断相比，有着明显的区别，主要表现在下面两个方面：(1) 在指令执行期间产生和处理中断信号。通常，CPU都是在一条指令执行完后，才检查是否有中断请求到达。若有，便去响应，否则，继续执行下一条指令。然而，缺页中断是在指令执行期间，发现所要访问的指令或数据不在内存时所产生和处理的。(2) 一条指令在执行期间，可能产生多次缺页中断。在下图中示出了一个例子。如在执行一条指令COPY A TO B 时，可能要产生6次缺页中断，其中指令本身跨了两个页面，A 和 B 又分别各是一个数据块，也都跨了两个页面。基于这些特征，系统中的硬件机构应能保存多次中断时的状态，并保证最后能返回到中断前产生缺页中断的指令处继续执行。不过，编译器在编译等处理时最好能进行字对齐以及页面长度为字的整数倍，这样可以减少指令跨页面的情况发生，虽然浪费了一定的存储空间。 地址变换机构请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，再为实现虚拟存储器而增加了某些功能而形成的，如产生和处理缺页中断，以及从内存中换出一页的功能等等。如果在快表中未找到该页的页表项时，应到内存中去查找页表，再从找到的页表项中的状态位P，来了解该页是否已调入内存。若该页已调入内存，这时应将此页的页表项写入快表，当快表已满时，应先调出按某种算法所确定的页的页表项，然后再写入该页的页表项；若该页尚未调入内存，这时应产生缺页中断，请求OS从外存把该页调入内存。以下是协助理解的一组图：事实上，支持操作系统存储管理的已经集成为一个芯片，该芯片称为主存管理部件（MMU），它提供地址转换和存储保护功能，并支持虚拟存储管理和多任务管理。MMU 由一组集成电路芯片组成，逻辑地址作为输入，物理地址作为输出，直接送达总线，对主存单元进行寻址。其主要功能如下图所示：请求分页的基本原理请求分页虚拟存储管理是将进程信息的副本存放在辅助存储器中，当它被调度投入运行时，并不把程序和数据全部装入主存，仅装入当前使用的页面，进程执行过程中访问到不在内存的页面时，产生缺页异常（或中断），系统从磁盘中把此指令或数据所在的页面装入，这样做能够保证用不到的页面不会被装入主存。请求分页与分页实存管理的比较：请求分页虚拟存储管理与分页实存管理不同，仅让进程当前使用部分装入，必然会发生某些页面不再主存中的情况。这就需要：扩充页表项的内容，增加驻留标志位（或失效异常位），用来之处页面是否装入主存。待调入的页面再辅存的具体位置也需要再页表项中体系那出来。为了对页面实施保护和淘汰等各种控制，可在页表中增加标志位，其他标志位包括修改位、引用位和访问权限位等，用来跟踪页面的使用情况和状态。下图给出使用快表的请求分页地址转换过程：请求分页的内存分配前面讲述的是请求分页管理所需要的信息和硬件。本小节之后将会具体讲述管理策略。在躲到程序设计环境下，多个进程进入内存，就有以下问题需要处理： 各个进程进入内存的最开始应分配多少个页面； 进程运行过程中是么时候调入将要用到的页面； 从何处调入将要用或正缺的页面； 进程运行过程中调入多少将要用的页面； 将要用的页面调入到内存的哪个具体的区域（进程的自身空间、其他进程的空闲空间还是系统预留空间等）； 当选好调入页面放入主存的具体位置之后，没有空闲的页框时，如何腾出（替换）页面； 对将被替换出的页面应该做怎么样的处理货应该在什么时候处理（就在替换的时候进行还是在替换之前的某个时候进行）；上面列出的问题实际上是根据请求分页的处理过程给出的。可见，对于不同过程有不同的处理方法。本小节及后面的章节都是围绕这些问题展开的。在为进程分配内存时，将涉及到三个问题：第一，最小物理块数的确定；第二，物理块的分配策略；第三，物理块的分配算法。 最小物理块数的确定这里所说的最小物理块数，是指能保证进程正常运行所需的最小物理块数。当系统为进程分配的物理块数少于此值时，进程将无法运行。进程应获得的最少物理块数与计算机的硬件结构有关，取决于指令的格式、功能和寻址方式。对于某些简单的机器，若是单地址指令且采用直接寻址方式，则所需的最少物理块数为2。其中，一块是用于存放指令的页面，另一块则是用于存放数据的页面。如果该机器允许间接寻址时，则至少要求有三个物理块。对于某些功能较强的机器，其指令长度可能是两个或多于两个字节，因而其指令本身有可能跨两个页面，且源地址和目标地址所涉及的区域也都可能跨两个页面。正如前面所介绍的在缺页中断机构中要发生 6 次中断的情况一样，对于这种机器，至少要为每个进程分配6个物理块，以装入6个页面。 物理块的分配策略在请求分页系统中，可采取两种内存分配策略，即固定和可变分配策略。在进行置换时，也可采取两种策略，即全局置换和局部置换。于是可组合出以下三种适用的策略。 固定分配局部置换这是指基于进程的类型(交互型或批处理型等)，或根据程序员、程序管理员的建议，为每个进程分配一定数目的物理块，在整个运行期间都不再改变。采用该策略时，如果进程在运行中发现缺页，则只能从该进程在内存的 n 个页面中选出一个页换出，然后再调入一页，以保证分配给该进程的内存空间不变。实现这种策略的困难在于：应为每个进程分配多少个物理块难以确定。若太少，会频繁地出现缺页中断，降低了系统的吞吐量；若太多，又必然使内存中驻留的进程数目减少，进而可能造成CPU空闲或其它资源空闲的情况，而且在实现进程对换时，会花费更多的时间。 可变分配全局置换这可能是最易于实现的一种物理块分配和置换策略，已用于若干个OS中。在采用这种策略时，先为系统中的每个进程分配一定数目的物理块，而 OS自身也保持一个空闲物理块队列。当某进程发现缺页时，由系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的(缺)页装入其中。这样，凡产生缺页(中断)的进程，都将获得新的物理块。仅当空闲物理块队列中的物理块用完时，OS才能从内存中选择一页调出，该页可能是系统中任一进程的页，这样，自然又会使那个进程的物理块减少，进而使其缺页率增加。 可变分配局部置换这同样是基于进程的类型或根据程序员的要求，为每个进程分配一定数目的物理块，但当某进程发现缺页时，只允许从该进程在内存的页面中选出一页换出，这样就不会影响其它进程的运行。如果进程在运行中频繁地发生缺页中断，则系统须再为该进程分配若干附加的物理块，直至该进程的缺页率减少到适当程度为止；反之，若一个进程在运行过程中的缺页率特别低，则此时可适当减少分配给该进程的物理块数，但不应引起其缺页率的明显增加。 物理块分配算法在采用固定分配策略时，如何将系统中可供分配的所有物理块分配给各个进程，可采用下述几种算法。 平均分配算法这是将系统中所有可供分配的物理块平均分配给各个进程。例如，当系统中有 100 个物理块，有5个进程在运行时，每个进程可分得20个物理块。这种方式貌似公平，但实际上是不公平的，因为它未考虑到各进程本身的大小。如有一个进程其大小为 200 页，只分配给它20个块，这样，它必然会有很高的缺页率；而另一个进程只有10页，却有10个物理块闲置未用。 按比例分配算法：这是根据进程的大小按比例（在所有进程大小中的占比）分配物理块的算法。 考虑优先权的分配算法：在实际应用中，为了照顾到重要的、紧迫的作业能尽快地完成，应为它分配较多的内存空间。通常采取的方法是把内存中可供分配的所有物理块分成两部分：一部分按比例地分配给各进程；另一部分则根据各进程的优先权，适当地增加其相应份额后，分配给各进程。在有的系统中，如重要的实时控制系统，则可能是完全按优先权来为各进程分配其物理块的。调页策略 调入页面的时机为了确定系统将进程运行时所缺的页面调入内存的时机，可采取预调页策略或请求调页策略，现分述如下。 预调页策略:如果进程的许多页是存放在外存的一个连续区域中，则一次调入若干个相邻的页，会比一次调入一页更高效些。但如果调入的一批页面中的大多数都未被访问，则又是低效的。可采用一种以预测为基础的预调页策略，将那些预计在不久之后便会被访问的页面预先调入内存。如果预测较准确，那么，这种策略显然是很有吸引力的。但遗憾的是，目前预调页的成功率仅约 50%。故这种策略主要用于进程的首次调入时，由程序员指出应该先调入哪些页。 请求调页策略:当进程在运行中需要访问某部分程序和数据时，若发现其所在的页面不在内存，便立即提出请求，由 OS 将其所需页面调入内存。由请求调页策略所确定调入的页，是一定会 被访问的，再加之请求调页策略比较易于实现，故在目前的虚拟存储器中大多采用此 策略。但这种策略每次仅调入一页，故须花费较大的系统开销，增加了磁盘 I/O 的启动频率。 确定从何处调入页面在请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。通常，由于对换区是采用连续分配方式，而文件区是采用离散分配方式，故对换区的磁盘I/O速度比文件区的高。这样，每当发生缺页请求时，系统应从何处将缺页调入内存，可分成如下三种情况：(1) 系统拥有足够的对换区空间，这时可以全部从对换区调入所需页面，以提高调页速度。为此，在进程运行前，便须将与该进程有关的文件从文件区拷贝到对换区。(2) 系统缺少足够的对换区空间，这时凡是不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出，以后再调入时，仍从文件区直接调入。但对于那些可能被修改的部分，在将它们换出时，便须调到对换区，以后需要时，再从对换区调入。(3) UNIX方式。由于与进程有关的文件都放在文件区，故凡是未运行过的页面，都应从文件区调入。而对于曾经运行过但又被换出的页面，由于是被放在对换区，因此在下次调入时，应从对换区调入。由于 UNIX 系统允许页面共享，因此，某进程所请求的页面有可能已被其它进程调入内存，此时也就无须再从对换区调入。 页面调入过程每当程序所要访问的页面未在内存时，便向CPU发出一缺页中断，中断处理程序首先保留CPU环境，分析中断原因后转入缺页中断处理程序。该程序通过查找页表，得到该页在外存的物理块后，如果此时内存能容纳新页，则启动磁盘I/O将所缺之页调入内存，然后修改页表。如果内存已满，则须先按照某种置换算法从内存中选出一页准备换出；如果该页未被修改过，可不必将该页写回磁盘；但如果此页已被修改，则必须将它写回磁盘，然后再把所缺的页调入内存，并修改页表中的相应表项，置其存在位为“1”，并将此页表项写入快表中。在缺页调入内存后，利用修改后的页表，去形成所要访问数据的物理地址，再去访问内存数据。整个页面的调入过程对用户是透明的。 页面清除策略页面清除策略与调入策略相对应，要考虑何时把修改过的页面写回辅助存储器，常用方法是：请页式和预约式。 请页式清除：该方法仅当一夜被选中进行替换且其被修改过，才把它写回磁盘。写出一页是在读进新页之前进行的，它要完成对操作，苏安然仅需写回一页，但进程不得不等待两次 I/O 操作完成，可能会降低系统性能。 预约式清除：预约式清除是对于所有更改过的页面，在需要替换之前把它们都写回磁盘，可成批进行。对于预约式清除，写出的也仍然在主存中，直到页替换算法选中此页从主存中移出。但如果刚刚写回很多页面，在它们被替换之前，其中大部分又被修改过，那么预约式清除就毫无意义。页面置换算法在进程运行过程中，若其所要访问的页面不在内存而需把它们调入内存，但内存已无空闲空间时，为了保证该进程能正常运行，系统必须从内存中调出一页程序或数据送磁盘的对换区中。但应将哪个页面调出，须根据一定的算法来确定。通常，把选择换出页面的算法称为页面置换算法(Page-Replacement Algorithms)。置换算法的好坏，将直接影响到系统的性能。如果选择不合适的算法，会出现这样的现象：刚被淘汰的页面立即又要调用，而调入不就随即被淘汰，淘汰不久再被调入，如此反复，使得整个系统的页面调度非常频繁以致大部分时间都花费在来回调度页面上，而不是执行计算任务，这种现象叫做“抖动”，一个好的调度算法应减少和避免抖动现象。一个好的页面置换算法，应具有较低的页面更换频率。从理论上讲，应将那些以后不再会访问的页面换出，或把那些在较长时间内不会再访问的页面调出。目前存在着许多种置换算法，它们都试图更接近于理论上的目标。置换算法可以用于全局页面也可用于局部页面，下面介绍几种常用的置换算法。缺页中断率某个进程的缺页中断率是指该进程缺页次数和总的访问次数的比值。影响缺页中断率的因素有： 主存页框数：进程所分得的快熟多，缺页中断率低，反之缺页率就高； 页面大小：页面大，缺页中断率低，否则缺页率就高； 页面替换算法：算法的优劣影响缺页中断次数； 程序特性：程序局部性号，它对缺页中断率有很大影响。最佳置换算法最佳置换算法是一种理想化的算法，它具有最好的性能，但实际上却难于实现，采用最佳置换算法，通常可保证获得最低的缺页率。但由于人们目前还无法预知一个进程在内存的若干个页面中，哪一个页面是未来最长时间内不再被访问的，因而该算法是无法实现的，但可以利用该算法去评价其它算法。先进先出(FIFO)页面置换算法这是最早出现的置换算法。该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。该算法实现简单，只需把一个进程已调入内存的页面，按先后次序链接成一个队列，并设置一个指针，称为替换指针，使它总是指向最老的页面。但该算法与进程实际运行的规律不相适应，因为在进程中，有些页面经常被访问，比如，含有全局变量、常用函数、例程等的页面，FIFO 算法并不能保证这些页面不被淘汰。Belady 异常：对有的页置换算法，缺页中断率可能会随着所分配的页框数的增加而增加。最近最久未使用(LRU)置换算法FIFO置换算法性能之所以较差，是因为它所依据的条件是各个页面调入内存的时间，而页面调入的先后并不能反映页面的使用情况。最近最久未使用(LRU)的页面置换算法，是根据页面调入内存后的使用情况进行决策的。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU 置换算法是选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 t，当须淘汰一个页面时，选择现有页面中其 t 值最大的，即最近最久未使用的页面予以淘汰。算法实现：LRU 页置换算法可能需要大量硬件支持。它的问题是为页框确定一个排序序列，这个序列按页框上次使用时间来定义。有两种可行实现： 计算器：最为简单的情况是，为每个页表项关联一个使用时间域，并为 CPU 增加一个逻辑始终或计数器。对每次内存引用，计数器都会增加。每次内存引用时，始终寄存器的内容会复制到相应页所对应的页表项的使用时间域内。当呀淘汰页面时，置换具有最小时间的页。这种方案需要搜索页表以查找 LRU 页，且每次内存访问都要写入内存（到页表的使用时间域）。在页表改变时（因 CPU 调度）也必须要保持时间，同时也要考虑始终溢出。 堆栈：可利用一个特殊的栈来保存当前使用的各个页面的页面号。每当进程访问某页面时，便将该页面的页面号从栈中移出，将它压入栈顶。因此，栈顶始终是最新被访问页面的编号，而栈底则是最近最久未使用页面的页面号。算法评价：最优置换和 LRU 置换都没有 Belacy 异常。如果只有标准 TLB 寄存器而没有其他硬件支持，那么这两种 LRU 实现都是不可能的。每次内存引用，都必须更新时钟域或堆栈。如果每次引用都采用中断，以允许软件更新这些数据结构，那么它会使内存引用慢至少 10 倍，进而使用户进程运行慢 10 倍。几乎没有系统可以容忍如此程度的内存管理开销。堆栈算法：有一类算法，称为堆栈算法，都绝不可能有 Belady 异常。堆栈算法可以证明为：对于页框数为 n 的内存页集合对于页框数为 n+1 的内存页集合的子集。对于 LRU 算法，如果内存页集合是最近引用的页，那么对于页框的增加，这些 n 页仍然是最近引用的页，所以仍然在内存中。LRU 近似页置换LRU 算法是较好的一种算法，但由于它要求有较多的硬件支持，因此，很少有计算机系统能支持真正的 LRU 页置换算法。故在实际应用中，大多采用 LRU 的近似算法。Clock 算法就是用得较多的一种LRU近似算法。 简单的 Clock 置换算法（最近未用算法 NRU）当采用简单 Clock 算法时，只需为每页设置一位访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位被置1。置换算法在选择一页淘汰时，只需检查页的访问位。如果是 0，就选择该页换出；若为 1，则重新将它置 0，暂不换出，而给该页第二次驻留内存的机会，再按照 FIFO 算法检查下一个页面。当检查到队列中的最后一个页面时，若其访问位仍为 1，则再返回到队首去检查第一个页面。由于该算法是循环地检查各页面的使用情况，故称为 Clock 算法。但因该算法只有一位访问位，只能用它表示该页是否已经使用过，而置换时是将未使用过的页面换出去，故又把该算法称为最近未用算法 NRU (Not Recently Used)。 改进型Clock置换算法在将一个页面换出时，如果该页已被修改过，便须将该页重新写回到磁盘上；但如果该页未被修改过，则不必将它拷回磁盘。在改进型 Clock 算法中，除须考虑页面的使用情况外，还须再增加一个因素，即置换代价，这样，选择页面换出时，既要是未使用过的页面，又要是未被修改过的页面。把同时满足这两个条件的页面作为首选淘汰的页面。由访问位 A 和修改位 M 可以组合成下面四种类型的页面： 1类(A=0，M=0)：表示该页最近既未被访问，又未被修改，是最佳淘汰页。 2类(A=0，M=1)：表示该页最近未被访问，但已被修改，并不是很好的淘汰页。 3类(A=1，M=0)：表示该页最近已被访问，但未被修改，该页有可能再被访问。 4类(A=1，M=1)：表示该页最近已被访问且被修改，该页可能再被访问。在内存中的每个页必定是这四类页面之一，在进行页面置换时，可采用与简单 Clock算法相类似的算法，其差别在于该算法须同时检查访问位与修改位，以确定该页是四类页面中的哪一种。该算法的执行过程可分成以下三步：(1) 从指针所指示的当前位置开始，扫描循环队列，寻找 A=0 且 M=0 的第一类页面，将所遇到的第一个页面作为所选中的淘汰页。在第一次扫描期间不改变访问位 A。(2) 如果第一步失败，即查找一周后未遇到第一类页面，则开始第二轮扫描，寻找 A=0 且 M=1 的第二类页面，将所遇到的第一个这类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置 0。(3) 如果第二步也失败，亦即未找到第二类页面，则将指针返回到开始的位置，并将所有的访问位复 0。然后重复第一步，如果仍失败，必要时再重复第二步，此时就一定能找到被淘汰的页。该算法与简单Clock算法比较，可减少磁盘的I/O操作次数。但为了找到一个可置换的页，可能须经过几轮扫描。换言之，实现该算法本身的开销将有所增加。最少使用置换算法在采用最少使用置换算法（LFU）时，应为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率。该置换算法选择在最近时期使用最少的页面作为淘汰页。由于存储器具有较高的访问速度（一页中有大量的指令或数据），通常不能直接利用计数器来记录某页被访问的次数，而是采用移位寄存器方式。每次访问某页时，便将该移位寄存器的最高位置 1，再每隔一定时间(例如100 ms)右移一次。这样，在最近一段时间使用最少的页面将是 ∑Ri（移位次数）最小的页。LFU置换算法的页面访问图与LRU置换算法的访问图完全相同；或者说，利用这样一套硬件既可实现 LRU 算法，又可实现 LFU 算法。应该指出，LFU 算法并不能真正反映出页面的使用情况，因为在每一时间间隔内，只是用寄存器的移位来记录页的使用情况，因此，在这期间访问一次和很多次是等效的（都只是右移一位），而且当移动到最右时候将会循环，再右移就相当于未曾访问的状态（所有位都变成了 0）。页面缓冲算法虽然 LRU 和 Clock置换算法都比 FIFO 算法好，但它们都需要一定的硬件支持，并需付出较多的开销，而且，置换一个已修改的页比置换未修改页的开销要大。而页面缓冲算法(PBA)则既可改善分页系统的性能，又可采用一种较简单的置换策略。VAX/VMS 操作系统便是使用页面缓冲算法。它采用了前述的可变分配和局部置换方式，置换算法采用的是 FIFO。该算法规定将一个被淘汰的页放入两个链表中的一个，即如果页面未被修改，就将它直接放入空闲链表中；否则，便放入已修改页面的链表中。须注意的是，这时页面在内存中并不做物理上的移动，而只是将页表中的表项移到上述两个链表之一中。空闲页面链表，实际上是一个空闲物理块链表，其中的每个物理块都是空闲的，因此，可在其中装入程序或数据。当需要读入一个页面时，便可利用空闲物理块链表中的第一个物理块来装入该页。当有一个未被修改的页要换出时，实际上并不将它换出内存，而是把该未被修改的页所在的物理块挂在自由页链表的末尾。类似地，在置换一个已修改的页面时，也将其所在的物理块挂在修改页面链表的末尾。利用这种方式可使已被修改的页面和未被修改的页面都仍然保留在内存中。当该进程以后再次访问这些页面时，只要改页还在这两个链表中且没有被重写，那么，只需花费较小的开销，使这些页面又返回到该进程的驻留集中。当被修改的页面数目达到一定值时，例如 64 个页面，再将它们一起写回到磁盘上，从而显著地减少了磁盘I/O的操作次数。一个较简单的页面缓冲算法已在 MACH 操作系统中实现了，只是它没有区分已修改页面和未修改页面。工作集替换算法最开始工作集模型用来对局部最佳页面替换算法进行模拟实现，也使用滑动窗口的概念，但并不向前查看页面引用串，而是基于程序局部性原理向后看，这意味着在任何给定的时刻，一个进程不就的将来所需主存页框数可通过考查其最近时间内的主存需要做出估计。进程工作集指“在某一段时间间隔内进程运行所需访问的页面集合”。工作集是程序局部性的近似表示，可通过它来确定驻留集的大小。 ①监视每个进程的工作集，只有属于工作集的页面才能驻留在主存； ②定期地从进程驻留集中删去那些不在工作集中的页面； ③仅当一个进程的工作集在主存时，进程才能执行。 模拟工作集替换算法工作集策略在概念上很有吸引力，但实现中监督驻留页面变化的开销却很大，估算合适的窗口大小也是一个难题，为此，已经设计出各种模拟工作集替换算法。下面介绍两种： 老化算法：进程在运行前要把它的工作集预先装入主存，为每个页设置引用位 r 及年龄寄存器，寄存器初始值为 0，每隔时间 t，系统扫描主存中所有页面，先将寄存器右移一位，再把引用位 r 的值加到对应寄存器的最左边，这样，未引用页面其年龄寄存器的值逐步减小，当达到下限或值 0 时，由于页面已经落在窗口之外，就可以把它从工作集中移出去。修改后的算法称为“老化算法”，年龄寄存器各位的累加值反映页面最近使用的情况，访问次数越多，累加值越大，而较早被访问的页面随着寄存器各位的右移，由于老化使得其作用也来越小。 方法二：为每个页面设置引用位及关联的时间截，通过超时中断，至少每隔若干条指令就周期性地检查引用位及时间截，当发现引用位为 1 时，就将其置 0 并把这次改变的时间作为时间截记录下来。每当发现引用位为 0 时，通过系统当前时间减去时间截的时间，计算出从上次使用以来未被再次访问的时间量，记作 t_off 。t_off 值会随着每次超时中断的处理而不断增加，除非页面在此期间被再次引用，导致其引用位为 1.把 t_off 与系统时间参数 t_max 相比，若 t_off &gt; t_max，就把页面从工作集中移出，释放相应的页框。 缺页频率替换算法在工作集算法中，保证最少缺页次数是通过调整工作集的大小来间接实现的，一种直接改善系统性能的方法是使用缺页频率替换算法（PFF）。这种算法根据连续的缺页之间的时间间隔来对缺页频率进行测量，每次缺页时，利用测量时间调整进程工作集尺寸。其股则是：如果本次缺页与前次缺页之间的时间间隔超过临界值 r，那么，在这个时间间隔内未引用的所有页面都被移出工作集。这就能保证进程工作集不会不必要地扩大，与工作集模型相比，实现效率高，只在发生缺页中断时才调整页面，而不是每次引用时都需要调整。分页系统颠簸频繁的页调度行为成为颠簸。如果一个进程在换页上用的时间要多于执行时间，呢么这个进程就在颠簸。系统颠簸的原因系统颠簸会导致严重的性能问题。下图显示了 CPU 利用率与多道程序程度的关系。随着多道程序程度增加，CPU 利用率（虽然有点慢）增加，直至达到最大值。如果多道程序程度还要继续增加，那么系统颠簸就开始了，且 CPU 利用率急剧下降。这时，为了增加 CPU 利用率和降低系统颠簸，必须降低躲到程序的程度。通过局部置换算法（或优先置换算法）能限制系统颠簸的结果。但是也没有多大作用。采用局部置换，如果一个进程开始颠簸，那么它不能从其他进程取页框，且不能使后者也颠簸，所置换的页必须是进程自己的页，然而，如果进程颠簸，那么绝大多数时间也会排队来等待调页设备。由于调页设备的更长的平均队列，页错误的平均等待时间也会增加。因此，即使对没有颠簸的进程，其有效访问时间也会增加。颠簸防止为了防止颠簸，必须提供进程所需的足够多的页框，但是如何知道进程“需要”多要页框呢？可以采用很多技术。工作集策略（请参看前面的替换算法）检查进程真正需要多少页框。这种方法定义了进程执行的局部模型（放映程序的局部性原理）。局部模型说明，当进程执行时，它从一个局部移向另一个局部，局部是一个经常使用页的集合。一个程序通常由多个不同局部组成，它们可能重叠。假设为每个进程都分配了可以满足其当前局部的页框，该进程在其局部内会出现页错误，知道所有野均在内存中，接着他不在会出现页错误知道它改变局部为止。如果分配的页框数少于现有的局部的大小，那么进程会颠簸，这是因为他不能讲所有经常使用的页放在内存中。请求分段存储管理方式在请求分段系统中，程序运行之前，只需先调入若干个分段(不必调入所有的分段)，便可启动运行。当所访问的段不在内存中时，可请求 OS将所缺的段调入内存。像请求分页系统一样，为实现请求分段存储管理方式，同样需要一定的硬件支持和相应的软件。请求分段中的硬件支持如同请求分页系统一样，应在系统中配置多种硬件机构，以快速地完成请求分段功能。请求分段管理所需的硬件支持有段表机制、缺段中断机构，以及地址变换机构。 段表机制在请求分段式管理中所需的主要数据结构是段表。由于在应用程序的许多段中，只有一部分段装入内存，其余的一些段仍留在外存上，故须在段表中增加若干项，以供程序在调进、调出时参考。下面给出请求分段的段表项。在段表项中，除了段名(号)、段长、段在内存中的起始地址外，还增加了以下诸项： (1) 存取方式：用于标识本分段的存取属性是只执行、只读，还是允许读/写。 (2) 访问字段A：其含义与请求分页的相应字段相同，用于记录该段被访问的频繁程度。 (3) 修改位M：用于表示该页在进入内存后是否已被修改过，供置换页面时参考。 (4) 存在位P：指示本段是否已调入内存，供程序访问时参考。 (5) 增补位：这是请求分段式管理中所特有的字段，用于表示本段在运行过程中是否做过动态增长。 (6) 外存始址：指示本段在外存中的起始地址，即起始盘块号。 缺段中断机构在请求分段系统中，每当发现运行进程所要访问的段尚未调入内存时，便由缺段中断机构产生一缺段中断信号，进入 OS 后由缺段中断处理程序将所需的段调入内存。缺段中断机构与缺页中断机构类似，它同样需要在一条指令的执行期间，产生和处理中断，以及在一条指令执行期间，可能产生多次缺段中断。但由于分段是信息的逻辑单位，因而不可能出现一条指令被分割在两个分段中和一组信息被分割在两个分段中的情况。缺段中断的处理过程如图所示。由于段不是定长的，这使对缺段中断的处理要比对缺页中断的处理复杂。 地址变换机构请求分段系统中的地址变换机构是在分段系统地址变换机构的基础上形成的。因为被访问的段并非全在内存，所以在地址变换时，若发现所要访问的段不在内存，必须先将所缺的段调入内存，并修改段表，然后才能再利用段表进行地址变换。为此，在地址变换机构中又增加了某些功能，如缺段中断的请求及处理等。下图出了请求分段系统的地址变换过程。共享段为了实现分段共享，应配置相应的数据结构共享段表，以及需要对共享段进行操作的过程。 共享段表为了实现分段共享，可在系统中配置一张共享段表，所有各共享段都在共享段表中占有一表项。表项中记录了共享段的段号、段长、内存始址、存在位等信息，并记录了共享此分段的每个进程的情况。共享段表如下图所示。其中各项说明如下：(1) 共享进程计数 count。非共享段仅为一个进程所需要。当进程不再需要该段时，可立即释放该段，并由系统回收该段所占用的空间。而共享段是为多个进程所需要的，当某进程不再需要而释放它时，系统并不回收该段所占内存区，仅当所有共享该段的进程全都不再需要它时，才由系统回收该段所占内存区。为了记录有多少个进程需要共享该分段，特设置了一个整型变量 count。(2) 存取控制字段。对于一个共享段，应给不同的进程以不同的存取权限。例如，对于文件主，通常允许他读和写；而对其它进程，则可能只允许读，甚至只允许执行。(3) 段号。对于一个共享段，不同的进程可以各用不同的段号去共享该段。 共享段的分配由于共享段是供多个进程所共享的，因此，对共享段的内存分配方法与非共享段的内存分配方法有所不同。在为共享段分配内存时，对第一个请求使用该共享段的进程，由系统为该共享段分配一物理区，再把共享段调入该区，同时将该区的始址填入请求进程的段表的相应项中，还须在共享段表中增加一表项，填写有关数据，把 count 置为1；之后，当又有其它进程需要调用该共享段时，由于该共享段已被调入内存，故此时无须再为该段分配内存，而只需在调用进程的段表中增加一表项，填写该共享段的物理地址；在共享段的段表中，填上调用进程的进程名、存取控制等，再执行 count :=count+1 操作，以表明有两个进程共享该段。 共享段的回收当共享此段的某进程不再需要该段时，应将该段释放，包括撤消在该进程段表中共享段所对应的表项，以及执行 count :=count-1 操作。若结果为 0，则须由系统回收该共享段的物理内存，以及取消在共享段表中该段所对应的表项，表明此时已没有进程使用该段；否则(减 1 结果不为 0)，只是取消调用者进程在共享段表中的有关记录。分段保护在分段系统中，由于每个分段在逻辑上是独立的，因而比较容易实现信息保护。目前，常采用以下几种措施来确保信息的安全。越界检查在段表寄存器中放有段表长度信息；同样，在段表中也为每个段设置有段长字段。在进行存储访问时，首先将逻辑地址空间的段号与段表长度进行比较，如果段号等于或大于段表长度，将发出地址越界中断信号；其次，还要检查段内地址是否等于或大于段长，若大于段长，将产生地址越界中断信号，从而保证了每个进程只能在自己的地址空间内运行。存取控制检查在段表的每个表项中，都设置了一个“存取控制”字段，用于规定对该段的访问方式。通常的访问方式有： (1) 只读，即只允许进程对该段中的程序或数据进行读访问。 (2) 只执行，即只允许进程调用该段去执行，但不准读该段的内容，也不允许对该段执行写操作。 (3) 读/写，即允许进程对该段进行读/写访问。对于共享段而言，存取控制就显得尤为重要，因而对不同的进程，应赋予不同的读写权限。这时，既要保证信息的安全性，又要满足运行需要。环保护机构这是一种功能较完善的保护机制。在该机制中规定：低编号的环具有高优先权。OS核心处于 0 环内；某些重要的实用程序和操作系统服务占居中间环；而一般的应用程序则被安排在外环上。在环系统中，程序的访问和调用应遵循以下规则： (1) 一个程序可以访问驻留在相同环或较低特权环中的数据。 (2) 一个程序可以调用驻留在相同环或较高特权环中的服务。请求段页式虚拟存储管理请参考请求分页或分段虚拟存储管理。实际上就是在普通段页式存储管理的基础上加上换人换出功能。设备管理计算机系统的一个重要组成部分是 I/O 系统。在该系统中包括有用于实现信息输入、 输出和存储功能的设备和相应的设备控制器，在有的大、中型机中，还有 I/O 通道或 I/O 处理机。设备管理的对象主要是 I/O 设备，还可能要涉及到设备控制器和 I/O 通道。而设备管理的基本任务是完成用户提出的 I/O 请求，提高 I/O 速率以及提高 I/O 设备的利用率。设备管理的主要功能有: 缓冲区管理、设备分配、设备处理、虚拟设备及实现设备独立性等。由于 I/O 设备不仅种类繁多，而且它们的特性和操作方式往往相差甚大，这就使得设备管理成为操作系统中最繁杂且与硬件最紧密相关的部分。I/O 系统概述不同的人对于 I/O 硬件的理解是不同的。对于电子工程师而言，I/O 硬件就是芯片、导线、电源、电机和其他组成硬件的物理部件。对程序员而言，则只注意 I/O 硬件提供给软件的接口，如硬件能够接受的命令、它能够完成的功能以及它能够报告的错误。I/O 设备类型I/O 设备的类型繁多，从 OS 观点看，其重要的性能指标有: 设备使用特性、数据传输速率、数据的传输单位、设备共享属性等。因而可从不同角度对它们进行分类。 按设备的使用特性分类 存储设备该类设备也称为外存或后备存储器、辅助存储器，是计算机系统用以存储信息的主要设备。该类设备存取速度较内存慢，但容量比内存大得多，相对价格也便宜。 输入/输出设备又具体可分为输入设备、输出设备和交互式设备。（1）输入设备用来接收外部信息，如键盘、鼠标、扫描仪、视频摄像、各类传感器等。（2）输出设备是用于将计算机加工处理后的信息送向外部的设备，如打印机、绘图仪、显示器、数字视频显示设备、音响输出设备等。（3）交互式设备则是集成上述两类设备，利用输入设备接收用户命令信息，并通过输出设备(主要是显示器)同步显示用户命令以及命令执行的结果。 按传输速率分类按传输速度的高低，可将 I/O设备分为三类:低速设备、中速设备、高速设备。 按信息交换的单位分类按信息交换的单位，可将 I/O 设备分成两类： 块设备这类设备用于存储信息。由于信息的存取总是以数据块为单位，故而得名。它属于有结构设备。典型的块设备是磁盘。磁盘设备的基本特征是其传输速率较高；另一特征是可寻址，即对它可随机地读/写任一块。此外，磁盘设备的 I/O 常采用 DMA 方式。 字符设备用于数据的输入和输出。其基本单位是字符，故称为字符设备。它属于无结构类型。字符设备的基本特征是其传输速率较低；另一特征是不可寻址，即输入/输出时不能指定数据的输入源地址及输出的目标地址；此外，字符设备在输入/输出时，常采用中断驱动方式。 按设备的共享属性分类这种分类方式可将I/O设备分为如下三类： 独占设备独占设备是指在一段时间内只允许一个用户(进程)访问的设备，即临界资源。因而，对多个并发进程而言，应互斥地访问这类设备。系统一旦把这类设备分配给了某 进程后，便由该进程独占，直至用完释放。应当注意，独占设备的分配有可能引起进程死锁。 共享设备共享设备是指在一段时间内允许多个进程同时访问的设备。当然，对于每一时刻而言，该类设备仍然只允许一个进程访问。显然，共享设备必须是可寻址的和可随机访问的设备。典型的共享设备是磁盘。对共享设备不仅可获得良好的设备利用率，而且它也是实现文件系统和数据库系统的物质基础。 虚拟设备虚拟设备是指通过虚拟技术将一台独占设备变换为若干台逻辑设备，供若干个用户(进程)同时使用。设备与控制器之间的接口通常，设备并不是直接与 CPU 进行通信，而是与设备控制器通信，因此，在 I/O设备中应含有与设备控制器间的接口，在该接口中有三种类型的信号(见下图所示)，各对应一条信号线。 1) 数据信号线这类信号线用于在设备和设备控制器之间传送数据信号。对输入设备而言，由外界输入的信号经转换器转换后所形成的数据，通常先送入缓冲器中，当数据量达到一定的比特(字符)数后，再从缓冲器通过一组数据信号线传送给设备控制器，如上图所示。对输出设备而言，则是将从设备控制器经过数据信号线传送来的一批数据先暂存于缓冲器中，经转换器作适当转换后，再逐个字符地输出。 2) 控制信号线这是作为由设备控制器向I/O设备发送控制信号时的通路。该信号规定了设备将要执行的操作，如读操作(指由设备向控制器传送数据)或写操作(从控制器接收数据)，或执行磁头移动等操作。 3) 状态信号线这类信号线用于传送指示设备当前状态的信号。设备的当前状态有正在读(或写)；设备已读(写)完成，并准备好新的数据传送。设备控制器设备控制器是计算机中的一个实体，其 主 要 职责是控制一个或多个I/O设备，以实现I/O设备和计算机之间的数据交换。它是CPU与I/O设备之间的接口，它接收从CPU发来的命令，并去控制I/O设备工作，以使处理机从繁杂的设备控制事务中解脱出来。设备控制器是一个可编址的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；若控制器可连接多个设备时，则应含有多个设备地址，并使每一个设备地址对应一个设备。设备控制器的复杂性因不同设备而异，相差甚大，于是可把设备控制器分成两类: 一类是用于控制字符设备的控制器; 另一类是用于控制块设备的控制器。在微型机和小型机中的控制器，常做成印刷电路卡形式，因而也常称为接口卡，可将它插入计算机。有些控制器还可以处理两个、四个或八个同类设备。 设备控制器的基本功能 1) 接收和识别命令 2) 数据交换 3) 标识和报告设备的状态 4) 地址识别就像内存中的每一个单元都有一个地址一样，系统中的每一个设备也都有一个地址，而设备控制器又必须能够识别它所控制的每个设备的地址。为此，在控制器中应配置地址译码器。 5) 数据缓冲由于 I/O 设备的速率较低而 CPU 和内存的速率却很高，故在控制器中必须设置一缓冲器。在输出时，用此缓冲器暂存由主机高速传来的数据，然后才以 I/O 设备所具有的速率将缓冲器中的数据传送给 I/O 设备；在输入时，缓冲器则用于暂存从 I/O 设备送来的数据，待接收到一批数据后，再将缓冲器中的数据高速地传送给主机。 差错控制设备控制器还兼管对由 I/O 设备传送来的数据进行差错检测。若发现传送中出现了错误，通常是将差错检测码置位，并向CPU报告，于是CPU将本次传送来的数据作废，并重新进行一次传送。这样便可保证数据输入的正确性。 设备控制器的组成由于设备控制器位于CPU与设备之间，它既要与 CPU通信，又要与设备通信，还应具有按照CPU所发来的命令去控制设备工作的功能，因此，现有的大多数控制器都是由以下三部分组成的。 1) 设备控制器与处理机的接口该接口用于实现 CPU 与设备控制器之间的通信。共有三类信号线: 数据线、地址线和控制线。数据线通常与两类寄存器相连接： 第一类是数据寄存器(在控制器中可以有一个或多个数据寄存器，用于存放从设备送来的数据(输入)或从 CPU 送来的数据(输出))； 第二类是控制/状态寄存器(在控制器中可以有一个或多个这类寄存器，用于存放从 CPU 送来的控制信息或设备的状态信息)。 2) 设备控制器与设备的接口在一个设备控制器上，可以连接一个或多个设备。相应地，在控制器中便有一个或多个设备接口，一个接口连接一台设备。在每个接口中都存在数据、控制和状态三种类型的信号。控制器中的I/O逻辑根据处理机发来的地址信号去选择一个设备接口。 3) I/O 逻辑在设备控制器中的 I/O 逻辑用于实现对设备的控制。它通过一组控制线与处理机交互，处理机利用该逻辑向控制器发送 I/O 命令；I/O 逻辑对收到的命令进行译码。每当 CPU 要启动一个设备时，一方面将启动命令发送给控制器；另一方面又同时通过地址线把地址发送给控制器，由控制器的 I/O 逻辑对收到的地址进行译码，再根据所译出的命令对所选设备进行控制。内存映射 I/O每个控制器有几个寄存器用来与 CPU 进行通信。通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行某些其他操作。通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。除了这些控制寄存器意外，许多设备还有一个操作系统可以读写的数据缓冲区。那么，CPU 如何与设备的控制寄存器和数据缓冲区进行通信？存在两个可选方法： 独立编址每个控制寄存器被分配一个 I/O 端口号，所有 I/O 端口号形成 I/O 端口空间，该空间只有操作系统可以访问。在这一方案中，内存地址空间和 I/O 地址空间是不同的。此时，CPU 访问内存和访问 IO 就需要不同的 CPU 指令去访问 统一编址它将所有的控制寄存器映射到内存空间，即在内存中单独开辟一块专有区域来共 I/O 设备和 CPU 通信使用。该方法又称为内存映射 I/O。该方法的优势是 IO 当作内存来访问，编程简单；缺点是 IO 也需要占用一定的 CPU 地址空间，而 CPU 的地址空间是有限资源。而且，保持该缓存与设备的同步是一个比较困难的事情。I/O 通道其目的是使一些原来由 CPU 处理的 I/O 任务转由通道来承担，从而把 CPU 从繁杂的 I/O 任务中解脱出来。在设置了通道后，CPU 只需向通道发送一条 I/O 指令。通道在收到该指令后，便从内存中取出本次要执行的通道程序，然后执行该通道程序，仅当通道完成了规定的 I/O 任务后，才向 CPU 发中断信号。实际上，I/O 通道是一种特殊的处理机，它具有执行 I/O 指令的能力，并通过执行通道(I/O)程序来控制 I/O 操作。但 I/O 通道又与一般的处理机不同，主要表现在以下两个方面: 一是其指令类型单一，这是由于通道硬件比较简单，其所能执行的命令主要局限于与 I/O 操作有关的指令； 二是通道没有自己的内存，通道所执行的通道程序是放在主机的内存中的，换言之，是通道与 CPU 共享内存。 通道类型通道是用于控制外围设备(包括字符设备和块设备)的。由于外围设备的类型较多，且其传输速率相差甚大，因而使通道具有多种类型。这里，根据信息交换方式的不同，可把通道分成以下三种类型: 1) 字节多路通道(Byte Multiplexor Channel)这是一种按字节交叉方式工作的通道。它通常都含有许多非分配型子通道，其数量可从几十到数百个，每一个子通道连接一台 I/O 设备，并控制该设备的 I/O 操作。这些子通道按时间片轮转方式共享主通道。只要字节多路通道扫描每个子通道的速率足够快，而连接到子通道上的设备的速率不是太高时，便不致丢失信息。 2) 数组选择通道(Block Selector Channel)字节多路通道不适于连接高速设备，这推动了按数组方式进行数据传送的数组选择通道的形成。这种通道虽然可以连接多台高速设备，但由于它只含有一个分配型子通道，在一段时间内只能执行一道通道程序，控制一台设备进行数据传送，致使当某台设备占用了该通道后，便一直由它独占，即使是它无数据传送，通道被闲置，也不允许其它设备使用该通道，直至该设备传送完毕释放该通道。可见，这种通道的利用率很低。 3) 数组多路通道(Block Multiplexor Channel)数组选择通道虽有很高的传输速率，但它却每次只允许一个设备传输数据。数组多路通道是将数组选择通道传输速率高和字节多路通道能使各子通道(设备)分时并行操作的优点相结合而形成的一种新通道。它含有多个非分配型子通道，因而这种通道既具有很高的数据传输速率，又能获得令人满意的通道利用率。也正因此，才使该通道能被广泛地用于连接多台高、中速的外围设备，其数据传送是按数组方式进行的。 瓶颈问题由于通道价格昂贵，致使机器中所设置的通道数量势必较少，这往往又使它成了 I/O 的瓶颈，进而造成整个系统吞吐量的下降。由于没引入通道之前，很多设备是可以并行使用的，但引入通道之后，一旦通道被占用，同一个通道下的其他设备只能等待。解决“瓶颈”问题的最有效的方法，便是增加设备到主机间的通路而不增加通道，换言之，就是把一个设备连接到多个控制器上，而一个控制器又连接到多个通道上。多通路方式不仅解决了“瓶颈”问题，而且提高了系统的可靠性，因为个别通道或控制器的故障不会使设备和存储器之间没有通路。I/O 数据传输控制方式计算机是一个信息处理工具，人们将要处理的信息首先输入到内存中，然后由 CPU 执行程序对其进行处理，再将处理结果存储到内存中，最后送到输出设备，这便是一个完整的数据传输过程。在此过程中，内存为核心，从就三级的整体流程看，数据传输指的是内存和 I/O 设备之间的数据传输，更具体地讲，是进程的数据存储区与 I/O 设备之间的数据传输。实际进程内存和 I/O 设备之间的数据传输时，不一定直接在内存和 I/O 设备之间进行，可以通过一些中间途径，如通过 CPU 的寄存器做中转。着计算机技术的发展，I/O 控制方式也在不断地发展。在早期的计算机系统中，是采用程序 I/O 方式；当在系统中引入中断机制后，I/O 方式便发展为中断驱动方式；此后，随着 DMA 控制器的出现，又使 I/O 方式在传输单位上发生了变化，即从以字节为单位的传输扩大到以数据块为单位进行转输，从而大大地改善了块设备的 I/O 性能；而通道的引入，又使对 I/O 操作的组织和数据的传送都能独立地进行而无需 CPU 干预。应当指出，在 I/O 控制方式的整个发展过程中，始终贯穿着这样一条宗旨，即尽量减少主机对 I/O 控制的干预，把主机从繁杂的 I/O 控制事务中解脱出来，以便更多地去完成数据处理任务。程序直接控制方式由程序直接控制内存与 I/O 设备之间的数据传输称为“忙等”方式或循环测试方式或轮询，即当要在内存和 I/O 设备之间进行信息传输时，由 CPU 向相应的设备控制器发出命令，由设备控制器控制 I/O 设备进行实际操作。在 I/O 设备工作时，CPU 执行一段循环测试程序，不断测试 I/O 设备的完成状况，以决定是否继续传输下一个数据。若设备未完成此次数据传输，则继续测试；若设备完成了此次数据传输，则进行下一次数据传输或执行程序。程序直接控制方式进行数据传输的方式如图所示：该方式使用 3 条指令： 查询指令：查询设备是否就绪； 读写指令： 当设备就绪时，执行数据交换； 转移指令： 当数据未就绪时，执行转移指令转向查询指令继续查询。有的系统中同时有多个设备要求执行 I/O 操作，那么对每个设备都编写一段 I/O 数据处理程序，然后，轮流查询这些设备的状态位。在程序 I/O 方式中，由于 CPU 的高速性和I/O设备的低速性，致使 CPU 的绝大部分时间都处于等待 I/O 设备完成数据 I/O 的循环测试中，造成对 CPU 的极大浪费。在该方式中，CPU 之所以要不断地测试 I/O 设备的状态，就是因为在 CPU 中无中断机构，使 I/O 设备无法向 CPU 报告它已完成了一个字符的输入操作。中断驱动 I/O 控制方式在硬件层面，中断的工作如下所述。当一个 I/O 设备完成交给它的工作时，它就产生一个中断（假设操作系统已经开放中断），它是通过在分配给它的一条总线信号线上置起信号产生中断信号。该信号被主板上的中断控制器芯片检测到，由中断控制器芯片决定做什么（详细的中断处理过程请参考“计算机组成原理”相关书籍）。中断控制方式详细过程：设备与中断控制器之间的连接实际上使用的是总线上的中断线而不是专用连线。当要在主机和 I/O 设备之间进行信息传输时，由 CPU 向相应的设备控制器发出命令，由设备控制器控制 I/O 设备进行实际操作，每次的数据传输单位是设备控制器的数据缓冲寄存器的容量。I/O 设备工作时，相应进程放弃处理机，处于等待状态，由操作系统调度其他就绪进程占用 CPU。I/O 完成工作时，由设备控制器向 CPU 发出中断信号，通知 CPU 本次 I/O 操作完成，然后由 CPU 执行一个中断处理程序，对此情况作出相应反应。中断处理过程一般首先保护现场，然后将等待 I/O 操作完成的进程唤醒，使其进入就绪状态，最后转进程调度。简而言之，当某进程要启动某个 I/O 设备工作时，便由 CPU 向相应的设备控制器发出一条 I/O 命令，然后立即返回继续执行原来的任务。设备控制器于是按照该命令的要求去控制指定 I/O 设备。此时，CPU 与 I/O 设备并行操作。中断识别：绝大多数 CPU 有两个中断请求线。一个非屏蔽中断，主要用来处理如不可恢复内存错误等事件。另一个是可屏蔽中断，这可以由 CPU 在执行关键的不可中断的指令序列前加以屏蔽。可屏蔽中断可以被设备控制器用来请求服务。中断机制接受一个地址，以用来从一小集合内选择特定的中断处理程序。对绝大多数体系机构，这个地址是一个称为中断向量的表中偏移量。该向量包含了特殊中断处理程序的内存地址。向量中断机制的目的是用来减少单个中断处理的需要，这些中断处理搜索所有可能的中断源以决定哪个中断需要服务。事实上，计算机设备常常要比向量内的地址多。解决这一问题的常用方法之一就是中断链接技术，即中断向量内的每个元素都指向中断处理程序列表的头。当有中断发生时，相应链表上的所有中断处理程序都将一一调用，直到发现可以处理请求的为止。这种结构是在大型中断向量表的大开销与分发到单个中断处理程序的低效率之间的一个折中。中断机制也实现了中断优先级。该中断机制使 CPU 延迟处理低优先级中断而不屏蔽所有中断，也可以让高优先级中断抢占低优先级中断处理。中断控制方式的评价：在 I/O 设备输入每个数据的过程中，由于无需 CPU 干预，因而可使 CPU 与 I/O 设备并行工作。仅当输完一个数据时，才需 CPU 花费极短的时间去做些中断处理。可见，这样可使 CPU 和 I/O 设备都处于忙碌状态，从而提高了整个系统的资源利用率及吞吐量。中断控制方式的缺点是：由于每次的数据传输单位是设备控制器的数据缓冲寄存器容量，单位传输数据量较小，进程每次需要传输的数据被分为若干部分进行传输，中断次数较多，每次中断都要运行一个中断处理程序，耗费 CPU 的时间很多，使 CPU 的有效计算时间减少。DMA 控制方式虽然中断驱动 I/O 比程序 I/O 方式更有效，但须注意，它仍是以字(节)为单位进行 I/O 的，每当完成一个字(节)的 I/O 时，控制器便要向 CPU 请求一次中断。换言之，采用中断驱动 I/O 方式时的 CPU 是以字(节)为单位进行干预的。如果将这种方式用于块设备的 I/O，显然是极其低效的。为了进一步减少 CPU 对 I/O 的干预而引入了直接存储器访问方式，该方式的特点是： (1) 数据传输的基本单位是数据块，即在 CPU 与 I/O 设备之间，每次传送至少一个数据块； (2) 所传送的数据是从设备直接送入内存的，或者相反； (3) 仅在传送一个或多个数据块的开始和结束时，才需 CPU 干预，整块数据的传送是在控制器的控制下完成的。 DMA 控制器的组成DMA 控制器由三部分组成：主机与 DMA 控制器的接口；DMA 控制器与块设备的接口；I/O 控制逻辑。为了实现在主机与控制器之间成块数据的直接交换，必须在DMA控制器中设置如下四类寄存器： (1) 命令/状态寄存器(CR)。用于接收从 CPU 发来的 I/O 命令，或有关控制信息，或设备的状态。 (2) 内存地址寄存器(MAR)。在输入时，它存放把数据从设备传送到内存的起始目标地址；在输出时，它存放由内存到设备的内存源地址。 (3) 数据寄存器(DR)。又称为数据缓冲寄存器或数据缓冲区，用于暂存从设备到内存，或从内存到设备的数据。 (4) 数据计数器(DC)。存放本次 CPU 要读或写的字(节)数。还需要： 设备地址寄存器：存放 I/O 信息的地址； 中断机制和控制逻辑：用于向 CPU 提出 I/O 中断请求，及保存 CPU 发来的 I/O 命令，管理 DMA 的传送过程。DMA 与主存之间采用子传送，DMA 与设备之间可能是字位或字节传送，所以，DMA 中要设置数据移位寄存器、字节计数器等硬件逻辑，不仅如此还需要内部缓冲区。其原因是，DMA与主存，DMA 与设备之间的数据传输速率是不匹配的，而且传输总线可能被争用，因此缓冲区是必不可少的。DMA 不仅设有中断机制，还增加了 DMA传输控制机制。若出现 DMA 与 CPU 同时经总线访问主存储器的情况，CPU 总是把总线占有权让给 DMA，DMA的这种占有称为周期窃用。窃取时间通常为一个存取周期，让设备和主存储器之间交换数据，而不再需要 CPU 干预。每次传输数据时，不必进入中断系统。从而提高了 CPU 资源利用率和数据传输效率。通道方式DMA 方式与程序中断方式相比，进一步减少了 CPU 对 I/O 操作的干预，但每发出一次 I/O 指令，只能读写一个数据块，用户希望一次能够读写多个离散的数据块，并把它们传送到不同的主存区域内或相反，则需要由 CPU 发出多条启动 I/O 指令及多次 I/O 中断处理才能完成。通道方式是 DMA 方式的发展，能够再次减少 CPU 对 I/O 操作的干预。同时，为了发挥 CPU 和设备之间的并行工作能力，也为了让种类繁多且物理特性各异的设备能够以标准的接口连接到系统中，计算机系统引入自成体系的通道结构。通道又称为I/O 处理器，能完成主存储器和设备之间的信息传送，与 CPU 并行地执行操作。采用通道技术主要解决 I/O 操作的独立性和硬部件工作的并行性，实现了设备和 CPU 并行操作、通道之间并行操作、设备之间并行操作，提高了整个系统的效率。通道计算机的体系结构：具有通道装置的计算机系统的主机、通道、控制器和设备之间采用四级连接，实施三级控制。一个 CPU 通常可以连接若干通道，一个通道可以连接若干控制器，一个控制器可以连接若干台设备。CPU 通过执行 I/O 指令对通道实施控制，通道通过执行通道命令对控制器实施控制，控制器发出动作序列对设备实施控制，设备执行相应的 I/O 操作。I/O 操作过程：采用 I/O 通道设计后，I/O 操作的过程如下：CPU 在执行主程序时遇到 I/O 请求，启动在指定通道上选址的设备，一旦启动成功，通道开始控制设备进行操作，这是 CPU 就可以执行其他任务并与通道并行工作，知道 I/O 操作完成；当通道发出 I/O 操作结束中断时，处理器才响应并停止当前工作，转而处理 I/O 操作结束事件。通道程序：通道是通过执行通道程序，并与设备控制器共同实现对I/O设备的控制的。通道程序是由一系列通道指令(或称为通道命令)所构成的。通道指令与一般的机器指令不同，在它的每条指令中都包含下列诸信息： (1) 操作码。操作码规定了指令所执行的操作，如读、写、控制等操作。 (2) 内存地址。内存地址标明字符送入内存(读操作)和从内存取出(写操作)时的内存首址。 (3) 计数。该信息表示本条指令所要读(或写)数据的字节数。 (4) 通道程序结束位 P。该位用于表示通道程序是否结束。P=1 表示本条指令是通道程序的最后一条指令。 (5) 记录结束标志 R。R=0 表示本通道指令与下一条指令所处理的数据是同属于一个记录；R=1 表示这是处理某记录的最后一条指令。缓冲管理为了缓和 CPU 与 I/O 设备速度不匹配的矛盾，提高 CPU 和 I/O 设备的并行性，在现代操作系统中，几乎所有的 I/O 设备在与处理机交换数据时都用了缓冲区。缓冲管理的主要职责是组织好这些缓冲区，并提供获得和释放缓冲区的手段。缓冲引入的原因在设备管理中，引入缓冲区的主要原因可归结为以下几点： 减少读块设备的次数：当进程在块设备上进行读操作（输入）时，通过系统调用，由操作系统将数据读入缓冲器，然后送入相应进程的数据存储区，由进程处理。缓冲器内保存的信息可能会被再次读到，因此，当再次对此块设备今次那个读操作时，可以先查看一下所读信息是否在缓冲器内，若在缓冲器内，则可以直接从缓冲器内读取，而不必从设备读取。这种场合要求对缓冲器的读取速度快于块设备的读取速度，则当命中率（所读数据在缓冲器内的次数与读操作的总次数的比值）较高时，会明显提高读操作的速度。CPU 和内存之间的告诉缓存的作用就是这样的。 缓和 CPU 与 I/O 设备间速度不匹配的矛盾：事实上，凡在数据到达速率与其离去速率不同的地方，都可设置缓冲区，以缓和它们之间速率不匹配的矛盾。 减少对CPU的中断频率，放宽对CPU中断响应时间的限制； 作为无法直接通信的设备间的中转站； 解决程序锁清秋的逻辑记录大小和设设备的物理记录大小不匹配的问题； 加快进程的推进速度，提高CPU和I/O设备之间的并行性。单缓冲在单缓冲情况下，每当用户进程发出一 I/O 请求时，操作系统便在主存中为之分配一缓冲区。单缓冲方式由于只有一个缓冲区，这一缓冲区在某个时候能存放输入数据或输出数据，但不能既是输入数据又是输出数据，否则缓冲区中的数据会引起混乱。因此，单缓冲方式不能使外部设备并行工作。双缓冲为了加快输入和输出速度，提高设备利用率，人们又引入了双缓冲区机制，也称为缓冲对换(Buffer Swapping)。为每台 I/O 设备分配两个缓冲区。双缓冲方式可以实现外部设备并行工作。先将数据输入到缓冲区 buffer1，然后进程从 buffer1 中取出数据进行计算，将输出的数据送往 buffer2，然后将 buffer2 中的数据送往输出设备，与此同时，从输入设备将数据输入到 buffer1，如此继续进行，使得输入设备和输出设备并行工作。循环缓冲当输入与输出或生产者与消费者的速度基本相匹配时，采用双缓冲能获得较好的效果，可使生产者和消费者基本上能并行操作。但若两者的速度相差甚远，双缓冲的效果则不够理想，不过可以随着缓冲区数量的增加，使情况有所改善。因此，又引入了多缓冲机制。可将多个缓冲组织成循环缓冲形式。对于用作输入的循环缓冲，通常是提供给输入进程或计算进程使用，输入进程不断向空缓冲区输入数据，而计算进程则从中提取数据进行计算。循环缓冲技术是在内存中分配大小相等的存储区作为缓冲区，并将这些缓冲区连接起来，每个缓冲区中有一个指向下一个缓冲区的指针，最后一个缓冲区的指针指向第一个缓冲区。使用虚幻缓冲结构需要两个指针，IN 指针指示可输入数据的第一个空缓冲区，OUT 指针指示可提取数据的第一个满缓冲区。系统初启时，这两个指针被初始化为 IN = OUT，在系统工作过程中，两个指针向同一个方向移动。输入时，数据输入到 IN 指针指示的缓冲区，输入完毕，IN 指针后移指向下一个可用的空缓冲区；当进程从循环缓冲结构提取数据时，提取 OUT 指针指示的缓冲区中的内容，提取完毕，OUT 指针后移指向下一个满缓冲区。指针移动时检测空/满缓冲区的数量，当空缓冲区数量为 0 时，IN 指针不能再后移动，此时 IN = OUT；满缓冲区数量为 0 时，OUT 指针不能再后移，此时 OUT = IN。所以必须注意进程同步问题。缓冲池上述的缓冲区仅适用于某特定的I/O进程和计算进程，因而它们属于专用缓冲。当系统较大时，将会有许多这样的循环缓冲，这不仅要消耗大量的内存空间，而且其利用率不高。为了提高缓冲区的利用率，目前广泛流行公用缓冲池(Buffer Pool)，在池中设置了多个可供若干个进程共享的缓冲区。 缓冲池组成对于既可用于输入又可用于输出的公用缓冲池，其中至少应含有以下三种类型的缓 冲区: 空(闲)缓冲区； 装满输入数据的缓冲区； 装满输出数据的缓冲区。为了管理上的方便，可将相同类型的缓冲区链成一个队列，于是可形成以下三个队列（队列的相关知识请参考“数据结构”）: 空缓冲队列； 输入队列； 输出队列。除了上述三个队列外，还应具有以下四种工作缓冲区： 用于收容输入数据的工作缓冲区； 用于提取输入数据的工作缓冲区； 用于收容输出数据的工作缓冲区； 用于提取输出数据的工作缓冲区。缓冲池中的队列本身是临界资源，多个进程在访问一个队列时，既应互斥，又须同步（详见“临界支援”和“进程同步”）。 缓冲池工作方式缓冲区可以工作在收容输入、提取输入、收容输出和提取输出四种工作方式下，如下图所示：I/O 软件I/O 软件的总体设计目标是高效率和通用性。前者是要确保 I/O 设备与 CPU 的并发性，以提高资源的利用率；后者则是指尽可能地提供简单抽象、清晰而统一的接口，采用统一标准的方法，来管理所有的设备以及所需的I/O操作。为了达到这一目标，通常将 I/O 软件组织成一种层次结构， 低层软件用于实现与硬件相关的操作，并可屏蔽硬件的具体细节； 高层软件则主要向用户提供一个简洁、友好和规范的接口。 每一层具有一个要执行的定义明确的功能和一个与邻近层次定义明确的接口，各层的功能与接口随系统的不同而异。I/O软件的设计目标和原则计算机系统中包含了众多的 I/O 设备，其种类繁多，硬件构造复杂，物理特性各异，速度慢，与 CPU 速度不匹配，并涉及到大量专用 CPU 及数字逻辑运算等细节，如寄存器、中断、控制字符和设备字符集等，造成对设备的操作和管理非常复杂和琐碎。因此， 从系统的观点出发，采用多种技术和措施，解决由于外部设备与 CPU 速度不匹配所引起的问题，提高主机和外设的并行工作能力，提高系统效率，成为操作系统的一个重要目标。 另一方面，对设备的操作和管理的复杂性，也给用户的使用带来了极大的困难。用户必须掌握 I/O 系统的原理，对接口和控制器及设备的物理特性要有深入了解，这就使计算机的推广应用受到很大限制。所以，设法消除或屏蔽设备硬件内部的低级处理过程，为用户提供一个简便、易用、抽象的逻辑设备接口，保证用户安全、方便地使用各类设备，也是 I/O 软件设计的一个重要原则。 具体而言，I/O软件应达到下面的几个目标： 1) 与具体设备无关对于I/O系统中许多种类不同的设备，作为程序员，只需要知道如何使用这些资源来完成所需要的操作，而无需了解设备的有关具体实现细节。为了提高OS的可移植性和易适应性，I/O软件应负责屏蔽设备的具体细节，向高层软件提供抽象的逻辑设备，并完成逻辑设备与具体物理设备的映射。对于操作系统本身而言，应允许在不需要将整个操作系统进行重新编译的情况下，增添新的设备驱动程序，以方便新的 I/O 设备的安装。 2) 统一命名要实现上述的设备无关性，其中一项重要的工作就是如何给I/O设备命名。不同的操作系统有不同的命名规则，一般而言，是在系统中对各类设备采取预先设计的、统一的逻辑名称进行命名，所有软件都以逻辑名称访问设备。这种统一命名与具体设备无关，换言之，同一个逻辑设备的名称，在不同的情况下可能对应于不同的物理设备。 3) 对错误的处理一般而言，错误多数是与设备紧密相关的，因此对于错误的处理，应该尽可能在接近硬件的层面处理，在低层软件能够解决的错误就不让高层软件感知，只有低层软件解决不了的错误才通知高层软件解决。许多情况下，错误恢复可以在低层得到解决，而高层软件不需要知道。 4) 缓冲技术由于CPU与设备之间的速度差异，无论是块设备还是字符设备，都需要使用缓冲技术。对于不同类型的设备，其 缓冲区(块)的大小是不一样的，块设备的缓冲是以数据块为单位的，而字符设备的缓冲则以字节为单位。就是同类型的设备，其缓冲区(块)的大小也是存在差异的， 因此，I/O软件应能屏蔽这种差异，向高层软件提供统一大小的数据块或字符单元，使得高层软件能够只与逻辑块大小一致的抽象设备进行交互。 5) 设备的分配和释放 6) I/O控制方式针对具有不同传输速率的设备，综合系统效率和系统代价等因素，合理选择I/O控制方式，如像打印机等低速设备应采用中断驱动方式，而对磁盘等高速设备则采用DMA控制方式等，以提高系统的利用率。为方便用户，I/O软件也应屏蔽这种差异，向高层软件提供统一的操作接口。I/O 分层结构：目前在I/O软件中已普遍采用了层次式结构，将系统中的设备操作和管理软件分为若干个层次，每一层都利用其下层提供的服务，完成输入、输出功能中的某些子功能，并屏蔽这些功能实现的细节，向高层提供服务。在层次式结构的 I/O 软件中，只要层次间的接口不变，对每个层次中的软件进行的修改都不会引起其下层或高层代码的变更，仅最低层才会涉及到硬件的具体特性。通常把 I/O 软件组织成四个层次，如下图所示(图中的箭头表示 I/O 的控制流)。各层次及其功能如下所述：(1) 用户层软件：实现与用户交互的接口，用户可直接调用在用户层提供的、与 I/O 操作有关的库函数，对设备进行操作。(2) 设备独立性软件：负责实现与设备驱动器的统一接口、设备命名、设备的保护以及设备的分配与释放等，同时为设备管理和数据传送提供必要的存储空间。(3) 设备驱动程序：与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动I/O设备工作的驱动程序。(4) 中断处理程序：用于保存被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完后再恢复被中断进程的现场后返回到被中断进程。实际上，在不同的操作系统中，这种层次的划分并不是固定的，主要是随系统具体情况的不同，而在层次的划分以及各层的功能和接口上存在一定的差异。下面我们将从低到高地对每个层次进行讨论。中断处理程序中断处理层的主要工作有：进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。由于中断处理与硬件紧密相关，对用户及用户程序而言，应该尽量加以屏蔽，故应该放在操作系统的底层进行中断处理，系统的其余部分尽可能少地与之发生联系。当一个进程请求I/O 操作时，该进程将被挂起，直到 I/O设备完成I/O操作后，设备控制器便向CPU发送一中断请求，CPU响应后便转向中断处理程序，中断处理程序执行相应的处理，处理完后解除相应进程的阻塞状态。对于为每一类设备设置一个I/O进程的设备处理方式，其中断处理程序的处理过程分成以下几个步骤： 唤醒被阻塞的驱动(程序)进程当中断处理程序开始执行时，首先去唤醒处于阻塞状态的驱动(程序)进程。 保护被中断进程的CPU环境通常由硬件自动将处理机状态字PSW和程序计数器(PC)中的内容，保存在中断保留区(栈)中，然后把被中断进程的CPU现场信息(即包括所有的CPU寄存器，如通用寄存器、段寄存器等内容)都压入中断栈中，因为在中断处理时可能会用到这些寄存器。 转入相应的设备处理程序由处理机对各个中断源进行测试，以确定引起本次中断的I/O设备，并发送一应答信号给发出中断请求的进程，使之消除该中断请求信号，然后将相应的设备中断处理程序的入口地址装入到程序计数器中，使处理机转向中断处理程序。 中断处理对于不同的设备，有不同的中断处理程序。该程序首先从设备控制器中读出设备状态，以判别本次中断是正常完成中断，还是异常结束中断。若是前者，中断程序便进行结束处理；若还有命令，可再向控制器发送新的命令，进行新一轮的数据传送。若是异常结束中断，则根据发生异常的原因做相应的处理。 恢复被中断进程的现场当中断处理完成以后，便可将保存在中断栈中的被中断进程的现场信息取出，并装入到相应的寄存器中，其中包括该程序下一次要执行的指令的地址 N+1、处理机状态字 PSW，以及各通用寄存器和段寄存器的内容。这样，当处理机再执行本程序时，便从 N+1 处开始，最终返回到被中断的程序。I/O 操作完成后，驱动程序必须检查本次 I/O 操作中是否发生了错误，并向上层软件报告，最终向调用者报告本次 I/O 的执行情况。除了上述的第 4 步外，其它各步骤对所有 I/O 设备都是相同的，因而对于某种操作系统，例如 UNIX 系统，是把这些共同的部分集中 起来，形成中断总控程序。每当要进行中断处理时，都要首先进入中断总控程序。而对于 第 4 步，则对不同设备须采用不同的设备中断处理程序继续执行。设备驱动设备驱动程序通常又称为设备处理程序，它是 I/O 进程与设备控制器之间的通信程序，又由于它常以进程的形式存在，故以后就简称之为设备驱动进程。其主要任务是接收上层软件发来的抽象I/O要求，如 read 或 write 命令，在把它转换为具体要求后，发送给设备控制器，启动设备去执行；此外，它也将由设备控制器发来的信号传送给上层软件。由于驱动程序与硬件密切相关，故应为每一类设备配置一种驱动程序；有时也可为非常类似的两类设备配置一个驱动程序。例如，打印机和显示器需要不同的驱动程序，但 SCSI 磁盘驱动程序通常可以处理不同大小和不同速度的多个 SCSI 磁盘，甚至还可以处理 SCSI CD-ROM。 设备驱动程序的功能为了实现I/O进程与设备控制器之间的通信，设备驱动程序应具有以下功能：(1) 接收由设备独立性软件发来的命令和参数，并将命令中的抽象要求转换为具体要求，例如，将磁盘块号转换为磁盘的盘面、磁道号及扇区号。(2) 检查用户I/O请求的合法性，了解I/O设备的状态，传递有关参数，设置设备的工作方式。(3) 发出 I/O 命令。如果设备空闲，便立即启动 I/O设备去完成指定的 I/O 操作；如果设备处于忙碌状态，则将请求者的请求块挂在设备队列上等待。(4) 及时响应由控制器或通道发来的中断请求，并根据其中断类型调用相应的中断处理程序进行处理。(5) 对于设置有通道的计算机系统，驱动程序还应能够根据用户的I/O请求，自动地构成通道程序。 设备处理方式在不同的操作系统中所采用的设备处理方式并不完全相同。根据在设备处理时是否设置进程，以及设置什么样的进程而把设备处理方式分成以下三类：(1) 为每一类设备设置一个进程，专门用于执行这类设备的I/O操作。比如，为所有的交互式终端设置一个交互式终端进程；又如，为同一类型的打印机设置一个打印进程。(2) 在整个系统中设置一个 I/O进程，专门用于执行系统中所有各类设备的 I/O操作。也可以设置一个输入进程和一个输出进程，分别处理系统中所有各类设备的输入或输出操作。(3) 不设置专门的设备处理进程，而只为各类设备设置相应的设备处理程序(模块)，供用户进程或系统进程调用。 设备驱动程序的特点设备驱动程序属于低级的系统例程，它与一般的应用程序及系统程序之间有下述明显差异:(1) 驱动程序主要是指在请求 I/O 的进程与设备控制器之间的一个通信和转换程序。它将进程的 I/O 请求经过转换后，传送给控制器；又把控制器中所记录的设备状态和 I/O 操作完成情况及时地反映给请求 I/O 的进程。(2) 驱动程序与设备控制器和 I/O 设备的硬件特性紧密相关，因而对不同类型的设备应配置不同的驱动程序。例如，可以为相同的多个终端设置一个终端驱动程序，但有时即使是同一类型的设备，由于其生产厂家不同，它们也可能并不完全兼容，此时也须为它们配置不同的驱动程序。(3) 驱动程序与 I/O 设备所采用的 I/O 控制方式紧密相关。常用的 I/O 控制方式是中断驱动和 DMA 方式，这两种方式的驱动程序明显不同，因为后者应按数组方式启动设备及进行中断处理。(4) 由于驱动程序与硬件紧密相关，因而其中的一部分必须用汇编语言书写。目前有很多驱动程序的基本部分，已经固化在 ROM 中。(5) 驱动程序应允许可重入。一个正在运行的驱动程序常会在一次调用完成前被再次调用。例如，网络驱动程序正在处理一个到来的数据包时，另一个数据包可能到达。(6) 驱动程序不允许系统调用。但是为了满足其与内核其它部分的交互，可以允许对某些内核过程的调用，如通过调用内核过程来分配和释放内存页面作为缓冲区，以及调用其它过程来管理 MMU 定时器、DMA 控制器、中断控制器等。 设备驱动程序的处理过程不同类型的设备应有不同的设备驱动程序，但大体上它们都可以分成两部分，其中，除了要有能够驱动 I/O 设备工作的驱动程序外，还需要有设备中断处理程序，以处理 I/O 完成后的工作。设备驱动程序的主要任务是启动指定设备。但在启动之前，还必须完成必要的准备工作，如检测设备状态是否为“忙”等。在完成所有的准备工作后，才最后向设备控制器发送一条启动命令。以下是设备驱动程序的处理过程: 1) 将抽象要求转换为具体要求通常在每个设备控制器中都含有若干个寄存器，分别用于暂存命令、数据和参数等。由于用户及上层软件对设备控制器的具体情况毫无了解，因而只能向它发出抽象的要求(命令)，但这些命令无法传送给设备控制器。因此，就需要将这些抽象要求转换为具体要求。例如，将抽象要求中的盘块号转换为磁盘的盘面、 磁道号及扇区。这一转换工作只能由驱动程序来完成，因为在 OS中只有驱动程序才同时了解抽象要求和设备控制器中的寄存器情况；也只有它才知道命令、 数据和参数应分别送往哪个寄存器。 2) 检查I/O请求的合法性对于任何输入设备，都是只能完成一组特定的功能，若该设备不支持这次的 I/O 请求或没有权限，则认为这次 I/O 请求非法。例如，用户试图请求从打印机输入数据，显然系统应予以拒绝。此外，还有些设备如磁盘和终端，它们虽然都是既可读又可写的，但若在打开这些设备时规定的是读，则用户的写请求必然被拒绝。 3) 读出和检查设备的状态在启动某个设备进行I/O操作时，其前提条件应是该设备正处于空闲状态。因此在启动设备之前，要从设备控制器的状态寄存器中，读出设备的状态。例如，为了向某设备写入数据，此前应先检查该设备是否处于接收就绪状态，仅当它处于接收就绪状态时，才能启动其设备控制器，否则只能等待。 4) 传送必要的参数对于许多设备，特别是块设备，除必须向其控制器发出启动命令外，还需传送必要的参数。例如在启动磁盘进行读/写之前，应先将本次要传送的字节数和数据应到达的主存始址，送入控制器的相应寄存器中。 5) 工作方式的设置有些设备可具有多种工作方式，典型情况是利用RS-232接口进行异步通信。在启动该接口之前，应先按通信规程设定参数：波特率、奇偶校验方式、停止位数目及数据字节长度等。 6) 启动I/O设备在完成上述各项准备工作之后，驱动程序可以向控制器中的命令寄存器传送相应的控制命令。对于字符设备，若发出的是写命令，驱动程序将把一个数据传送给控制器；若发出的是读命令，则驱动程序等待接收数据，并通过从控制器中的状态寄存器读入状态字的方法，来确定数据是否到达。驱动程序发出 I/O 命令后，基本的I/O操作是在设备控制器的控制下进行的。通常，I/O 操作所要完成的工作较多，需要一定的时间，如读/写一个盘块中的数据，此时驱动(程序)进程把自己阻塞起来，直到中断到来时才将它唤醒。设备独立性软件为了提高 OS 的可适应性和可扩展性，在现代 OS 中都毫无例外地实现了设备独立性(Device Independence)，也称为设备无关性。设备独立性的含义：应用程序独立于具体使用的物理设备。为了实现设备独立性而引入了逻辑设备和物理设备这两个概念。在应用程序中，使用逻辑设备名称来请求使用某类设备；而系统在实际执行时，还必须使用物理设备名称。因此，系统须具有将逻辑设备名称转换为某物理设备名称的功能，这非常类似于存储器管理中所介绍的逻辑地址和物理地址的概念。在应用程序中所使用的是逻辑地址，而系统在分配和使用内存时，必须使用物理地址。在实现了设备独立性的功能后，可带来以下两方面的好处： 1) 设备分配时的灵活性当应用程序(进程)以物理设备名称来请求使用指定的某台设备时，如果该设备已经分配给其他进程或正在检修，而此时尽管还有几台其它的相同设备正在空闲，该进程却仍阻塞。但若进程能以逻辑设备名称来请求某类设备时，系统可立即将该类设备中的任一台分配给进程，仅当所有此类设备已全部分配完毕时，进程才会阻塞。 2) 易于实现 I/O 重定向所谓 I/O 重定向，是指用于 I/O 操作的设备可以更换(即重定向)，而不必改变应用程序。例如，我们在调试一个应用程序时，可将程序的所有输出送往屏幕显示；而在程序调试完后，如需正式将程序的运行结果打印出来，此时便须将 I/O 重定向的数据结构——逻辑设备表中的显示终端改为打印机，而不必修改应用程序。I/O 重定向功能具有很大的实用价值，现已被广泛地引入到各类OS中。 设备独立性软件驱动程序是一个与硬件(或设备)紧密相关的软件。为了实现设备独立性，必须再在驱动程序之上设置一层软件，称为设备独立性软件。至于设备独立性软件和设备驱动程序之间的界限，根据不同的操作系统和设备有所差异，主要取决于操作系统、设备独立性和设备驱动程序的运行效率等多方面因素的权衡，因为对于一些本应由设备独立性软件实现的功能，可能由于效率等诸多因素，实际上设计在设备驱动程序中。总的来说，设备独立性软件的主要功能可分为以下两个方面： (1) 执行所有设备的公有操作。这些公有操作包括:① 对独立设备的分配与回收；② 将逻辑设备名映射为物理设备名，进一步可以找到相应物理设备的驱动程序；③ 对设备进行保护，禁止用户直接访问设备；④ 缓冲管理，即对字符设备和块设备的缓冲区进行有效的管理，以提高I/O的效率；⑤ 差错控制，由于在I/O操作中的绝大多数错误都与设备无关，故主要由设备驱动程序处理，而设备独立性软件只处理那些设备驱动程序无法处理的错误；⑥ 提供独立于设备的逻辑块，不同类型的设备信息交换单位是不同的，读取和传输速率也各不相同，如字符型设备以单个字符为单位，块设备是以一个数据块为单位，即使同一类型的设备，其信息交换单位大小也是有差异的，如不同磁盘由于扇区大小的不同，可能造成数据块大小的不一致，因此设备独立性软件应负责隐藏这些差异，对逻辑设备使用并向高层软件提供大小统一的逻辑数据块。 (2) 向用户层(或文件层)软件提供统一接口。无论何种设备，它们向用户所提供的接口应该是相同的。例如，对各种设备的读操作，在应用程序中都使用 read；而对各种设备的写操作，也都使用 write。 逻辑设备名到物理设备名映射的实现 1) 逻辑设备表为了实现设备的独立性，系统必须设置一张逻辑设备表(LUT，Logical Unit Table)，用于将应用程序中所使用的逻辑设备名映射为物理设备名。在该表的每个表目中包含了三项：逻辑设备名、物理设备名和设备驱动程序的入口地址，如下图所示。当进程用逻辑设备名请求分配 I/O 设备时，系统为它分配相应的物理设备，并在 LUT 上建立一个表目，填上应用程序中使用的逻辑设备名和系统分配的物理设备名，以及该设备驱动程序的入口地址。当以后进程再利用该逻辑设备名请求 I/O 操作时，系统通过查找 LUT，便可找到物理设备和驱动程序。 2) LUT的设置问题LUT的设置可采取两种方式：第一种方式是在整个系统中只设置一张 LUT。由于系统中所有进程的设备分配情况都记录在同一张 LUT 中，因而不允许在 LUT 中具有相同的逻辑设备名，这就要求所有用户都不使用相同的逻辑设备名。在多用户环境下这通常是难以做到的，因而这种方式主要用于单用户系统中。第二种方式是为每个用户设置一张 LUT。每当用户登录时，便为该用户建立一个进程，同时也为之建立一张 LUT，并将该表放入进程的 PCB 中。由于通常在多用户系统中，都配置了系统设备表，故此时的逻辑设备表可以采用上图(b)中的格式。用户层的 I/O 软件一般而言，大部分的 I/O 软件都在操作系统内部，但仍有一小部分在用户层，包括与用户程序链接在一起的库函数，以及完全运行于内核之外的一些程序。用户层软件必须通过一组系统调用来取得操作系统服务。在现代的高级语言以及 C 语言中，通常提供了与各系统调用一一对应的库函数，用户程序通过调用对应的库函数使用系统调用。这些库函数与调用程序连接在一起，包含在运行时装入在内存的二进制程序中，如 C 语言中的库函数 write 等，显然这些库函数的集合也是 I/O 系统的组成部分。但在许多现代操作系统中，系统调用本身已经采用 C 语言编写，并以函数形式提供，所以在使用 C 语言编写的用户程序中，可以直接使用这些系统调用。另外，在操作系统中还有一些程序，如下面章节我们将要论述的 Spooling 系统以及在网络传输文件时常使用的守护进程等，就是完全运行在内核之外的程序，但它们仍归属于 I/O 系统。设备分配在多道程序环境下，系统中的设备供所有进程共享。为防止诸进程对系统资源的无序竞争，特规定系统设备不允许用户自行使用，必须由系统统一分配。每当进程向系统提出 I/O 请求时，只要是可能和安全的，设备分配程序便按照一定的策略，把设备分配给请求用户(进程)。在有的系统中，为了确保在 CPU 与设备之间能进行通信，还应分配相应的控制器和通道。为了实现设备分配，必须在系统中设置相应的数据结构。设备分配中的数据结构在进行设备分配时，通常都需要借助于一些表格的帮助。在表格中记录了相应设备或控制器的状态及对设备或控制器进行控制所需的信息。在进行设备分配时所需的数据结构(表格)有：设备控制表、控制器控制表、通道控制表和系统设备表等。 设备控制表(DCT)系统为每一个设备都配置了一张设备控制表，用于记录本设备的情况，如下图：设备控制表中，除了有用于指示设备类型的字段 type 和设备标识字段 deviceid 外，还应含有下列字段：(1) 设备队列队首指针。凡因请求本设备而未得到满足的进程，其 PCB 都应按照一定的策略排成一个队列，称该队列为设备请求队列或简称设备队列。其队首指针指向队首 PCB。在有的系统中还设置了队尾指针。(2) 设备状态。当设备自身正处于使用状态时，应将设备的忙/闲标志置“1”。若与该设备相连接的控制器或通道正忙，也不能启动该设备，此时则应将设备的等待标志置“1”。(3) 与设备连接的控制器表指针。该指针指向该设备所连接的控制器的控制表。在设备到主机之间具有多条通路的情况下，一个设备将与多个控制器相连接。此时，在 DCT 中还应设置多个控制器表指针。(4) 重复执行次数。由于外部设备在传送数据时，较易发生数据传送错误，因而在许多系统中，如果发生传送错误，并不立即认为传送失败，而是令它重新传送，并由系统规定设备在工作中发生错误时应重复执行的次数。在重复执行时，若能恢复正常传送，则仍认为传送成功。仅当屡次失败，致使重复执行次数达到规定值而传送仍不成功时，才认为传送失败。 控制器控制表、通道控制表和系统设备表(1) 控制器控制表(COCT)。系统为每一个控制器都设置了一张用于记录本控制器情况的控制器控制表，如下图(a)所示。(2) 通道控制表(CHCT)。每个通道都配有一张通道控制表，如下图(b)所示。(3) 系统设备表(SDT)。这是系统范围的数据结构，其中记录了系统中全部设备的情况。每个设备占一个表目，其中包括有设备类型、设备标识符、设备控制表及设备驱动程序的入口等项，如上图(c)所示。设备分配时应考虑的因素为了使系统有条不紊地工作，系统在分配设备时，应考虑这样几个因素: ① 设备的固有属性； ② 设备分配算法； ③ 设备分配时的安全性； ④ 设备独立性。本小节介绍前三个问题，下一小节专门介绍设备独立性问题。 设备的固有属性在分配设备时，首先应考虑与设备分配有关的设备属性。设备的固有属性可分成三种: 第一种是独占性，独占性是指这种设备在一段时间内只允许一个进程独占，此即第二章所说的“临界资源”；对于独占设备，应采用独享分配策略，即将一个设备分配给某进程后，便由该进程独占，直至该进程完成或释放该设备，然后，系统才能再将该设备分配给其他进程使用。这种分配策略的缺点是，设备得不到充分利用，而且还可能引起死锁。 第二种是共享性，共享性指这种设备允许多个进程同时共享；对于共享设备，可同时分配给多个进程使用，此时须注意对这些进程访问该设备的先后次序进行合理的调度。 第三种是可虚拟设备，可虚拟设备指设备本身虽是独占设备，但经过某种技术处理，可以把它改造成虚拟设备。由于可虚拟设备是指一台物理设备在采用虚拟技术后，可变成多台逻辑上的所谓虚拟设备，因而说，一台可虚拟设备是可共享的设备，可以将它同时分配给多个进程使用，并对这些访问该(物理)设备的先后次序进行控制。 设备分配算法对设备进行分配的算法，与进程调度的算法有些相似之处，但前者相对简单，通常只采用以下两种分配算法：(1) 先来先服务。当有多个进程对同一设备提出 I/O 请求时，该算法是根据诸进程对某设备提出请求的先后次序，将这些进程排成一个设备请求队列，设备分配程序总是把设备首先分配给队首进程。(2) 优先级高者优先。在进程调度中的这种策略，是优先权高的进程优先获得处理机。如果对这种高优先权进程所提出的 I/O 请求也赋予高优先权，显然有助于这种进程尽快完成。在利用该算法形成设备队列时，将优先权高的进程排在设备队列前面，而对于优先级相同的 I/O 请求，则按先来先服务原则排队。 设备分配中的安全性从进程运行的安全性考虑，设备分配有以下两种方式。 1) 安全分配方式在这种分配方式中，每当进程发出 I/O 请求后，便进入阻塞状态，直到其 I/O 操作完成时才被唤醒。在采用这种分配策略时，一旦进程已经获得某种设备(资源)后便阻塞，使该进程不可能再请求任何资源，而在它运行时又不保持任何资源。因此，这种分配方式已经摒弃了造成死锁的四个必要条件之一的“请求和保持”条件，从而使设备分配是安全的。其缺点是进程进展缓慢，即 CPU 与 I/O 设备是串行工作的。 2) 不安全分配方式在这种分配方式中，进程在发出 I/O 请求后仍继续运行，需要时又发出第二个I/O请求、 第三个 I/O 请求等。仅当进程所请求的设备已被另一进程占用时，请求进程才进入阻塞状态。这种分配方式的优点是，一个进程可同时操作多个设备，使进程推进迅速。其缺点是分配不安全，因为它可能具备“请求和保持”条件，从而可能造成死锁。因此，在设备分配程序中，还应再增加一个功能，以用于对本次的设备分配是否会发生死锁进行安全性计算，仅当计算结果说明分配是安全的情况下才进行设备分配。独占设备的分配程序 基本的设备分配程序下面我们通过一个具有I/O通道的系统案例，来介绍设备分配过程。当某进程提出 I/O 请求后，系统的设备分配程序可按下述步骤进行设备分配。 1) 分配设备首先根据 I/O 请求中的物理设备名，查找系统设备表(SDT)，从中找出该设备的 DCT，再根据 DCT 中的设备状态字段，可知该设备是否正忙。若忙，便将请求 I/O 进程的 PCB 挂在设备队列上；否则，便按照一定的算法来计算本次设备分配的安全性。如果不会导致系统进入不安全状态，便将设备分配给请求进程；否则，仍将其 PCB 插入设备等待 队列。 2) 分配控制器在系统把设备分配给请求 I/O 的进程后，再到其 DCT 中找出与该设备连接的控制器的 COCT，从 COCT 的状态字段中可知该控制器是否忙碌。若忙，便将请求 I/O 进程的 PCB 挂在该控制器的等待队列上；否则，便将该控制器分配给进程。 3) 分配通道在该 COCT 中又可找到与该控制器连接的通道的 CHCT，再根据 CHCT 内的状态信息，可知该通道是否忙碌。若忙，便将请求 I/O 的进程挂在该通道的等待队列上；否则，将该通道分配给进程。只有在设备、 控制器和通道三者都分配成功时，这次的设备分配才算成功。然后，便可启动该 I/O 设备进行数据传送。 设备分配程序的改进仔细研究上述基本的设备分配程序后可以发现: ① 进程是以物理设备名来提出 I/O 请求的； ② 采用的是单通路的 I/O 系统结构，容易产生“瓶颈”现象。为此，应从以下两方面对基本的设备分配程序加以改进，以使独占设备的分配程序具有更强的灵活性，并提高分配的成功率。 1) 增加设备的独立性为了获得设备的独立性，进程应使用逻辑设备名请求 I/O。这样，系统首先从 SDT 中找出第一个该类设备的 DCT。若该设备忙，又查找第二个该类设备的 DCT，仅当所有该类设备都忙时，才把进程挂在该类设备的等待队列上；而只要有一个该类设备可用，系统便进一步计算分配该设备的安全性。 2) 考虑多通路情况为了防止在 I/O 系统中出现“瓶颈”现象，通常都采用多通路的 I/O 系统结构。此时对控制器和通道的分配同样要经过几次反复，即若设备(控制器)所连接的第一个控制器(通道)忙时，应查看其所连接的第二个控制器(通道)，仅当所有的控制器(通道)都忙时，此次的控制器(通道)分配才算失败，才把进程挂在控制器(通道)的等待队列上。而只要有一个控制器(通道)可用，系统便可将它分配给进程。SPOOLing 技术如前所述，虚拟性是 OS 的四大特征之一。如果说可以通过多道程序技术将一台物理 CPU 虚拟为多台逻辑 CPU，从而允许多个用户共享一台主机，那么，通过 SPOOLing 技术便可将一台物理 I/O 设备虚拟为多台逻辑 I/O 设备，同样允许多个用户共享一台物理 I/O 设备。 什么是SPOOLing为了缓和 CPU 的高速性与 I/O 设备低速性间的矛盾而引入了脱机输入、脱机输出技术。该技术是利用专门的外围控制机，将低速 I/O 设备上的数据传送到高速磁盘上；或者相反。事实上，当系统中引入了多道程序技术后，完全可以利用其中的一道程序，来模拟脱机输入时的外围控制机功能，把低速 I/O 设备上的数据传送到高速磁盘上；再用另一道程序来模拟脱机输出时外围控制机的功能，把数据从磁盘传送到低速输出设备上。这样，便可在主机的直接控制下，实现脱机输入、输出功能。此时的外围操作与CPU对数据的处理同时进行，我们把这种在联机情况下实现的同时外围操作称为 SPOOLing(Simultaneaus Periphernal Operating On Line)，或称为假脱机操作。 SPOOLing系统的组成由上所述得知，SPOOLing 技术是对脱机输入、输出系统的模拟。相应地，SPOOLing系统必须建立在具有多道程序功能的操作系统上，而且还应有高速随机外存的支持，这通常是采用磁盘存储技术。SPOOLing 系统主要有以下三部分：(1) 输入井和输出井。这是在磁盘上开辟的两个大存储空间。输入井是模拟脱机输入时的磁盘设备，用于暂存 I/O 设备输入的数据；输出井是模拟脱机输出时的磁盘，用于暂存用户程序的输出数据。(2) 输入缓冲区和输出缓冲区。为了缓和 CPU 和磁盘之间速度不匹配的矛盾，在内存中要开辟两个缓冲区：输入缓冲区和输出缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据，以后再传送给输出设备。(3) 输入进程 SPi 和输出进程 SPo。这里利用两个进程来模拟脱机 I/O 时的外围控制机。其中，进程 SPi 模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井，当 CPU 需要输入数据时，直接从输入井读入内存；进程 SPo 模拟脱机输出时的外围控制机，把用户要求输出的数据先从内存送到输出井，待输出设备空闲时，再将输出井中的数据经过输出缓冲区送到输出设备上。 共享打印机打印机是经常要用到的输出设备，属于独占设备。利用 SPOOLing 技术，可将之改造为一台可供多个用户共享的设备，从而提高设备的利用率，也方便了用户。共享打印机技术已被广泛地用于多用户系统和局域网络中。当用户进程请求打印输出时，SPOOLing 系统同意为它打印输出，但并不真正立即把打印机分配给该用户进程，而只为它做两件事 ： ①由输出进程在输出井中为之申请一个空闲磁盘块区，并将要打印的数据送入其中； ②输出进程再为用户进程申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到请求打印队列上。如果还有进程要求打印输出，系统仍可接受该请求，也同样为该进程做上述两件事。如果打印机空闲，输出进程将从请求打印队列的队首取出一张请求打印表，根据表中的要求将要打印的数据，从输出井传送到内存缓冲区，再由打印机进行打印。打印完后，输出进程再查看请求打印队列中是否还有等待打印的请求表。若有，又取出队列中的第一张表，并根据其中的要求进行打印，如此下去，直至请求打印队列为空，输出进程才将自己阻塞起来。仅当下次再有打印请求时，输出进程才被唤醒。 SPOOLing系统的特点SPOOLing系统具有如下主要特点：(1) 提高了 I/O 的速度。这里，对数据所进行的 I/O 操作，已从对低速 I/O 设备进行的 I/O 操作，演变为对输入井或输出井中数据的存取，如同脱机输入输出一样，提高了 I/O 速度，缓和了 CPU 与低速 I/O 设备之间速度不匹配的矛盾。(2) 将独占设备改造为共享设备。因为在 SPOOLing 系统中，实际上并没为任何进程分配设备，而只是在输入井或输出井中为进程分配一个存储区和建立一张I/O请求表。这样，便把独占设备改造为共享设备。(3) 实现了虚拟设备功能。宏观上，虽然是多个进程在同时使用一台独占设备，而对于每一个进程而言，他们都会认为自己是独占了一个设备。当然，该设备只是逻辑上的设备。SPOOLing 系统实现了将独占设备变换为若干台对应的逻辑设备的功能。磁盘存储器的管理磁盘存储器不仅容量大，存取速度快，而且可以实现随机存取，是当前存放大量程序和数据的理想设备，故在现代计算机系统中，都配置了磁盘存储器，并以它为主来存放文件。这样，对文件的操作，都将涉及到对磁盘的访问。磁盘I/O速度的高低和磁盘系统的可靠性，都将直接影响到系统性能。因此，设法改善磁盘系统的性能，已成为现代操作系统的重要任务之一。磁盘性能概述磁盘设备是一种相当复杂的机电设备。 数据的组织和格式一个物理记录存储在一个扇区上，磁盘上存储的物理记录块数目是由扇区数、磁道数以及磁盘面数所决定的。为了提高磁盘的存储容量，充分利用磁盘外面磁道的存储能力，现代磁盘不再把内外磁道划分为相同数目的扇区，而是利用外层磁道容量较内层磁道大的特点，将盘面划分成若干条环带，使得同一环带内的所有磁道具有相同的扇区数。显然，外层环带的磁道拥有较内层环带的磁道更多的扇区。为了减少这种磁道和扇区在盘面分布的几何形式变化对驱动程序的影响，大多数现代磁盘都隐藏了这些细节，向操作系统提供虚拟几何的磁盘规格，而不是实际的物理几何规格。磁盘格式化：为了在磁盘上存储数据，必须先将磁盘低级格式化。下图示出了一种温盘(温切斯特盘)中一条磁道格式化的情况。每个扇区包括两个字段：(1) 标识符字段，其中一个字节的 SYNCH 具有特定的位图像，作为该字段的定界符，利用磁道号、 磁头号及扇区号三者来标识一个扇区；CRC 字段用于段校验。(2) 数据字段，其中可存放 512 个字节的数据。格式化还对性能产生影响。上一次数据传送完之后，要通过计算等才能继续进行下一块数据的传送，此期间磁头将继续旋转，可能将越过相邻的下一个数据块，如果要读取该块数据，只能等到转一圈再回来。通过在格式化磁盘时以交错方式对扇区进行编号可以消除这一问题。如下图：磁盘格式化完成后，一般要对磁盘分区。在逻辑上，每个分区就是一个独立的逻辑磁盘。每个分区的起始扇区和大小都记录在磁盘 0 扇区的主引导记录分区表所包含的分区表中。在这个分区表中必须有一个分区被标记成活动的，以保证能够从硬盘引导系统。 但是，在真正可以使用磁盘前，还需要对磁盘进行一次高级格式化，即设置一个引导块、空闲存储管理、根目录和一个空文件系统，同时在分区表中标记该分区所使用的文件系统。 磁盘的类型对磁盘，可以从不同的角度进行分类。最常见的有：将磁盘分成硬盘和软盘、单片盘和多片盘、固定头磁盘和活动头(移动头)磁盘等。下面仅对固定头磁盘和移动头磁盘做些介绍。 1) 固定头磁盘这种磁盘在每条磁道上都有一读/写磁头，所有的磁头都被装在一刚性磁臂中。通过这些磁头可访问所有各磁道，并进行并行读/写，有效地提高了磁盘的 I/O 速度。这种结构的磁盘主要用于大容量磁盘上。 2) 移动头磁盘每一个盘面仅配有一个磁头，也被装入磁臂中。为能访问该盘面上的所有磁道，该磁头必须能移动以进行寻道。可见，移动磁头仅能以串行方式读/写，致使其 I/O 速度较慢；但由于其结构简单，故仍广泛应用于中小型磁盘设备中。在微型机上配置的温盘和软盘都采用移动磁头结构，故本节主要针对这类磁盘的 I/O 进行讨论。磁盘访问时间磁盘设备在工作时以恒定速率旋转。为了读或写，磁头必须能移动到所要求的磁道上，并等待所要求的扇区的开始位置旋转到磁头下，然后再开始读或写数据。故可把对磁盘的访问时间分成以下三部分。 1）寻道时间 Ts这是指把磁臂(磁头)移动到指定磁道上所经历的时间。该时间是启动磁臂的时间 s 与磁头移动n条磁道所花费的时间之和，即Ts = m ×n + s其中，m 是一常数，与磁盘驱动器的速度有关。磁臂的启动时间约为 2 ms。这样，对于一般的温盘，其寻道时间将随寻道距离的增加而增大，大体上是 5～30 ms。 2) 旋转延迟时间 Tr这是指定扇区移动到磁头下面所经历的时间。不同的磁盘类型中，旋转速度至少相差一个数量级。 3) 传输时间 Tt这是指把数据从磁盘读出或向磁盘写入数据所经历的时间。在访问时间中，寻道时间和旋转延迟时间基本上都与所读/写数据的多少无关，而且它通常占据了访问时间中的大头。适当地集中数据(不要太零散)传输，将有利于提高传输效率。坏扇区的处理制道时的瑕疵引入坏扇区，也就是说，扇区不能正确地读回写到其上的值。如果瑕疵非常小，比如说只有几位，那么使用坏扇区并且每次只是让 ECC 矫正错误是可能的。如果瑕疵较大，那么错误就不能被掩盖。对于坏块存在两种一般的处理方法：在控制器中对它们进行处理或者在操作系统中对它们进行处理。在前一种方法中，磁盘在从工厂出厂之前要进行测试，并且将一个坏扇区列表写在磁盘上。对于每个坏扇区，用一个备用扇区替换它。有两种方法进行这样的替换： 控制器对坏扇区进行重映射到一个备用的好扇区； 另一种方法是将所有扇区向上移动一个扇区。在这两种情况下，控制器都必须知道哪个扇区是坏扇区。它可以通过内部的表来跟踪这一信息（每个磁道一张表），或者通过重写前导码来给出重映射的扇区号。如果是重写前导码，将会移动所有扇区以回避坏扇区。稳定存储器磁盘调度磁盘是可供多个进程共享的设备，当有多个进程都要求访问磁盘时，应采用一种最佳调度算法，以使各进程对磁盘的平均访问时间最小。由于在访问磁盘的时间中，主要是寻道时间，因此，磁盘调度的目标是使磁盘的平均寻道时间最少。目前常用的磁盘调度算法有先来先服务、最短寻道时间优先及扫描等算法。下面逐一介绍。先来先服务这是一种最简单的磁盘调度算法。它根据进程请求访问磁盘的先后次序进行调度。此算法的优点是公平、简单，且每个进程的请求都能依次地得到处理，不会出现某一进程的请求长期得不到满足的情况。但此算法由于未对寻道进行优化，致使平均寻道时间可能较长。FCFS 算法仅适用于请求磁盘 I/O 的进程数目较少（这样优化的余地本来就很少了）的场合。最短寻道时间优先该算法选择这样的进程：其要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短。但这种算法不能保证平均寻道时间最短。SSTF 算法的平均每次磁头移动距离明显低于 FCFS 的距离，因而 SSTF 较之 FCFS 有更好的寻道性能，故过去曾一度被广泛采用。不过该方法存在一个问题：局部的（不论什么时候到达该区域）集中访问，远离该部分（即使先来的，而且等待了很久）长久得不到访问。扫描(SCAN)算法SSTF 算法虽然能获得较好的寻道性能，但却可能导致某个进程发生“饥饿”(Starvation)现象。因为只要不断有新进程的请求到达，且其所要访问的磁道与磁头当前所在磁道的距离较近，这种新进程的I/O请求必然优先满足。对 SSTF算法略加修改后所形成的 SCAN 算法，即可防止老进程出现“饥饿”现象。 SCAN 算法：该算法不仅考虑到欲访问的磁道与当前磁道间的距离，更优先考虑的是磁头当前的移动方向。 由于在这种算法中磁头移动的规律颇似电梯的运行，因而又常称之为电梯调度算法。循环扫描(CSCAN)算法SCAN 算法既能获得较好的寻道性能，又能防止“饥饿”现象，故被广泛用于大、中、小型机器和网络中的磁盘调度。但 SCAN 也存在这样的问题：当磁头刚从里向外移动而越过了某一磁道时，恰好又有一进程请求访问此磁道，这时，该进程必须等待，待磁头继续从里向外，然后再从外向里扫描完所有要访问的磁道后，才处理该进程的请求，致使该进程的请求被大大地推迟。为了减少这种延迟，CSCAN 算法规定磁头单向移动，NStepSCAN 和 FSCAN 调度算法 NStepSCAN 算法在 SSTF、SCAN 及 CSCAN 几种调度算法中，都可能会出现磁臂停留在某处不动的情况，例如，有一个或几个进程对某一磁道有较高的访问频率，即这个(些)进程反复请求对某一磁道的 I/O 操作，从而垄断了整个磁盘设备。我们把这一现象称为“磁臂粘着”(Armstickiness)。在高密度磁盘上容易出现此情况。N步SCAN 算法是将磁盘请求队列分成若干个长度为 N 的子队列，磁盘调度将按 FCFS 算法依次处理这些子队列。而每处理一个队列时又是按 SCAN 算法，对一个队列处理完后，再处理其他队列。当正在处理某子队列时，如果又出现新的磁盘 I/O 请求，便将新请求进程放入其他队列，这样就可避免出现粘着现象。 当 N 值取得很大时，会使 N 步扫描法的性能接近于 SCAN 算法的性能； 当 N=1 时，N 步 SCAN 算法便蜕化为 FCFS 算法。 FSCAN算法FSCAN 算法实质上是 N 步 SCAN 算法的简化，即 FSCAN 只将磁盘请求队列分成两个子队列。一个是由当前所有请求磁盘 I/O 的进程形成的队列，由磁盘调度按 SCAN 算法进行处理。在扫描期间，将新出现的所有请求磁盘 I/O 的进程，放入另一个等待处理的请求队列。这样，所有的新请求都将被推迟到下一次扫描时处理。磁盘 I/O 速度的提高目前，磁盘的 I/O 速度远低于对内存的访问速度，通常要低上 4～6 个数量级。因此，磁盘的 I/O 已成为计算机系统的瓶颈。于是，人们便千方百计地去提高磁盘 I/O 的速度，其中最主要的技术便是采用磁盘高速缓存(Disk Cache)。磁盘高速缓存这里所说的磁盘高速缓存，并非通常意义下的内存和CPU之间所增设的一个小容量高速存储器，而是指利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。因此，这里的高速缓存是一组在逻辑上属于磁盘，而物理上是驻留在内存中的盘块。高速缓存在内存中可分成两种形式: 第一种是在内存中开辟一个单独的存储空间来作为磁盘高速缓存，其大小是固定的，不会受应用程序多少的影响； 第二种是把所有未利用的内存空间变为一个缓冲池，供请求分页系统和磁盘I/O时(作为磁盘高速缓存)共享。此时，高速缓存的大小显然不再是固定的。当磁盘I/O的频繁程度较高时，该缓冲池可能包含更多的内存空间；而在应用程序运行得较多时，该缓冲池可能只剩下较少的内存空间。 数据交付方式数据交付(Data Delivery)是指将磁盘高速缓存中的数据传送给请求者进程。当有一进程请求访问某个盘块中的数据时，由核心先去查看磁盘高速缓冲器，看其中是否存在进程所需访问的盘块数据的拷贝。若有其拷贝，便直接从高速缓存中提取数据交付给请求者进程，这样，就避免了访盘操作，从而使本次访问速度提高4～6个数量级；否则，应先从磁盘中将所要访问的数据读入并交付给请求者进程，同时也将数据送高速缓存。当以后又需要访问该盘块的数据时，便可直接从高速缓存中提取。系统可以采取两种方式将数据交付给请求进程： (1) 数据交付。这是直接将高速缓存中的数据，传送到请求者进程的内存工作区中。 (2) 指针交付。这是只将指向高速缓存中某区域的指针交付给请求者进程。后一种方式由于所传送的数据量少，因而节省了数据从磁盘高速缓存到进程的内存工作区的时间。 置换算法如同请求调页(段)一样，在将磁盘中的盘块数据读入高速缓存时，同样会出现因高速缓存中已装满盘块数据而需要将该数据先换出的问题。相应地，也必然存在着采用哪种置换算法的问题。较常用的置换算法仍然是最近最久未使用算法 LRU、最近未使用算法 NRU 及最少使用算法 LFU 等。由于请求调页中的联想存储器与高速缓存(磁盘I/O中)的工作情况不同，因而使得在置换算法中所应考虑的问题也有所差异。因此，现在不少系统在设计其高速缓存的置换算法时，除了考虑到最近最久未使用这一原则外，还考虑了以下几点： 1) 访问频率通常，每执行一条指令时，便可能访问一次联想存储器，亦即联想存储器的访问频率，基本上与指令执行的频率相当。而对高速缓存的访问频率，则与磁盘I/O的频率相当。因此 ，对联想存储器的访问频率远远高于对高速缓存的访问频率。 2) 可预见性在高速缓存中的各盘块数据，有哪些数据可能在较长时间内不会再被访问，又有哪些数据可能很快就再被访问，会有相当一部分是可预知的。例如，对二次地址及目录块等，在它被访问后，可能会很久都不再被访问。又如，正在写入数据的未满盘块，可能会很快又被访问。 3) 数据的一致性由于高速缓存是做在内存中的，而内存一般又是一种易失性的存储器，一旦系统发生故障，存放在高速缓存中的数据将会丢失；而其中有些盘块(如索引结点盘块)中的数据已被修改，但尚未拷回磁盘，因此，当系统发生故障后，可能会造成数据的不一致性。基于上述考虑，在有的系统中便将高速缓存中的所有盘块数据拉成一条LRU链。对于那些会严重影响到数据一致性的盘块数据和很久都可能不再使用的盘块数据，都放在 LRU链的头部，使它们能被优先写回磁盘，以减少发生数据不一致性的概率，或者可以尽早地腾出高速缓存的空间。对于那些可能在不久之后便要再使用的盘块数据，应挂在 LRU链的尾部，以便在不久以后需要时，只要该数据块尚未从链中移至链首而被写回磁盘，便可直接到高速缓存中(即LRU链中)去找到它们。 周期性地写回磁盘还有一种情况值得注意: 那就是根据 LRU 算法，那些经常要被访问的盘块数据，可能会一直保留在高速缓存中，长期不会被写回磁盘。(注意，LRU 链意味着链中任一元素在被访问之后，总是又被挂到链尾而不被写回磁盘；只是一直未被访问的元素，才有可能移到链首，而被写回磁盘。)例如，一位学者一上班便开始撰写论文，并边写边修改，他正在写作的论文就一直保存在高速缓存的LRU链中。如果在快下班时，系统突然发生故障，这样，存放在高速缓存中的已写论文将随之消失，致使他枉费了一天的劳动。为了解决这一问题，在 UNIX 系统中专门增设了一个修改(update)程序，使之在后台运行，该程序周期性地调用一个系统调用 SYNC。该调用的主要功能是强制性地将所有在高速缓存中已修改的盘块数据写回磁盘。一般是把两次调用SYNC的时间间隔定为30 s。这样，因系统故障所造成的工作损失不会超过30 s的劳动量。而在MS-DOS中所采用的方法是: 只要高速缓存中的某盘块数据被修改，便立即将它写回磁盘，并将这种高速缓存称为“写穿透、高速缓存”(write-through cache)。MS-DOS所采用的写回方式，几乎不会造成数据的丢失，但须频繁地启动磁盘。提高磁盘I/O速度的其它方法在系统中设置了磁盘高速缓存后，能显著地减少等待磁盘I/O的时间。本小节再介绍几种能有效地提高磁盘I/O速度的方法，这些方法已被许多系统采用。 提前读(Read-ahead)用户(进程)对文件进行访问时，经常采用顺序访问方式，即顺序地访问文件各盘块的数据。在这种情况下，在读当前块时可以预知下一次要读的盘块。因此，可以采取预先读方式，即在读当前块的同时，还要求将下一个盘块(提前读的块)中的数据也读入缓冲区。这样，当下一次要读该盘块中的数据时，由于该数据已被提前读入缓冲区，因而此时便可直接从缓冲区中取得下一盘块的数据，而不需再去启动磁盘I/O，从而大大减少了读数据的时间。这也就等效于提高了磁盘 I/O 的速度。“提前读”功 能 已 被广泛采用，如在UNIX系统、OS/2，以及在 3 Plus和Netware等的网络 OS 中，都已采用该功能。 延迟写延迟写是指在缓冲区A中的数据，本应立即写回磁盘，但考虑到该缓冲区中的数据在不久之后可能还会再被本进程或其它进程访问(共享资源)，因而并不立即将该缓冲区 A 中的数据写入磁盘，而是将它挂在空闲缓冲区队列的末尾。随着空闲缓冲区的使用，缓冲区也缓缓往前移动，直至移到空闲缓冲队列之首。当再有进程申请到该缓冲区时，才将该缓冲区中的数据写入磁盘，而把该缓冲区作为空闲缓冲区分配出去。当该缓冲区A仍在队列中时，任何访问该数据的进程，都可直接读出其中的数据而不必去访问磁盘。这样，又可进一步减小等效的磁盘I/O时间。同样，“延迟写”功能已在UNIX系统、OS/2等OS中被广泛采用。 优化物理块的分布另一种提高磁盘 I/O 速度的重要措施是优化文件物理块的分布，使磁头的移动距离最小。虽然链接分配和索引分配方式都允许将一个文件的物理块分散在磁盘的任意位置，但如果将一个文件的多个物理块安排得过于分散，会增加磁头的移动距离。例如，将文件的第一个盘块安排在最里的一条磁道上，而把第二个盘块安排在最外的一条磁道上，这样，在读完第一个盘块后转去读第二个盘块时，磁头要从最里的磁道移到最外的磁道上。如果我们将这两个数据块安排在属于同一条磁道的两个盘块上，显然会由于消除了磁头在磁道间的移动，而大大提高对这两个盘块的访问速度。对文件盘块位置的优化，应在为文件分配盘块时进行。如果系统中的空白存储空间是采用位示图方式表示的，则要将同属于一个文件的盘块安排在同一条磁道上或相邻的磁道上是十分容易的事。这时，只要从位示图中找到一片相邻接的多个空闲盘块即可。但当系统采用线性表(链)法来组织空闲存储空间时，要为一文件分配多个相邻接的盘块，就要困难一些。此时，我们可以将在同一条磁道上的若干个盘块组成一簇，例如，一簇包括 4 个盘块，在分配存储空间时，以簇为单位进行分配。这样就可以保证在访问这几个盘块时，不必移动磁头或者仅移动一条磁道的距离，从而减少了磁头的平均移动距离。 虚拟盘所谓虚拟盘，是指利用内存空间去仿真磁盘，又称为RAM盘。该盘的设备驱动程序也可以接受所有标准的磁盘操作，但这些操作的执行，不是在磁盘上而是在内存中。这些对用户都是透明的。换言之，用户并不会发现这与真正的磁盘操作有什么不同，而仅仅是略微快些而已。虚拟盘的主要问题是：它是易失性存储器，故一旦系统或电源发生故障，或系统再启动时，原来保存在虚拟盘中的数据将会丢失。因此，虚拟盘通常用于存放临时文件，如编译程序所产生的目标程序等。虚拟盘与磁盘高速缓存的主要区别在于: 虚拟盘中的内容完全由用户控制，而高速磁盘缓存中的内容则是由 OS控制的。例如，RAM 盘在开始时是空的，仅当用户(程序)在RAM盘中创建了文件后，RAM盘中才有内容。廉价磁盘冗余阵列廉价磁盘冗余阵列(RAID，Redundant Array of Inexpensive Disk),它是利用一台磁盘阵列控制器，来统一管理和控制一组(几台到几十台)磁盘驱动器，组成一个高度可靠的、快速的大容量磁盘系统。 并行交叉存取为了提高对磁盘的访问速度，已把在大、中型机中应用的交叉存取(Interleave)技术应用到了磁盘存储系统中。在该系统中，有多台磁盘驱动器，系统将每一盘块中的数据分为若干个子盘块数据，再把每一个子盘块的数据分别存储到各个不同磁盘中的相同位置上。在以后，当要将一个盘块的数据传送到内存时，采取并行传输方式，将各个盘块中的子盘块数据同时向内存中传输，从而使传输时间大大减少。例如，在存放一个文件时，可将该文件中的第一个数据子块放在第一个磁盘驱动器上；将文件的第二个数据子块放在第二个磁盘上；……；将第 N 个数据子块，放在第N个驱动器上。以后在读取数据时，采取并行读取方式，即同时从第1～N个数据子块读出数据，这样便把磁盘I/O的速度提高了 N-1 倍。 RAID的分级RAID 在刚被推出时，是分成 6 级的，即 RAID 0 级至 RAID 5 级，后来又增加了 RAID 6级和 RAID 7 级。(1) RAID 0级。本级仅提供了并行交叉存取。它虽能有效地提高磁盘 I/O 速度，但并无冗余校验功能，致使磁盘系统的可靠性不好。只要阵列中有一个磁盘损坏，便会造成不可弥补的数据丢失，故较少使用。(2) RAID 1级。它具有磁盘镜像功能，例如，当磁盘阵列中具有8个盘时，可利用其中4个作为数据盘，另外 4 个作为镜像盘，在每次访问磁盘时，可利用并行读、写特性，将数据分块同时写入主盘和镜像盘。故其比传统的镜像盘速度快，但其磁盘容量的利用率只有50%，它是以牺牲磁盘容量为代价的。(3) RAID 3级。这是具有并行传输功能的磁盘阵列。它利用一台奇偶校验盘来完成数据的校验功能，比起磁盘镜像，它减少了所需要的冗余磁盘数。例如，当阵列中只有 7 个盘时，可利用 6 个盘作数据盘，一个盘作校验盘。磁盘的利用率为 6/7。RAID 3 级经常用于科学计算和图像处理。(4) RAID 5级。这是一种具有独立传送功能的磁盘阵列。每个驱动器都各有自己独立的数据通路，独立地进行读/写，且无专门的校验盘。用来进行纠错的校验信息，是以螺旋(Spiral)方式散布在所有数据盘上。RAID 5级常用于 I/O 较频繁的事务处理中。(5) RAID 6 级和 RAID 7级。这是强化了的RAID。在RAID 6级的阵列中，设置了一个专用的、可快速访问的异步校验盘。该盘具有独立的数据访问通路，具有比 RAID 3级及 RAID 5级更好的性能，但其性能改进得很有限，且价格昂贵。RAID 7 级是对 RAID 6 级的改进，在该阵列中的所有磁盘，都具有较高的传输速率和优异的性能，是目前最高档次的磁盘阵列，但其价格也较高。 RAID的优点RAID 自 1988 年问世后，便引起了人们的普遍关注，并很快地流行起来。这主要是因为 RAID 具有下述一系列明显的优点:(1) 可靠性高。RAID 最大的特点就是它的高可靠性。除了 RAID 0级外，其余各级都采用了容错技术。当阵列中某一磁盘损坏时，并不会造成数据的丢失，因为它既可实现磁盘镜像，又可实现磁盘双工，还可实现其它的冗余方式。所以此时可根据其它未损坏磁盘中的信息，来恢复已损坏的盘中的信息。它与单台磁盘机相比，其可靠性高出了一个数量级。(2) 磁盘 I/O 速度高。由于磁盘阵列可采取并行交叉存取方式，故可将磁盘 I/O 速度提高 N-1 倍(N 为磁盘数目)。或者说，磁盘阵列可将磁盘 I/O 速度提高数倍至数十倍。(3) 性能/价格比高。利用 RAID 技术来实现大容量高速存储器时，其体积与具有相同容量和速度的大型磁盘系统相比，只是后者的 1/3，价格也只是后者的 1/3，且可靠性高。换言之，它仅以牺牲 1/N 的容量为代价，换取了高可靠性；而不像磁盘镜像及磁盘双工那样，须付出 50% 容量的代价。文件管理文件系统是操作系统中负责存取和管理信息的模块，它采用统一方法管理用户信息和系统信息的存储、检索、更新、共享和保护，并为用户提供一整套行之有效的文件使用及操作方法。“文件”这一术语不但反映用户概念中的逻辑结构，而且同存放它的辅助存储器的存储结构紧密相关。所以，必须从逻辑文件和物理文件两个侧面来观察文件。 对于用户而言，可按照需要并遵循文件系统的规则来定义文件信息的逻辑结构，由文件系统提供“按名存取”方式来实现对文件信息的存储和检索； 对于系统而言，必须采用特定的数据结构和有效算法，实现文件的逻辑结构到存储结构的映射，实现对文件存储空间和文件信息的管理，提供多种存取方法。 例如，用户希望与具体的存储硬件无关，使用路径名、文件名、文件内位移就可以执行数据的读、写、修改、删除操作；而作为实现这些功能的文件系统来说，其工作与存储硬件紧密相关，是将用户的文件操作请求转化为对磁盘上的信息按照所在的物理位置进行寻址、读写和控制。所以，文件系统的功能就是在逻辑文件和物理文件、逻辑地址与物理地址、逻辑结构与物理结构之间实现转换，使得存取速度快、存储空间利用率高、数据可共享、安全可靠性好。文件系统的主要功能有： 文件的按名存取，实现从逻辑文件到物理文件的转换； 文件目录的建立和维护； 文件的查找和定位； 文件存储空间的分配和管理； 提供文件的存取方法和文件存储结构； 实现文件的共享、保护和保密； 提供一组易用的文件操作和命令； 提供与设备管理交互的统一接口。文件文件是记录在外存上的相关信息的具有名称的集合。从用户角度而言，文件是逻辑外存的最小分配单元，即数据除非在文件中，否则不能写到外存。通常，文件表示程序（源形式和目标形式）和数据。数据文件可以是数字、字符、字符数字或二进制。文件可以是自由形式，如文本文件，也可以具有严格的格式。通常，文件由位、字节、行或记录组成，其具体意义是由文件创建者和使用者来定义的。因此，文件的概念几位广泛。文件应具有自己的属性，属性可以包括： 文件基本属相：文件名称和扩展名、文件属主 ID、文件所属组 ID 等 文件类型：可以从不同的角度来规定文件的类型，如源文件、目标文件及可执行文件等。 文件保护属性：规定谁能够访问文件，以何种方式（读、写、执行、更新、删除等）访问。 文件管理属性：如文件创建时间、最后访问时间、最后修改时间等。 文件控制信息：逻辑记录长、文件当前长、文件最大长、关键字位置、关键字长度、信息位置、文件打开次数等。。文件概述文件是进程创建的信息逻辑单元。文件不仅仅被用来对磁盘建模，以替代对随机存储器的建模，事实上，如果能把每个文件看成一种地址空间，那么就离理解文件的本质不远了。进程可以读取已经存在的文件，并在需要时建立新的文件。存储在文件中的信息必须是持久的，也就是说，不会因为进程的创建与终止受到影响。一个文件应只在其所有者明确删除它的情况下才会消失。文件是由文件名锁标识的一组信息的集合，文件名是字母或数字组成的字母数字串，其格式和长度因系统而异。文件信息是由其创建者定义的。文件可存储许多不同类型的信息：源程序、目标程序、可执行程序、数字数据、文本、工资记录、图像、声音记录等。文件根据其类型具有一定结构。文本文件是由行（或页）组成，而行（或页）是由字符组成的。源文件由子程序和函数组成。而他们有事由声明和执行语句组成的。目标文件是一系列字节序列，它们按目标系统链接器所能理解的方式组成。可执行文件为一系列代码段，以供装入程序调入内存执行。操作系统提供文件系统后，应具备以下功能： 首先，便于用户使用，无需记住信息存放在辅存中的物理位置，无需考虑如何将信息存放到介质上，只要知道文件名，给出有关的操作要求便可访问，实现了“按名存取”。特别地，当文件存放位置发生改变，甚至更换文件的存储设备，对使用者也不会产生丝毫影响； 其次，文件安全可靠，由于用户通过文件系统才能实现对文件的访问，而系统能提供各种安全、保密和保护措施，可防止对文件信息的有意或无意的破坏或窃用。 此外，系统能有效地利用存储空间，优化安排不同属主文件的位置；如果在文件使用过程中出现设备故障，系统可组织充执或回复，对于因硬件失效而可能造成的信息破坏，可组织转储以加强可靠性。 最后，文件系统还能提供文件共享功能，不同的用户可使用同名或异名的同一个文件，这样，合理利用文件存储空间，缩短传输信息的交换时间，提高文件空间的利用率。 文件命名文件是一种抽象机制。这种抽象性体现在，用户不必去关心具体的实现细节。对于任何一种抽象机制来说，可能最重要的特性是对管理对象的命名方式。当进程创建一个文件时，必须给它指定一个名字；当进程终止时，这个文件继续存在，别的进程可以通过它的名字来访问它。文件的具体命名规则并无统一的标准，不同的系统可能会有不同的要求。许多操作系统支持两部分组成的文件名。两部分之间用句点隔开，在句点后面的部分称为文件扩展名，它通常给出了与文件类型有关的一些信息。在有些系统中，文件扩展名仅仅是一种惯例，并不强迫使用。文件类型为了便于管理和控制文件而将文件分成若干种类型。由于不同系统对文件的管理方式不同，因而它们对文件的分类方法也有很大差异。为了方便系统和用户了解文件的类型，在许多OS中都把文件类型作为扩展名而缀在文件名的后面，在文件名和扩展名之间用“.”号隔开。下面是常用的几种文件分类方法。 按用途分类根据文件的性质和用途的不同，可将文件分为三类: (1) 系统文件。这是指由系统软件构成的文件。大多数的系统文件只允许用户调用，但不允许用户去读，更不允许修改；有的系统文件不直接对用户开放。 (2) 用户文件。指由用户的源代码、目标文件、可执行文件或数据等所构成的文件。用户将这些文件委托给系统保管。 (3) 库文件。这是由标准子例程及常用的例程等所构成的文件。这类文件允许用户调用，但不允许修改。 按文件中数据的形式分类按这种方式分类，也可把文件分为三类： (1) 源文件。这是指由源程序和数据构成的文件。通常由终端或输入设备输入的源程序和数据所形成的文件都属于源文件。它通常是由ASCII码或汉字所组成的。 (2) 目标文件。这是指把源程序经过相应语言的编译程序编译过，但尚未经过链接程序链接的目标代码所构成的文件。它属于二进制文件。通常，目标文件所使用的后缀名是“.obj”。 (3) 可执行文件。这是指把编译后所产生的目标代码再经过链接程序链接后所形成的文件。 按存取控制属性分类根据系统管理员或用户所规定的存取控制属性，可将文件分为三类： (1) 只执行文件。该类文件只允许被核准的用户调用执行，既不允许读，更不允许写。 (2) 只读文件。该类文件只允许文件主及被核准的用户去读，但不允许写。 (3) 读写文件。这是指允许文件主和被核准的用户去读或写的文件。 按组织形式和处理方式分类根据文件的组织形式和系统对其的处理方式，可将文件分为三类： (1) 普通文件：由 ASCII 码或二进制码组成的字符文件。一般用户建立的源程序文件、数据文件、目标代码文件及操作系统自身代码文件、库文件、实用程序文件等都是普通文件，它们通常存储在外存储设备上。 (2) 目录文件：由文件目录组成的，用来管理和实现文件系统功能的系统文件，通过目录文件可以对其它文件的信息进行检索。由于目录文件也是由字符序列构成，因此对其可进行与普通文件一样的种种文件操作。 (3) 特殊文件：特殊文件特指系统中的各类 I/O 设备。为了便于统一管理，系统将所有的 输入/输出设备都视为文件，按文件方式提供给用户使用，如目录的检索、权限的验证等都与普通文件相似，只是对这些文件的操作是和设备驱动程序紧密相连的，系统将这些操作转为对具体设备的操作。根据设备数据交换单位的不同，又可将特殊文件分为块设备文件和字符设备文件。前者用于磁盘、光盘或磁带等块设备的 I/O 操作，而后者用于终端、打印机等字符设备的 I/O 操作。文件操作用户通过文件系统所提供的系统调用实施对文件的操作。最基本的文件操作有: 创建文件、删除文件、读文件、写文件、截断文件和设置文件的读/写位置。但对于一个实际的OS，为了方便用户使用文件而提供了更多的对文件的操作，如打开和关闭一个文件及改变文件名等操作。 最基本的文件操作(1) 创建文件。在创建一个新文件时，系统首先要为新文件分配必要的外存空间，并在文件系统的目录中，为之建立一个目录项。目录项中应记录新文件的文件名及其在外存的地址等属性。(2) 删除文件。当已不再需要某文件时，可将它从文件系统中删除。在删除时，系统应先从目录中找到要删除文件的目录项，使之成为空项，然后回收该文件所占用的存储空间。(3) 读文件。在读一个文件时，须在相应系统调用中给出文件名和应读入的内存目标地址。此时，系统同样要查找目录，找到指定的目录项，从中得到被读文件在外存中的位置。在目录项中，还有一个指针用于对文件的读/写。(4) 写文件。在写一个文件时，须在相应系统调用中给出该文件名及该文件在内存中的(源)地址。为此，也同样须先查找目录，找到指定文件的目录项，再利用目录中的写指针进行写操作。(5) 截断文件。如果一个文件的内容已经陈旧而需要全部更新时，一种方法是将此文件删除，再重新创建一个新文件。但如果文件名及其属性均无改变时，则可采取另一种所谓的截断文件的方法，此即将原有文件的长度设置为0，或者说是放弃原有的文件内容。(6) 设置文件的读/写位置。前述的文件读/写操作都只提供了对文件顺序存取的手段，即每次都是从文件的始端读或写。设置文件读/写位置的操作，用于设置文件读/写指针的位置，以便每次读/写文件时，不是从其始端而是从所设置的位置开始操作。也正因如此，才能改顺序存取为随机存取。 文件的“打开”和“关闭”操作所谓“打开”，是指系统将指名文件的属性(包括该文件在外存上的物理位置)从外存拷贝到内存打开文件表的一个表目中，并将该表目的编号(或称为索引)返回给用户。以后，当用户再要求对该文件进行相应的操作时，便可利用系统所返回的索引号向系统提出操作请求。系统这时便可直接利用该索引号到打开文件表中去查找，从而避免了对该文件的再次检索。这样不仅节省了大量的检索开销，也显著地提高了对文件的操作速度。如果用户已不再需要对该文件实施相应的操作时，可利用“关闭”(close)系统调用来关闭此文件，OS将会把该文件从打开文件表中的表目上删除掉。 其他文件操作为了方便用户使用文件，通常，OS都提供了数条有关文件操作的系统调用，可将这些调用分成若干类:最常用的一类是有关对文件属性进行操作的，即允许用户直接设置和获得文件的属性，如改变已存文件的文件名、改变文件的拥有者(文件主)、改变对文件的访问权，以及查询文件的状态(包括文件类型、大小和拥有者以及对文件的访问权等)；另一类是有关目录的，如创建一个目录，删除一个目录，改变当前目录和工作目录等；此外，还有用于实现文件共享的系统调用和用于对文件系统进行操作的系统调用等。值得说明的是，有许多文件操作都可以利用上述基本操作加以组合来实现。例如，创建一个文件拷贝的操作，可利用两条基本操作来实现。其第一步是利用创建文件的系统调用来创建一个新文件；第二步是将原有文件中的内容写入新文件中。文件的逻辑结构通常，文件是由一系列的记录组成的。文件系统设计的关键要素，是指将这些记录构成一个文件的方法，以及将一个文件存储到外存上的方法。事实上，对于任何一个文件，都存在着以下两种形式的结构:(1) 文件的逻辑结构(File Logical Structure)。这是从用户观点出发所观察到的文件组织形式，是 用 户 可以直接处理的数据及其结构，它独立于文件的物理特性，又称为文件组织(File Organization)。(2) 文件的物理结构，又称为文件的存储结构，是指文件在外存上的存储组织形式。这不仅与存储介质的存储性能有关，而且与所采用的外存分配方式有关。无论是文件的逻辑结构，还是其物理结构，都会影响对文件的检索速度。对文件逻辑结构所提出的基本要求，首先是能提高检索速度，即在将大批记录组成文件时，应有利于提高检索记录的速度和效率；其次是便于修改，即便于在文件中增加、删除和修改一个或多个记录；第三是降低文件的存储费用，即减少文件占用的存储空间，不要求大片的连续存储空间。文件逻辑结构的类型文件的逻辑结构可分为两大类，一类是有结构文件，这是指由一个以上的记录构成的文件，故又把它称为记录式文件；其二是无结构文件，这是指由字符流构成的文件，故又称为流式文件。 有结构文件在记录式文件中，每个记录都用于描述实体集中的一个实体，各记录有着相同或不同数目的数据项。记录的长度可分为定长和不定长两类。(1) 定长记录。这是指文件中所有记录的长度都是相同的，所有记录中的各数据项都处在记录中相同的位置，具有相同的顺序和长度。文件的长度用记录数目表示。对定长记录的处理方便、开销小，所以这是目前较常用的一种记录格式，被广泛用于数据处理中。(2) 变长记录。这是指文件中各记录的长度不相同。产生变长记录的原因，可能是由于一个记录中所包含的数据项数目并不相同，也可能是数据项本身的长度不定.不论是哪一种，在处理前，每个记录的长度是可知的。根据用户和系统管理上的需要，可采用多种方式来组织这些记录，形成下述的几种文件： (1) 顺序文件。这是由一系列记录按某种顺序排列所形成的文件。其中的记录通常是定长记录，因而能用较快的速度查找文件中的记录。 (2) 索引文件。当记录为可变长度时，通常为之建立一张索引表，并为每个记录设置一个表项，以加快对记录检索的速度。 (3) 索引顺序文件。这是上述两种文件构成方式的结合。它为文件建立一张索引表，为每一组记录中的第一个记录设置一个表项。 无结构文件如果说大量的数据结构和数据库是采用有结构的文件形式的话，则大量的源程序、可执行文件、库函数等，所采用的就是无结构的文件形式，即流式文件。其长度以字节为单位。对流式文件的访问，则是采用读/写指针来指出下一个要访问的字符。可以把流式文件看做是记录式文件的一个特例。在 UNIX 系统中，所有的文件都被看做是流式文件，即使是有结构文件，也被视为流式文件，系统不对文件进行格式处理，所有的含义只能由用户层的程序来解释。操作系统把文件看成是简单的字节流，这种方式提供了很大的灵活性。用户程序可以在文件中加入任何内容，并且以任何方便的形式命名。操作系统不会停帮助，但也不会设置障碍。对于那些需要做特殊事情的用户来说，后者可能更为重要。堆堆（pile）是最简单的文件内容组织形式。数据按照它们到达的顺序被采集，每个记录由一串数据组成。堆得目的仅仅是积累大量的数据并保存数据。记录可以有不同的域，或者域相似但顺序不同。因此，每个域应该是自描述的。包括域名和值。每个域的长度由划分符隐式地指定，或者明确地包含在一个子域中，或者是该域类型的默认长度。由于堆文件没有结构，因而对记录的访问是通过穷军查找的方式，也就是说，如果想找到包括某一特定域且值为某一特定值得记录，则需要检查堆中的每一个记录，知道找到想要的记录，或者查找完整个文件为止。如果想查找包括某一个特定的域，或者包含具有某一特定值的域的所有记录，则必须查找整个文件。当数据在处理前采集并存储时，或者当数据难以组织时，会用到堆文件。当保存的数据大小和结构不同时，这种类型的文件空间使用情况很好，能较好地用于穷军查找，且易于查找。但是，除了这些受限制的使用，这类文件岁大多数应用都是不使用的。顺序文件文件是记录的集合。文件中的记录可以是任意顺序的，因此，它可以按照各种不同的顺序进行排列。一般地，可归纳为以下两种情况：第一种是串结构，各记录之间的顺序与关键字无关。通常的办法是由时间来决定，即按存入时间的先后排列，最先存入的记录作为第一个记录，其次存入的为第二个记录……， 依此类推。第二种情况是顺序结构，指文件中的所有记录按关键字(词)排列。可以按关键词的长短从小到大排序，也可以从大到小排序；或按其英文字母顺序排序。对顺序结构文件可有更高的检索效率，因为在检索串结构文件时，每次都必须从头开始，逐个记录地查找，直至找到指定的记录，或查完所有的记录为止。而对顺序结构文件，则可利用某种有效的查找算法，如折半查找法、插值查找法、跳步查找法等方法来提高检索效率。 对顺序文件(Sequential File)的读/写操作顺序文件中的记录可以是定长的，也可以是变长的。对于定长记录的顺序文件，如果已知当前记录的逻辑地址，便很容易确定下一个记录的逻辑地址。边读边统计该记录的长度（定长的话，就不用统计了，直接给出），读完一个记录之后，当前记录的首地址加上该记录的长度就得到了下一个待读记录的首地址了。 顺序文件的优缺点顺序文件的最佳应用场合是在对诸记录进行批量存取时，即每次要读或写一大批记录时。此时，对顺序文件的存取效率是所有逻辑文件中最高的；此外，也只有顺序文件才能存储在磁带上，并能有效地工作。在交互应用的场合，如果用户(程序)要求查找或修改单个记录，为此系统便要去逐个地查找诸记录。这时，顺序文件所表现出来的性能就可能很差，尤其是当文件较大时，情况更为严重。如果是可变长记录的顺序文件，则为查找一个记录所需付出的开销将更大，这就限制了顺序文件的长度。顺序文件的另一个缺点是，如果想增加或删除一个记录都比较困难。为了解决这一问题， 可以为顺序文件配置一个运行记录文件(Log File)，或称为事务文件(Transaction File)，把试图增加、删除或修改的信息记录于其中，规定每隔一定时间，例如 4 小时，将运行记录文件与原来的主文件加以合并，产生一个按关键字排序的新文件。索引文件对于定长记录，除了可以方便地实现顺序存取外，还可较方便地实现直接存取（如同操作数组一般）。然而，对于变长记录就较难实现直接存取了，因为用直接存取方法来访问变长记录文件中的一个记录是十分低效的（需要读取前面的记录并统计长度，最后才能到达需要访问的位置），其检索时间也很难令人接受。为了解决这一问题，可为变长记录文件建立一张索引表，对主文件中的每个记录，在索引表中设有一个相应的表项，用于记录该记录的长度L及指向该记录的指针(指向该记录在逻辑地址空间的首址)。由于索引表是按记录键排序的，因此，索引表本身是一个定长记录的顺序文件，从而也就可以方便地实现直接存取。在对索引文件进行检索时，首先是根据用户(程序)提供的关键字，并利用折半查找法去检索索引表，从中找到相应的表项；再利用该表项中给出的指向记录的指针值，去访问所需的记录。而每当要向索引文件中增加一个新记录时，便须对索引表进行修改。由于索引文件可有较快的检索速度，故它主要用于对信息处理的及时性要求较高的场合，例如，飞机订票系统。使用索引文件的主要问题是，它除了有主文件外，还须配置一张索引表，而且每个记录都要有一个索引项，因此提高了存储费用。索引顺序文件索引顺序文件(Index Sequential File)可能是最常见的一种逻辑文件形式。它有效地克服了变长记录文件不便于直接存取的缺点，而且所付出的代价也不算太大。前已述及，它是顺序文件和索引文件相结合的产物。它将顺序文件中的所有记录分为若干个组(例如，50个记录为一个组)；为顺序文件建立一张索引表，在索引表中为每组中的第一个记录建立一个索引项，其中含有该记录的键值和指向该记录的指针。索引顺序文件如下图所示。在对索引顺序文件进行检索时，首先也是利用用户(程序)所提供的关键字以及某种查 找算法去检索索引表，找到该记录所在记录组中第一个记录的表项，从中得到该记录组第 一个记录在主文件中的位置；然后，再利用顺序查找法去查找主文件，从中找到所要求的 记录。但对于一个非常大的文件，为找到一个记录而须查找的记录数目仍然很多，为了进一步提高检索效率，可以为顺序文件建立多级索引，即为索引文件再建立一张索引表，从而形成两级索引表。直接文件采用前述几种文件结构对记录进行存取时，都须利用给定的记录键值，先对线性表或链表进行检索，以找到指定记录的物理地址。然而对于直接文件，则可根据给定的记录键值，直接获得指定记录的物理地址。换言之，记录键值本身就决定了记录的物理地址。这种由记录键值到记录物理地址的转换被称为键值转换(Key to address transformation)。组织直接文件的关键，在于用什么方法（如哈希方法）进行从记录值到物理地址的转换。哈希(Hash)文件这是目前应用最为广泛的一种直接文件。它利用 Hash 函数(或称散列函数)，可将记录键值转换为相应记录的地址。但为了能实现文件存储空间的动态分配，通常由 Hash 函数所求得的并非是相应记录的地址，而是指向一目录表相应表目的指针，该表目的内容指向相应记录所在的物理块。外存分配方式由于磁盘具有可直接访问的特性，故当利用磁盘来存放文件时，具有很大的灵活性。在为文件分配外存空间时所要考虑的主要问题是：怎样才能有效地利用外存空间和如何提高对文件的访问速度。目前，常用的外存分配方法有连续分配、链接分配和索引分配三种。通常，在一个系统中，仅采用其中的一种方法来为文件分配外存空间。 如前所述，文件的物理结构直接与外存分配方式有关。在采用不同的分配方式时，将形成不同的文件物理结构。例如，在采用连续分配方式时的文件物理结构，将是顺序式的文件结构；链接分配方式将形成链接式文件结构；而索引分配方式则将形成索引式文件结构。连续分配连续分配(Continuous Allocation)要求为每一个文件分配一组相邻接的盘块（也可能是编号相邻而已）。一组盘块的地址定义了磁盘上的一段线性地址。通常，它们都位于一条磁道上，在进行读/写时，不必移动磁头，仅当访问到一条磁道的最后一个盘块后，才需要移到下一条磁道，于是又去连续地读/写多个盘块。在采用连续分配方式时，可把逻辑文件中的记录顺序地存储到邻接的各物理盘块中，这样所形成的文件结构称为顺序文件结构，此时的物理文件称为顺序文件。这种分配方式保证了逻辑文件中的记录顺序与存储器中文件占用盘块的顺序的一致性。为使系统能找到文件存放的地址，应在目录项的“文件物理地址”字段中，记录该文件第一个记录所在的盘块号和文件长度(以盘块数进行计量)。如同内存的动态分区分配一样，随着文件建立时空间的分配和文件删除时空间的回收，将使磁盘空间被分割成许多小块，这些较小的连续区已难于用来存储文件，此即外存的碎片。同样，我们也可以利用紧凑的方法，将盘上所有的文件紧靠在一起，把所有的碎片拼接成一大片连续的存储空间。这种方法能将含有多个文件的盘上的所有空闲盘块都集中在一起，从而消除了外部碎片。但为了将外存上的空闲空间进行一次紧凑，所花费的时间远比将内存紧凑一次所花费的时间多得多。连续分配的主要优点：(1) 顺序访问容易。访问一个占有连续空间的文件非常容易。系统可从目录中找到该顺序文件所在的第一个盘块号，从此开始顺序地、逐个盘块地往下读/写。连续分配也支持直接存取。例如，要访问一个从 b 块开始存放的文件中的第 i 个盘块的内容，就可直接访问 b+i 号盘块。(2) 顺序访问速度快。因为由连续分配所装入的文件，其所占用的盘块可能是位于一条或几条相邻的磁道上，这时，磁头的移动距离最少，因此，这种对文件访问的速度是几种存储空间分配方式中最高的一种。连续分配的主要缺点：(1) 要求有连续的存储空间。要为每一个文件分配一段连续的存储空间，这样，便会产生出许多外部碎片，严重地降低了外存空间的利用率。如果是定期地利用紧凑方法来消除碎片，则又需花费大量的机器时间。(2) 必须事先知道文件的长度。要将一个文件装入一个连续的存储区中，必须事先知道文件的大小，然后根据其大小，在存储空间中找出一块其大小足够的存储区，将文件装入。在有些情况下，知道文件的大小是件非常容易的事，如可拷贝一个已存文件。但有时却很难，在此情况下，只能靠估算。如果估计的文件大小比实际文件小，就可能因存储空间不 足而中止文件的拷贝，须再要求用户重新估算，然后再次执行。这样，显然既费时又麻烦。这就促使用户往往将文件长度估得比实际的大，甚至使所计算的文件长度比实际长度大得多，显然，这会严重地浪费外存空间。对于那些动态增长的文件，由于开始时文件很小，在运行中逐渐增大，比如，这种增长要经历几天、几个月。在此情况下，即使事先知道文件的最终大小，在采用预分配存储空间的方法时，显然也将是很低效的，即它使大量的存储空间长期地空闲着。链接分配如同内存管理一样，连续分配所存在的问题就在于: 必须为一个文件分配连续的磁盘空间。如果在将一个逻辑文件存储到外存上时，并不要求为整个文件分配一块连续的空间，而是可以将文件装到多个离散的盘块中，这样也就可以消除上述缺点。在采用链接分配(Chained Allocation)方式时，可通过在每个盘块上的链接指针，将同属于一个文件的多个离散的盘块链接成一个链表，把这样形成的物理文件称为链接文件。链接分配的优势：由于链接分配是采取离散分配方式，消除了外部碎片，故而显著地提高了外存空间的利用率；又因为是根据文件的当前需要，为它分配必需的盘块，当文件动态增长时，可动态地再为它分配盘块，故而无需事先知道文件的大小。此外，对文件的增、删、改也十分方便。链接方式：链接方式又可分为隐式链接和显式链接两种形式。 隐式链接在采用隐式链接分配方式时，在文件目录的每个目录项中，都须含有指向链接文件第一个盘块和最后一个盘块的指针。隐式链接分配方的主要问题在于：它只适合于顺序访问，它对随机访问是极其低效的。如果要访问文件所在的第i个盘块，则必须先读出文件的第一个盘块……，就这样顺序地查找直至第i块。当i=100时，须启动100次磁盘去实现读盘块的操作，平均每次都要花费几十毫秒。可见，随机访问的速度相当低。此外，只通过链接指针来将一大批离散的盘块链接起来，其可靠性较差，因为只要其中的任何一个指针出现问题，都会导致整个链的断开。为了提高检索速度和减小指针所占用的存储空间，可以将几个盘块组成一个簇(cluster)。比如，一个簇可包含 4 个盘块，在进行盘块分配时，是以簇为单位进行的。在链接文件中的每个元素也是以簇为单位的。这样将会成倍地减小查找指定块的时间，而且也可减小指针所占用的存储空间，但却增大了内部碎片，而且这种改进也是非常有限的。 显式链接这是指把用于链接文件各物理块的指针，显式地存放在内存的一张链接表中。该表在整个磁盘仅设置一张，在每个表项中存放链接指针，即下一个盘块号。在该表中，凡是属于某一文件的第一个盘块号，或者说是每一条链的链首指针所对应的盘块号，均作为文件地址被填入相应文件的 FCB的“物理地址”字段中。由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。由于分配给文件的所有盘块号都放在该表中，故把该表称为文件分配表 FAT(File Allocation Table)。索引分配链接分配方式虽然解决了连续分配方式所存在的问题，但又出现了下述另外两个问题：(1) 不能支持高效的直接存取。要对一个较大的文件进行直接存取，须首先在 FAT 中顺序地查找许多盘块号。(2) FAT 需占用较大的内存空间。由于一个文件所占用盘块的盘块号是随机地分布在 FAT 中的，因而只有将整个 FAT 调入内存，才能保证在 FAT 中找到一个文件的所有盘块号。当磁盘容量较大时，FAT 可能要占用数兆字节以上的内存空间，这是令人难以接受的。 单级索引分配事实上，在打开某个文件时，只需把该文件占用的盘块的编号调入内存即可，完全没有必要将整个 FAT 调入内存。为此，应将每个文件所对应的盘块号集中地放在一起。索引分配方法就是基于这种想法所形成的一种分配方法。它为每个文件分配一个索引块(表)，再把分配给该文件的所有盘块号都记录在该索引块中，因而该索引块就是一个含有许多盘块号的数组。在建立一个文件时，只需在为之建立的目录项中填上指向该索引块的指针。索引分配方式支持直接访问。当要读文件的第i个盘块时，可以方便地直接从索引块中找到第 i 个盘块的盘块号；此外，索引分配方式也不会产生外部碎片。当文件较大时，索引分配方式无疑要优于链接分配方式。索引分配方式的主要问题是：可能要花费较多的外存空间。每当建立一个文件时，便须为之分配一个索引块，将分配给该文件的所有盘块号记录于其中。但在一般情况下，总是中、小型文件居多，甚至有不少文件只需 1～2 个盘块，这时如果采用链接分配方式，只需设置 1～2 个指针。如果采用索引分配方式，则同样仍须为之分配一索引块。通常是采用一个专门的盘块作为索引块，其中可存放成百个、甚至上千个盘块号。可见，对于小文件采用索引分配方式时，其索引块的利用率将是极低的。 多级索引分配当 OS 为一个大文件分配磁盘空间时，如果所分配出去的盘块的盘块号已经装满一个索引块时，OS便为该文件分配另一个索引块，用于将以后继续为之分配的盘块号记录于其中。依此类推，再通过链指针将各索引块按序链接起来。显然，当文件太大，其索引块太多时，这种方法是低效的。此时，应为这些索引块再建立一级索引，称为第一级索引，即系统再分配一个索引块，作为第一级索引的索引块，将第一块、第二块……等索引块的盘块号填入到此索引表中，这样便形成了两级索引分配方式。如果文件非常大时，还可用三级、四级索引分配方式。混合索引分配方式所谓混合索引分配方式，是指将多种索引分配方式相结合而形成的一种分配方式。 1) 直接地址为了提高对文件的检索速度，在索引结点中可设置 10 个直接地址项。换言之，在这里的每项中所存放的是该文件数据所在盘块的盘块号。假如每个盘块的大小为 4 KB，当文件不大于 40 KB 时，便可直接从索引结点中读出该文件的全部盘块号。 2) 一次间接地址对于大、中型文件，只采用直接地址是不现实的。为此，可再利用索引结点中的地址项中的一次间接地址。这种方式的实质就是一级索引分配方式。图中的一次间址块也就是索引块，系统将分配给文件的多个盘块号记入其中。在一次间址块中可存放 1 K个盘块号，因而允许文件长达 4 MB。 3) 多次间接地址当文件长度大于4 MB + 40 KB时(一次间址与10个直接地址项)，系统还须采用二次间址分配方式。该方式的实质是两级索引分配方式。系统此时是在二次间址块中记入所有一次间址块的盘号。在采用二次间址方式时，文件最大长度可达 4 GB。同理，地址项三次间接地址，其所允许的文件最大长度可达 4 TB。目录管理通常，在现代计算机系统中，都要存储大量的文件。为了能对这些文件实施有效的管理，必须对它们加以妥善组织，这主要是通过文件目录实现的。文件目录也是一种数据结构，用于标识系统中的文件及其物理地址，供检索时使用。对目录管理的要求如下：(1) 实现“按名存取”，即用户只须向系统提供所需访问文件的名字，便能快速准确地找到指定文件在外存上的存储位置。这是目录管理中最基本的功能，也是文件系统向用户提供的最基本的服务。(2) 提高对目录的检索速度。通过合理地组织目录结构的方法，可加快对目录的检索速度，从而提高对文件的存取速度。这是在设计一个大、中型文件系统时所追求的主要目标。(3) 文件共享。在多用户系统中，应允许多个用户共享一个文件。这样就须在外存中只保留一份该文件的副本，供不同用户使用，以节省大量的存储空间，并方便用户和提高文件利用率。(4) 允许文件重名。系统应允许不同用户对不同文件采用相同的名字，以便于用户按照自己的习惯给文件命名和使用文件。文件控制块为了能对一个文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构，称之为“文件控制块(FCB)”。文件管理程序可借助于文件控制块中的信息，对文件施以各种操作。文件与文件控制块一一对应，而人们把文件控制块的有序集合称为文件目录，即一个文件控制块就是一个文件目录项。通常，一个文件目录也被看做是一个文件，称为目录文件。为了能对系统中的大量文件施以有效的管理，在文件控制块中，通常应含有三类信息，即基本信息、存取控制信息及使用信息。 1) 基本信息类 文件标识和控制信息：文件名、用户名、文件主存取权限、授权者存取权限、文件口令、文件类型等。 文件逻辑结构信息：文件的逻辑结构，如记录类型、记录个数、记录长度、成组银子数等。 文件物理结构信息：文件所在设备名、文件物理结构类型、记录存放在辅助存储器的盘块号或文件信息首块盘块号，也可指出文件索引所在的位置等。 文件使用信息：共享文件的进程数、文件修改情况、文件最大长度和当前大小等。 文件管理信息：文件建立日期、最近修改日期等。 2) 存取控制信息类存取控制信息类包括：文件主的存取权限、核准用户的存取权限以及一般用户的存取 权限。 3) 使用信息类使用信息类包括: 文件的建立日期和时间、文件上一次修改的日期和时间及当前使用信息(这项信息包括当前已打开该文件的进程数、是否被其它进程锁住、文件在内存中是否已被修改但尚未拷贝到盘上)。应该说明，对于不同 OS 的文件系统，由于功能不同，可能只含有上述信息中的某些部分。索引结点文件目录通常是存放在磁盘上的，当文件很多时，文件目录可能要占用大量的盘块。在查找目录的过程中，先将存放目录文件的第一个盘块中的目录调入内存，然后把用户所给定的文件名与目录项中的文件名逐一比较。若未找到指定文件，便再将下一个盘块中的目录项调入内存。稍加分析可以发现，在检索目录文件的过程中，只用到了文件名，仅当找到一个目录项(即其中的文件名与指定要查找的文件名相匹配)时，才需从该目录项中读出该文件的物理地址。而其它一些对该文件进行描述的信息，在检索目录时一概不用。显然，这些信息在检索目录时不需调入内存。为此，在有的系统中，如 UNIX 系统，便采用了把文件名与文件描述信息分开的办法，亦即，使文件描述信息单独形成一个称为索引结点的数据结构，简称为i 结点。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i结点的指针所构成。 磁盘索引结点这是存放在磁盘上的索引结点。每个文件有惟一的一个磁盘索引结点，它主要包括以下内容： (1) 文件主标识符，即拥有该文件的个人或小组的标识符。 (2) 文件类型，包括正规文件、目录文件或特别文件。 (3) 文件存取权限，指各类用户对该文件的存取权限。 (4) 文件物理地址，每一个索引结点中含有 13 个地址项，它们以直接或间接方式给出数据文件所在盘块的编号。 (5) 文件长度，指以字节为单位的文件长度。 (6) 文件连接计数，表明在本文件系统中所有指向该(文件的)文件名的指针计数。 (7) 文件存取时间，指本文件最近被进程存取的时间、最近被修改的时间及索引结点最近被修改的时间。 内存索引结点这是存放在内存中的索引结点。当文件被打开时，要将磁盘索引结点拷贝到内存的索引结点中，便于以后使用。在内存索引结点中又增加了以下内容： (1) 索引结点编号，用于标识内存索引结点。 (2) 状态，指示 i 结点是否上锁或被修改。 (3) 访问计数，每当有一进程要访问此 i 结点时，将该访问计数加 1，访问完再减 1。 (4) 文件所属文件系统的逻辑设备号。 (5) 链接指针。设置有分别指向空闲链表和散列队列的指针。目录结构目录结构的组织，关系到文件系统的存取速度，也关系到文件的共享性和安全性。因此，组织好文件的目录，是设计好文件系统的重要环节。目前常用的目录结构形式有单级目录、两级目录和多级目录。 单级目录结构这是最简单的目录结构。在整个文件系统中只建立一张目录表，每个文件占一个目录项，目录项中含文件名、文件扩展名、文件长度、文件类型、文件物理地址以及其它文件属性。此外，为表明每个目录项是否空闲，又设置了一个状态位。每当要建立一个新文件时，必须先检索所有的目录项，以保证新文件名在目录中是惟一的。然后再从目录表中找出一个空白目录项，填入新文件的文件名及其它说明信息，并置状态位为 1。删除文件时，先从目录中找到该文件的目录项，回收该文件所占用的存储空间，然后再清除该目录项。单级目录结构住哟啊用于单用户操作系统，它具有如下优点： 结构简单，通过管理其目录文件，便可实现文件信息的管理； 实现按名存取。同时，单级目录结构具有以下缺点： 文件较多时，目录检索时间长； 有命名冲突：在躲到程序系统中，尤其是多用户的分时系统中，重名很难避免，这就很难准确地找到用户需要的文件。显然，如果人工管理文件名注册，以避免命名冲突非常麻烦。 不便于共享：通常，每个用户都有自己的名字空间或命名习惯。因此，应当允许不同用户使用不同的文件名来访问同一个文件。然而，该目录结构要求所有用户用相同的名字访问同一个文件。 两级目录为了克服单级目录所存在的缺点，可以为每一个用户建立一个单独的用户文件目录UFD(User File Directory)。这些文件目录具有相似的结构，它由用户所有文件的文件控制块组成。此外，在系统中再建立一个主文件目录MFD(Master File Directory)；在 主 文件目录中，每个用户目录文件都占有一个目录项，其目录项中包括用户名和指向该用户目录文件的指针。两级目录结构基本克服了单级目录结构的缺点而具有以下优点： 提高了检索目录的速度； 在不同的用户目录中可以使用相同的文件名； 不同用户可使用不同的文件名来访问系统中的同一个共享文件。采用两级目录结构也存在一些问题。该结构虽然能有效地将多个用户隔开，在各用户之间完全无关时，这种隔离是一个优点；但当多个用户之间要相互合作去完成一个大任务，且一用户又需去访问其他用户的文件时，这种隔离便成为一个缺点，因为这种隔离会使诸用户之间不便于共享文件。 多级目录结构对于大型文件系统，通常采用三级或三级以上的目录结构，以提高对目录的检索速度和文件系统的性能。多级目录结构又称为树型目录结构，主目录在这里被称为根目录，把数据文件称为树叶，其它的目录均作为树的结点。路径名在树形目录结构中，从根目录到任何数据文件，都只有一条惟一的通路。在该路径上从树的根(即主目录)开始，把全部目录文件名与数据文件名依次地用“/”（不同系统使用的分隔符可能不同）连接起来，即构成该数据文件的路径名(path name)。系统中的每一个文件都有惟一的路径名。当前目录当一个文件系统含有许多级时，每访问一个文件，都要使用从树根开始直到树叶(数据文件)为止的、包括各中间节点(目录)名的全路径名。这是相当麻烦的事，同时由于一个进程运行时所访问的文件大多仅局限于某个范围，因而非常不便。基于这一点，可为每个进程设置一个“当前目录”，又称为“工作目录”。进程对各文件的访问都相对于“当前目录”而进行。此时各文件所使用的路径名，只需从当前目录开始，逐级经过中间的目录文件，最后到达要访问的数据文件。把这一路径上的全部目录文件名与数据文件名用“/”连接形成路径名。多级目录的优点：就多级目录较两级目录而言，其查询速度更快，同时层次结构更加清晰，能够更加有效地进行文件的管理和保护。在多级目录中，不同性质、不同用户的文件可以构成不同的目录子树，不同层次、不同用户的文件分别呈现在系统目录树中的不同层次或不同子树中，可以容易地赋予不同的存取权限。多及目录的缺点：但是在多级目录中查找一个文件，需要按路径名逐级访问中间节点，这就增加了磁盘访问次数，无疑将影响查询速度。目录查询技术当用户要访问一个已存在文件时，系统首先利用用户提供的文件名对目录进行查询，找出该文件的文件控制块或对应索引结点；然后，根据 FCB 或索引结点中所记录的文件物理地址(盘块号)，换算出文件在磁盘上的物理位置；最后，再通过磁盘驱动程序，将所需文件读入内存。目前对目录进行查询的方式有两种: 线性检索法和 Hash 方法。 线性检索法在一级目录结构中，利用用户提供的文件名，用顺序查找的方法直接从文件目录表中找到指定文件的目录项。在树形目录结构中，用户提供的文件名是由多个文件分量名组成的路径名，此时需要对多级目录进行查找，即系统先读入第一个文件分量名，用它和根目录文件或当前目录文件中各个目录项进行比较，若找到匹配者，便可找到匹配项的文件控制块或索引结点，然后再读入路径名中的第二个分量名，用它和相应的第二级文件目录中各个文件目录项的文件名顺序比较，若找到匹配项，再取下一个分量名，直至全部差玩，最后可得到数据文件控制块或索引结点。若在查找过程中发现一个分量名没有查找到，则应停止查找并返回“文件未找到”的信息。 Hash 方法如果我们建立了一张Hash索引文件目录，便可利用Hash 方法进行查询，即系统利用用户提供的文件名并将它变换为文件目录的索引值，再利用该索引值到目录中去查找，这将显著地提高检索速度。在进行文件名的转换时，有可能把n个不同的文件名转换为相同的Hash值，即出现了所谓的“冲突”。一种处理此“冲突”的有效规则是: (1) 在利用 Hash 法索引查找目录时，如果目录表中相应的目录项是空的，则表示系统中并无指定文件。 (2) 如果目录项中的文件名与指定文件名相匹配，则 表 示该目录项正是所要寻找的文件所对应的目录项，故而可从中找到该文件所在的物理地址。 (3) 如果在目录表的相应目录项中的文件名与指定文件名并不匹配，则表示发生了“冲突”，此时须将其Hash值再加上一个常数(该常数应与目录的长度值互质)，形成新的索引值，顺便指出，在现代操作系统中，通常都提供了模式匹配功能，即在文件名中使用了通配符“*”、“？”等。对于使用了通配符的文件名，系统此时便无法利用 Hash 方法检索目录，因此，这时系统还是需要利用线性查找法查找目录。文件存储空间的管理文件管理要解决的重要问题之一是如何为新创建的文件分配存储空间。其分配方法与内存的分配有许多相似之处，即同样可采取连续分配方式或离散分配方式。前者具有较高的文件访问速度，但可能产生较多的外存零头；后者能有效地利用外存空间，但访问速度较慢。不论哪种分配方式，文件存储空间的基本分配单位都是磁盘块而非字节。为了实现存储空间的分配，系统首先必须能记住存储空间的使用情况。为此， 系统应为分配存储空间而设置相应的数据结构； 系统应提供对存储空间进行分配和回收的手段。下面介绍几种常用的文件存储空间的管理方法。空闲表法空闲表法属于连续分配方式，它与内存的动态分配方式雷同，它为每个文件分配一块连续的存储空间，即系统也为外存上的所有空闲区建立一张空闲表，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列。存储空间的分配与回收空闲盘区的分配与内存的动态分配类似，同样是采用首次适应算法、循环首次适应算法等。例如，在系统为某新创建的文件分配空闲盘块时，先顺序地检索空闲表的各表项，直至找到第一个其大小能满足要求的空闲区，再将该盘区分配给用户(进程)，同时修改空闲表。系统在对用户所释放的存储空间进行回收时，也采取类似于内存回收的方法，即要考虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。应该说明，在内存分配上，虽然很少采用连续分配方式，然而在外存的管理中，由于这种分配方式具有较高的分配速度，可减少访问磁盘的I/O频率，故它在诸多分配方式中仍占有一席之地。例如，在前面所介绍的对换方式中，对对换空间一般都采用连续分配方式。对于文件系统，当文件较小(1～4个盘块)时，仍采用连续分配方式，为文件分配相邻接的几个盘块；当文件较大时，便采用离散分配方式。空闲链表法空闲链表法是将所有空闲盘区拉成一条空闲链。根据构成链所用基本元素的不同，可把链表分成两种形式：空闲盘块链和空闲盘区链。 (1) 空闲盘块链。空闲盘块链是将磁盘上的所有空闲空间，以盘块为单位拉成一条链。当用户因创建文件而请求分配存储空间时，系统从链首开始，依次摘下适当数目的空闲盘块分配给用户。当用户因删除文件而释放存储空间时，系统将回收的盘块依次插入空闲盘块链的末尾。这种方法的优点是用于分配和回收一个盘块的过程非常简单，但在为一个文件分配盘块时，可能要重复操作多次。 (2) 空闲盘区链。空闲盘区链是将磁盘上的所有空闲盘区(每个盘区可包含若干个盘块)拉成一条链。在每个盘区上除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小(盘块数)的信息。分配盘区的方法与内存的动态分区分配类似，通常采用首次适应算法。在回收 盘区时，同样也要将回收区与相邻接的空闲盘区相合并。在采用首次适应算法时，为了提高对空闲盘区的检索速度，可以采用显式链接方法，亦即，在内存中为空闲盘区建立一张链表。位示图法位示图是利用二进制的一位来表示磁盘中一个盘块的使用情况。当其值为“0”时，表示对应的盘块空闲；为“1”时，表示已分配。有的系统把“0”作为盘块已分配的标志，把“1”作为空闲标志。磁盘上的所有盘块都有一个二进制位与之对应，这样，由所有盘块所对应的位构成一个集合，称为位示图。通常可用 m ×n 个位数来构成位示图，并使 m ×n 等于磁盘的总块数， 盘块的分配根据位示图进行盘块分配时，可分三步进行：(1) 顺序扫描位示图，从中找出一个或一组其值为“0”的二进制位(“0”表示空闲时)。(2) 将所找到的一个或一组二进制位转换成与之相应的盘块号。假定找到的其值为“0”的二进制位位于位示图的第i行、第j列，则其相应的盘块号应按下式计算：b = n(i - 1) + j式中，n代表每行的位数。(3) 修改位示图，令 map[i,j]=1。 盘块的回收盘块的回收分两步：(1) 将回收盘块的盘块号转换成位示图中的行号和列号。转换公式为：i = (b - 1) DIV n + 1j = (b - 1) MOD n + 1(2) 修改位示图。令 map[i,j] =0。 位图法评价这种方法的主要优点是，从位示图中很容易找到一个或一组相邻接的空闲盘块。例如，我们需要找到6个相邻接的空闲盘块，这只需在位示图中找出6个其值连续为“0”的位即可。此外，由于位示图很小，占用空间少，因而可将它保存在内存中，进而使在每次进行盘区分配时，无需首先把盘区分配表读入内存，从而节省了许多磁盘的启动操作。因此，位示图常用于微型机和小型机中，如 CP/M、Apple-DOS 等 OS 中。成组链接法空闲表法和空闲链表法都不适用于大型文件系统，因为这会使空闲表或空闲链表太长。在 UNIX 系统中采用的是成组链接法，这是将上述两种方法相结合而形成的一种空闲盘块管理方法，它兼备了上述两种方法的优点而克服了两种方法均有的表太长的缺点。 空闲盘块的组织 空闲盘块的分配与回收当系统要为用户分配文件所需的盘块时，须调用盘块分配过程来完成。该过程首先检查空闲盘块号栈是否上锁，如未上锁，便从栈顶取出一空闲盘块号，将与之对应的盘块分配给用户，然后将栈顶指针下移一格。若该盘块号已是栈底，即 S.free(0)，这是当前栈中最后一个可分配的盘块号。由于在该盘块号所对应的盘块中记有下一组可用的盘块号，因此，须调用磁盘读过程，将栈底盘块号所对应盘块的内容读入栈中，作为新的盘块号栈的内容，并把原栈底对应的盘块分配出去(其中的有用数据已读入栈中)。然后，再分配一相应的缓冲区(作为该盘块的缓冲区)。最后，把栈中的空闲盘块数减1并返回。在系统回收空闲盘块时，须调用盘块回收过程进行回收。它是将回收盘块的盘块号记入空闲盘块号栈的顶部，并执行空闲盘块数加 1 操作。当栈中空闲盘块号数目已达 100 时，表示栈已满，便将现有栈中的100个盘块号记入新回收的盘块中，再将其盘块号作为新栈底。文件共享在现代计算机系统中，必须提供文件共享手段，即系统应允许多个用户(进程)共享同一份文件。这样，在系统中只需保留该共享文件的一份副本。如果系统不能提供文件共享功能，就意味着凡是需要该文件的用户，都须各自备有此文件的副本，显然这会造成对存储空间的极大浪费。随着计算机技术的发展，文件共享的范围也在不断扩大，从单机系统中的共享，扩展为多机系统的共享，进而又扩展为计算机网络范围的共享，甚至实现全世界的文件共享。基于索引结点的共享方式在树型结构的目录中，当有两个(或多个)用户要共享一个子目录或文件时，必须将共享文件或子目录链接到两个(或多个)用户的目录中，才能方便地找到该文件，如下图所示。此时该文件系统的目录结构已不再是树型结构，而是个有向无环图 DAG (Directed Acyclic Graph)。可以通过将待共享的原始文件的文件信息拷贝到共享该文件的目录中，不过该方法如同通过复制文件一般（虽然没有这么消耗空间），很难保持共享文件的一致性，行为一旦共享的文件被修改（特别是增删物理块），那么文件信息发生改变，但另一方的备份文件信息并没有改变，从而出现不一致的情况，除非重新拷贝文件信息（当然有多少用户共享该文件，就要重新拷贝多少份）。为了解决这个问题，可以引用索引结点，即诸如文件的物理地址及其它的文件属性等信息，不再是放在目录项中，而是放在索引结点中。在文件目录中只设置文件名及指向相应索引结点的指针。只要该文件的首地址没有改变，那么共享仍然有效，而且总是一致的。在索引结点中还应有一个链接计数 count，用于表示链接到本索引结点(亦即文件)上的用户目录项的数目。当 count=3 时，表示有三个用户目录项连接到本文件上，或者说是有三个用户（包括文件的创建者或拥有者）共享此文件。对于共享文件，即使是创建者当 count &gt; 1 时也不能删除该文件，只是让 count 减 1；只有 count = 1 时才能删除该文件，利用符号链实现文件共享为使 B 能共享 C 的一个文件 F，可以由系统创建一个 LINK 类型的新文件，也取名为 F，并将 F 写入 B 的目录中，以实现 B 的目录与文件F的链接。在新文件中只包含被链接文件 F 的路径名。这样的链接方法被称为符号链接(Symbolic Linking)（类似 Windows 中的快捷方式）。新文件中的路径名则只被看作是符号链(Symbolic Link)，当 B 要访问被链接的文件 F 且正要读 LINK 类新文件时，此要求将被 OS 截获，OS 根据新文件中的路径名去读该文件，于是就实现了用户 B 对文件 F的共享。符号链实现共享方式的优点：在利用符号链方式实现文件共享时，只是文件主才拥有指向其索引结点的指针；而共享该文件的其他用户则只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除一共享文件后留下一悬空指针的情况。当文件的拥有者把一个共享文件删除后，其他用户试图通过符号链去访问一个已被删除的共享文件时，会因系统找不到该文件而使访问失败，于是再将符号链删除，此时不会产生任何影响。符号链方式有一个很大的优点，是它能够用于链接(通过计算机网络)世界上任何地方的计算机中的文件，此时只需提供该文件所在机器的网络地址以及该机器中的文件路径即可。符号链实现共享方式的优点：然而符号链的共享方式也存在自己的问题: 当其他用户去读共享文件时，系统是根据给定的文件路径名，逐个分量(名)地去查找目录，直至找到该文件的索引结点。因此，在每次访问共享文件时，都可能要多次地读盘。这使每次访问文件的开销甚大，且增加了启动磁盘的频率。此外，要为每个共享用户建立一条符号链，而由于该链实际上是一个文件，尽管该文件非常简单，却仍要为它配置一个索引结点，这也要耗费一定的磁盘空间。基于索引结点的共享方式和利用符号链实现文件共享方式都存在这样一个共同的问题，即每一个共享文件都有几个文件名。换言之，每增加一条链接，就增加一个文件名。这在实质上就是每个用户都使用自己的路径名去访问共享文件。当我们试图去遍历(traverse)整个文件系统时，将会多次遍历到该共享文件。例如，当有一个程序员要将一个目录中的所有文件都转储到磁带上去时，就可能对一个共享文件产生多个拷贝。磁盘容错技术磁盘容量越来越大，存储的文件也越来越多，一旦出错可能是毁灭性的，这也就带来了不安全性。影响文件安全性的主要因素有三： (1) 人为因素，即由于人们有意或无意的行为，而 使 文件系统中的数据遭到破坏或丢失。 (2) 系统因素，即由于系统的某部分出现异常情况，而造成对数据的破坏或丢失。特别是作为数据存储介质的磁盘，在出现故障或损坏时，会对文件系统的安全性造成影响； (3) 自然因素，即存放在磁盘上的数据，随着时间的推移将可能发生溢出或逐渐消失。为了确保文件系统的安全性，可针对上述原因而采取以下措施： (1) 通过存取控制机制来防止由人为因素所造成的文件不安全性。 (2) 通过磁盘容错技术来防止由磁盘部分的故障所造成的文件不安全性。 (3) 通过“后备系统”来防止由自然因素所造成的不安全性。本小节主要讨论磁盘容错技术。容错技术是通过在系统中设置冗余部件的办法，来提高系统可靠性的一种技术。磁盘容错技术则是通过增加冗余的磁盘驱动器、磁盘控制器等方法，来提高磁盘系统可靠性的一种技术，即当磁盘系统的某部分出现缺陷或故障时，磁盘仍能正常工作，且不致造成数据的丢失或错误。目前广泛采用磁盘容错技术来改善磁盘系统的可靠性。磁盘容错技术往往也被人们称为系统容错技术 SFT。可把它分成三个级别： 第一级是低级磁盘容错技术； 第二级是中级磁盘容错技术； 第三级是系统容错技术，它基于集群技术实现容错。第一级容错技术SFT-Ⅰ第一级容错技术(SFT-I是最基本的一种磁盘容错技术，主要用于防止因磁盘表面缺陷所造成的数据丢失。它包含双份目录、双份文件分配表及写后读校验等措施。 双份目录和双份文件分配表在磁盘上存放的文件目录和文件分配表 FAT，是文件管理所用的重要数据结构。为了防止这些表格被破坏，可在不同的磁盘上或在磁盘的不同区域中，分别建立(双份)目录表和 FAT。其中一份为主目录及主 FAT；另一份为备份目录及备份 FAT。一旦由于磁盘表面缺陷而造成主文件目录或主 FAT 的损坏时，系统便自动启用备份文件目录及备份 FAT，从而可以保证磁盘上的数据仍是可访问的。 热修复重定向和写后读校验由于磁盘价格昂贵，当磁盘表面有少量缺陷时，则可采取某种补救措施后继续使用磁盘。一般主要采取以下两个补救措施：(1) 热修复重定向：系统将磁盘容量的一部分(例如 2%～3%)作为热修复重定向区，用于存放当发现磁盘有缺陷时的待写数据，并对写入该区的所有数据进行登记，以便于以后对数据进行访问。(2) 写后读校验方式。为了保证所有写入磁盘的数据都能写入到完好的盘块中，应该在每次从内存缓冲区向磁盘中写入一个数据块后，又立即从磁盘上读出该数据块，并送至另一缓冲区中，再将该缓冲区内容与内存缓冲区中在写后仍保留的数据进行比较。若两者一致，便认为此次写入成功，可继续写下一个盘块；否则，再重写。若重写后两者仍不一致，则认为该盘块有缺陷，此时，便将应写入该盘块的数据，写入到热修复重定向区中。第二级容错技术 SFT-II第二级容错技术主要用于防止由磁盘驱动器和磁盘控制器故障所导致的系统不能正常工作，它具体又可分为磁盘镜像和磁盘双工。 1) 磁盘镜像(Disk Mirroring)为了避免磁盘驱动器发生故障而丢失数据，便增设了磁盘镜像功能。为实现该功能，须在同一磁盘控制器下再增设一个完全相同的磁盘驱动器，当采用磁盘镜像方式时，在每次向主磁盘写入数据后，都需要将数据再写到备份磁盘上，使两个磁盘上具有完全相同的位像图。磁盘镜像虽然实现了容错功能，但未能使服务器的磁盘 I/O 速度得到提高，却使磁盘的利用率降至仅为 50%。 2) 磁盘双工(Disk Duplexing)如果控制这两台磁盘驱动器的磁盘控制器发生故障，或主机到磁盘控制器之间的通道发生了故障，磁盘镜像功能便起不到数据保护的作用。因此，在第二级容错技术中，又增加了磁盘双工功能，即将两台磁盘驱动器分别接到两个磁盘控制器上，同样使这两台磁盘机镜像成对。基于集群技术的容错功能所谓集群，是指由一组互连的自主计算机组成统一的计算机系统，给人们的感觉是，它们是一台机器。利用集群系统不仅可提高系统的并行处理能力，还可用于提高系统的可用性，它们是当前使用最广泛的一类具有容错功能的集群系统。其主要工作模式有三种： ① 热备份模式； ② 互为备份模式； ③ 公用磁盘模式。下面我们介绍如何利用集群系统来提高服务器的可用性。 1) 双机热备份模式在这种模式的系统中，备有两台服务器，两者的处理能力通常是完全相同的，一台作为主服务器，另一台作为备份服务器。平时主服务器运行，备份服务器则时刻监视着主服务器的运行，一旦主服务器出现故障，备份服务器便立即接替主服务器的工作而成为系统中的主服务器，修复后的服务器再作为备份服务器。为使在这两台服务器间能保持镜像关系，应在这两台服务器上各装入一块网卡，并通过一条镜像服务器链路MSL(Mirrored Server Link)将两台服务器连接起来。两台服务器之间保持一定的距离，其所允许的距离取决于所配置的网卡和传输介质。此外，还必须在系统中设置某种机制，来检测主服务器中数据的改变。一旦该机制检测到主服务器中有数据变化，便立即通过通信系统将修改后的数据传送到备份服务器的相应数据文件中。为了保证在两台服务器之间通信的高速性和安全性，通常都选用高速通信信道，并有备份线路。在这种模式下，一旦主服务器发生故障，系统能自动地将主要业务用户切换到备份服务器上。为 保证切换时间足够快(通常为数分钟)，要求在系统中配置有切换硬件的开关设备，在备份服务器上事先建立好通信配置，并能迅速处理客户机的重新登录等事宜。该模式是早期使用的一种集群技术，它的最大优点是提高了系统的可用性，易于实现，而且主、备份服务器完全独立，可支持远程热备份，从而能消除由于火灾、爆炸等非计算机因素所造成的隐患。该模式的主要缺点是从服务器处于被动等待状态，整个系统的使用效率只有 50%。 2) 双机互为备份模式在双机互为备份的模式中，平时，两台服务器均为在线服务器，它们各自完成自己的任务，例如，一台作为数据库服务器，另一台作为电子邮件服务器。为了实现两者互为备份，在两台服务器之间，应通过某种专线连接起来。如果希望两台服务器之间能相距较远，最好利用 FDDI 单模光纤来连接两台服务器，在此情况下，最好再通过路由器将两台服务器互连起来，作为备份通信线路。在互为备份的模式中，最好在每台服务器内都配置两台硬盘，一个用于装载系统程序和应用程序，另一个用于接收由另一台服务器发来的备份数据，作为该服务器的镜像盘。在正常运行时，镜像盘对本地用户是锁死的，这样就较易于保证在镜像盘中数据的正确性。如果仅有一个硬盘，则可用建立虚拟盘的方式或分区方式来分别存放系统程序和应用程序，以及另一台服务器的备份数据。如果通过专线链接检查到某台服务器发生了故障，此时，再通过路由器去验证这台服务器是否真的发生了故障。如果故障被证实，则由正常服务器向故障服务器的客户机发出广播信息，表明要进行切换。连接到故障服务器上的客户机在切换过程中会感觉到网络服务器的短暂停顿。在切换成功后，客户机无需重新登录便可继续使用网络提供的服务和访问服务器上的数据。而对于接在非故障服务器上的客户机，则只会感觉到网络服务稍有减慢而已，不会有任何影响。当故障服务器修复并重新连到网上后，已被迁移到无故障服务器上的服务功能将被返回，恢复正常工作。这种模式的优点是两台服务器都可用于处理任务，因而系统效率较高，现在已将这种模式从两台机器扩大到 4 台、8 台、16 台甚至更多。系统中所有的机器都可用于处理任务，当其中一台发生故障时，系统可指定另一台机器来接替它的工作。 3) 公用磁盘模式为了减少信息复制的开销，可以将多台计算机连接到一台公共的磁盘系统上去。该公共磁盘被划分为若干个卷。每台计算机使用一个卷。如果某台计算机发生故障，此时系统将重新进行配置，根据某种调度策略来选择另一台替代机器，后者对发生故障的机器的卷拥有所有权，从而来接替故障计算机所承担的任务。这种模式的优点是：消除了信息的复制时间，因而减少了网络和服务器的开销。数据一致性控制数据一致性，是数据应用中必须解决的一个重要问题。事实上，只要把一个数据分别存储到多个文件中时，便可能使数据一致性出现问题。为了保证在不同文件中所存储的同一个数据相一致，在现代操作系统乃至数据库系统中，都配置了能保证数据一致性的软件，以及相应的支持硬件。硬件支持主要是要求在系统中能配置一个高度可靠的存储器系统，或称之为稳定存储器(Stable Storage)。实现一个稳定存储器的措施是采用冗余技术。亦即，将一份信息同时存放在多个独立的、非易失性存储器(Nonvolatile Storage)上。目前，广泛采用磁盘双工方式来实现稳定存储器。事务事务是用于访问和修改各种数据项的一个程序单位。事务也可以被看做是一系列相关读和写操作。被访问的数据可以分散地存放在同一文件的不同记录中，也可放在多个文件中。只有对分布在不同位置的同一数据所进行的读和写(含修改)操作全部完成时，才能再以托付操作(Commit Operation)来终止事务。只要有一个读、写或修改操作失败，便须执行夭折操作(Abort Operation)。读或写操作的失败可能是由于逻辑错误，也可能是系统故障所导致的。一个夭折的事务，通常已执行了一些操作，因而可能已对某些数据做了修改。为使夭折的事务不会引起数据的不一致性，须将该事务内刚被修改的数据项恢复成原来的情况，使系统中各数据项与该事务未执行时的数据项内容完全相同。此时，可以说该事务“已被退回”(rolled back)。不难看出，一个事务在对一批数据执行修改操作时，要么全部完成，并用修改后的数据去代替原来的数据，要么一个也不修改。事务操作所具有的这种特性，就是“原子性”。 事务记录为了实现上述的原子修改，通常须借助于称为事务记录的数据结构来实现。这些数据结构被放在稳定存储器中，用来记录在事务运行时数据项修改的全部信息，故又称为运行记录(Log)。该记录中包括有下列字段: 事务名：用于标识该事务的惟一名字； 数据项名：指被修改数据项的惟一名字； 旧值：修改前数据项的值； 新值：修改后数据项将具有的值。在事务记录表中的每一记录，描述了在事务运行中的重要事务操作，如修改操作、开始事务、托付事务或夭折事务等。 恢复算法由于一组被事务 Ti 修改的数据以及它们被修改前和修改后的值都能在事务记录表中找到，因此，利用事务记录表，系统能处理任何故障而不致使故障造成非易失性存储器中信息的丢失。恢复算法可利用以下两个过程: (1) undo〈Ti〉。该过程把所有被事务 Ti 修改过的数据恢复为修改前的值。 (2) redo〈Ti〉。该过程把所有被事务 Ti 修改过的数据设置为新值。如果系统发生故障，系统应对以前所发生的事务进行清理。通过查找事务记录表，可以把尚未清理的事务分成两类。一类是其所包含的各类操作都已完成的事务。确定为这一类事务的依据是，在事务记录表中，既包含了〈Ti 开始〉记录，又包含了〈Ti 托付〉记录。此时系统利用 redo〈Ti〉过程，把所有已被修改的数据设置成新值。另一类是其所包含的 各个操作并未全部完成的事务。对于事务 Ti，如果在 Log 表中只有〈Ti 开始〉记录而无 〈 Ti托付〉记录，则此 Ti 便属于这类事务。此时，系统便利用 undo〈Ti〉过程，将所有已被修改的数据，恢复为修改前的值。检查点如前所述，当系统发生故障时，必须去检查整个 Log 表，以确定哪些事务需要利用 redo〈Ti〉过程去设置新值，而哪些事务需要利用undo〈Ti〉过程去恢复数据的旧值。由于在系统中可能存在着许多并发执行的事务，因而在事务记录表中就会有许多事务执行操作的记录。随着时间的推移，记录的数据也会愈来愈多。因此，一旦系统发生故障，在事务记录表中的记录清理起来就非常费时。引入检查点的主要目的，是使对事务记录表中事务记录的清理工作经常化，即每隔一定时间便做一次下述工作：首先是将驻留在易失性存储器(内存)中的当前事务记录表中的所有记录输出到稳定存储器中；其次是将驻留在易失性存储器中的所有已修改数据输出到稳定存储器中；然后是将事务记录表中的〈检查点〉记录输出到稳定存储器中；最后是每当出现一个〈检查点〉记录时，系统便执行上小节所介绍的恢复操作，利用 redo和 undo 过程实现恢复功能。如果一个事务 Ti 在检查点前就做了托付，则在事务记录表中便会出现一个在检查点记录前的〈Ti托付〉记录。在这种情况下，所有被 Ti 修改过的数据，或者是在检查点前已写入稳定存储器，或者是作为检查点记录自身的一部分写入稳定存储器中。因此，以后在系统出现故障时，就不必再执行 redo 操作了。 新的恢复算法在引入检查点后，可以大大减少恢复处理的开销。因为在发生故障后，并不需要对事务记录表中的所有事务记录进行处理，而只需对最后一个检查点之后的事务记录进行处理。因此，恢复例程首先查找事务记录表，确定在最近检查点以前开始执行的最后的事务 Ti。在找到这样的事务后，再返回去搜索事务记录表，便可找到第一个检查点记录，恢复例 程便从该检查点开始，返回搜索各个事务的记录，并利用 redo 和 undo 过程对它们进行处理。如果把所有在事务 Ti 以后开始执行的事务表示为事务集 T，则新的恢复操作要求是: 对所有在 T 中的事务 TK，如果在事务记录表中出现了〈TK 托付〉记录，则执行 redo〈TK〉操作；反之，如果在事务记录表中并未出现〈TK托付〉记录，则执行undo〈TK〉操作。并发控制在多用户系统和计算机网络环境下，可能有多个用户在同时执行事务。由于事务具有原子性，这使各个事务的执行必然是按某种次序依次执行的，只有在一个事务执行完后，才允许另一事务执行，即各事务对数据项的修改是互斥的。人们把这种特性称为顺序性(Serializability)。把用于实现事务顺序性的技术称为并发控制(Concurrent Control)。虽然可以利用信号量机制来保证事务处理的顺序性(例如，令所有的事务共享一互斥信号量，每当一事务开始执行时，便执行 wait(mutex)操作，在事务正常或异常结束时，再执行 signal(mutex)操作)，但在数据库系统和文件服务器中，应用得最多的还是较简单且较灵活的同步机制——锁。 利用互斥锁实现“顺序性”实现顺序性的一种最简单的方法是，设置一种用于实现互斥的锁，简称为互斥锁(Exclusive Lock)。在利用互斥锁实现顺序性时，应为每一个共享对象设置一把互斥锁。当一事务 Ti要去访问某对象时，应先获得该对象的互斥锁。若成功，便用该锁将该对象锁住，于是事务 Ti 便可对该对象执行读或写操作；而其它事务由于未能获得该锁而不能访问该对象。如果 Ti需要对一批对象进行访问，则为了保证事务操作的原子性，Ti 应先获得这一批对象的互斥锁，以将这些对象全部锁住。如果成功，便可对这一批对象执行读或写操作；操作完成后又将所有这些锁释放。但如果在这一批对象中的某一个对象已被其它事物锁住，则此时 Ti 应对此前已被 Ti 锁住的其它对象进行开锁，宣布此次事务运行失败，但不致引起数据的变化。 利用互斥锁和共享锁实现顺序性利用互斥锁实现顺序性的方法简单易行。目前有不少系统都是采用这种方法来保证事务操作的顺序性，但这却存在着效率不高的问题。因为一个共享文件虽然只允许一个事务去写，但却允许多个事务同时去读；而在利用互斥锁来锁住文件后，则只允许一个事务去读。为了提高运行效率而又引入了另一种形式的锁——共享锁(Shared Lock)。共享锁与互斥锁的区别在于: 互斥锁仅允许一个事务对相应对象执行读或写操作，而共享锁则允许多个事务对相应对象执行读操作，不允许其中任何一个事务对对象执行写操作。在为一个对象设置了互斥锁和共享锁的情况下，如果事务 Ti 要对 Q 执行读操作，则只需去获得对象 Q 的共享锁。如果对象 Q 已被互斥锁锁住，则 Ti 必须等待；否则，便可获得共享锁而对 Q 执行读操作。如果 Ti 要对 Q 执行写操作，则 Ti 还须去获得 Q 的互斥锁。若失败，须等待；否则，可获得互斥锁而对 Q 执行写操作。利用共享锁和互斥锁来实现顺序性的方法，非常类似于读者—写者问题的解法。重复数据的数据一致性问题为了保证数据的安全性，最常用的做法是把关键文件或数据结构复制多份，分别存储在不同的地方，当主文件(数据结构)失效时，还有备份文件(数据结构)可以使用，不会造成数据丢失，也不会影响系统工作。显然，主文件(数据结构)中的数据应与各备份文件中的对应数据相一致。此外，还有些数据结构(如空闲盘块表)在系统运行过程中，总是不断地对它进行修改，因此，同样应保证不同处的同一数据结构中数据的一致性。 重复文件的一致性在有重复文件时，如果一个文件拷贝被修改，则必须也同时修改其它几个文件拷贝，以保证各相应文件中数据的一致性。这可采用两种方法来实现： 第一种方法是当一个文件被修改后，可查找文件目录，以得到其它几个拷贝的索引结点号，再从这些索引结点中找到各拷贝的物理位置，然后对这些拷贝做同样的修改； 第二种方法是为新修改的文件建立几个拷贝，并用新拷贝去取代原来的文件拷贝。 盘块号一致性的检查如果正在修改时，机器突然发生故障，此时也会使盘块数据结构中的数据产生不一致性现象。因此，在每次启动机器时，都应该检查相应的多个数据结构，看它们之间是否保持了数据的一致性。为了保证盘块数据结构(中数据)的一致性，可利用软件方法构成一个计数器表，每个盘块号占一个表项，可有0，…，N-1 项，N 为盘块总数。每一个表项中包含两个计数器，分别用作空闲盘块号计数器和数据盘块号计数器。分配时对空闲块号进行计数，写好数据后再对该块号进行数据块号计数，如此可以保证分配和写入过程的完整完成，如果出现错误，这该过程将不会完成，那么这两个计数就不会都完成。如果情况正常，则上述两组计数器中对应的一对(计数器中的)数据应该互补，亦即，若 某个盘块号在被第一组计数器进行计数后，使该盘块号计数器为 1，则在第二组计数器中相应盘块号计数器中的计数必为 0；反之亦然。但如果情况并非如此，则说明发生了某种错误。 链接数一致性检查在 UNIX 类型的文件目录中，其每个目录项内都含有一个索引结点号，用于指向该文件的索引结点。对于一个共享文件，其索引结点号会在目录中出现多次。另一方面，在该共享文件的索引结点中有一个链接计数 count，用来指出共享本文件的用户(进程)数。在正常情况下这两个数据应该一致，否则就会出现数据不一致性差错。为了检查这种数据不一致性差错，同样要配置一张计数器表，此时应是为每个文件而不是为每个盘块建立一个表项，其中含有该索引结点号的计数值。在进行检查时，从根目录开始查找，每当在目录中遇到该索引结点号时，便在该计数器表中相应文件的表项上加1。当把所有目录都检查完后，便可将该计数器表中每个表项中的索引结点号计数值与该文件索引结点中的链接计数count值加以比较，如果两者一致，表示是正确的；否则，便是产生了链接数据不一致的错误。如果索引结点中的链接计数 count 值大于计数器表中相应索引结点号的计数值，则 即使在所有共享此文件的用户都不再使用此文件时，其 count 值仍不为 0，因而该文件不会被删除。这种错误的后果是使一些已无用户需要的文件仍驻留在磁盘上，浪费了存储空间。当然这种错误的性质并不严重。解决的方法是用计数器表中的正确的计数值去为 count 重新赋值。反之，如果出现 count 值小于计数器表中索引结点号计数值的情况时，就有潜在的危险。假如有两个用户共享一个文件，但是 count 值仍为 1，这样，只要其中有一个用户不再需要此文件时，count 值就会减为 0，从而使系统将此文件删除，并释放其索引结点及文件所占用的盘块，导致另一共享此文件的用户所对应的目录项指向了一个空索引结点，最终是使该用户再无法访问此文件。如果该索引结点很快又被分配给其它文件，则又会带来潜在的危险。解决的方法是将 count 值置为正确值。虚拟文件系统操作系统接口操作系统是用户与计算机硬件系统之间的接口，用户通过操作系统的帮助，可以快速、有效和安全、可靠地操纵计算机系统中的各类资源，以处理自己的程序。为使用户能方便地使用操作系统，OS又向用户提供了如下两类接口：(1) 用户接口：操作系统专门为用户提供了“用户与操作系统的接口”，通常称为用户接口。该接口支持用户与OS之间进行交互，即由用户向OS请求提供特定的服务，而系统则把服务的结果返回给用户。(2) 程序接口：操作系统向编程人员提供了“程序与操作系统的接口”，简称程序接口，又称应用程序接口API(Application Programming Interface)。该接口是为程序员在编程时使用的，系统和应用程序通过这个接口，可在执行中访问系统中的资源和取得OS的服务，它也是程序能取得操作系统服务的惟一途径。大多数操作系统的程序接口是由一组系统调用(system call)组成，每一个系统调用都是一个能完成特定功能的子程序。值得说明的是，在计算机网络中，特别是在Internet广为流行的今天，又出现了一种面向网络的网络用户接口。系统调用程序接口是OS专门为用户程序设置的，也是用户程序取得OS服务的唯一途径。程序接口通常是由各种类型的系统调用所组成的，因而，也可以说，系统调用提供了用户程序和操作系统之间的接口，应用程序通过系统调用实现其与OS的通信，并可取得它的服务。系统调用不仅可供所有的应用程序使用，而且也可供OS自身的其它部分，尤其是命令处理程序使用。在每个系统中，通常都有几十条甚至上百条的系统调用，并可根据其功能而把它们划分成若干类。例如，有用于进程控制(类)的系统调用和用于文件管理(类)、设备管理(类)及进程通信等类的系统调用。系统态和用户态在计算机系统中，通常运行着两类程序：系统程序和应用程序，为了保证系统程序不被应用程序有意或无意地破坏，为计算机设置了两种状态：系统态(也称为管态或核心态)和用户态(也称为目态)。操作系统在系统态运行，而应用程序只能在用户态运行。在实际运行过程中，处理机会在系统态和用户态间切换。相应地，现代多数操作系统将CPU的指令集分为特权指令和非特权指令两类。 1) 特权指令所谓特权指令，就是在系统态时运行的指令，是关系到系统全局的指令。其对内存空间的访问范围基本不受限制，不仅能访问用户存储空间，也能访问系统存储空间，如启动各种外部设备、设置系统时钟时间、关中断、清主存、修改存储器管理寄存器、执行停机指令、转换执行状态等。特权指令只允许操作系统使用，不允许应用程序使用，否则会引起系统混乱。 2) 非特权指令非特权指令是在用户态时运行的指令。一般应用程序所使用的都是非特权指令，它只能完成一般性的操作和任务，不能对系统中的硬件和软件直接进行访问，其对内存的访问范围也局限于用户空间。这样，可以防止应用程序的运行异常对系统造成的破坏。这种限制是由硬件实现的，如果在应用程序中使用了特权指令，就会发出权限出错信号，操作系统捕获到这个信号后，将转入相应的错误处理程序，并将停止该应用程序的运行，重新调度。系统调用的基本概念通常，在OS的核心中都设置了一组用于实现各种系统功能的子程序(过程)，并将它们提供给应用程序调用。由于这些程序或过程是OS系统本身程序模块中的一部分，为了保护操作系统程序不被用户程序破坏，一般都不允许用户程序访问操作系统的程序和数据，所以也不允许应用程序采用一般的过程调用方式来直接调用这些过程，而是向应用程序提供了一系列的系统调用命令，让应用程序通过系统调用去调用所需的系统过程。系统调用在本质上是应用程序请求OS内核完成某功能时的一种过程调用，但它是一种特殊的过程调用，它与一般的过程调用有下述几方面的明显差别：(1) 运行在不同的系统状态。一般的过程调用，其调用程序和被调用程序都运行在相同的状态——系统态或用户态；而系统调用与一般调用的最大区别就在于：调用程序是运行在用户态，而被调用程序是运行在系统态。(2) 状态的转换通过软中断进入。由于一般的过程调用并不涉及到系统状态的转换，可直接由调用过程转向被调用过程。但在运行系统调用时，由于调用和被调用过程是工作在不同的系统状态，因而不允许由调用过程直接转向被调用过程。通常都是通过软中断机制，先由用户态转换为系统态，经核心分析后，才能转向相应的系统调用处理子程序。(3) 返回问题。在采用了抢占式(剥夺)调度方式的系统中，在被调用过程执行完后，要对系统中所有要求运行的进程做优先权分析。当调用进程仍具有最高优先级时，才返回到调用进程继续执行；否则，将引起重新调度，以便让优先权最高的进程优先执行。此时，将把调用进程放入就绪队列。(4) 嵌套调用。像一般过程一样，系统调用也可以嵌套进行，即在一个被调用过程的执行期间，还可以利用系统调用命令去调用另一个系统调用。当然，每个系统对嵌套调用的深度都有一定的限制，例如最大深度为6。但一般的过程对嵌套的深度则没有什么限制。中断机制：系统调用是通过中断机制实现的，并且一个操作系统的所有系统调用都通过同一个中断入口来实现。 应用程序通过该中断获取操作系统的服务。对于拥有保护机制的操作系统来说，中断机制本身也是受保护的，只有授权给应用程序保护等级的中断号，才是可以被应用程序调用的。对于未被授权的中断号，如果应用程序进行调用，同样会引起保护异常，而导致自己被操作系统停止。系统调用的实现通常，一个 OS所具有的许多功能，可以从其所提供的系统调用上表现出来。显然，由于各OS的性质不同，在不同的OS中所提供的系统调用之间也会有一定的差异。对于一般通用的OS而言，可将其所提供的系统调用分为：进程控制、文件操纵、通信管理和系统维护等几大类。系统调用的实现与一般过程调用的实现相比，两者间有很大差异。对于系统调用，控制是由原来的用户态转换为系统态，这是借助于中断和陷入机制来完成的，在该机制中包括中断和陷入硬件机构及中断与陷入处理程序两部分。当应用程序使用OS的系统调用时，产生一条相应的指令，CPU 在执行这条指令时发生中断，并将有关信号送给中断和陷入硬件机构，该机构收到信号后，启动相关的中断与陷入处理程序进行处理，实现该系统调用所需要的功能。中断和陷入硬件机构中断是指 CPU 对系统发生某事件时的这样一种响应: CPU暂停正在执行的程序，在保留现场后自动地转去执行该事件的中断处理程序；执行完后，再返回到原程序的断点处继续执行。还可进一步把中断分为外中断和内中断。所谓外中断，是指由于外部设备事件所引起的中断，如通常的磁盘中断、打印机中断等；而内中断则是指由于 CPU 内部事件所引起的中断，如程序出错(非法指令、地址越界)、电源故障等。内中断(trap)也被译为“捕获”或“陷入”。通常，陷入是由于执行了现行指令所引起的；而中断则是由于系统中某事件引起的，该事件与现行指令无关。由于系统调用引起的中断属于内中断，因此把由于系统调用引起中断的指令称为陷入指令。中断和陷入向量：为了处理上的方便，通常都是针对不同的设备编制不同的中断处理程序，并把该程序的入口地址放在某特定的内存单元中。此外，不同的设备也对应着不同的处理机状态字 PSW，且把它放在与中断处理程序入口指针相邻接的特定单元中。在进行中断处理时，只要有了这样两个字，便可转入相应设备的中断处理程序，重新装配处理机的状态字和优先级，进行对该设备的处理。因此，我们把这两个字称为中断向量。相应地，把存放这两个字的单元称为中断向量单元。类似地，对于陷入，也有陷入向量，不同的系统调用对应不同的陷入向量，在进行陷入处理时，根据陷入指令中的陷入向量，转入实现相应的系统调用功能的子程序，即陷入处理程序。由所有的中断向量和陷入向量构成了中断和陷入向量表。系统调用的处理步骤在设置了系统调用号和参数后，便可执行一条系统调用命令。不同的系统可采用不同的执行方式。在 UNIX系统中，是执行 CHMK 命令；而在 MS-DOS 中则是执行 INT 21 软中断。系统调用的处理过程可分成以下三步：首先，将处理机状态由用户态转为系统态；之后，由硬件和内核程序进行系统调用的一般性处理，即首先保护被中断进程的CPU环境，将处理机状态字 PSW、程序计数器 PC、系统调用号、用户栈指针以及通用寄存器内容等，压入堆栈；然后，将用户定义的参数传送到指定的地址保存起来。其次，是分析系统调用类型，转入相应的系统调用处理子程序。为使不同的系统调用能方便地转向相应的系统调用处理子程序，在系统中配置了一张系统调用入口表。表中的每个表目都对应一条系统调用，其中包含该系统调用自带参数的数目、系统调用处理子程序的入口地址等。因此，核心可利用系统调用号去查找该表，即可找到相应处理子程序的入口地址而转去执行它。最后，在系统调用处理子程序执行完后，应恢复被中断的或设置新进程的 CPU 现场，然后返回被中断进程或新进程，继续往下执行。系统调用处理子程序的处理过程系统调用的功能主要是由系统调用子程序来完成的。对于不同的系统调用，其处理程序将执行不同的功能。我们以一条在文件操纵中常用的Creat命令为例来说明之。进入 Creat 的处理子程序后，核心将根据用户给定的文件路径名 Path，利用目录检索过程去查找指定文件的目录项。查找目录的方式可以用顺序查找法，也可用 Hash 查找法。 如果在文件目录中找到了指定文件的目录项，表示用户要利用一个已有文件来建立一个新文件。 但如果在该已有(存)文件的属性中有不允许写属性，或者创建者不具有对该文件进行修改的权限，便认为是出错而做出错处理； 若不存在访问权限问题，便将已存文件的数据盘块释放掉，准备写入新的数据文件。 如未找到指名文件，则表示要创建一个新文件，核心便从其目录文件中找出一个空目录项，并初始化该目录项，包括填写文件名、文件属性、文件建立日期等，然后将新建文件打开。" }, { "title": "计算机网络基础", "url": "/2016/10/internet-basic.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2016-10-11 01:01:18 +0800", "snippet": " 计算机网络是计算机技术和通信技术的深度结合，本博客将从通信技术的角度和设计层面以及居高临下的视角对计算机网络进行深度讲解。计算机网络除了利用物理性质和数学编码实现了二进制数字信号和对不同二进制组合进行不同的解读外，剩下就是标准制定的问题了，换句话说，就是设计层面的问题，也是逻辑设定的问题。本文只是基础章节，不涉及到过多细节，但会尽量从宏观视野出发以在迷路过程中充当指南针的角色。 计算机...", "content": " 计算机网络是计算机技术和通信技术的深度结合，本博客将从通信技术的角度和设计层面以及居高临下的视角对计算机网络进行深度讲解。计算机网络除了利用物理性质和数学编码实现了二进制数字信号和对不同二进制组合进行不同的解读外，剩下就是标准制定的问题了，换句话说，就是设计层面的问题，也是逻辑设定的问题。本文只是基础章节，不涉及到过多细节，但会尽量从宏观视野出发以在迷路过程中充当指南针的角色。 计算机网络概述 计算机网络分类 计算机网络元素 网络节点 传输链路 协议 计算机网络体系结构 层的划分 五层协议的体系结构 分层模型中基本概念 物理层 通信基础基础 有关信道的基本概念 数字数据的数字传输 基带传输 频带传输 模拟数据的数字传输 数据同步方式 信道的多路复用技术 宽带接入技术 数据链路层 基本概念 链路层协议 三个基本问题 比特差错检测方法 PPP 协议 使用广播信道的数据链路层 CSMA/CD 协议 以太网 以太网的信道利用率 以太网的 MAC 层 MAC 帧的格式 扩展以太网 在物理层拓展以太网 在数据链路层扩展以太网 虚拟局域网 无线局域网 网络层 网络层提供的两种服务 虚电路 无连接的数据报服务 网际协议 IP 分类的 IP 地址 划分子网 构造超网 IP 地址与硬件地址的联系 ARP 和 RARP IP 数据报格式 IP 层转发分组的流程 ICMP 协议 ICMP 报文的种类 路由选择协议 分层次的路由选择协议 路由选择算法的理论基础 优化原则 最短路径 泛洪算法 内部网关协议 RIP RIP 特点 距离向量算法 RIP 协议的报文格式 内部网关协议 OSPF OSPF 算法 OSPF 与 RIP 的对比： OSPF 报文格式 外部网关协议 BGP 路由器 广播路由 无控制洪泛 受控洪泛 生成树广播 IP 多播（组播） 硬件多播 IGMP 和多播路由 多播路由选择协议 虚拟专用网 VPN 网络地址转换 NAT 传输层 传输层概述 传输协议概述 UDP 可靠传输的工作原理 停止-等待协议 连续 ARQ 协议 TCP TCP 首部格式 TCP 可靠传输的实现 必须考虑传输效率 TCP 的拥塞控制 慢开始和拥塞避免 随机早期检测 RED TCP 的运输连接管理 TCP 的链接建立 TCP 的连接释放 TCP 的有限状态机 应用层 域名系统 DNS DNS 名字空间 域名服务器 域名解析过程 文件传送协议 FTP 远程终端协议 TELNET 计算机网络概述计算机网络是计算机技术与通信技术相集合的产物，或者说是用通信介质将多台计算机连接起来所形成的计算机系统。这里的连接有两重含义： 通过传输介质和传输设备建立的物理上的连接； 由一些网络软件实现的逻辑上的连接。之所以要进行连接，是为了实现下列功能： 通信：计算机间的数据传送。 资源共享：即实现计算机硬件、软件资源和信息资源的异地互用。 提高计算机系统的可靠性：在计算机网络中各台计算机网络中各台计算机间可以互为后备，从而提高了计算机系统的可靠性。计算机网络分类计算机网络是一种复杂的系统。可以从不同的角度对计算机网络进行分类。 按拓扑结构分类从拓扑学的观点，网络是由一组节点（node）和连接节点的链路（link）组成。在计算机网络中，计算机作为节点，连接计算机的通信线路作为链路，形成计算机的地理分布和互连关系上的几何排序（几何构形）。这种计算机与链路之间的拓扑关系，称为计算机网络的拓扑结构。计算机网络的拓扑结构有许多种。但是，按照网络中一条链路所能连接的计算机的台数，可以把计算机网络归结为两大类：链路型网络（点到点的结构）和广播型网络（多点共享链路结构）。（１）链路型网络（点到点的结构）在点到点的结构中，一条链路只能连接两个节点。这样，两点之间要么直接通信，要么必须通过中间节点转发。 星型结构：其拓扑特点是，中央节点与多条链路连接，其余节点只与一条链路连接。由于各外围节点分别用线缆与中央节点直接连接，因而在星型结构中数据的传输不会在线路上发生碰撞，并且系统比较容易扩充，但中央节点会成为系统的“瓶颈”和可靠工作的最薄弱环节。 树型结构树型结构的特点是网络中有多个中心节点，但主要的数据流通是在网络的各分支之间进行，形成一种分级管理的集中式网络，适宜于各种管理部门进行分级数据传送的场合。其拓扑特点是，多个中心节点与多条链路连接，其余节点（末端节点）只与一条链路连接。树型结构的优点是连接容易、管理简单、维护方便，缺点是共享能力差、可靠性低。 环型结构其拓扑特点是，每一个节点都与两条链路连接。在这种结构中，任意两点之间形成两条路径，当某一链路有故障时，还可以通过另一条路径进行通信。 格状结构格状结构是所有节点具有两个或两个以上直接通路的拓扑结构。 全互连结构全互连结构是所有节点之间都有直接通路的拓扑结构。格状结构和全互连结构也称网状结构，具有较高的可靠性，但网络结构复杂，链路多，投资大。(２）广播型网络广播型网络的特点是，通信线路为多个节点共享。这样，一个节点发送的信息可以传输到其他所有的节点；而当有两个以上节点同时发送信息时，便会引起冲突。总线型结构是一种应用最普遍的广播型网络拓扑结构。在总线型结构中各个计算机网络节点的设备用一根总线挂接起来。总线型结构目前在局域网中应用很广，有如下一些特点： 节点的插入或拆卸方便，易于扩充； 不需要中央控制器，有利于分布式控制，某个节点发生故障时对整个系统影响很小，网络的可靠性高； 总线自身的故障对系统是毁灭性的，因而要求较高的安装质量。 按覆盖地域分类网络按照其覆盖地域的大小可以分为微微网（Piconet，使用蓝牙技术）、个人局域网（PAN，Personal Area Network，使用无线电技术）、局域网（LAN，Local Area Network）、城域网（MAN，Metropolitan Area Network）和广域网（WAN，Wide Area Network）。 按照网络中主机的台数分类这是 Internet 中根据 IP 地址数的分类方法，它按主机台数将网络分为Ａ、Ｂ、Ｃ三类，对应大型网络、中型网络和小型网络。 其他分类方法 按使用权限：公用网和专用网（私用网） 按操作系统及其版本分类：如 UNIX 网 按所用技术分类：如 x.25、帧中继网、ATM 等 按使用介质：如 无线网、光纤网等 按业务范围：如校园网、企业网、金桥网、教育科研网、经济网、科技网、医卫网等计算机网络元素从平面拓扑结构的角度，可以认为节点、链路构成了网络的平面结构（节点的分布和连接）；从分层的垂直结构的角度，可以认为协议（协议栈）、服务、接口等构成了网络的垂直结构（可以认为是节点的垂直剖析）。网络节点在复杂的网络中进行数据传输，从源节点往往要经过多个中间节点才能传送到目的节点。中间节点大致有４种：端节点、中继节点、交换节点和路由节点。 端节点端节点是进行数据处理的节点。在计算机网络中，这些节点应当具有两种功能：数据处理（数据终端设备 DTE）和通信（数据通信设备 DCE） 。数据终端设备ＤＴＥ为具有一定数据处理能力的发送、接收设备，如计算机或各种终端设备；数据通信设备ＤＣＥ为通信接口设备，在ＤＴＥ与通信网之间提供信号变换及编码功能，并负责建立、维护和释放物理连接，如波形变换器、基带传输器、调制解调器等。 中继节点信号在介质中传输时，随着传输距离的增加，幅度将会逐渐衰减，波形将会产生失真。中继器（Repeater）用于同类网络介质之间的互连，起到信号再生、放大作用。再生就是通过对失真的但仍可以辨认的波形的分析，重新生成原来的波形；放大就是将信号衰减了的幅度加以恢复。通过再生和放大能够使网络传输的距离范围得以扩大。中继有一通一的中继和一通多的中继。应当强调的是，经过集线器的信号都是重新整理过后再传送出去。不同的通信介质有不同的中继器。 交换节点一个通信过程往往要 经过多条 链路之间 的转接才 能实现。转接由 交换（Switching）节点实现。简单地说，交换节点的功能是将一条链路上送来的数据有选择地转送到另外的一条链路上。复杂拓扑结构网络中的通信信道就是经过多个中间节点的转发—连接而实现的。 路由节点路由节点是一种特殊的节点。它位于网络之间，起连接网络的作用，属于所连接的网络共有。正是由于路由节点，才使互联网得以形成。如果把每个网络看成一个通路———链路，那么路由节点的分布就形成了互联网络的拓扑结构或框架。路由器的网络连接功能主要体现在它能为到达的数据选择到达目的节点的路由。这就是路由节点称为路由器（Router）的原因。路由和交换虽然具有相似之处，但是是在不同的层次中实现的。传输链路传输链路是网络中连接两个节点的直接信息通路，简称链路（Link）。数据在计算机网络中传输，往往要经过多条链路一段一段地传输。中间可能经过中继节点，也可能经过交换节点。链路可能是物理的，也可能是逻辑的。采用多路复用技术可以把一条物理链路划分成多条逻辑链路。通信介质就是搭载信号的传输媒介，是链路的物理基础。通信介质分为硬介质（双绞线电缆、同轴电缆、光缆等）和软介质（即空间介质，如微波通信、卫星通信、红外通信等）。协议凡是两个以上的对象或系统相互进行联系，都需要建立联系的规则或约定。这些为了通信或联系所制定的约定、规则和标准就被称为协议（Protocol）。实际上，人类的每一种语言都是一种协议。协议存在于任何通信过程中，它包含了所传输信息的格式（语法）、语义和定时（传输顺序）三个方面的约束。协议的基本功能在计算机网络中，协议的目的是确保通信过程顺利、安全、可靠地进行，因此它的基本功能有以下几点： 分割与组装：在通信网络中，为了提高传输效率以及克服传输能力的限制，在发送端要将报文分割成一些适合网络传输的数据包———分组，并在分组时加上控制信息；在接收端要将数据分组重新组装成报文。 规定格式和特性：规定数据格式，规定网络接口的机械、物理、功能和规程特性等。 传输服务：不同的通信系统有不同的传输服务。 传输控制：包括流量控制、差错控制和连接控制。流量控制用于控制数据传输过程中发送方的发送速度和数量，解决信道上的拥塞问题；差错控制用于减少、检测和纠正错误；连接控制用于通信实体间连接的建立或拆除。协议的实现网络协议通常是由网卡和网络操作系统共同实现的。 网卡网卡是网络设备（如工作站、服务器等）与网络的通信介质进行连接服务的设备。网络正常工作时，网卡通过通信介质的端口监视网络的状态，接收传输介质上的信号。当网卡接收到有效的数字信号时，网卡会判断是否发给本站（是，则将数据通过网络设备的接口传输到网络设备；否则放弃或按原方向转发）；另一方面，要适时将所连设备需发送的数据发送到网上，以实现网络设备间的通信。 网络操作系统网络操作系统（NOS，Network Operating System）是网络用户与通信网络之间的接口。计算机网络体系结构计算机网络的各层及其协议的集合，称为网络的体系结构。换句话说，计算机网络的体系结构就是这个计算机网络及其构件所应完成的功能的精确定义。但是，这些功能究竟是用何种硬件或软件完成的，则是一个遵循这种体系结构的实现的问题。 体系结构是抽象的，而实现则是具体的，是真正在运行的计算机硬件和软件。层的划分前面提到了计算机网络体系涉及到层和协议，其中协议已经讲过了，现在来看下层的划分。当一个问题很复杂时就应考虑模块化或分层等问题了，因为这样可以使问题得到简化。分层带来的好处列举如下： 各层之间是独立的 灵活性好：当任何一层发生变化时，只要层间接口关系保持不变，则在这层以上或以下各层均不受影响。因为层中协议的具体实现对上下层是透明的，这有服务（通过层间接口实现）时可见的。 结构上可分隔开：各层都可以采用最合适的技术来实现。 易于实现和维护。 能促进标准化工作。分层时应注意使每一层的功能非常明确。若层数太少，就会使每一层的协议太复杂，但层数太多又会在描述和综合各层功能的系统工程任务时遇到较多的困难。通常各层所要完成的功能主要有以下一些（可以根据需要选择）： 差错控制：使得和网络对等端的相应层次的通信更加可靠。 流量控制：使得发送端的发送速率不要太快，要使接收端来得及接收。 分段和重装：发送端将要发送的数据块划分为更小的单位，在接收端将其还原。 复用和分用：发送端几个高层会话复用一条底层连接，在接收端再进行分用。分层当然也有一些缺点，如，有些功能会在不同的层次中重复出现，因而产生了额外开销。五层协议的体系结构OSI 七层模型和协议过于复杂，而且其中的表示层和会话层没有什么内容。而 TCP/IP 模型虽然分层不及 OSI 模型清楚，且最下面的网络接口层是一个空洞的层次，根本就没什么内容。为此，结合 OSI 的理论性和 TCP/IP 的实用性对层次划分进行折中而采用五层模型。集体见下图： 应用层：应用层是面向网络用户应用进程的，直接为用户服务的，它的数据就放在 TCP 等运输层协议数据包的”数据”部分应用程序收到”传输层”的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。“应用层”的作用，就是规定应用程序的数据格式。 运输层：运输层的任务就是负责向两个主机中进程之间的通信提供服务，使得应用层用户进程看见的就是好像在连个运输层实体之间有一条端到端的、全双工通信通路。换句话说，运输层实现了端到端（进程间）通信服务，隐藏了网络细节。 网络层：翁洛层实现了主机间（并非进程间）的通信服务。为主机通信提供了一条通路，隐藏了各个分段链路，好像就是两台主机直接通信一样。数据链路层从一条传输链路的角度来解决传输中的可靠性问题。网络层则是从整个网络的角度来处理数据传输中的有关问题，处理问题过程中需要考虑通信双方的终端节点及中间节点间的关系。 数据链路层：数据链路层实现了点对点通信。两个主机之间的数据传输，总是在一段一段的链路上传送的，而在两个相邻结点之间传送数据时直接传送的，这是就需要使用专门的链路层协议。其最重要的作用是：通过一些数据链路层协议在不太可靠的物理链路上实现可靠的数据传输。在物理层实现了透明的０、１码传输的基础上，数据链路层将加强这些原始比特的传输，使之成为一条无错的数据传输链路。 物理层：物理层并不是指连接计算机的具体物理设备或传输介质，而是指在通信设备或介质之上透明地传送比特流。具体来说，物理层协议要解决的是主机、工作站等数据终端设备与通信线路上通信设备之间的接口问题。分层模型中基本概念 实体：实体表示任何可发送或接收信息的硬件或软件进程。 协议：协议是控制两个(或多个)对等实体进行通信的规则的集合。 服务：协议的实现保证了能够向上一层提供服务。使用本层服务的实体只能看见服务而无法看见下面的协议。下面的协议对上面的实体是透明的。服务就好像是面向对象语言中的抽象数据类型或者对象，它定义了在对象上可以执行的操作，但是并没有说明如何实现这些操作。而协议与服务的具体实现有关，它对于服务的用户是完全不可见的。物理层物理层考虑的是怎样才能在链接各种计算机的传输媒体上传输比特流，而不是只具体的传输媒体。这很显然包括：物理信号的编码和译码、比特的产生发送传输和接收、我们知道，物理层建立在传输媒体之上，因此可以将物理层的主要任务描述为确定与传输媒体的接口有关的一些性质，如机械特性（接口形态）、电气特性（电压范围）、功能特性（电压编码）和过程特性（事件顺序）等。数据在计算机中多采用并行传输方式。但数据在通信线路上的传输方式一般都是串行传输（这是出于经济上的考虑），即逐个比特按照事件顺序传输。因此物理层还要完成传输方式的转换。通信基础基础既然物理层建立在传输媒体之上，必然会用到一些数据通信基础。该系统包括四类部件：计算机（或终端）、通信控制器、信号变换器和通信线路。其中，计算机为信源或信宿；通信控制器负责数据传输控制，以减轻主机负担，在微机一侧，它的功能一般由微机承担；信号变换器完成数据与电信号之间的变换，以匹配通信线路的信道特性，依据通信线路的不同，信号变换器称之为“波行变换器”或“调制解调器”；通信线路泛指各种使用的传输介质，是传输信号的通路。网络传输介质上一般使用串行的方式进行通信，而计算机内部则是使用并行方式进行通信的。所以有时需要进行相互转换。有关信道的基本概念信道是信源和信宿之间的通信线路，用来表示向某个方向传送信息的媒体。信道和电路并不等同，一条通信电路往往包含一条发送信道和一条接收信道。 单向通信：又称为单工通信 双向交替通信：又称为半双工通信。即通信的双方都可以发送信息，但不能双方同时发送（当然也不能同时接收）。这种通信方式是一方发送另一方接收，过一段时间后再反过来。 双向同时通信：又称为全双工通信。来自信源的信号常称为基带信号（即基本频带信号）。基带信号往往包含有较多的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。为此，就必须对基带信号进行调制。调制可分为两大类： 基带调制：仅仅对基带信号的波形进行变换，使它能够与信道特性相适应，变换后的信号仍然是基带信号。 带通调制：使用载波进行调制，把基带信号的频率范围搬移到较高的频段以便在信道中传输。经过载波调制后的信号称为带通信号（即仅在一段频率范围内能够通过信道），而使用载波的调制称为带通调制。根据载波的振幅、频率和相位随基带数字信号而变化，形成了最基本的带通调制方法：调幅（AM）、调频（FM）、调相（PM）。为了达到更高的信息传输速率，必须采用技术上更为复杂的多元制的振幅相位混合调制方法。信道的极限容量：在任何信道中，码元（通信中指的是能够被识别的波形）传输的速率是有上限的，传输速率超过此上限，就会出现严重的码间串扰的问题，是接收端对码元的判决（即识别）称为不可能。香农公式指出：信道的极限信息传输速率 C 是：从上述可知，对于频带宽度已确定的信道，如果信噪比不能再提高了，并且码元传输速率也达到了上限值，那么还有什么办法提高信息的传输速率呢？这就是用编码的方法让每一个码元携带更多比特的信息量。数字数据的数字传输用于传输数字数据的线路有数字通信线路和模拟通信线路。因此，数字数据的传输有相应的两种方式：基带传输方式和频带传输方式。基带传输数字数据以原来的 0 或 1 （一般为矩形波）的形式原封不动地在信道上传送，称为基带传输。基带传输是一种最简单的传输方式，近距离通信的局域网都采用基带传输。基带传输时，需要解决的问题是数字数据的数字信号表示。对于传输数字信号来说，最常用的方法是用不同的电压电平来表示两个二进制数字，即数字信号由矩形脉冲组成。 曼彻斯特码其特点是将每个比特周期分为两部分：前半个比特周期传送该比特的原码，后半个周期传送该比特的反码，于是在每个比特周期的中间产生一个电平跃变。这个跃变信号既可以用做同步信号，也可以用做表示数据（如图所示，用正跃变表示为“０”，用负跃变表示为“１”）。 差分曼彻斯特码它是对曼彻斯特码的的改进，它用每一码元的开始边界处有无跃变来区别“０”和“１”，如图所示，有跃变表示为“０”，无跃变表示为“１”。这时，每个比特周期中间的跃变仅仅用做同步时钟。数字信号编码方式评价指标： 脉冲宽度：脉冲宽度大，信号的能量就大，对于提高接收端的信噪比有利。 占用的频带宽度：脉冲宽，占用的频带就窄，如归零码比全宽码占用的频带要宽。 直流分量的成分：直流分量低有利于传输，如双极性码的直流分量较低，曼彻斯特码和差分曼彻斯特码的每个码元中都有跃变，因而没有直流分量。 自同步能力：曼彻斯特码和差分曼彻斯特码的每个码元中都有跃变，可以提供自同步能力。如在 IEEE 802.5 中，正常的信号编码都采用差分曼彻斯特码，只有起始和结束字段中各有４位“特殊比特”，这些特殊比特的码元中间没有跃变，要么是全高电平，要么是全低电平，以“特殊比特”来作为信号编码起始和结束的标志。其中，不归零码在传输中难以确定一位的结束和另一位的开始，需要用某种方法使发送器和接收器之间进行定时或同步；归零码的脉冲较窄，根据脉冲宽度与传输频带宽度成反比的关系，归零码在信道上占用的频带较宽；单极性码会积累直流分量，不能使用交流耦合，而且直流分量还会损坏连接点表面电镀层；双极性码的直流分量大大减少，这对数据传输是很有利的。频带传输为了利用廉价的公共电话交换网实现计算机之间的远程通信，必须将发送端的数字信号变换成能够在公共电话网上传输的音频信号，经传输后再在接收端将音频信号逆变换成对应的数字信号。实现数字信号与模拟信号互换的设备称为调制解调器。数字信号的调制实际上是用基带信号对载波波形的某些参数进行控制，而模拟信号传输的基础是载波。载波具有三大要素：幅度、频率和相位。数字数据可以针对载波不同要素或它们的组合进行调制。数字调制的三种基本形式：幅移键控法 ASK（调幅）、频移键控法 FSK（调频）、相移键控法 PSK（调相）。模拟数据的数字传输模拟数据的数字传输是利用数字信号传输系统来传输模拟信号。这就需要在发送端将模拟数据数字化，即需要进行模/数（A/D）转换；在接收端再将数字信号转换成模拟信号。通常把 A/D 转换器称为编码器，把 D/A 转换器称为译（解）码器。和调制解调器一样，编码器和解码器也常在一个设备中实现，称之为编码解码器。脉码调制 PCM是以采用定理为基础，对连续变化的模拟新华进行周期性采样，利用大于或等于有效信号最高频率或其带宽 2 倍的采样频率，通过低通滤波器从这些采样中重新构造出原始信号。模拟信号数字化的三步骤：数据同步方式数据在传输线路上传输时，为了保证发送端发送的信号能够被接收端正确无误地接收，接收端必须与发送端同步。也就是说，接收端不但要知道一组二进制位的开始与结束，还需要知道每位的持续时间，这样才能做到用合适的采样频率采样所接收到的数据。通常接收器在每位的中心进行采样，如果发送端和接收端的时钟不同步，即使只有较小的误差，随着时间的增加，误差逐渐积累，终究会造成收、发之间的失步和误读。由于发送端和接收端的时钟信号不可能绝对一致，因此必须采取一定的同步手段。实际上，同步技术直接影响着通信质量，质量不好的同步将会使通信系统不能正常工作。 主要的同步方式：位同步：位同步又称同步传输，它是使接收端对每一位数据都要和发送端保持同步。实现位同步的方法分为外同步法和自同步法两种。 外同步法：在外同步法中，接收端的同步信号事先由发送端送来，而不是自己产生也不是从信号中提取出来。即在发送数据之前，发送端先向接收端发出一串同步时钟脉冲，接收端按照这一时钟脉冲频率和时序锁定接收端的接受频率，以便在接收数据的过程中始终与发送端保持同步。外同步法中典型例子是不归零吗 NRZ， 自同步法：自同步法是指能从数据信号波形中提取同步信号的方法。典型例子就是著名的曼切斯特码和查分曼切斯特码。两种曼切斯特码具有自同步能力和良好的抗干扰性能。但每一个码元都被调成连个电平，所以数据传输速率只有调制速率的 1/2。字符同步：字符同步也叫异步传输，每次传送一个字符，具体做法是：每个字符的首末分别设一位起始位和一位（或 1.5 位或 2 位）停止位，分别表示字符的开始和结束。起始位是 0，结束位是 1，字符可以是 5 位或 8 位，一般 5 位的停止位是 1.5位，8 位字符的停止位是2 位。平时不传输字符时，传输线一直处于停止位状态，高电平。一旦检测到传输线有 1 到 0 的跳变，说明发送端开始发送字符，接收端立即应用这个电平变化启动定时机构，按发送端的顺序接收字符。待发送字符结束，发送端又使传输线处于高电平，直至下一个字符。这种方式接收始终仍应与发送时钟同步，但由于每次只接收一个字符，对接收端始终的精度要求降低了，除非时钟偏差超过 50%（这是不可能的），时钟偏差才会引起采样出错。字符同步简单、易于实现，但传输效率低，因为每个字符都要附加起始位和结束位，辅助开销比例很大。因此一般用于低速线路中，像计算机与终端、计算机与调制解调器、计算机与复用器等通信设备的连接。帧同步：帧同步以字符块为单位进行传输，一块一般由几千个数据位。为了防止发送端和接收端失步，发送时钟和接收时钟必须同步。目前一般采用自同步法，即从所接收的数据中提取时钟特征（如曼切斯特码）。为了使接收端和发送端同步，除使双方时钟同步外，还必须使接收端能准确判断出数据的开始和结束。一般的做法是在数据块前加一个一定长度的位模式，一般称为同步信号或前文（SYN，前导码），数据结束后加上后同步信号（后文）。前文、后文加上所传输的数据信息构成了一个完整的异步传输方式下的数据单位，称为帧。帧是数据链路层的数据传输单位。简单说来，帧的传输过程是这样的：接收端检测到前文后，说明发送端已开始发送数据，接收端利用从数据中提取出的时钟信号作为接收时钟，按顺序接收前文之后的数据信息，直到碰上后文为止。帧同步因为以位块为单位（几千比特），额外开销小，因此传输效率高，在数据通信中得到了广泛应用，但这种方式的缺点是发送端和接收端的控制复杂，且对线路要求较高。信道的多路复用技术在通信系统中，信道有逻辑信道与物理信道之分。物理信道是实实在在的物理通路。物理信道与逻辑信道之间的关系有点像铁路与车次之间的关系，物理信道好比是铁路，逻辑信道好比是车次。逻辑信道是建立在物理信道基础上的：一条物理信道通过载波、分时或改变连接方式等，有可能分为几条逻辑信道（好像同一条铁道上同时运行多趟列车一样）；在复杂拓扑结构的网络上，两点之间的通信并不一定要有一条专门的物理线路，而可以由其内部节点间的连接来实现。通常把逻辑信道的实现称为“连接”。多路复用指在一个物理信道上同时传送多个信号，或者说是把一个物理信道设法分成多个逻辑信道，以提高信道利用率。最基本的复用是频分复用 FDM 和时分复用 TDM。复用技术还有波分复用 WDM 和码分复用等。 频分复用频分复用 FDM 是模拟传输（频带传输）中常用的一种多路复用技术。它把一个物理信道划分为多个逻辑信道，各个逻辑信道占用互不重叠的频带（频率相差较大的波没有明显的干涉现象），相邻信道之间用“警戒频带”隔离（频率相近的波会发生干涉现象），以便将不同路的信号调制（滤波）分别限制在不同的频带内，在接收端再用滤波器将它们分离。频分复用的所有用户在同样的时间占用不同的带宽资源，若每一个用户的带宽不变，则当复用的用户数增加时，复用后的信道的总带宽就跟着变宽。 时分复用与 FDM 的同时发送多路信号相比，时分多路复用是一种非同时发送的多路复用技术。它将一个传送周期划分为多个时隙，让多路信号分别在不同的时隙内传送，形成每一路信号在连续的传送周期内轮流发送的情形。TDM 信号也成为等时信号。时分复用的所有用户是在不同时间占用同样的频带宽度，若每一个时分复用帧的长度是不变的，那么随着用户的增加，单个用户分配到的时限宽度就变窄了。但是，时限宽度非常窄的脉冲信号所占的频谱范围也是非常宽的。统计时分复用 STDM 是一种改进的时分复用（又称为异步时分复用），它能明显提高信道的利用率。集中器常使用这种统计时分复用。数字信号的时分复用也称为复接，参与复接的信号称为支路信号，复用后的信号称为合路信号，从合路信号中将原来的支路信号分离出来称为分接。复接方式：ＴＤＭ可以设计成按位、按字节、按字符、按字或按任意多位的方式来对每个终端进行扫描复接。按位复接又称为比特复接，即复接时每支路依次复接一个比特。这是目前广泛使用的方法，它的设备简单，需容量小，且容易进行，但对信号的交换不利。按字节复接的方法如下：对基群来说，一个码字有８位，复接前先将８位码存起来，在规定的时间内一次复接；４个支路轮流复接。这种方法需要较大的存储容量，适合于数字电话交换。按帧复接是每次复接一个支路的帧（256比特）。这种方法不破坏原来的帧结构，有利于交换，但需要更大的存储容量。同步时分复用和异步时分复用 同步时分复用：同步时分多路复用是指时分方案中的时间片是预先分配好的，时间片与数据源是一一对应的，不管某一个数据源有无数据要发送，对应的时间片都是属于它的；或者说，各数据源的传输定时是同步的。在接收端，根据时间片的序号来分辨是哪一路数据，以确定各时间片上的数据应当送往哪一台主机。 异步时分复用：采用异步时分多路复用时，各时间片与数据源无对应关系，系统可以按照需要动态地为各路信号分配时间片，各时间片与数据源无对应关系。为使数据传输顺利进行，所传送的数据中需要携带供接收端辨认的地址信息，因此异步时分多路复用也称为标记时分多路复用。ＡＴＭ技术中的传输就是这种方式。复接时系统间的同步问题当由几个低次群数字信号复接成一个高次群数字信号时，如果各低次群采用独立的时钟，即使每个低次群所使用的时钟的标称数码率相同，也会由于线路长短不同产生的时延差异等原因，造成瞬时数码率的差异，从而形成如图所示的重叠或错位现象，使复接合成后的数字信号无法分接恢复成为原来的低次群数字信号。为避免这个问题，需要解决系统与系统间的同步问题。系统间的同步可以用两种方法实现： 用一个高稳定的主时钟来控制被复接的几个低次群，使它们的数码率统一在主时钟的频率上，从而达到同步的目的； 另一种，也是最常用的，是称为码速调整的方法。码速调整方法是让各低次群仍然使用自己的时钟，并在复接前插入一些码元。调整后的数码率高于调整前的数码率的码速调整方法称为正码码速调整。在复接器中为调整码率要插入插入码，在分接器中要将它们去掉———消插。分接器进行消插的依据是“插入标志码”。当插入标志码的 ４ 位中有“000”时，表示无插入码；当插入标志码的 ４ 位中有“111”时，表示有插入码。这种方法叫做“大数判决法”。实际上，同步复接中也要使用插入码。与异步复接不同的是，它在每一个帧中都要插入插入码，目的是使低次群的码速能在复接后符合高次群的要求。 波分复用：波分复用就是光的频分复用技术。光波分多路复用技术是在一根光纤中能同时传输多个光波信号的技术。它在发送端将不同波长的光信号组合起来，复用到一根光纤上，在接收端又将组合的光信号分开（解复用），并送入不同的终端。 码分复用：码分多路复用（CDM）（又称为码分多址，CDMA）也是一种共享信道的方法，每个用户可在同一时间使用同样的频带进行通信，但使用的是基于码型的分割信道的方法，即每个用户分配一个地址码，各个码型互不重叠，通信各方之间不会相互干扰，且抗干拢能力强。码分多路复用技术主要用于无线通信系统，特别是移动通信系统。在 CDMA 中，每一个比特时间再划分为 m 个短的间隔，称为码片。使用 CDMA 的每一个站被指派一个唯一的 m bit 码片序列。一个站要发送比特 1，则发送它自己的 m bit 码片序列。如果要发送比特 0，则发送该码片序列的二进制反码。为了方便，我们按照惯例将码片中的 0 写为 -1，将 1 写为 +1.CDMA 系统的一个重要特点就是这种体制给每一个站分配的码片序列不仅必须各不相同，并且必须互相正交。在实用的系统中是使用伪随机码序列。从上面的定义可知，向量 S 和各站码片反码的向量的内积是 0（相互正交），而且任何一个码片向量和自身做内积都是 1，同时任何一个码片和自身的反码向量的规格化内积是 -1.码分复用通信原理：现嘉定有一个 X 站要接收 S 站发送的数据。X 站就必须知道 S 站所特有的码片序列（就像你打电话给张三，必须知道张三的电话号码一样）。X 站使用它得到的码片向量 S 与接收到的未知信号进行求内积的运算。X 站接收到的信号时各站发送的码片序列之和（没有收到则为 0）。根据前面的公式，在根据叠加原理（假定各种信号经过信道到达接收端是叠加的关系）。那么内积得到的结果是：所有其他站（除了 S 站）信号都被过滤掉（正交，其内积的相关项都是 9），而只剩下 S 站发送的信号。当 S 站发送比特 1 时，在 X 站计算内积的记过是 +1，当 S 站发送比特 0 时，内积的结果是 -1.宽带接入技术宽带接入技术有很多种，如 XDSL 技术、光纤同轴混合网（HFC网）、FTTx 技术（光纤到…）等。这里只提下 xDSL 技术。xDSL 技术就是用数字技术对现有的模拟电话用户线进行改造，使它能够承载宽带业务。虽然标准模拟电话信号的频带被限制在 300~3400 kHz 的范围内，但用户线本身实际可通过的信号频率仍然超过 1 MHz。因此 xDSL 技术就把 0~4 kHz 低端频谱留给传统电话使用，而把原来没有被利用的高端频谱留给用户上网使用。 DSL 就是数字用户线的缩写，而 DSL 的前缀 x 则表示在数字用户线上实现的不同宽带方案。数据链路层前面已经说过的物理层，它只关注单个比特传输，具体一点，它只关注节点产生发送接收比特（而传输只是完全依赖物理性质）。物理层不知道接收的比特是否有问题（接收端只负责接收和解读，至于该解读与发送端本来的意思是否相同是不知道的）、也不知道信道是否拥挤，当然也不知道应该什么是否发送（它只管发送就可以了，不知道发送的时机）。发送端和接收端都不知道所发送或接收的一串比特序列有什么意义，也不清楚该从哪里分段等，总之，物理层只关注单个比特的产生发送和接收，不清楚比特组合的意义，而传输依赖通信线路本来的物理性质。它不知道线路的任何状况，也不清楚发送的最好时机。然而，通信线路偶尔会出错，而且，它们只有有限的数据传输率（物理层只管发送，不管线路是否能承受），并且在比特的发送时间和接收时间之间存在一个非零延迟。这些限制对数据传输的效率有非常重要的影响。数据链路层所采用的协议必须考虑所有这些因素。链路层协议的任务是将网络层的数据报通过路径中的单段链路节点到节点地传送。链路层的一个重要特点是数据保在路径的不同链路上可能由不同的链路层协议所承载。基本概念 链路：所谓“链路”就是从一个结点到相邻结点的一段物理线路，而中间没有任何其他的交换结点。在进行数据通信时，两个计算机之间的通信路径往往要经过许多段这样的链路，可见链路只是一条路径的组成部分。 数据链路：数据链路是不同于链路的另一个概念。这是因为当需要在一套线路上传送数据时，除了必须有一条物理线路外，还必须有一些必要的通信协议来控制这些数据的传输。如果把实现这些协议的硬件和软件加在链路上，就构成了数据链路。一般用网络适配器（俗称“网卡”）来实现这些协议的硬件和软件。一般的适配器都包括了数据链路层和物理层这两层的功能。可见链路与物理链路对应，数据链路与逻辑链路对应。数据链路层使用的信道主要有以下两种类型： （1）点对点信道：这种信道使用一对一的点对点通信方式。 （2）广播信道：广播信道使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专用的共享信道协议来协调这些主机的数据发送。 （数据）帧：帧是数据链路层协议数据单元，它由数据链路层协议对网络层提交来的数据添加首尾部而成。链路层协议数据链路层使用的信道有两类，所以数据链路层协议也分为两类：点对点类协议和广播类协议。三个基本问题不论是哪一类协议，都会涉及到以下三个问题：封装成帧、透明传输和查错检测。 封装成帧封装成帧就是在一段网络层数据的前后分别添加首部和尾部，这样就构成了一个帧。接收端再收到物理层上交的比特流后，就能根据首部和尾部的标记，从收到的比特流中识别帧的开始和结束。可见，帧长等于数据部分的长度加上帧首部和帧尾部的长度，而首部和尾部的一个重要作用就是进行帧定界。此外，首部和尾部还包括许多必要的控制信息。显然，为了提高帧的传输效率，应当使帧的数据部分长度尽可能地大于首部和尾部的长度。但是，每一种链路层协议都规定了帧的数据部分的长度上限，即最大传送单元 MTU。帧定界（拆分比特流）的方法： 字节计数法：利用头部中的一个字段来标识该帧中的字符数。当接收方的数据链路层看到字符计数值时，它就知道后面跟着多少个字节，因此也就知道了该帧在哪里结束。这个算法的问题在于一旦计数值出错，那么后面所有帧被边界都可能弄混。即使检查出了错误要求重传，接收方也不知道该跳过多少字节才能到达重传的帧的开始。 字节填充的标志字节法：鉴于字节计数法出现的出错之后的重新同步问题，本方法让每个帧用一些特殊的字节作为开始和结束。这些特殊字节通常都相同，称为标志字节，作为帧的起始和结束分解符。即使某个帧出错，只要向后搜索就可以知道下一个帧的开始处。然而，当标志字节出现在数据中时，就需要区分是数据还是帧定界符。一般的方法就是使用类似转义字符插入到数据中出现的标志字节之前。但是，转义字符也可能出现在数据中，这样就需要再次转义。为了统一这两种情况，只需要在数据中出现的标志字节或转义字符前插入转义字符即可，当接收时，只需要将遇到的转义字符去除即可（如果没有这个动作说明到了帧的边界）。 比特填充的标志比特法：本方法考虑了字节填充的缺点，即只能使用 8 比特的字节。帧的划分可以在比特级完成，因而帧可以包含由任意大小单元（而不是只能以 8比特为单元）组成的二进制比特数。这种方法是为曾经非常流行的 HDLC（高级数据链路控制）协议而开发的。每个帧的开始和结束由一个特殊的比特模式，0111 1110 或十六进制 0x7E 标记。每当发送方的数据链路层在数据中遇到五个 1，它便自动在输出的比特流中填入一个比特 0（在接收方做相反的处理即可）。比特填充还确保了转换的最小密度，这将有助于物理层保持同步。正是由于这个原因，USB（通用串行总线）采用了比特填充技术。 物理层编码违禁法：采用比特填充和字节填充的一个副作用是：一帧的长度现在要取决于它所现代的数据内容，因为数据中可能存在特殊标志，需要填充，至于数据中有多少这样的特殊标志，上层是不关心的，发送方也是不计数的。由物理层的知识可知，比特编码信号通常包括一些冗余比特，以便帮助接收器同步接收。这种冗余意味着一些信号将不会出现在常规数据中。例如，在 4B/5B 线性编码模式下，4 个数据位被映射成 5 个信号比特，通过这种方法确保线路上的信号有足够的跳变。这意味着 32 个可能的信号中有 16 个是不会被使用的。我们可以利用这些保留的信号来表示帧的开始和结束。实际上，我们使用“编码违法”来区分帧的边界。这种方案的优点在于，因为这些用作分解符的信号是保留不用的，所以很容易通过它们找到帧的开始和结束，而且不再需要填充数据。许多数据链路协议为安全起见综合使用了这些方法。具体请参看后面讲到的具体协议。 透明传输相关内容在前面“封装成帧”时已经提到过了。网络层交给数据链路层的数据不需要知道链路层采用的是怎样的定界方法，更不需要对数据链路层涉及到的特殊标志做特殊处理，也不需要担心会造成链路层帧定界混乱等，这些都是数据链路层应该做的事情，也就是说，这些对网络层是透明的。 差错检测：当帧中的一个比特作为 1 传输时，接收方结点可能错误地判断为 0，反之亦然（称之为“比特差错”）。这种比特差错是由信号衰减和电磁噪声所致。对于出错的帧应遵循早发现早处理的原则。因为没有必要转发一个有差错的数据报，所以许多链路层协议提供一种机制以检测是否存在一个或多个差错。通过让发送结点在在帧中设置差错检测比特，让接收结点进行差错检测来完成这项工作。一旦发现帧中出现差错，此时会向发送方提供反馈信息，通常情况下，协议要求接收方发回一些特殊的控制帧。但是，控制帧也有可能出错或丢失，那么就得不到任何反馈信息，这样就需要引入计时器来解决此类问题，当计时器超时就重发。但是接收端不能区分帧是第一次发还是重发过来的。注意，在数据链路层只能做到帧的无差错接受，或者说，凡是接收端数据链路层接受的帧均五差错（因为有差错的已经被丢弃了）。特别注意的是，我们现在并没有要求数据链路层向网络层提供“可靠传输”的服务。所谓“可靠传输”就是：数据链路层的发送端发送什么，在接收端就收到什么。传输插锁可分为两大类： 比特差错 没有出现比特差错，但却出现了帧丢失、帧重复或帧失序。为此，OSI 的观点是必须把数据链路层做成是可靠传输的。因此在比特差错检测的基础上，增加了帧编号、确认和重传机制。收到正确的帧就要向发送端发送确认。发送端在一定的期限内若没有收到对方的确认，就认为出现了差错，因而就进行重传，直到收到对方的确认为止，这样通信效率比较低。因此，因特网广泛使用的数据链路层协议都不使用确认和重传机制（通信线路的通信质量大大提高了，出现错误的概率大大降低了，再发过多的开销去应付小概率事件是不值得的）。这种机制应由更高层进行识别和处理为好，因为小概率事件发生是很少的，如果交由链路层处理，那么在如此众多的中间节点（除发送和目标主机之外）都要增加相应的硬件或软件处理逻辑，处理时间和投入（如增加缓存，因为需要保留发出的帧，以备出错重传）代价过高；如果放在主机中处理，相对的投入也会集中而且少了很多，并且由于出现的概率少，即使在主机收到之后再要求重传，总体来说损失的时间也不多。 流量控制链路每一端的结点都具有有限容量的帧缓存能力。当接收结点以比它能够处理的速率更快的速率接收分组时，这是一个潜在问题。没有流量控制，接收方的缓存区就会溢出，并使帧丢失。比特差错检测方法前面一节中已经提到过差错检测和比特差错，那如何检测比特差错呢？总体思想是：假设 n 位由于编码组合，这样的所有组合会组成一个集合，那么只使用集合中的一部分表示正确数据（暂称为”合法区“），那么剩下的那部分就是“违法”的（暂称之为“违禁区”，一旦正确的组合中的某个位出错，如果落入违禁区，则说明出错。这样就可以检测错误了；如果要纠正错误，则需要合法区和违禁区形成对应关系，方可知道错在哪里，才有可能纠正错误。 基本概念一帧包含 m 个数据位（即报文）和 k 个冗余位（校验位）。假设帧的总长度为 n，则由 n=m+k。像这样包含数据和校验位的 n 位单元通常称为 n 为码字。海明码距（码距）是两个码字中不相同的二进制位的个数；两个码字的码距是一个编码系统中任意两个合法编码（码字）之间不同的二进制数位数；编码系统的码距是整个编码系统中任意两个码字的码距的最小值。误码率是传输错误的比特占所传输比特总数的比率。海明研究发现，检测 d 个错误，则编码系统码距 ≥d+1；纠正 d 个错误，则编码系统码距 &gt; 2d。 奇偶校验码奇偶校验码是一种增加二进制传输系统最小距离的简单和广泛采用的方法。是一种通过增加冗余位使得码字中”1”的个数恒为奇数或偶数的编码方法，它是一种检错码。在实际使用时又可分为垂直奇偶校验、水平奇偶校验和水平垂直奇偶校验等几种。 海明码海明码是一种多重（每个校验位负责不同的信息位组合）奇偶检错系统，它具有检错和纠错的功能。海明码中的全部传输码字是由原来的信息和附加的奇偶校验位组成的。每一个这种奇偶校验位和信息位被编在传输码字的特定位置上。这种系统组合方式能找到错误出现的位置，无论是原有信息位，还是附加校验位。海明码校验位的个数以及在码字中的位置是由码字的信息位长和位置编号方式（从左至右还是从右至左）决定的。换句话说，码字的信息位长不同或位置编号起止方式不同，海明码序列则不同。但是需要注意的是，接收时校验的方式应和发送时产生校验位的方式（如编号起止位方式）保持一致。由于海明码是及奇偶校验码（即只有两种状态，奇或偶），所以校验位要放在 1、2、4、8、……（2的次方）位置上。纠正单比特错或发现两位错至少满足的条件：海明码例子： 第一种方法：假设信息位数为 4，则根据公式可知需要三个校验比特，并假定位置编号从右至左（符合一般数字规范）。具体产生校验位和接收端进行校验的方法步骤如下： 第二种方法与第一种方法在步骤二的地方有所区别。将信息位的位置将十进制转为二进制，然后类似垂直奇偶校验啊进行处理。还是以上个例子作为本方法的例子。请看步骤二，具体如下表： 信息位 信息位位置 位置二进制 I4 7 1　1　1 I3 6 1　1　0 I2 5 1　0　1 I1 3 0　1　1 校验位   r2 r1 r0 校正因子   S2 S1 S0 表中的校验位就是由表中对应列中为 1 的相应信息位做异或运算得出（参照方法一步骤三结果），而校正因子指的是接收端对数据和原校验位进行校验时得到的新校验位。 CRC 编码纠错码广泛用于无线通信中，因为无线线路比有线噪声更多、容易出错。有线线路上的错误率非常低，所以对于偶然的错误，利用错误检测和重传机制更为有效。数据链路层广泛使用循环冗余校验码（CRC）进行错误检测。CRC 编码又称为多项式编码。CRC 的基本思想是：吧位串看成系数为 0 或 1 的多项式，一个 k 位的帧看成是一个 k-1 次多项式（共有 k 项）的系数列表。例如，1101 有 4 位，可以代表一个 4 项（次数从 0 开始）或 3 阶多项式，系数为 1、1、0、1，即 (1 * x^3 + 1 * x^2 + 0 * x^1 + 1 * x^0 =) x^3 + x^2 + 1。使用 CRC 编码，需要先商定一个生成多项式 G(x) 。生成多项式的最高位和最低位必须为 1 。假设原始信息有 m 位，则对应多项式 M(x)（每一位串都有唯一的多项式与之对应）。生成校验码的思想是：在原始信息位后追加若干校验位（比 G(x) 系数列表少一位），使得追加的信息能被 G(x) 整除。接收方接收到带校验位的信息，然后用 B(x) 整除。余数为 0.则没有错误；反之则发生错误。CRC 校验的例子：假设原始信息串位 10110，CRC 的生成多项式位 G(x) = x^4 + x + 1，求 CRC 校验码。 1）原始信息后“添 0”主语添加多少个 0 ，由生成多项式的系数列表的位数决定（比该位数少 1）。 2）使用生成多项式除得到校验码得到余数 1111.注意：余数位数不足，则余数左边用若干个 0 补齐。 3）将余数添加到原始信后上例中，原始信息 10110，添加余数 1111 后，结果为 10110 1111. 4）接收方校验接收方接收了带校验和的帧后，用多项式 G(x) 来除。余数为 0，则表示信息无措；否则要求发送方进行重传。注意：收发信息双方需使用相同的生成多项式。常见的 CRC 生成多项式PPP 协议在通信线路质量较差（重传比纠错的代价更高）的年代，在数据链路层使用可靠传输协议曾经是一种好办法。因此，能实现可靠传输的高级数据链路控制协议 HDLC 就称为了当时比较流行的数据链路层协议，不过现在 HDLX 已很少使用了。对于点对点的链路，简单得多的 PPP 则是目前使用得最广泛的数据链路层协议。因特网用户通常都要连接到某个 ISP（伊特网服务提供商）才能接入到因特网。PPP（点对点协议）就是计算机和 ISP 进行通信时所使用的数据链路层协议。 PPP 协议应满足的需求 简单IETF 在设计因特网体系结构时把其中最复杂的部分放在传输层的 TCP 协议中，而网际协议 IP 则相对比较简单，它提供的是不可靠的数据报服务。在这种情况下，数据链路层没有必要提供比 IP 协议更多的功能。因此，对数据链路层的帧，不需要纠错，不需要序号，也不需要流量控制当然，在误码率较高的无线链路上可能会需要更为复杂的链路层协议。总之，这种数据链路层的协议非常简单：接收方每收到一个帧，就进行 CRC 检验。如 CRC 检验正确就收下，否则就丢弃这个帧，其他什么也不做。 封装成帧这是所有链路层协议所必需的。PPP 协议必须规定特殊的字符作为帧定界符，以便使接收端从收到的比特流中能准确第找出帧的开始和结束位置。 透明性：请参考”三个基本问题“PPP 协议不能对出现在网络层分组中的数据（首部或者数据）做任何限制。 多种网络层协议PPP 协议必须能够支持同时运行在相同的物理链路的多种网络层协议，即必须能够在单一点对点连接上多路复用不同的网络层协议。这个要求意味着 PPP 至少可能需要一个协议类型字段或某种相似的机制，这样接收方的 PPP 就能够将接收的帧向上分解到合适的网络层协议。 多种类型链路除了要支持多种网络层的协议外，PPP 还必须能够在多种类型的链路上运行。如运行在以太网上的 PPP，即 PPPoE，这是 PPP 协议能够适应多种类型链路的一个典型例子。这个协议把 PPP 帧再封装在以太网帧中，而且可以让多个连接在以太网上的用户共享一条道 ISP 的宽带链路。 差错检测PPP 接收方必须能够检测到接收帧中的比特差错，并立即丢弃有差错的帧（若继续转发错误帧就会拜拜浪费网络资源）。 检测连接状态PPP 必须能够检测到链路层次的故障，并且向网络层通知该差错的情况。 最大传送单元PPP 协议必须对每一种类型的点对点链路设置最大传送单元 MTU 的标准默认值（不过通信双发可以协商具体大小）。如果高层协议发送的分组过长并超过 MTU 的数值，PPP 就要丢弃这样的帧，并返回差错。需要强调的是，MTU 是数据链路层的帧可以载荷的数据部分的最大长度，而不是该帧的总长度。 网络层地址协商PPP 协议必须提供一种机制使通信的两个网络层的实体能够通过协商知道或能够配置彼此的网络层地址。因为仅仅在链路层建立了连接而不知道对方网络层地址时，则还不能够保证网络层能够床送分组。 数据压缩协商PPP 协议必须提供一种方法来协商使用数据压缩算法，但 PPP 协议并不要求将数据压缩算法进行标准化。 PPP 协议不需要的功能PPP 协议是不可靠传输协议，只能检测比特差错，只支持点对点全双工链路。因此，不需要纠错、流量控制（交给传输层）、序号。不支持多点线路，也不支持半双工或单工链路。PPP 首部的协议字段表示所携带的数据所遵循的协议类型，以便提交到对应的网络层协议处进行处理。当协议字段为 0x0021，则 PPP 帧的信息字段就是 IP 数据报；若为 0xC021，则信息字段是 PPP 链路层控制协议 LCP 的数据；若为 0x8021 ，则表示是网络层的控制数据（IPCP，其为 NCP 协议类中的一种）；另外有，C023:密码鉴权协议 PAP，C223: 握手挑战鉴权协议。最后，对 LCP、IPCP的数据报文有兴趣的请参考其他资料。FCS 校验域（FrameCheck Sequence, FCS）为 2 个字节，它计算的是在没有插入任何转义符号前的地址域、控制域、协议域、信息域内的数据，不包括标志域和校验域。在发送数据时，依次计算上述内容，然后将计算后的结果放入校验域；在接收时，首先去除转义字符，然后再计算校验。在接收中计算校验时可以将校验域也计算在内，计算的结果应该是固定值 F0B8 (16 进制)。帧定界符出现在数据部分时可以使用字节填充，也可以使用零比特填充（请参考“三个基本问题”）。 PPP 协议的工作状态PPP 协议有三个组成部分： 一个将 IP 数据报封装到串行链路的方法。 一个用来建立、配置和测试数据链路连接的链路控制协议 LCP。 一套网络控制协议 NCP，其中的每一个协议支持不同的网络层协议。接下来我们来看看 PPP 协议各个部分是如何协调工作的。LCP 协商时，即发送 LCP 的配置请求帧，另一方可以发送以下几种响应中的一种： 配置确认帧：所有选项都接受。 配置否认帧：所有选项都理解但不能接受（如 MTU）。 配置拒绝帧：选项有的无法识别或不能接受，需要协商。LCP 配置选项包括链路上的最大帧长、所使用的鉴别协议的规约（如果有的话），以及不使用 PPP 帧中的地址和控制字段（因为这两个字段的值时固定的，没有任何信息量，可以在 PPP 帧的首部中省略这两个字节）。协商结束后双方就建立了 LCP 链路，接着就进入“鉴别”状态，在这一状态，值允许床送 LCP 协议的分组、鉴别协议的分组以及监测链路质量的分组。若使用口令鉴别协议 PAP，则需要发起通信的一方发送身份标识符和口令。系统可允许用户重试若干次。如果需要有更好的安全性，则可使用更加复杂的口令握手鉴别协议 CHAP。若鉴别身份失败，则转到“链路终止”状态；若鉴别成功，则进入“网络层协议”状态（可以运行不同的网络层协议，但仍然可使用同一个 PPP 协议进行通信）。使用广播信道的数据链路层广播信道可以进行一对多的通信。局域网使用的就是广播信道。局域网有以下特点： 具有广播功能，可共享硬件和软件资源。 便于系统的扩展和逐渐地演变。 提高了系统的可靠性、可用性和生存性。局域网可按网络拓扑进行分类。由于集线器的出现和双绞线大量用于局域网中，星形以太网及多级星型结构的以太网获得了非常广泛的应用。必须指出，局域网工作的层次跨越了数据链路层和物理层。局域网使用的拓扑结构意味着要共享信道，这在技术上有两种方法： 静态划分信道：参见“信道的多路复用技术”。 动态媒体接入控制：它有称为多点接入，其特点是信道并非在用户通信时固定分配给用户。这里又分为两类： 随机接入：速记接入的特点是所有的用户可随机地发送信息，但如果恰巧有两个或更多的用户在同一时刻发送信息，那么在共享媒体上就要产生碰撞（或冲突），使得这些用户的发送都失败。因此，必须有解决碰撞的网络协议。 受控接入：受控接入的特点是用户不能随机地发送信息而必须服从一定的控制。这类的典型代表有分散控制的令牌环局域网和集中控制的多点线路探询（或称为轮训）。该接入方法已经很少使用了。 为了使数据链路层更好地适应多种局域网标准（增加了 LLC），IEEE 802 委员会就把局域网的数据链路层拆成两个子层，即逻辑链路控制 LLC 子层和媒体接入控制 MAC 子层、与接入到传输媒体有关的内容都放在 MAC 子层，而 LLC 子层则与传输媒体无关，不管采用何种传输媒体和 MAC 子层的局域网对 LLC 子层来说都是透明的。由于以太网在局域网市场中已经取得了垄断地位，并且几乎成为了局域网的代名词，所以 LLC 子层的作用已经消失了，很多产商生产的适配器（跨越物理层和数据链路层，提供 MAC 地址）上就仅装有 MAC 协议而没有 LLC 协议。CSMA/CD 协议以太网为了简化和高效，其发送的数据都使用具有自同步能力的慢切斯特编码的信号，其提供的服务时不可靠的交付，即尽最大努力的交付。当目的站收到有差错的数据帧时，就把帧丢弃，其他什么也不做。但对有差错帧是否需要重传则由高层来决定。即使重传，以太网也不知道这是重传帧，而是当做新的数据帧来发送。载波监听多路访问/冲突检测 CSMA/CD 是一种争用型的介质访问控制协议。它是低于万兆以太网的应用的 MAC 层协议。其工作原理是：发送数据前先监听信道是否空闲（载波监听、坚持算法）。若空闲，则立即发送数据。在发送数据时，边发送边继续监听。若监听到冲突（多点接入、碰撞检测），则立即停止发送数据，同时发出一个干扰信号（Jam）清除已发出的帧并通知所有结点“冲突已经发生”，等待一段随机时间（退避算法）再重新尝试。碰撞产生的原因：既然每一个站在发送数据之前已经监听到信道为“空闲”，那么为什么还会出现数据在总线上的碰撞呢？这是因为电磁波传输信号存在延迟（具体原因有：同时检测到空闲并同时发送；检测到空闲，但已经有帧在途中，由于延迟而没有检测到）。电磁波在 1 km 电缆的传播时延约为 5 μm（应该记住，很多计算都用到）。常把总线上的单程端到端（发送端和接收端）传播时延记为 τ。那么，A 发送（假设发给 B ）数据后，最迟要经过多长时间才能知道自己发送的数据和其他站的数据有没有发生碰撞？极限状态是：当 A 发送的帧快到 B 时，B 却发送开始发送数据，此时发生碰撞（离开 A 发送该帧的时间已经有 τ），当 B 发出的帧（发生了碰撞）到达 A 时才会被检测出来（又需要 τ），所以这个时间最多是两倍的总线端到端的传播时延（即为端到端往返传播时延）。由于局域网上任意两个站之间的传播时延有长有短，因此局域网必须按最坏情况设计，即取总线两端的两个站（距离最大的两个站）之间的传播时延为端到端传播时延。由此可见，每一个站在自己发送数据之后的一小段时间内，存在着遭遇碰撞的可能性，而且这一小段时间是不确定的，只有经过争用期（又称为碰撞窗口）（以太网的端到端往返时间）这段时间还没有检测到碰撞，才能肯定这次发送不会发送碰撞。显然，在使用 CSMA/CD 协议时，一个站不可能同时进行发送和接收。因此使用 CSMA/CD 协议的以太网不可能进行全双工通信而只能进行双向交替通信（半双工通信）。 坚持算法载波监听时，信道空闲则依据一定的坚持算法来决定如何发送（占用信道的一方，刚发往一帧需要等帧间最小间隔为 9.6 μs后，再执行坚持算法）。坚持算法分为以下三类： 1-持续 CSMA：始终坚持监听，若空闲则立即发送。 feud持续 CSMA：等待随机的一段时间再发送。 p-持续 CSMA：发送方按 P 概率发送帧。p 的取值比较困难，打了会产生冲突，小了会延长等待时间而降低通信效率。 碰撞检测以太网规定争用期为 512 bit（即64字节，也是以太网最小帧长）时间，帧间最小间隔时间为 96 bit.对于 10M 以太网的争用期为 51.2 μs，帧间最小间隔时间为 9.6 μs。CSMA 只能减少冲突，不能完全避免冲突，以太网使用退避算法中的一种（截断的二进制指数退避算法）来解决发送数据的碰撞问题。退避算法：这种算法规定：发生碰撞的站在信道空闲后并不立即发送数据，而是推迟一个随机时间（避免同步）再进入发送流程。这种方法减少了重传时再次发生碰撞的概率。具体算法如下： （1）设定基本退避时间为争用期 2 τ。 （3）当重传达 16 次仍不能成功时（这表明同时打算发送数据的站太多，以致连续发生冲突），则丢弃该帧，并向高层报告。我们可以看出，以太网在发送数据时，如果帧的前 64 字节没有发送冲突（如果发现信号变化幅度超过一定限度，则表明发生冲突），那么后续的数据就不会发送冲突。因此以太网规定了最短有效帧长为 64 字节，凡长度小于 64 字节的帧都是由于冲突而异常终止的无效帧，收到了这种无效帧就必须应当立即丢弃。传输介质一般使用 10Base-T 形式进行描述。其中 10 是速率，即 10 Mb/s；Base 是基带，Broad 是宽带；而 T 则代表传输介质，T 是双绞线，F 是光纤，以太网在将局域网的代表以太网前，先简单概述下局域网。局域网 LAN 是一种在有限的地理范围内将大量 PC 机及各种设备互连在一起，实现数据传输和资源共享的计算机网络。局域网的主要特点： 网络所覆盖的地理范围比较小。 高传输率和低误码率。 局域网一般采用同轴电缆、双绞线等建立单位内部专用线（而广域网多租用公用线或专用线路）。 局域网与广域网侧重点不完全一样。局域网侧重共享信息的处理，而广域网一般侧重共享位置准确无误及传输的安全性。决定局域网的主要技术主要涉及拓扑结构（如星形、环形、总线形或树形）、传输媒体和媒体访问控制等三项技术问题。局域网的传输形式有两种：基带传输与宽带传输。介质访问控制方法主要有五类：固定分配、按需分配、适应分配、探询访问和随机访问。局域网的主要硬件设备有：网卡、集线器、网络传输介质和中继器、网桥、路由器、网关等网络互连设备。以太网的信道利用率CSMA/CD 要求载波监听、随机发送、碰撞退让等，所以信道的利用率不可能达到 100%；组理想的情况是不发生碰撞（着当然就不是 CSMA/CD 了），即没有上图中的争用期，也就只剩下从接口发出帧的时间和传播时延（图中统称为“占用信道时间”）。以太网的 MAC 层 MAC 层的硬件地址在局域网中，硬件地址又称为物理地址或 MAC 地址（应为这种地址用在 MAC 帧中）。IEEE 802 标准为局域网规定了一种 48 位的全球地址（一般简称为“地址”），是指局域网上的每一台计算机中固化在适配器的 ROM 中的地址（同一台电脑换了网络适配器也就意味着该地址发生了改变）。严格地讲，局域网的”地址“应当是每一个站的”名字“或标识符。请注意，如果连接在局域网上的主机或路由器安装有多个适配器，那么这样的主机或路由器就有多个“地址”。更准确些说，这种 48 位“地址”应当是某个接口的标识符。现在 IEEE 的注册管理机构 RA 是局域网全球地址（相对于本地管理而言）的法定管理机构，它负责分配地址字段的 6 个字节中的前三个字节给制造商。地址字段中的后三个字节则是由厂家自行指派，只要保证生产处的适配器没有重复地址即可。我们知道，适配器具有过滤功能。但适配器从网络上每收到一个 MAC 帧就先用硬件检查 MAC 帧中的目的地址。如果是发往本站的帧则收下，然后再进行其他处理。否则就将此帧丢弃，不再进行其他的处理。这样做就不浪费主机的处理机和内存资源。这里“发往本站的帧“包括以下三种帧： 单播帧（一对一）：即收到的帧的 MAC 地址与本站的硬件地址相同。 广播帧（一对全体）：即发送给本局域网上所有站点的帧（全 1 地址）。 多播帧（一对多）：即发送给本局域网上一部分站点的帧。所有的适配器都至少应当能够识别前两种帧（即单薄和广播地址）。有的适配器可用编程方法识别多播地址。当操作系统启动时，它就把适配器初始化，使适配器能够识别某些多播地址。显然，只有目的地址才能使用广播地址和多播地址。以太网适配器还可设置为一种特殊的工作方式，即混杂方式。工作在混杂方式的适配器只要“听到”有帧在以太网上传输就都悄悄地接受下来，而不管这些帧是发往哪个站的（窃听但不中断其他站点的通信）。MAC 帧的格式下图是 MAC 帧的格式已经在物理层的再次封装。顺便指出，在使用 SONET/SDH 进行同步传输时则不需要用前同步码，因为在同步传输时收发双方的位同步总是一直保持着。在以太网上传送数据时是以帧为单位传送。以太网传送阵时，各帧之间还必须有一定的间隙。因此，接收端只要找到帧开始定界符，其后面的连续到达的比特流就都属于同一个 MAC 帧。可见以太网不需要使用帧结束定界符，也不需要使用字节插入来保证透明传输。IEEE 802.3 标准规定凡出现以下情况之一的即为无效的 MAC 帧： 帧的长度不是整数个字节； 用收到的帧检验序列 FCS 查出有差错； 收到的帧的 MAC 客户数据字段长度不在 46~1500 字节之间。对于检查出的无效 MAC 帧就简单地丢弃，以太网不负责重传丢弃的帧。IEEE 802.3 标准规定的 MAC 帧格式与上图的格式的区别就是两个地方： 第三个字段是“长度/类型”当这个字段值大于 0x0600（即 1536），就表示“类型”；否则表示 MAC 帧的数据部分的“长度”。 当“长度/类型”字段值小于 ox0600 时，数据字段必须装入上面的 LLC 子层的 LLC 帧（LLC 帧已经失去了意义）。扩展以太网有时候需要把以太网的覆盖范围扩展。可以在物理层、数据链路层、网络层等扩展网络，在物理层拓展以太网以太网上的主机之间的距离不能太远，否则主机发送的信号经过铜线的传输就会衰减到使 CSMA/CD 协议无法正常工作。在过去广泛使用粗缆或细缆以太网时，常使用工作在物理层的转发器（两站之间最多可以经过三个电缆网段）来扩展以太网的地理覆盖范围。但随着双绞线以太网成为主流，转发器已经很少使用了。现在，扩展主机和集线器之间的距离的一种简单方法就是使用光纤（通常是一对）和一对光纤调制解调器。如果使用多个集线器，就可以连接成覆盖更大范围的多级新型结构的以太网。这样做的可以有以下两个好处： 能跨几个小局域网进行通信 扩大了以太网覆盖的地理范围。但这种多级结构的集线器以太网也带来了一些缺点： 将各自独立的碰撞域变成了一个更大更严重的碰撞域。 如果不同的小局域网使用的以太网技术不同（如数据率不同），那么就不可能用传统的集线器互连起来。在数据链路层扩展以太网在数据链路层扩展以太网要使用网桥。网桥工作在数据链路层，它根据 MAC 帧的目的地址对收到的帧进行转发和过滤。当网桥收到一个帧时，并不是向所有的借口转发此帧，而是先检查此帧的目的 MAC 地址，然后再确定将该帧转发到相应的接口，或者是把它丢弃（过滤，当转发接口和进入网桥的接口一致时，说明是同一个网段，不需要转发，直接丢弃）。、网桥依靠转发表（也叫作转发数据库或路由目录，至于此表如何得出，请参见“透明网桥”）来转发或过滤帧。网桥是通过内部的接口管理软件和网桥协议实体来完成转发和过滤操作的。使用网桥带来的好处： 过滤通信量、增大吞吐量（因为隔开了碰撞域、各个网段保持各自的通信速率）。 扩大了物理范围、提高了可靠性（各个网段的故障被隔离）。 可互连不同物理层、不同 MAC 子层和不同速率的以太网。网桥也有一些缺点，如： 使用网桥转发增加了处理时延。 MAC 子层并没有流量控制功能。当网络上的符合很重时，网桥中的缓存可能溢出，导致帧丢失。 网桥只适合于用户数不太多和通信量不太大的以太网，否则有时还会因传播过多的广播信息而产生网络拥塞（因为网桥不过滤广播帧）。这就是所谓的广播风暴。注意，连个网桥之间还可使用一段点到点链路（可能使用 PPP 协议）；网桥在转发帧时，不该表帧的源地址。 透明网桥（2-4个端口）目前使用最多的网桥是透明网桥，其保准是 IEEE 802.1D 。“透明”是指以太网上的结点并不知道所发送的帧将经过哪几个网桥，以太网上的站点都看不见以太网上的网桥。透明网桥是一种即插即用设备，意思是只要把网桥接入局域网，不用人工培植转发表，网桥就能工作。当网桥刚刚连接到以太网时，其转发表是空的。网桥通过自学习算法处理收到的帧。网桥的自学习算法： 网桥工作在混杂方式下先收下进来的所有帧。 记下转发表中没有的地址（帧源地址）和对应的接口（有则更新时间或接口），并转发出去自学习算法原理：某帧从某接口进来，其携带的源 MAC 地址说明一定可以通过该接口找到该 MAC 地址（即当其作为目的 MAC 地址时）。如果源 MAC 地址不在转发表中，则可根据前述原理将源 MAC 地址和对应接口登记到转发表的地址和接口栏。如果该帧携带的目的 MAC 地址不在转发表中则将其转发到其他所有端口。 重复上述过程就可以逐渐健全转发表，如此就可以利用转发表实现过滤和转发功能了。实际上，在网桥的转发表中写入的信息除了地址和接口外，还有帧进入该网桥的时间，以便用于更新转发表。因为以太网上的所有工作站并非总是接通电源的。把每个帧到达网桥的时间登记下来，就可以在转发表中只保留网络拓扑的最新状态信息。具体的做法是，网桥中的接口管理软件周期性地扫描转发表中的项目。只要是在一定时间（如几分钟）以前登记的都要删除，这样就使得网桥中的转发表能反映当前网络的最新拓扑状态。透明网桥还使用了一个生成树算法，即互连在一起的网桥在进行彼此通信后，就能找出原来的网络拓扑的一个子集。在这个子集里，整个连通的网络中不存在回路，即在任何两站之间只有一条路径（但不一定是最佳路径）。为了得出能够反映网络拓扑发生变化时的生成树，在生成树上的根网桥每隔一段时间还要对生成树的拓扑进行更新。 源路由网桥透明网桥的最大优点就是容易安装，一接上就能工作。但是，网络资源的利用还不充分。因此，另一种由发送帧的源站负责路由选择的源路由网桥问世了。 源路由网桥的工作原理： 主机配置网桥的标识以及连接到的相应的各个网段。 源路由(source route)网桥在发送帧时将详细的路由信息放在帧的首部中。 源站以广播方式向欲通信的目的站发送一个发现帧，每个发现帧都记录所经过的路由。 发现帧到达目的站时就沿各自的路由返回源站。 源站在得知这些路由后，从所有可能的路由中选择出一个最佳路由。 凡从该源站向该目的站发送的帧的首部，都必须携带源站所确定的这一路由信息。源路由网桥对主机不是透明的，主机必须知道网桥的标识以及连接到哪一个网段上。使用源路由网桥可以利用最佳路由。若在两个以太网之间使用并联的源路由网桥，则可使通信量较平均地分配给每一个网桥。用透明网桥则只能使用生成树，而使用生成树一般并不能保证所使用的路由是最佳的，也不能在不同的链路中进行负载均衡。 以太网交换机交换式集线器常称为以太网交换机或第二层交换机，表明这种交换机工作在数据链路层。以太网交换机实质上就是一个多接口的透明网桥（意味着自学习和生成树算法参考透明网桥）。此外，以太网交换机的每个接口都直接单个主机或另一个集线器相连（注意：普通网桥的接口往往是连接到以太网的一个网段），并且一般都工作在全双工方式。当主机需要通信时，交换机能同时连通许多对的接口，使每一对相互通信的主机都能像独占通信媒体那样，无碰撞地传输数据。交换模式：交换机将数据从一个端口转发到另一个端口的处理方式称为交换模式。交换模式有以下三种： 存储转发：存储校验（适合普通或劣质链路）转发。 直通交换：交换机只读出数据帧的前 6 个字节，即通过地址映射表查找目标地址以确定转发端口，不进行校（适合质量好的链路））验就直接转发这个数据帧。 分段过滤（或称碎片丢弃）接收到 64 字节（进行冲突检测，适合一般链路）就查目标地址进行转发。可见存储转发模式最慢，直通交换最快。交换机与其他设备的比较：   交换机 网桥 集线器 延迟 小 大 小 端口 多 少 多 碰撞域 接口级隔离 网段级隔离 不能隔离 广播域 不隔离 不隔离 不隔离 带宽 接口独占 网段独占 共享 传输模式 全双工 半或全双工 半双工 工作层次 数据链路层 数据链路层 物理层 主要功能实现方式 硬件 软件 硬件 功能 转发/过滤帧，虚拟局域网等 过滤/转发帧 比特整形放大 碰撞域（冲突域）：物理网段（冲突域）：链接在同一导线上的所有物理层设备或工作站的集合。广播域：逻辑网段（广播域）：限制以太网广播报文的范围。一般来说，逻辑网段定义了第三层网络，如 IP 子网等。虚拟局域网利用以太网交换机可以很方便地实现虚拟局域网，在 IEEE 802.1Q标准中，对虚拟局域网 VLAN 是这样定义的：虚拟局域网是由一些局域网网段构成的与物理位置无关的逻辑组，而这些网段只有某些共同的需求。每一个 VLAN 的帧都有一个明确的标识符，指明发送这个帧的工作站是属于哪一个 VLAN。虚拟局域网其实只是局域网给用户提供的一种胡武，而并不是一种新型局域网。虚拟局域网限制了接收广播信息的工作站数，使得网络不会因传播过多的广播信息（“广播风暴”）而引起性能恶化。IEEE 802.3ac 标准定义了以太网的帧格式的扩展，以便支持虚拟局域网。无线局域网这里只讲述冲突的解决方案。EEE 802.11标准使用一种名为载波侦听多路访问／冲突避免（CSMA/CA）的方法来避免冲突。注意，IEEE 802.3有线网络是检测冲突，而IEEE 802.11网络是尽可能避免冲突。为实现冲突避免，要求所有工作站在传输每帧前进行侦听，当工作站有帧需要发送时，面临的将是下列情况之一： ① 没有其他设备在传输数据，工作站可立刻传输其帧，接收工作站必须发送一个确认帧，确认原始帧已在没有发生冲突的情况下到达。 ② 另一台设备正在传输，工作站必须等待，等到当前帧传输完毕后，它再等待一段随机时间，然后传输自己的帧。无线帧的长度不是固定的，一个工作站传输其帧时，其他工作站如何知道该帧已传输完毕，可以使用无线介质呢？显然，工作站可以进行侦听，等待静默期的到来，但这样做并非总是有效的，其他工作站也在侦听，可能同时决定开始传输。IEEE 802.11标准要求所有工作站在开始传输前等待一段时间，这段时间被称为DCF帧间间隔（DCF Interframe Space , DIFS）。传输工作站可以在IEEE 802.11报头中包含一个持续时间值，以指出传输完当前帧所需的大概时间。持续时间值包含传输完当前帧所需要的时隙数（单位通常为毫秒），其他无线工作站必须查看持续时间值，并在考虑传输数据前等待相应的时间。由于每个侦听站在传输的帧中看到的持续时间值相同，因此它们都可能在这段时间过去后决定传输自己的帧，这可能导致冲突。所以，在实际中，除持续定时器外，每个无线工作站还必须实现一个随机后退定时器，传输帧之前，工作站必须选择一个要等待的随机时隙数，这个数字位于0和最大争用窗口值之间。这里的基本思想是，准备传输的工作站必须等待一段随机时间，以减少试图立即传输的工作站数量。这个过程被称为分布式协调功能（Distributed Coordination Function，DCF），由于后退定时器是随机的，多台工作站仍可能选择相同的退避时间，因此，无法防止这些工作站同时传输数据，进而导致冲突。这样，在无线网络中将会出现传输错误，而接收站不会返回确认，为此发送站必须考虑重新发送其帧。最后，工作站在其随机后退定时器过期后并准备传输数据时，如果发现有人正在传输，该如何办呢？它必须再等待当前正在传输的帧的持续时间、DIFS时间和随机后退时间。网络层网络层的作用从表面上看极为简单，即使=将分组从一台发送主机移动到一台接收主机。为此，需要两种重要的网络层功能： 转发：当一个分组到达某路由器的一条输入链路时，该路由器必须将该分组移动到适当的输出链路。该部分的主要内容涉及到路由器的内部结构、数据报的分组转发、IP 协议、网络层编址（IPv4、IPv6）、网络地址转换（NAT）、ICMP、网络的划分等。 选路（或路由）当分组从发送方流向接收方时，网络层决定这些分组所采用的路由或路径。计算这些路径的算法被称为路由算法。网络层提供的两种服务网络层可以提供两种服务：面向连接的和无连接的服务。这实质上是可靠的传输服务应该由哪一层负责实现的问题。虚电路有些人认为应当借助于电信网的成功经验，让网络层负责可靠交付，使用面向连接的通信方式。对于面向连接的服务，我们需要一个虚电路网络。其工作原理如下：隐藏在虚电路背后的思想是避免为每个要发送的数据报选择新路径。一条虚电路（VC）的组成如下： 源和目的主机之间的路径（即一系列链路和路由器） VC号，沿着该路径的每段链路一个号码 沿着该路径的每台路由器中的转发表项。属于一条虚电路的分组将在它的首部携带一个 VC 号（可类比虚拟局域网 VLAN）。因为一条虚电路在每条链路上可能具有不同的 VC 号（这样可以简化处理，避免对所有虚电路进行协同处理来确定相同的编号），所以每台中间路由器必须用一个新的 VC 号替代每个传输分组的 VC 号（这种方式可以减少分组首部中的 VC 字段长度）。该新的 VC 号从转发表获得。虚电路有三个明显不同的阶段： 虚电路建立：使用路由算法建立一条虚电路（也可人工配置），为沿途路由器分配 VC 号，增加转发表项，预留虚电路沿途所需资源等。 数据传送：一旦创建了虚电路，分组就可以开始沿着该虚电路流动了。 数据传送：进行虚电路建立的逆过程。在有些上下文中，这个过程称为标签交换。一种面向连接的网络服务例子是多协议标签互换（MPLS），让主要被用在 Internet 的 ISP网络，IP 数据报被一个有 20 位连接标识或标签的 MPLS 头包裹着。MPLS 往往对客户端是隐藏的，客户看不到这些标签，ISP 用它来为超大流量建立长期的连接；但是，当服务质量变得很重要而且还需要协助其他 ISP 完成流量管理任务时，MPLS 的作用越来越突出。无连接的数据报服务和电信系统终端不同的是，计算机网络的端系统是有只能的计算机，计算机有很强的差错处理能力，因此应该将可靠的传输服务由端系统负责（即由上层的传输层负责）。因特网采用的设计思路是这样的：网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务。网络在发送分组时不需要先建立连接。每一个分组（即 IP 数据报）独立发送，与其前后的分组无关（不进行编号）。网络层不提供服务质量的承诺。也就是说，所传送的分组可能出错、丢失、重复和失序（即不按序到达终点），当然也不保证分组交付的时限。采用这种设计思路的好处是：网络的造价大大降低，运行方式灵活，能够适应多种应有。网际协议 IP网际协议 IP 是 TCP/IP 体系中最主要的协议之一。与 IP 协议配套使用的还有四个协议：使用 IP 协议使得无数复杂差别各异的网络成为了一个虚拟互连网络（虚拟的 IP 网）。一般俩说，将网络互连起来需要使用一些中间设备。根据中间设备所在的层次，可以有以下四种不同的中间设备： 物理层使用的中间设备叫做转发器（如集线器）。 数据链路层使用的中间设备叫做网桥或桥接器（如透明网桥、以太网交换机） 网络层使用的中间设备叫做路由器。 在网络层以上使用的中间设备叫做网关。接下来条轮网络互连时都是指用路由器进行网络互连和路由选择。路由器其实就是一台专用计算机，用来在互联网中进行路由选择。分类的 IP 地址IP 地址就是给因特网上的每一个主机（或路由器）的每一个接口分配一个在全世界范围是唯一的 32 位 （IPv 4）的标识符。IP 地址现在由因特网名字与号码指派公司 ICANN 进行分配。IP 地址的编址方法共经历了三个历史阶段。这三个阶段是： 分类的 IP 地址。 子网的划分。 构成超网。这几个阶段的演变实际上就是为了更加充分的利用显得有点不足的 IP 地址，最后不得已引进了 IPv6。分类的 IP 地址所谓“分类的 IP 地址”就是将 IP 地址划分为若干个固定类，每一类地址都由两个固定长度的字段组成，其中第一个字段是网络号。它标志主机（或路由器）所连接到的网络，一个网络号在整个因特网范围内必须是唯一的。第二个字段是主机号，它标志该主机（或路由器）。一个主机号在它前面的网络号所指明的网络范围内必须是唯一的。由此可见，一个 IP 地址在整个因特网范围内是唯一的。这种两极的 IP 地址可以定义为：IP 地址 ::= {&lt;网络号&gt;,&lt;主机号&gt;}下表中 A 类、B 类和 C 类地址都是单薄地址（一对一通信），是最常用的。下表给出了一般不适用的特殊 IP 地址。IP 地址的重要特点： IP 是分等级的地址结构IP 地址的网络号由 IP 地址管理机构分配，而剩下的主机号则由得到该网络号的单位自行分配。路由器仅根据目的主机所连接的网络号来转发分组（不考虑目的主机的主机号），这样就可以使路由表中的项目数大幅度减少，从而减少了路由表所占的存储空间以及查找路由表的时间。 IP 地址标志网络端口实际上 IP 地址时标志一个主机（或路由器）和一条链路的接口。当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的 IP 地址，其网络号必须是不同的。这种主机称为多归属主机。可见路由器至少有两个或多个不同的 IP 地址。 公平性在 IP 地址中，所有分配到网络号的网络都是平等的。IP 观点看待局域网按照因特网的观点，一个网络是指具有相同网络号的主机的集合。因此用转发器或网桥连接起来的若干个局域网仍然是一个网络。因此，具有不同网络号的局域网必须使用路由器进行互连。下图使用过三个路路由器连接三个局域网的例子：可见： 在同一个局域网上的主机或路由器的 IP 地址中的网络号必须是一样的。 用网桥互连的网段仍然是一个局域网，只能有一个网络号。 当两个路由器相连时，在连线两端的接口处，可以分配也可以不分配 IP 地址（相当于点对点链路，如此不分配的叫做无编号网络或无名网络）。划分子网前面说过的分类的 IP 地址时两极结构，设计的不够合理： IP 地址空间利用率有时很低。如 申请了一个 A 类网络号，却只有几十台主机。 给每一个物理网络分配一个网络号会使路由表变得太大因而使网络性能变坏。 两级 IP 地址不够灵活。为了解决上述问题，在 IP 地址中又增加了一个 “子网号字段”，使两极 IP 地址变成了三级 IP 地址。这种做法叫做划分子网或子网寻址或子网路由选择。划分子网的基本思路如下： 一个拥有许多物理网络的单位，可将所属的物理网络划分为若干个子网，划分子网纯属一个单位内部的事情。本单位意外的网络看不见这个网络是多少个子网组成，因为这个单位对外仍然表现为一个网络。 划分子网的方法是从网络的主机号借用若干为作为子网号，当然主机号也就相应减少了同样的位数。于是两级 IP 地址在本单位内部就变成了三级 IP 地址：网络号、子网号、主机号。 凡是从其他网络发送给本单位某个主机的 IP 数据报，仍然是根据 IP 数据报的目的网络号找到连接在本单位网络上的路由器。但此路由器在收到 IP 数据报后，再按目的网络号和子网号找到目的子网，把 IP 数据报交付给目的主机。通过这种方式就减轻了主干网上路由器所需存储的网络号项数，从而层层降低了网络造价。 子网掩码假定一个数据报已经进入到一个与各子网互连的主干路由器，那么该路由器应怎样转发到特定的子网所在的路由器呢？从 IP 数据报的首部并不知道源主机或目的主机所连接的网络是否进行了子网的划分（因为两极 IP 没有子网的信息，而三级 IP 是面向单位内部的，外面是不知道的）。因此必须另想办法，这就是使用子网掩码。子网掩码将作为网络号和子网号对应的所有为位取 1，而剩下的主机号对应的所有位取 0 得到（然后一般再将其使用十进制记法）。子网号计算用子网掩码和收到的数据报的目的 IP 地址对应位相与便可得到子网号。使用子网掩码的好处就是：不管网络有没有划分子网（都必须在路由器的路由表中有子网掩码这一栏，没有划分子网者使用针对网络号的默认子网掩码，可方便查找路由表和统一算法），只要把子网掩码和 IP 地址进行逐位的“与”运算（这完全可以用硬件实现），就立即得出网络地址来。这样在路由器处理到来的分组时就可以采用同样的算法（不论是单位内部还是外部的路由器）。下图是一个具体的子网划分例子：可见，划分子网增加了灵活性，但却减少了能够连接在网络上的主机总数。构造超网划分子网在一定程度上缓解了因特网在发展中遇到的困难。然而仍然面临着以下困难：IP 地址已分配所剩不多，主干网上的路由表项急剧增加。同一个网络划分子网使用的子网号是固定位数的，为解决面临的困难，使用变长子网掩码 VLSM 可进一步提高 IP 地址资源的利用率。在 VLAM 的基础上又进一步研究出无分类编址方法，即无分类域间路由选择 CIDR。CIDR 最主要的特点有两个： （1）无分类编址CIDR 消除了传统的 A 类、B 类、C 类地址以及划分子网的概念。CIDR 把 32 位的 IP 地址划分为两个部分。前面的部分是“网络前缀”（或简称为“前缀”），用来指明网络，后面的部分则用来指明主机。因此，CIDR 使 IP 地址从三级编址（使用子网掩码）又回到了两极编址，但这已是无分类的两极编址。CIDR 一般使用“斜线记法”或称为 CIDR 记法，即在 IP 地址后面加上斜线“/”，然后写上网络前缀所占的位数。 CIDR 地址快CIDR 把网络前缀都相同的连续的 IP 地址组成一个 “CIDR 地址快”。我们只要知道 CIDR 地址快中的任何一个地址，就可以知道这个地址块的起始地址（即最小地址）和最大地址，以及地址块中的地址数。地址掩码（为兼容可称为子网掩码）为了更方便地进行路由选择，CIDR 使用 32 位的地址掩码。地址掩码是一串 1 和一串 0 组成，而 1 的个数就是网络前缀的长度。斜线记法中，斜线后面的数字就是地址掩码中 1 的个数。请注意，“CIDR 不适用子网”是指 CIDR 并没有在 32 位地址中指明若干位作为子网字段。但分配到一个 CIDR 地址块的组织，仍然可以在本组织内根据需要划分出一些子网。这些子网也都只有一个网络前缀和一个主机号字段，但子网的网络前缀比整个组织的网络前缀更长些。CIDR 的不同记法形式：路由聚合由于一个 CIDR 地址快中有很多地址，所以在路由表中就利用 CIDR 地址块来查找目的网络。这种地址的聚合常常成为路由聚合，它使得路由表中的一个项目可以表示原来传统分类地址的很多个路由。路由聚合也称为构成超网。具体见下图示意。可见，把四个系的路由聚合为大学的一个路由（即构成超网），是将网络前缀缩短。网络前缀越短，其地址块所包含的地址数就越多。而在三级结构中，划分子网是使网络前缀变长。 使用 CIDR 的分组转发使用 CIDR 时，路由器每个项目由“网络前缀”和“下一跳地址”组成，但是在查找路由表时可能会得到不止一个匹配结果，那如何选择呢？最长前缀匹配应当从匹配结果中选择具有最长网络前缀的路由。这叫做最长前缀匹配（又称为最长匹配或最佳匹配）。因为网络前缀越长，它指明的网络约具体。已经确定了最长匹配原则，那么如何查找路由表找出最长前缀匹配呢？使用二叉线索查找路由表对无分类编址的路由表的最简单的查找算法就是对所有可能的前缀进行循环查找。这样查找次数太多，最坏的情况是路由表中没有这路由。对于默认的路由查找都要经历最多-1次不必要的查找。为了进行更加有效的查找，通常是把无分类编址的路由表存放在一种层次的数据结构中，然后自上而下地按层次进行查找。这里最常用的是二叉线索。以上只是给出了二叉线索这种数据结构的用法，并没有说明“与唯一前缀匹配”和“与网络前缀匹配”的关系。显然，要将二叉线索用于路由表中，还必须使二叉线索中的每一个叶子结点包含所对应的网络前缀和子网掩码。当搜索到一个叶结点时，就必须寻找匹配的目的地址和该叶结点的子网掩码进行逐位“与”运算，看结果是否与对应的网络前缀相匹配。若匹配，就按下一跳的接口转发该分组。否则，就丢弃该分组。为了提高二叉线索的查找速度，广泛使用各种压缩技术，以减少层次数。如没有分叉就可以将其作为一个结点。例如，上图中的最后两个地址，其最前面的 4 位都是 1011.欧美从。只要一个地址的前 4 位是 1011，就可以跳过前面 4 位（即压缩了 4 个层次）而直接从第 5 位开始比较。IP 地址与硬件地址的联系从层次的角度来看，物理地址时数据链路层和物理层使用的地址。而 IP 地址是网络层和以上各层使用的地址，是一种逻辑地址（称IP 地址是逻辑地址是因为 IP 地址是用软件实现的）。区别总结如下：总之，IP 地址放在 IP 数据报的首部，而硬件地址则放在 MAC 帧的首部。在网络层和网络层以上使用的是 IP 地址，而数据链路层及以下使用的是硬件地址。当 IP 数据报放入数据链路层的 MAC 帧中以后，整个的 IP 数据报就称为 MAC 帧的数据，因而在数据链路层看不见数据报的 IP 地址。当然传输过程中 IP 地址不变，而硬件地址发生相应的改变。需要强调的是： （1）在 IP 层抽象的互联网上只能看到 IP 数据报。数据报中间经过的路由器的 IP 地址并不出现在其转发的 IP 数据报中。 （2）虽然在 IP 数据报首部有源站 IP 地址，但路由器只根据目的站的 IP 地址的网络号进行路由选择。 （3）在局域网的链路层，只能看见 MAC 帧。 （4）尽管互连在一起的网络的硬件地址体系各不相同，但 IP 层抽象的互联网却屏蔽了下层这些很复杂的细节。只要我们在网络层上讨论问题，就能够使用同一的、抽象的 IP 地址研究主机和知己或路由器之间的通信。ARP 和 RARP前面说到在 IP 数据报传送过程中，MAC 帧的首部地址字段都会改变，那么主机或路由器怎样知道应当在 MAC 帧的首部填入什么样的硬件地址呢？换句话说，怎么根据 IP 地址找到相应的物理地址或者反过来。而地址接卸协议 ARP 和逆地址解析协议 RARP 就是用来解决这样的问题的。其中逆地址解析协议 RARP 已经包含在 DHCP 协议中了。这里不再赘述。网络层使用的是 IP 地址，但在实际网络的链路上传送数据帧时，最终还是必须使用该网络的硬件地址。但 IP 地址和下面的网络的硬件地址之间由于格式不同而不存在简单的映射关系，而且主机或主机网卡可能改换也会是某个网络中的硬件地址集发生改变。为此，地址解析协议 ARP 解决这个问题的方法是：在主机 ARP 高速缓存中赢存放一个从 IP 地址到硬件地址的映射表（该表有本局域网上目前正工作的个主机和路由器的 IP 地址到硬件地址的映射表），并且这个映射表还经常动态更新（新增或超时删除）。ARP 映射表的建立：首先来看下 ARP 映射表已经建立后是如何被使用的。假设当主机 A 要向本局域网上的某个主机 B 发送 IP 数据报时，就现在其 ARP 高速缓存中查看有无主机 B 的 IP 地址。如有，就在 ARP 高速缓存中查出其对应的硬件地址。再把这个硬件地址写入 MAC 帧，然后通过局域网把该 MAC 帧发往此硬件地址（实际上是群发的，只不过其他站对照自己的 MAC 地址，然后丢弃了，路由器或交换机也可能启动过滤进程）。也有可能查不到主机 B 的 IP 地址的项目（可能 B 刚入网或主机 A 刚启动而 ARP 缓存是空的）。在这种情况下： 本机（主机 A） ARP 进程主机 A 就会自动运行 ARP 进程向本局域网广播一个 ARP 请求分组，该分组的主要内容是：“我的 IP 是 xxx…x，硬件地址是 xx-…-xx。我想知道 IP 地址为 xx…xx 的主机的硬件地址。“ 其他主机 ARP 进程本局域网上所有的主机 ARP 进程都收到了该广播的 ARP 请求帧，然后对照自己的 IP 地址。只有 IP 地址对应者才会用单播的方式发送 ARP 相应分组给予回应。 主机 A 根据收到的 ARP 相应分组提取有用信息添加到 ARP 缓存的映射表中。下次就不需要再进行类似的过程了。当 ARP 映射表中信息过时（如主机 B 更换了网络适配器或者已经被删除），仍然按照该表进行发送，则会出现发送失败，那么同样会启动前面的过程对映射表进行更新。请注意，ARP 是解决同一个局域网上的主机或路由器的 IP 地址和硬件地址的映射问题。如果索要找的主机和源主机不再同一个局域网上怎么办呢？事实上可以通过局域网的路由器（该路由器在本局域网中，可以使用 ARP ）转发到下一跳路由器（由路由表得到吓一跳的 IP 地址，然后 ARP 得到下一跳的 MAC 地址）而进入另一个局域网（又可启用 ARP）中，如此通过不断地转发，不断地从一个局域网到另一个局域网，如此就可以不断地通过更换的 MAC 地址转发出去并找到目的主机了。可见，要使用 ARP 有以下典型情况（其他是这些的组合）： 主机之间通信（同一个局域网中） 路由器与主机间（出网或到目的主机） 路由器之间（跨网中）从 IP 地址到硬件地址的解析是自动进行的，主机的用户对这种地址解析过程是不知道的。既然数据传输过程中必须用到硬件地址，那么为什么不直接用硬件地址通信而还要使用 IP 地址？由于全世界存在着各式各样的网络，它们使用不同的硬件地址，要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转换工作，而且中间的硬件地址都有可能变化，所以完成这样的工作简直是不可能的事情。如以太网的 MAC 地址的单播是通过硬件布线实现的（既然是硬件地址当然通过硬件来实现了），如果进入到使用不同地址格式的网络中，那比对地址的硬件结构就需要改变了，如果中途相邻的硬件地址发生了改变（如更换了网络设配器），那么其他相邻结点的硬件地址布线也应该随着改变，可见这样是及其不方便、不灵活和不透明的。IP 数据报格式IP 数据报的格式能够说明 IP 协议具有的功能。IP 数据报分片示例：IP 首部校验和在发送数据时，为了计算数 IP 据报的校验和。应该按如下步骤： 1）将校验和字段置为0,然后将 IP 包头按 16 比特分成多个单元，若 IP 首部不是偶数字节，则填充一个全0字节； 2）对各个单元采用反码加法运算(即高位溢出位会加到低位,通常的补码运算是直接丢掉溢出的高位)。 3）将最终得到的和的反码填入校验和字段；发送数据包。在接收数据时，计算数据报的校验和相对简单，按如下步骤： 1）将 IP 包头按 16 比特分成多个单元，若 IP 首部不是偶数字节，则填充一个全0字节； 2）对各个单元采用反码加法运算，检查得到的和是否符合是全1或全0； 3）如果是全1则进行下步处理,否则意味着包已变化从而丢弃之。二进制反码求和：先进行二进制求和，然后对和取反。需要强调的是反码和是采用高位溢出加到低位的，如 3比特的反码和运算：100b+101b=010b(因为100b+101b=1001b,高位溢出1，其应该加到低位，即001b+1b(高位溢出位)=010b)。IP 层转发分组的流程值得强调的是，在网络层只有具有网络层的路由器（专用计算机）和主机才能转发 IP 分组。实际上，转发 IP 分组可以认为是路由器之间的通信。从上图的简化图中，可以看到，在互联网上转发分组时，是从一个路由器转发到下一个路由器，最后知道路由器直接交付目的主机。路由器可采用默认路由，可减少路由表项。对于只连接了一个路由器的主机网络可免去查找比对路由表的过程。如何找到下一跳路由器？既然 IP 数据报中始终没有下一跳路由器的 IP 地址（只有一直不变的源 IP 地址和目的 IP 地址），那么呆转发的数据报又怎样能够找到下一跳路由器呢？事实上，下一跳的 IP 地址（为何不直接使用硬件地址，因为不同网络的硬件地址格式可能各异，长度不同，会导致路由算法的复杂法，开销更大；使用统一格式和长度的 IP 地址代表这些硬件地址就简单多了）是写入在路由表中的，只需要查找出来，然后使用 ARP 得出对应的硬件地址并将原来的 IP 数据报封装在 MAC 帧中从对应的接口发送出去，然后根据这个硬件地址（此处能不能不用硬件地址呢？不能，因为路由器可能不是用点对点链路连接的，可能也连在多个路由器共享的链路上）就可以找到下一跳路由器。由此可见，当发送一连串的数据报时，上述的这种查找路由表、计算硬件地址、写入 MAC 帧的首部等过程，将不断地重复进行，造成了一定的开销（为的是层层简化问题）。IP 分组转发算法： （1）从 IP 数据报中首部提取目的主机的 IP 地址 D，得出（得出的方法请参考划分子网和构成超网一节）目的网络地址为 Ｎ。 （2）若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付，不需要再转发到其他路由器；否则就是间接交付，执行（3）。 （3）若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给路由表所指明的下一跳路由器；否则，执行（4）。 （4）若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行（5）。 （5）若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则执行（6）。 （6）报告转发分组出错。ICMP 协议IP 提供的尽力数据报通信服务无连接服务，而并不能解决网络低层的数据报丢失、重复、延迟或乱序等问题，TCP 在 IP 基础建立有连接服务解决以上问题，不能解决网络故障或其它网络原因无法传输的包的问题。所以， 网际控制报文协议 ICMP 设计的本意就是希望对 IP 包无法传输时提供报告，ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。这些差错报告帮助了发送方了解为什么无法传递，网络发生了什么问题，确定应用程序后续操作。但 ICMP 不是高层协议，而是 IP 层协议。ICMP 报文的种类ICMP 报文的种类有两种：ICMP 差错报告报文和 ICMP 询问报文。这是由 ICMP 报文格式中的类型字段决定的。徐颖发送 ICMP 差错报告报文的情况： ICMP不能用来报告 ICMP 消息的错误，这样就避免了无限循环。当 ICMP 查询消息时通过发送 ICMP 来响应。 对于被分段的数据报，ICMP 消息只发送关于第一个分段中的错误。也就是说，ICMP 消息永远不会引用一个具有非 0 片偏移量字段的 IP 数据报。 响应具有一个广播或组播（多播）目的地址的数据报时，永远不会发送ICMP消息 对具有特殊地质（请参见 IP 分类地址一节）的数据报不发送 ICMP 差错报告报文。源站抑制没有一种机制可以告诉源站，拥塞程度已经减轻，因为可以按照原来的速率发送数据报。源站应继续降低发送速率，直到不再收到更多的源站抑制报文为止。在多对一的通信中，许多个源站产生的数据报都必须由路由器或目的主机来处理。在这种情况下，有的会以低速率发送而有的则以高速率发送，这就导致了源站抑制报文在发送后，路由器或主机并不知道哪一个源站应对拥塞负责。它可能丢弃从不非常低速率的源站法来的数据报，而没有丢弃真正产生拥塞的源站所发来的数据报。超时有两种情况需要发送超时报文。一种是路由器把数据报的生存时间减至零时，路由器丢弃数据报，并向源主机发送超时报文；另一种是在规定的时间内没有收到所有的分片时，它就丢弃所有的分片，并向源站发送了超时报文。下面对改变路由报文进行简短的解释：出于效率的考虑，连接在网络上的主机的路由表一般都采用人工配置，并且主机不和连接在网络上的路由器定期交换路由信息。在主机刚开始工作时，一般都在路由表中设置了一个默认路由器的IP地址。不管数据报要发送到哪个目的地址，都一律先将数据报传送给网络上的这个默认路由器，而这个默认路由器知道到每一个目的网络的最佳路由。如果默认路由器发现主机发往某个目的地址的数据报的最佳路由不应当经过默认路由器，而是应当经过网络上的另一个路由器R时，就用改变路由报文将此情况报告主机。于是，该主机就在其路由表中增加一项：到某某目的地址应经过路由器R（而不是默认路由器）。ICMP 应用有三种基于ICMP的简单而广泛使用的应用为：Ping ， Traceroute，MTU 测试。 pingPing 命令利用了ICMP两种类型的控制消息：“echo request”（回显请求）、“echo reply”（回显应答）。Ping 是应用层直接使用网络层ICMP的一个例子。它没有通过运输层的TCP或UDP.比如在主机 A 上执行ping命令，目标主机是 B。在 A 主机上就会发送“echo request”（回显请求）控制消息，主机 B 正确接收后即发回“echo reply”（回显应答）控制消息，从而判断出双方能否正常通信。如果在 A 主机上能够 ping 通 B 主机，那么主机 A 上显示的信息就是从主机 B 上返回来的“回显应答”。如果不能 ping 通，主机 A 上显示的信息则是由系统自身所产生的错误提示。顺便提一下：回显应答中有“time”和“TTL”信息。 Traceroute源主机向目的主机发送一连串 IP 数据报，数据报中封装的是无法交互的 UDP 用户数据报。它把一个 TTL 为 1 的 IP 数据报发送给目的主机。第一个路由器把 TTL 减小到 0，丢弃该数据报并把 ICMP 超时消息返回给源主机。这样，路径上的第一个路由器就被标识了。随后用不断增大的TTL值重复这个过程直至该数据报到达目的主机。此时数据报的 TTL 是 1，主机不转发数据报，也不把 TTL 值减 1 。但因 IP 数据报中封装的是无法交付的运输层的 UDP 用户数据报，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。这样，源主机达到了自己的目的，因为这些路由器和最后的目的主机发来的 ICMP 报文正好给出了源主机想知道的路由信息—-到达目的主机所经过的路由器的 IP 地址，以及到达其中的每一个路由器的往返时间。 确定 MTU确定路径MTU的方法是“要求报告分片但又不被允许” 的 ICMP 报文。 1、将IP数据报的标志域中的分片 BIT 位置 1，不允许分片。 2、当路由器发现 IP 数据报长度大于 MTU 时，丢弃数据报，并发回一个要求分片的 ICMP 报文。 3、将 IP 数据报长度减小，分片 BIT 位置 1 重发，接收返回的 ICMP 报文的分析。 4、发送一系列的长度递减的、不允许分片的数据报，通过接收返回的 ICMP 报文的分析，可确定路径 MTU。常见的ICMP网络攻击手段 利用ICMP echo数据包进行DOS攻击 利用ICMP重定向报文进行IP欺骗与窃听 利用ICMP路由器广播报文进行IP欺骗 利用ICMP隧道机制绕过防火墙进行信息获取和远程控制路由选择协议前面提到的大部分内容是关于分组转发的，简单说来，分组转发就是按照路由表把分组转发到相应的接口。而路由（或选路）选择协议是产生路由表信道的。路由选择协议的核心就是路由算法，即需要何种算法来获得并填充路由表中的各项目。一个理想路由算法的特点： （1）正确性和完整性：所有染着路由表所指引的路由，分组一定能够最终到达目的网络和目的主机。 （2）计算简单：算法的开销要小。 （3）要有自适应性（或“稳健性”）：能自动适应通信量和网络拓扑变化。 （4）稳定性：一定网络条件下，路由算法应收敛于一个可以接受的解，而不应该使得出的路由不断地变化。 （5）公平性 （6）最佳的：路由选择算法应当能够找出最好的路由。所谓“最佳”只能是相对于某一种特定要求下得出的较为合理的选择而已。一个世纪的路由选择算法，应尽可能接近于理想的算法。在不同的应用条件下，对以上提出的也可由不同的侧重。应当指出，路由选择是个非常复杂的问题。因为： 它是网络中的所有结点共同协调工作的结果。 路由选择的环境往往是不断变化的（且无法事先知道）。 当网络发生拥塞是，需要选择信息很难获取，从而很难对缓解拥塞有所作为。从适应网络变化的角度可将路由选择算法分为两类： 静态路由选择策略（也叫非自适应路由选择）：人工配置简单小网络。 动态路由选择策越（也叫自适应路由选择）：实现复杂且开销大，适用于较复杂的大网络。分层次的路由选择协议因特网采用的路由选择协议主要是自适应的（即动态的）、分布式路由选择协议。至少由于以下两个原因，因特网采用分层次的路由选择协议： 规模大：这将导致路由表过大和路由器通信占用过多带宽。 管理自治：隐藏内部路由器细节的管理上的需要。这两个问题都可以通过将路由器组织进自治系统 AS 来解决。自治系统 AS 的经典定义是： AS 内部路由器使用相同的路由技术和协议（即内部路由选择策略一致） AS 对外的路由器应和其他 AS 对外的路由器保持一致的路由选择策略（即外部路由选择策略一致）。因此，路由选择协议也自然划分为两大类： 内部网关（或路由）协议 IGP（或 IRP）：在一个自治系统内部使用的路由选择协议。如 RIP 和 OSPF 协议。 外部网关（或路由）协议 EGP（或 ERP）：跨越自治系统的路由就就需要 EGP 了。如 BGP-4.自治系统之间的路由选择也叫域间路由选择，这些路由器被称为网关路由器，可见网关路由器充当了双重角色，在内测运行 IGP 类协议，在外侧运行 EGP 类协议；而在自治系统内部的路由选择叫做域内路由选择。当一个自治系统非常大时，那如何进一步分层呢？如何分最好呢？前面已经说过了，分层路由可以减少每个路由器中路由表项数，但这里需要强调的是，这种空间的节省不是免费得来的，它需要付出代价，其代价就是增加了路径长度（经过的路由器多了，查找路由表的次数也增加了）。如何分层请看下面的例子：考虑一个具有 720 个路由器的子网： 如果没有分层，每个路由器需要 720 个路由表项； 如果分成 24 个区域，每个区域 30 个路由器，那么每个路由器只需要 30 个本地表项（本地路由器），加上 23 个远程表项目，总共 53 个表项（网关路由器）； 如果采用三级层次结构，总共 8 个簇，每个簇包含 9 个区域，每个区域 10 个路由器，那么，每个路由器需要 10 个表项用于记录本地路由器，8 个表项用于到同一簇内其他区域的路由，7 个表项用于远程的簇，总共 25 个表项。有人发现：*对于一个包含 N 个路由器的网络，最优的层数是 ln N，每个路由器所需的路由器表项是 eln N 个。他们还证明了，由于分层路由器而导致的平均路径长度的实际增长非常小，通常是可以接受的。路由选择算法的理论基础计算机网络中的路由器可以看做数据结构中图的结点，而路由器之间的通路可以看成图中的有向边（因为源路由到目的路由是有方向），并且每条计算机链路上有耗时长短、流量大小等指标（相当于有向边上的权值），这样计算机网络中路由器之间的关系就可以用有向带权图来简化了。从而转化成图论和数据结构中图的相关问题了。优化原则最优化路径（可参考数据结构中的 单源点最短路径一节）的一般陈述如下：全局最优必是局部最优，反之不然，因为局部可能有多个最优。具体到计算机网络的表述是：如果路由器 J 在从路由器 B 到路由器 S 的最优路径上，那么从 J 到 S 的最优路径也必定遵循同样的路由（可用反证法证明）。最为最优化原则的一个直接结果，从所有的源到一个指定目标的最优路径的集合构成了一颗以目标节点为根的树，这样的树称为汇集树。所欲路由算法的目标是为所有路由器按照一定的度量找到这样的汇集树。举例（途中举例度量是跳数）如下：请注意，汇集树不一定是唯一的，有可能存在具有相同路径长度的其他汇集树。如果我们允许选择所有可能的路径，则树就变成了更一般的结构，称为有向无环图（DAG）。由于汇集树确实是一棵树，它不包含任何环，所以每个数据报将在有限的跳数内完成传递。然而，实际情形并非如此简单。在运行过程中，链路和路由器可能会出故障，然后又恢复运行。所以，不同的路由器对当前拓扑结构的了解可能有所不同。为此，炫耀做出以下选择：每台路由器是独立地获取用于计算汇集树的信息，还是通过相互交换或其他方式获取这些信息。不过，最优化原则和汇集树为评估其他路由算法提供了一个基准。最短路径详细请参考数据结构中的“最短路径”。这里强调一下，除了调数和物理距离外，还可以用许多其他度量来标识路径长短，例如，带宽、平均流量、通信成本、平均延迟等其他因素（或综合因素）的一个函数。通过改变函数的权重，路由算法就可以根据任何一种标准或多种标准的组合来计算“最短”路径。泛洪算法在实现路由算法时，由于分层路由规则，每个路由器必须根据本地知识而不是网络的全貌做决策。一个简单的本地技术是泛洪，这种技术将每一个入境数据报发送到除了入境链路外的每条出境线路。很显然，泛洪法会产生大量的重复数据报。这里列举两种抑制方法： 设置跳数限制。不过带有跳计数器的泛洪能够差生随着跳数增大而指数增长的重复数据报，而且路由器会复制以前已经看到过的数据报（虽然路由器不知道）。 序号标记泛洪数据报可以让路由器跟踪已经泛洪过的数据报，从而避免第二次发送它们。实现这个目标的一种方式是让每个源路由器在接收来自主机的数据报填上一个序号，然后每个路由器为每个源路由器准备一张表，记录已经观察到的来自源路由器的序号。如果入境数据报在这张表中，它就不能再泛洪到其他路由器。为了防止该表无线地膨胀，每个表应该使用一个计数器 k 作为参数，它表示直到 k 的所有序号都已经观察到了（这样序号为 k 及其以前的序号就不需要存储在该表中了）、当一个数据报抵达是，很容易检查该数据报是否已经被泛洪过（只需要将该数据报的序号与 k 和表中的序号比对即可）。如果是被泛洪过，则丢弃该数据报、饭后会发送大量数据报，有时候对实际的网络是不现实的。不过泛洪途径的鲁棒性非常好，不论有多少路由器被破坏了，只要存在到目的站的路径就一定能找到。泛洪需要的安装很少，路由器仅仅需要知道自己的邻居即可。这意味着，泛洪可以作为其他路由算法的基本构件，那些算法更有效但需要更多的处理。而泛洪还可以用作其他路由算法进行比较的性能度量，因为泛洪能并发地选择每一条可能的路径，因此总能选出最短的那条路径，没有其他算法（很多算法只是求得相对最佳的路径）能够产生一个更短的延迟（忽略泛洪过程本身开销）。内部网关协议 RIP路由信息西医 RIP 是一种分布式的基于距离向量的路由选择协议，是内部网关协议 IGP 中的一员。其最大的优点就是简单。RIP 特点RIP 协议将“距离（或跳数）”定义如下：直接交付主机的路由器的跳数定位 1（即每条链路的“费用”为 1）。从一路由器到非直接连接的网络的距离定义为所经过的路由器数加 1。RIP 协议认为好的路由就是它通过的路由器的数据要少，即“距离短”、RIP 允许一条路径最多只能包含 15 个路由器。因此“距离”等于 16 时即相当于不可达。可见 RIP 只适用于小型互联网。RIP 不能在两个网络之间同时使用多条路由。RIP 选择一条具有最少路由器的路由，哪怕还存在另一条高速（低时延）但路由器较多的路由。RIP 协议是分布式路由选择协议，需要不断地和其他路由器交换路由信息，那么和哪些路由器交换信息，交换什么信息，在什么时候交换信息呢？ 仅和相邻路由器交换信息。 交换的是各自的整个路由表。 按固定时间间隔交换路由信息。距离向量算法距离向量算法是这样工作的：每个路由器维护一张表（即一个矢量），表中列出了当前已知的到每个目标的最佳距离，以及所使用的链路。这些表通过邻居之间定时的相互交换信息而不断被更新，最终每个路由器都了解整个自治系统的所有最佳路由信息。具体算法步骤： （1）修改接收到的邻居（设为 X）路由表所有表项把”下一跳“字段中的地址都改成 X，并把所有”距离“字段的值加 1.每一个项目都有三个关键数据，即：到目的网络 N，距离是 d，下一跳路由器是 X。 （2）将修改后邻居路由表整合到本路由器的路由表。 若自己原来的表中没有目的网络 N，则添加该项；否则， 若下一跳地址相同（都是 X），则替换旧有项；否则， 若收到的项目中的距离 d 小一些，则进行更新替换；否则， 什么也不做。 （3）保持活性，否则不可达若 3 分钟还没有收到相邻路由器的更新路由表，则把此相邻路由器记为不可达的路由器，即把下一跳为该路由器的路由表项的距离置为 16 （距离为 16 表示不可达）。 重复上述过程。由上可知，虽然所有路由器最终都拥有了整个自治系统的全局路由信息，但由于每一个路由器的位置不同，它们的路由表当然应当是不同的（如下一跳的地址等）。RIP 协议的优缺点：RIP 协议的最大的优点就是实现简单、开销较小。但 RIP 协议的缺点也较多： RIP 限制了网络的规模（最大距离为 15） 交换的是完整路由表，随着网络规模的扩大，开销也就增加。 好消息转得块，坏消息传得满，使更新过程的收敛时间过长。因此，对于规模较大的网络就应当使用同类的 OSPF 协议。RIP 协议的报文格式RIP 2 可以支持变长子网掩码和 CIDR。此外，RIP 2 还提供简单的鉴别过程支持多播。RIP 协议使用运输层的用户数据报 UDP 进行传送（使用 UDP 端口 520）。RIP2 还具有简单的鉴别功能，若使用鉴别功能，则将原来写入第一个路由信息（20 字节）的位置用作鉴别。这是应将地址簇标识符置为全 1（即 0xFFFF），而路由标识写入鉴别类型，剩下的 16 字节为鉴别数据。在鉴别数据之后才写入路由歇息，但这时最多只能再放入 24 个路由信息。内部网关协议 OSPF就像 RIP 一样，开放最短路径优先 OSPF 协议也被广泛用于因特网中的 AS 内部选路。OSPF 通常被设置在较顶层的 ISP 中，而RIP 却被设置在较低层 ISP 和企业网中。OSPF 被认为是 RIP 的后继者。然而，*OSPF 的核心就是一个使用泛洪链路状态信息的链路状态协议和一个 Dijkstra 最低费用路径算法。使用 OSPF 的每台路由器构建了一幅相同关于整个自治系统的完整拓扑图。于是，路由器在本地运行 Dijkstra 最短路径算法，以确定一个以自身为根结点的到所有子网的最短路径树（汇集树）。各条链路费用是由网络管理员配置的。OSPF 算法使用 OSPF 时，路由器向自治系统内所有其他路由器广播选路信息，而不仅仅是向其相邻路由器广播。每当一条链路的转台发生变化时，路由器就会广播链路状态信息。即使链路状态未发生变化，它也要周期性地广播链路状态。而 RIP 协议的每一个路由器虽然知道到所有的网络的距离以及下一跳路由，但却不知道全网的拓扑结构（只有到了下一跳路由器，才能知道再下一跳应当怎样走）。链路状态路由算法：OSPF 使用的链路状态路算法的设计思想非常简单，可以用五个部分加以描述。每一个路由器必须完成以下的事情，算法才能正常工作： （1）发现它的邻居结点，并了解其网络地址。（发现邻居） （2）设置到每个邻居结点的距离或者成本度量值。（设置链路成本） （3）构造一个包含所有所有刚刚获知的链路信息包（关于邻居的）。（构造链路状态包） （4）将这个包发送给所有其他的路由器，并接收来自所有其他路由器的信息包。（分发链路状态包） （5）就算出自己到每个其他路由器的最短路径。（计算新路由）OSPF 的链路状态数据库能够较快地进行更新，使各个路由器能及时更新其路由表。OSPF 的更新过程收敛得块是其重要有点。OSPF 区域划分：为了使 OSPF 能够用于规模很大的网络，OSPF 将一个自治系统再划分为若干个更小的范围，叫做区域。每个居于都有一个 32位的区域标识符。当然，一个区域也不能太大，在一个区域内的路由器最好不超过 200 个。每个区域都运行自己的 OSPF 链路状态选路算法，一个区域内的每台路由器都向该区域内的所有其他路由器广播其链路状态。因此，一个区域的内部细节对于该区域外的偶遇路由器来说都是不可见的。区域内选路仅涉及同一区域内的那些路由器。可见，划分区域的好处就是把利用洪泛交换链路状态信息的范围局限于每一个区域而不是整个自治系统，这就减少了整个网络上的通信量。在一个区域内部的路由器只知道本区域的完整网络拓扑，而不知道其他区域的网络拓扑的情况（可见,每台路由器的 OSPF的链路状态数据库也会小很多，可节省存储量和计算最短路径的时间等开销）。为了使每一个区域能够和本区域以外的区域进行通信。如上图，OSPF 使用层次结构的区域划分。主干区域的作用是用来连通其他在下层的区域。从其他区域来的信息都由区域边界路由器进行概括。 内部路由器：内部路由器位于非主干区域且只执行 AS 内部选路。 区域边界路由器：区域边界路由器同时属于区域与主干两个区域。 主干路由器（非边界路由器）：主干路由器执行主干中的选路，但其自身不是区域边界路由器。内部路由器通过该区域中的主干路由器，从信息（基本上是链路状态通告，但通告的是到另一个区域的路由费用，而不是链路费用）广播中知道存在通向其他区域的路由。 边界路由器：边界路由器与属于其他自治系统的路由器交换选路信息。例如，这台路由器也许会使用 BGP 执行 AS 间的选路。其他路由器正是通过这样的边界路由器才知道通向外部网络的路径。从上面可以知道，采用分层次划分区域的方法虽然是交换信息的种类增多了，同时也使 OSPF 协议更加复杂了。但这样做却能使每一个区域内部交换路由器信息的通信量大大减少。因而使 OSPF 协议能够用于规模更大的自治系统中。OSPF 与 RIP 的对比：所有在 OSPF 路由器之间交换的分组都具有鉴别功能，因而保证了仅在可信赖的路由器之间交换链路状态信息。由于网络中的链路状态可能经常发生变化，因此 OSPF 让每一个链路状态都带上一个 32 位的序号，序号越大状态就越新。OSPF 规定，链路状态序号增长速率不得超过每 5 秒钟一次。这样，全部序号空间在 600 年内不会产生重复号。OSPF 与 RIP 比较列表如下：   RIP OSPF 算法 距离矢量路由 链路状态路由 度量 跳数 带宽、延迟等可自设费用 信息交换单位 整个路由表 邻居链路状态 信息承载方 UDP 直接 IP数据报 交换方式 相邻交换 组播链路状态 信息更新方式 无视变化定期 有变则组播出去、即使无变也定期 网络概念结构 平面 分层次划分区域 安全机制 简单鉴别 可启用复杂鉴别 变化适应 收敛慢 收敛快 知晓信息 全 AS 距离及下一跳 全网拓扑结构 个性信息 下一跳及距离 汇集树 使用规模 较小网络 较大网络 最短路径 一条 可多条 负载均衡 无 较弱 多播   支持 复杂性 简单 复杂 OSPF 报文格式OSPF 不用 UDP 而是直接用 IP 数据报（协议字段值为 89）传送。OSPF 构成的数据报很短，这样做可减少路由信息的通信量。数据报很短的另一好处是：可以不必将长的数据报分片传送。而分片传送的数据报只要丢失一个，就无法组装成原来的数据报，而整个数据报就必须重传。 类型 1：问候(Hello)分组，用来发现和维持邻站的可达性（每隔10s交换一次，若有 40s 未收到则不可达）。 类型 2：数据库描述分组，向邻站给出自己的链路状态数据库中所欲链路状态项目的摘要信息。 类型 3：链路状态请求分组，向对方请求发送某些链路状态项目的详细信息。 类型 4：链路状态更新分组，用泛洪法对全网更新链路状态。链路状态更新分组共有五种不同的链路状态（略）。 类型 5：链路状态确认分组，对链路更新分组的确认。后面四种分组都是用来进行链路状态数据库的同步。所谓同步就是指不同路由器的链路状态数据库的内容是一样的。两个同步的路由器叫做“完全邻接的”路由器，不是完全邻接的路由器表明它们虽然在物理上是相邻的，但其链路状态数据库并没有达到一致。外部网关协议 BGPBGP 是不同 AS 的路由器之间交换路由信息的协议（或边界网关协议）。为什么 AS 间和 AS 内部需要不同的选路协议呢？基于以下几个原因： 策略：比如安全保密性，商业关系、各个 ISP 的服务质量考量对流量进行分流等而人为的设定路由偏好或路由限制。 规模：AS 内部路由选择协议可以自行划分层次，而对于 AS 间就有些不现实了（因为各有各的策略）。 性能：由于 AS 间选路是面向策略的，因此所用路由的质量或性能通常是次要的问题。AS 之间甚至没有与路由相关的费用概念。而在一个 AS 内部选路就特别注重最短路径。可见，边界网关协议 BGP 只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），而并非要寻找一条最佳路由（毕竟由于各个 ISP 采取的策略不同，甚至对外隐藏了比较好的路由，同时也没有费用等性能指标的概念）。BGP 采用了路径向量路由选择协议,它与距离向量协议和链路状态协议都有很大的区别。BGP 算法概述在配置 BGP 时，每一个 AS 的管理员要选择至少一个路由器作为该 AS 的“BGP 发言人”。一般说来，两个 BGP 发言人都是通过一个共享网络连接在一起的，而 BGP 发言人往往就是BGP 边界路由器。但也可以不是 BGP 边界路由器。一个 BGP 发言人与其他 AS 的 BGP 发言人要交换路由信息，就要先建立 TCP 连接（端口号 179），然后再此连接上交换 BGP 报文以建立 BGP 会话，利用BGP 会话交换路由信息（如更新路由信息或报告差错等）。BGP 所交换的网络可达性的信息就是要到达某个网络（用网络前缀表示，聚合路由从而减少了路由项）索要经过的一系列 AS。当 BGP发言人就根据所采用的策略从收到的路由信息中找出各 AS 的较好路由。实际上就是构造出 AS 连通图，它是树形结构，不存在回路。BGP 支持 CIDR，因此 BGP 的路由表也就应当包括目的网络前缀、下一跳路由器，以及到达该目的网络锁要经过的 AS 序列。由于使用了路径向量的信息，就可以很容易避免产生兜圈子的路由。如果一个 BGP 发言人收到了其他 BGP 发言人发来的路径通知，它就要检查一下本 AS 是否在此通知的路径中。如果在这条路径中，就不能采用这条路径（因为会形成环）。在 BGP 刚刚运行时，BGP 的邻站是交换整个的 BGP 路由表。但以后只需要在发生变化时更新有变化的部分。这样做对节省网络带宽和减少路由器的处理开销方面都有好处。BGP 报文类型这里只是简单罗列下 BGP 几种报文，不会涉及每种报文的具体格式（因为 BGP 过于复杂，有专著研究 BGP，要想完全理解 BGP 至少几个月，甚至几年）。下面是 BGP-4 的四种报文： （1）OPEN（打开）报文：用来与相邻的另一个 BGP 发言人建立关系，使通信初始化。 （2）UPDATE（更新）报文：用来通告某一路由的信息，以及列出要撤销的多条路由（但只能一条一条的增加）。 （3）KEEPSLIVE（保活）报文：用来周期性地证实邻站的连通性。 （4）NOTIFICATION（通知）报文：用来发送检测到的查错。两个相邻的 BGP 发言人通过 OPEN 报文商谈建立起邻站关系，然后周期性交换 KEEPLIVE 报文（短小而通信开销小）维持这种邻站关系，一旦路由发生变化就会立即用 UPDATE 报文告知邻居（这样邻居再告知它的另外的邻居）逐条增加路由或一次撤销多条路由（从而轻松解决“RIP 中出现的坏消息传得慢”的问题），如果发现错误机会发回 NOTIFICATION 报文告知对方。路由器路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组。这也是网络层的主要工作。由上图可知，整个的路由器结构可划分为两大部分：路由选择部分（也叫控制部分）和分组转发部分。其中路由选择部分的核心构件是路由选择处理机。该处理机的任务是歌剧所选定的路由选择协议构造出路由表，同时经常或定期地和相邻路由器交换路由信息而不断地更新和维护路由表。“转发”和“路由选择”的区别： 转发“转发”就是路由器根据转发表把收到的 IP 数据报从路由器合适的端口转发出去。而转发表是从路由表得出的。转发表必须包含完成转发功能所必须的信息。这就是说，在转发表的每一行必须包含从要到达的目的网络到输出端口和某些 MAC 地址信息的映射。 路由选择“转发”仅仅涉及到一个路由器，但“路由选择”则设计到很多路由器，路由表则是许多路由器协同工作的结果。这些路由器按照复杂的路由算法，得出整个网络的拓扑变化情况，因而能够动态地改变所选择的路由，并由此构造出整个的路由表。路由表一般仅包含从墓地网络到下一跳）用 IP 地址表示）的映射。将转发表和路由表用不同的数据结构实现会带来一些好处，这是因为在转发分组时，转发表的结构应当使查找过程最优化，但路由表则需要对网络拓扑变化的计算最优化。路由表总是用软件实现的，但转发表则甚至可用特殊的硬件来实现。为提高查找效率研究转发表的查找算法是值得的，优势为了利用局部性原理会把某些已经查过的转发表项放在高速缓存中。输入端口输出端口交换结构广播路由前面关注的是单播通信的选路协议，单个源点基于这种协议向单个目的节点发送分组。而在广播选路中，网络层提供了一个源节点到网络中的所有其他结点交付分组的服务。多播选路使单个源节点能够向其他网络结点的一个子集发送分组的拷贝。 广播选路算法也许完成广播通信的最直接方式是由发送结点向每个目的地分别发送分组的拷贝。但这样效率低，不同结点收到广播消息的时延较大（最好能“同时”接收到广播信息）。可见，基于单薄选路基础设施来实现广播将是不明智的。显然更为有效的方式是：经第一跳仅发送分组的单个拷贝，然后让第一跳后面其他端的结点差生并转发任何附加的拷贝。也就是说，让网络结点本身（而不只是源节点）产生分组的冗余拷贝将更加有效。无控制洪泛实现广播的最显而易见的技术是使用洪泛方法。该方法要求源节点向他的所有邻居发送该分组的拷贝。当某个结点接收到了一个广播分组时，它复制该分组并向它的所有其他邻居转发之。如此，只要图示连通的，这种方案最终会将广播分组的拷贝交付给该途中所有结点。遗憾的是，如果该图有圈（网络中很正常），则每个广播分组的一个或多个分组拷贝将无休止第循环，浙江导致广播风暴，最后、网络将瘫痪。受控洪泛避免广播分包的关键是每个结点明智第选择何时洪泛分组，何时不洪泛分组。这可以通过几种方式实现，例如： 序号控制洪泛此方法中，源节点将其地址）或其他的唯一标识符）以及广播序号放入广播分组，再向它的所有邻居发送该分组。每个结点维护他已经收到的、复制的和转发的原地址和每个广播分组的序号列表。当一个结点接收到一个广播分组时，它首先检查该分组是否在列表中。如果在，丢弃该分组；如果不在，复制该分组并向该结点的所有其他邻居转发。可见，这样很容易消除图中的环，防止广播风暴。 反向路径转发（RPF）也称为反向路径广播（RPB）。RPF 的基本思想简单且优雅：当一台路由器接收到具有给定源地址的广播分组时，仅当该分组到达的链路正好是位于它自己到其源的最短单播路径上（将原地址视为目的地址），它才向其所有其他出链路传输分组；否则，丢弃该分组。也就是说，它只接收和转发处在到达广播源地址（视为目的地址）最短路径上的下一跳路由器发来的广播分组。由于单播的路由表是一颗汇集树，不存在环，可见 RPF 不存在广播风暴。生成树广播虽然序号控制洪泛和 RPF 避免了广播风暴，但它们不能完全避免冗余广播分组的传输。序号控制洪泛存在该问题显而易见。而 RPF 存在该问题的原因是：不同路由器到同一个源地址（视为目的地址）形成的不同汇集树中存在相同的中间节点（可以通过手工运行 RPF 发现这个原因）。RPF 只是丢弃了符合条件的分组，但是这些分组还是转发到这里了（不该来这里的），能不能消除这些冗余的转发路径，只留下必须的路径呢？这实际上就是生成树问题（详见数据结构）。更确切地说，我们需要构造最小生成树。因此，另一种提供广播的方法是首先对网络结点构造出一颗生成树。当一个源节点要发送一个广播分组时，它向所有属于该生成树的特定链路发送分组。接收广播分组的结点则向生成树中的所有其他邻居转发该分组（注意：一个结点不必知道整棵树，它只知道它在图中哪些邻居是生成树的邻居）。与生成树方法相关的主要复杂性是生成树的生成和维护。至于具体算法请参考其他资料。IP 多播（组播）IP 多播（曾译为组播），即一对多通信，但又不是广播通信，例如，实时信息的交付（如新闻、股市行情等）、软件更新、交互式会议等。与单播相比，在一对过的通信中，多播可大大节约网络资源。见下图：IP 多播所传送的分组需要使用多播 IP 地址。在多播数据报的目的地址写入的是多播组的标识符，然后设法加入到这个多播组的主机的 IP 地址与多播组的标识符关联起来。其实多播组的标识符就是 IP 地址中的 D 类地址（前四位是 1110，因此 D 类地址范围是 224.0.0.0 到 239.255.255.255）。多播数据报也是“尽最大努力交付”，不保证一定能够交付给多播组内的所有成员。因此，多播数据报和一般的 IP 数据报的区别就是它使用 D 类 IP 地址（但有些地址不能随意使用，因为已经被 IANA 指派）作为目的地址，并且首部中的协议字段值是 2，表明使用 IGMP 协议。显然，多播地址只能用于目的地址，而不能用于源地址。此外，对多播数据报不产生 ICMP 差错报文。因此，若在 PING 命令后面键入多播地址，将永远不会受到相应。IP 多播可以分为两种： 只在本地局域网上进行硬件多播 在因特网范围进行多播前一种虽然比较简单，但很重要，因为现在大部分主机都是通过局域网接入到因特网的。在因特网上进行多播的最后阶段，还是要把多播数据报在局域网上用硬件多播交付给多播组的所有成员。硬件多播因特网号码指派管理局 IANA 拥有的以太网地址块的搞 24 位为 00-00-5E。从下图不难看出，在每一个地址中，只有 23 位可用作多播。这只能和 D 类 IP 地址中的 23 位有一一对应关系。D 类 IP 地址可供分配的有 28 位，可见者 28 位中的前 5 位不能用来构成以太网硬件地址。由于多播 IP 地址与以太网硬件地址的映射关系不是唯一的，因此收到多播数据报的主机，还要在 IP 层利用软件进行过滤，把不是本主机要接收的数据报丢弃。IGMP 和多播路由IP 多播在互联网上进行需要两种协议：网际组管理协议 IGMP、多播路由选择协议。但 IGMP 并非在因特网范围内对所有多播组成员进行管理的协议，它是让连接在本地局域网上的多播路由器知道本局域网上是否有（至于有几个不关心）主机（某个进程）参加或退出某个多播组。显然，仅有 IGMP 协议是不能完成多播任务的。连接在局域网上的多播路由器还必须和因特网上的其他多播路由器协同工作，以便把多播数据报用最小代价传送给所有的组成员。这就需要使用多播路由选择协议。多播数据报可以由没有加入多播的主机发出，也可以通过没有组成员接入的网络。多播组成员可以随时加入或退出或不加入就发送数据报，多播转发必须动态地适应这种成员变化，但网络拓扑并未发生变化（单播路由选择通常是在网络拓扑发生变化时才能更新路由）。可见，多播路由选择协议要比单薄路由选择协议复杂得多。 IGMP 协议IGMP 使用 IP 数据报传递报文，但它也向 IP 提供服务。因此，我们不把 IGMP 看成是一个单独的协议，而是属于整个网际协议 IP 的一个组成部分。IGMP 报文格式 组成员加入过程：当一个主机进程希望接收一个组播组的数据，则使用硬件多播发送成员加入报告给本地 IGMP 路由器，然后改路由器向外网理由多播路由选择算法多播出去。 查询与响应过程 组成员离开过程 IGMP v1 余 IGMP v2 互作用在主机和多播路由器之间的所有通信都是使用 IP 多播。只要有可能，携带 IGMP 报文的数据报都用硬件多播来传送。因此在支持硬件多播的网络上，没有参加 IP 多播的主机不会受到 IGMP 报文。多播路由选择协议多播路由选择实际上就是要找出以援助及为根结点的多播转发树。在多播转发树上，每一个多播路由器向树的叶子结点方向转发受到的多播数据报，但在多播转发树上的路由器不会收到重复的多播数据报（即多播数据报不应在互联网中兜圈子）。不难看出，对不同的多播组对应于不同的多播转发树。同一个多播组，对不同的源点也会有不同的多播转发树。在实践中，有两种方法用于确定多播转发树。这两种方法区别在于：是用单一的组共享树来为组中的所有发送方分发流量，还是为每个独立的发送方构建一颗特定源的转发树。不过这两种方法都使用了以下三种技术： 洪泛与剪除：如广播路由中提到的受控洪泛和 RFB（剪除不需要的分组转发路径），可以防止数据报兜圈子。 隧道技术：当多播数据报路径没有运行多播协议的路由器时，对多播数据报进行再次封装，使之称为向单一目的站发送的单薄数据报，当到了多播环境时在恢复使用多播技术。 生成树 建议使用的多播协议虚拟专用网 VPN局域网中不需要所有的主机都和因特网直接相连，也就不需要全球唯一的 IP 地址了，换句话说，这些内部使用的计算机可以由本机构自行分配其 IP 地址（不对外通信，即使和外面的重复也没关系）。为此，专用地址实现了上面的需求。专用地址只能用作本地地址而不能用作全球地址。*在因特网中的所有路由器，对目的地址是专用地址的数据报一律不进行转发。采用这样的专用 IP 地址的互连网络成为专用互联网或本地互联网或专用网。由于这些专用地址仅在本机构内部使用，专用 IP 地址也叫作可重用地址。有时一个很大的机构有许多部门分布在相距很远的一些地点，而每一个地点都有自己的专用网。假定这些分布在不同地点的专用网需要经常进行通信。这时，可以有两种方法： 租用电信公司的通信线路这种方法的好处是简单方便，但线路租金太高。 使用虚拟专用网 VPN利用公用的因特网作为本机构各个专用网之间的通信载体，这样的专用网又称为虚拟专用网。有时一个机构的 VPN 需要有某些外部机构（如合作伙伴）参加进来。这样的 VPN 就称为外联网。内联网和外联网都采用了因特网技术（TCP/IP 协议）。还有一种类型的 VPN，就是远程接入 VPN，适合对流动员工的管理与通信。网络地址转换 NAT专用网内的主机没有全球 IP 地址，因此无法直接与因特网上的主机通信，专用网如何和因特网上的主机通信呢？最简单和最直接的办法就是申请一些全球 IP 地址，但毕竟全球 IP 地址是有限的，而且付出的代价不少。目前使用得最多的方法是采用网络地址转换。而网络地址转换 NAT方法需要在专用网连接到因特网的路由器上安装 NAT 软件（该路由器称为 NAT 路由器）。它至少有一个有效的外部全球的 IP 地址。这样，所有使用本地地址的主机在和外界通信时，都要在 NAT 路由器上将其本地地址转换成全球 IP 地址，才能和因特网连接。当 NAT 路由器具有 n 个全球 IP 地址时，专用网内最多可以同时有 n 个主机接入到因特网。这样就可以轮流使用 NAT 路由器有限数量的全球 IP 地址。为了更加有效地利用 NAT 路由器上的全球 IP 地址，现在常用的 NAT 转换表把运输层的端口号也利用上（这种 NAT 也叫作网络地址与端口转换 NAPT）。这样就可以使多个拥有本地地址的主机或多个进程，共用一个 NAT 路由器上的全球 IP 地址，因而可以同时和因特网上的不同主机进行通信。传输层传输层的最终目标是向它的用户提供高效的、可靠的和成本有效的数据传输服务，它的用户通常是应用层的进程。为了实现这个目标，传输层需要充分利用网络层提供给它的主机到主机间的通信服务。与网络层提供面向连接和无连接两种服务一样，传输层的服务类型也分为两种。面向连接的传输服务在许多方面与面向连接的网络服务类似，两者的连接都要经历 3 个阶段：连接建立、数据传输和连接释放。这这两层上，寻址和流量控制非常相像。另外，无连接的传输服务与无连接的网络服务也极为相似。既然传输层服务与网络层服务如此相似，为什么还要设立两个独立的层？事实上，用户对网络层没有真正的控制权，因为他们不拥有路由器，所以不能用更好的路由器火灾在数据链路层上用更好的错误处理机制来解决服务太差的问题。唯一的可能是在网络层之上再加一层，由该层来提高网络的服务质量，而运输层只存在主机上，用户有很强的控制权。本质上，由于传输层的存在，使得传输服务有可能比网络服务更加可靠。而且，传输服务原语可以通过调用库程序来实现，从而使得这些源于独立于网络服务原语。不同网络上的网络服务原语可能有很大的差别。将网络服务影藏在一组传输服务原语的背后，带来的好处是：一旦改变了网络服务，只需要替换一组库程序即可：新的库程序使用了不同的底层网络服务，但是实现了同样的传输服务原语，如此，对于用户程序而言，相当于没有改变，也就是说不用改变用户程序。值得庆幸的是，正是有了传输层，应用程序才可以按照一组标准的原语来编写代码，并且程序可以运行在各种各样的网络上：他们根本无须处理不同的网络接口，也不用担心传输的可靠性。因此，下 4 层可以看做是传输服务的提供者，而上面的层次则可视为传输服务的用户。传输层概述从 IP 层来说，通信的两端是来那个主机。IP 数据报的首部明确第标志了这两个主机的 IP 地址。但“两个主机之间的通信”这种说法还不够清楚，因为同一台主机上同时运行着多个进程，而且这些进程都可能在进行网络通信。真正进行通信的实体是在在主机中的进程，是不同主机之间的进程间交换数据。从运输层的角度看，通信的真正端点并不是主机而是主机中的进程。可见，网络层是为主机支架提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。逻辑通信的意思是：运输层之间的通信好像是沿水平方向传送数据，而屏蔽了一下各层的诸多细节。但这条逻辑通信信道对上层的表现却因运输层使用的不同协议而有很大的差别： TCP 协议当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的，但这种逻辑通信信道就相当于一条全双工可靠信道。 UDP 协议当运输层采用无连接的 UDP 协议时，这种逻辑通信信道仍然是一条不可靠信道。UDP 和 TCP 最基本的任务是：将两个端系统间 IP 的交付服务扩展为运行在两个端系统上的进程之间的交付服务。这种将主机间交付扩展到进程间交付，称为运输层的多路复用与多路分解。这里的“复用”是指在发送方不同的应用进程都可以使用同一个运输层协议和同一个源 IP 传送数据，而“分用”是指接收方的运输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程。传输协议概述传输服务由传输协议实现，两个传输实体之间的通信必须使用传输使用传输协议。前面提到了传输层提供的服务与网络层很相似，但前面已经分析了这两层都是不可少的。网络层下面的链路层，传输层的下面是网络层，它们的实现环境是不一样的。在协议角度来看，数据链路层协议（针对 OSI 模型）和传输协议有些方面类似，比如错误处理、顺序性和流量控制等。然而两者也存在着重大差别： 地址点到点链路上，路由器不必指定它要与哪一台路由器进行通信（因为可以与接口绑定）。而在传输层，必须显式地指定接收方的地址。 连接在一条线路上建立一个连接的过程非常简单，而在网络之上传输层中初始的连接建立过程非常复杂（参见 TCP 连接的简历），因为其下的网络层状态非常复杂。数据链路层中的连接是少量的，而传输层的连接是大量的，所以在输出层中，必须要妥善管理大量的连接。 数据传输数据链路层和传输层之间的另一个差别是，网络存在着潜在的存储容量，即在网络中滞留了大量的数据报。由于网络内部的路由是独立进行的且可能无序抵达，甚至他的重传数据报都已经到达，它却稍后才到。网络具有的这种延迟和重复数据报的特性所产生的后果需要协议进行仔细的设计，以便正确地传输信息。传输层协议之间可能有很大不同，但仍然可以通过以下基本元素来考量各个传输协议。传输协议的基本元素： 寻址 连接建立 数据传输 连接释放 差错控制和流量控制 多路复用 拥塞控制TCP/IP 运输层的两个主要协议都是因特网的正式标准，即：用户数据报协议 UDP，传输控制协议 TCP。它们传送的数据单元分别称之为 TCP 报文段 或 UDP 用户数据报。UDP在传送数据之前不需要先建立连接。园地主机的运输层在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 却是一种最有效的工作方式。TCP 则是提供面向连接的服务。在传送数据之前必须先建立连接，数据传送借宿后要释放连接。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务，因此不可避免地增加了许多的开销。如确认、流量控制、计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。运输层的端口区别同一主机不同的正在使用网络通信的用户进程的一个方法就是在运输层使用协议端口号（简称端口）。这就是说，虽然通信的终点是应用进程，但我们只需要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付给目的进程）就由 TCP 来完成。请注意，这种在协议栈层间的抽象的协议端口是软件端口，和路由器或交换机上的硬件端口是完全不同的概念。硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址。端口号只具有本地意义，它只是为了标志本计算机应用层中的各个进程在和运输层交互时的层间接口。在因特网不同计算机中，相同的端口号是没有关联的。由此可见，两个计算机中的进程要相互通信，不仅必须知道对方的 IP 地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）。UDP用户数据包协议 UDP 只在 IP 的数据包服务之上增加了很少一点的功能，这就是复用和奋勇的功能以及差错检测的功能。UDP 是一个基于不可靠通信子网的不可靠传输层协议。因此，基于 UDP 的应用程序必须自己解决可靠性问题，如报文丢失、报文重复、报文失序、流量控制等。UDP 的主要特点是： UDP 是无连接的，可减少开销和发送数据之前的时延。 UDP 使用尽最大努力交付，这点和 IP 协议一样。 UDP 是面向报文的。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付给 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。也就是说，应用层交给 UDP 多长的报文，UDP 就照样发送，一次发送一个完整的报文。因此，应用程序必须选择合适大小的报文。若报文太长，UDP 把它交给 IP 层后，IP 层在传送时可能哟啊进行分片，这回降低 IP 层的效率。反之，若报文太短，UDP 把它交给 IP 层后，会使 IP 数据报的首部相对较长，这也降低了 IP 层的效率。 UDP 没有拥塞控制UDP 可以提高实时传输效率，但 UDP 中缺乏拥塞控制能够导致 UDP 发送方和接收方高丢包率，并将挤垮具有拥塞控制的 TCP 会话，这是一个潜在的严重问题。实际上实时传输协议 RTP 和实时传输控制协议 RTCP 在 UDP 的基础上做了改进时期有助于接收端处理流媒体信息。 UDP 支持一对一、一对多、多对一和多对多的交互通信。 UDP 的首部开销小。在 UNIX 系统中，一个 UDP 端口是一个可读和可写的软件结构， UDP 协议为每个端口维护一个接收缓冲区。发送数据时， UDP 协议将数据内容生成一个UDP 数据报，然后交给网络层的ＩＰ协议发送。接收数据时， UDP 协议从网络层 IP 协议接收到 UDP ，然后根据目的端口号将其放在相应的接收缓冲区中。如果没有匹配的端口号， UDP 协议将丢弃该数据报，并向发送主机返回一个“不可到达”的 ICMP 消息；如果匹配端口号已满， UDP 协议也丢弃该数据报，但不回送错误消息，将来靠超时重发。UDP 首部格式下图中所谓伪首部是因为这种伪首部并不是 UDP 用户数据报真正的首部。只是在计算校验和时，临时添加在 UDP 用户数据报前面，得到一个临时的 UDP 用户数据报。伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和。UDP 用户数据报首部中校验和的计算方法有些特殊。在计算校验和时，要在 UDP 用户数据报之前增加 12 个字节的伪首部（见上图）。校验和就是按照临时的 UDP 用户数据报来计算的。UDP 计算校验和的方法和计算 IP 数据报首部校验和的方法相似。但不同的是：IP 数据报检验和只检验 IP 数据报首部，但 UDP 的校验和时整个临时数据报（包括伪首部、首部、数据部分）。UDP 校验和计算： 把伪首部、首部、和数据部，按顺序划分成多个双字节单元；最后不足两个字节补一个全零字节。 对这些双字节单元进行二进制反码运算求和（建议先两个单元做二进制反码运算得到和，在与下一个单元求和）； 对求得的和取反，放入检验和字段。二进制反码求和运算：对应列相加，1 + 0 =1 ；0+0= 0 ； 1+1 =0 ，产生进位；最高位进位加到和的末尾。UDP 校验示例可靠传输的工作原理TCP 下面的网络提供的是不可靠传输，其要实现可靠传输，必须采用适当的措施才能使得两个运输层之间的通信变得可靠。理想的传输条件有以下两个特点： （1）传输信道不产生差错。 （2）不管发送方以多块的速度发送数据，接收方总是来得急处理收到的数据。然而实际的网络都不具备以上两个理想条件。但可以使用一些可靠协议，实现： （1）当出现差错时让发送方重传出现差错的数据， （2）在接收方来不及处理收到的数据时，即使告诉发送方适当降低发送数据的速度。停止-等待协议TCP 实现的是全双工通信，不过为了讨论问题的简单，仅考虑 A 发送数据而 B 接收数据并发送确认的情况。所谓“停止-等待”就是没发送一个分组就停止发送，等待对方的确认，在收到确认后在发送下一个分组。 无差错的情况这种情况很简单，因为不会发生发送出来的分组和确认帧的丢失，因此该协议可以很好的工作。 出现差错的情况发送的分组本身在传输中出现差错被丢弃或直接丢失了，或者确认帧也出现了前面的情况，这样发送方将收不到来自接收方的确认，按照协议就得无休止的等待，因此又加入了超时重传机制。哟啊实现超时重传，发送方就要在放完一个分组后就会设置一个超时计时器（要比数据在分组传输的平均往返时间更长一些），而且要在这期间暂时保留已发送的分组的副本以备重传，会出现两种情形： 超时前收到了对方的确认，则撤销计时，清除保留的该分组副本 超时就立即重传。需要注意的是，IP 层提供的是不可靠传输服务，可能出现丢失、失序到达等。具体说来，有以下情形： 收到重复分组原来的分组有可能在重传分组不久之后到达，而重传的分组也随后到达，这样就出现了冗余分组，这必须区分出来以便丢弃，所以需要对分组进行编号。收到重复分组，在停止-等待协议下可以有两种处理方式：①丢弃重复分组，其他什么也不做；当确认分组丢失或被丢弃，将会导致发送方无休止的重传。②丢弃重复分组，而且发送确认（只要收到分组就发送确认）。当确认分组无序到达或重复到达时，将会引起混乱，所以此时确认分组也必须编号，而且这个编号和被确认分组的编号有一一对应的关系。利用上述的确认和超时重传再确认机制，就可以在不可靠的传输网络上实现可靠的通信。像上述的这种可靠传输协议常称为地洞重传请求 ARQ或带有重传的肯定确认，意思是重传的请求是自动（此处是超时重传）进行的，接收方不需要请求发送方重传某个出错的分组。信道利用率：所谓信道利用率就是传输有用分组所占的比率，一般用时间比来表示。为了提高传输效率，发送方可以不适用低效率的停止等待协议，而是采用流水线传输。不过这就会增减缓冲区的管理复杂度，同时要处理分组和确认分组无序到达，以及中间分组丢失等情况。连续 ARQ 协议连续重发请求ARQ方案是指发送方可以连续发送一系列信息帧，即不用等前一帧被确认便可继续发送下一帧，效率大大提高。不过也带来了如下影响： 必须增加序号范围：防止序号在传输过程中未确认的分组和缓冲区中分组发生序号循环导致的重复。必须保证这一过程中序号唯一性。 增加缓存协议的发送方和接收方也许必须缓存多个分组。发送方最低限度应当能缓存那些已发送但未确认的分组。 出错分组处理复杂化所需序号范围和对缓冲的要求取决于数据传输协议处理丢失、损坏及过度延时分组的方式。解决流水线传输差错回复有两种方法：混退 N 帧和选择重传。当某个分组没有收到确认，发送方可以用两种处理方式： 重传该分组及其之后的所有分组：这种方法中接收方不需要保留无序到达的分组，因为数据必须按序交付，并且发送方反正要重传没有确认的分组及其后面的已发送的分组的。这种方法使得接收方缓存管理简单，不过丢弃已经正确接收的失序分组是有些浪费，而且随后对该分组的重传也许会丢失或出错，从而导致更多的重传。这种方法就是混退 N 帧的基本思想。*在回退 N 帧协议中，对序号为 n 的分组的确认采取累积确认的方式，表明接收方已经正确接收到序号 n 及其之前的所有分组。这就是说，接收方不必对收到的分组逐个发送确认，而是可以在收到几个连续分组后，对按序到达的最后一个分组发送确认。能使用累积确认的原因是：发送方连续发送分组，接收方就能在超时重传前这段时间收到多个分组并发出确认到达发送方。超时事件：如果出现超时，发送方将重传所有已发送单还未被确认的分组。每个分组可以启动一个定时器（洗脑利用率更高），也可以统一使用一个计时器，不过在回退 N 帧协议中，一个定时器就足够了（因为反正后面的数据都会重传的）。当使用一个定时器时，它可被当做是最早的已发送但未被确认的分组所使用的定时器。如果收到一个确认，但仍有已发送但未被确认的分组，则定时器被重新启动；如果没有，则该定时器被终止。 只重传丢失的分组：这种方法避免了不必要的重传，但对发送方和接收方的缓存管理提出了更高的要求，失序的分组将被缓存知道所有丢失分组（即序号更小的分组）都被收到，这才可以将一批分组按序交付给上层。这就是选择重传的基本思想。注意：接收方重新确认（而不是负略）已收到过的那些序号小于当前发送窗口基序号（最早的未被确认的序号）的分组，这一点是必须的。既然接收方已经收到的分组，发送方还是重传分组并到达了接收方，这说明在发送方看来，接收方没有收到该分组（所以会重传，尽管接收方已经收到，但发送方并不知道）。如果不重新发送确认，则发送窗口将永远不能向前滑动。通过本节的讲述，可靠的传输协议就能实现了。具体请见 TCP 可靠传输的实现。前面的讨论是在嘉定一个放松和一个接收方的前提下进行的，实际上，实际的 TCP 是全双工通信，我们知道确认分组（又称哑帧）是非常短小的，但单独发送确认分组必将降低传输效率（首部占的比重非常大），可使用“捎带确认”技术：就是暂时延缓确认以便将确认信息搭载在下一个出境数据报上。TCPTCP 是 TCP/IP 体系中非常复杂的一个协议。其主要的特点如下： TCP 是面向连接的运输层协议。 每一条 TCP 连接只能有两个端点，也就是，只支持一对一通信。 TCP 提供可靠交付的服务。 TCP 提供全双工通信，TCP 连接的两端都有发送缓存和接收缓存。 面向字节流。“流”指的是流入到进程或从进程流出的字节序列。虽然应用程序和 TCP 的交互式一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP 并不知道所传送的字节流的含义。至于如何换分和组合起来和如何解读这些数据时上层应用程序的事情。TCP 面向连接和虚电路的区别：TCP 是运输层协议，在路由器协议栈中没有运输层，也就是说，TCP 经过的网络路径由下面的网络决定，下面的网络可能是数据报网络，也可能是虚电路网络。当为数据报网络时，一个 TCP 连接中的数据传输路径是不确定，不同报文的路径也可能是不一样的，这取决于网络环境。而虚电路处在网络层，其连接一旦建立，该连接上的数据经过的路径都是一样的，知道该连接的拆除。可见，TCP 面向连接指的是传输数据前要先建立连接，传输完不用后要释放连接。TCP 连接TCP 连接的端口叫做套接字或插口。端口号拼接到 IP 地址即构成了套接字。每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定（两点决定一条直线）。TCP 首部格式TCP 虽然是面向字节流的，但 TCP 传送的数据单元却是报文段。一个 TCP 报文段分为首部和数据两部分。而 TCP 的全部功能都体现在他首部中各字段的作用。首部就像是 C 语言中两端主机的具有网络时延的全局变量，特别需要注意其不完全同步性带来的问题。下面对个别字段进行详细解释： 紧急 UEG：当 URG = 1 时，表明紧急指针字段有效，并结合紧急指针指出从序号字段值（序号）开始的紧急指针值（表示紧急字节数）个为紧急数据。紧急数据指的是高优先级发送（紧急数据一旦交给 TCP，就立即装包发送）和（接收端）向上交付的数据（一旦紧急数据一到就马上交给上层，不必遵照次序）。 确认 ACK：仅当 ACK = 1 时确认号字段才有效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1. 推送 PSH：发送方不必等待缓冲区满后才发送，应先将缓冲区现有的数据发送出去；接收方不必等缓冲区满了之后才上交。 同步 SYN：在连接建立时用来同步序号。当 SYN = 1 而 ACK = 0 （即还没有建立连接）时，表明这是一个连接请求报文段。对方若同意建立连接，则应在相应的报文段中使 SYN = 1 和 ACK = 1（请求发送数据）。因此，SYN 置为 1 就表示这是一个连接请求或连接接受报文。选项字段： MSS：MSS最大报文段长度(Maxium Segment Size)：指明数据字段的最大长度，数据字段的长度加上 TCP 首部的长度才等于整个 TCP 报文段的长度。MSS 值指示自己期望对方发送 TCP 报文段时那个数据字段的长度。通信双方可以有不同的 MSS 值。如果未填写，默认采用 536 字节。MSS 只出现在 SYN 报文中。即：MSS 出现在 SYN=1 的报文段中。 窗口扩大选项窗口扩大选项(Windows Scaling)：由于 TCP 首部的窗口大小字段长度是 16 位，所以其表示的最大数是 65535。但是随着时延和带宽比较大的通信产生（如卫星通信），需要更大的窗口来满足性能和吞吐率，所以产生了这个窗口扩大选项。 SACK选择确认项SACK 选择确认项(Selective Acknowledgements)：用来确保只重传缺少的报文段，而不是重传所有报文段。比如主机 A 发送报文段 1、2、3，而主机 B 仅收到报文段 1、3。那么此时就需要使用 SACK 选项来告诉发送方只发送丢失的数据。那么又如何指明丢失了哪些报文段呢？使用 SACK 需要两个功能字节。一个表示要使用 SACK 选项，另一个指明这个选项占用多少字节。描述丢失的报文段 2，是通过描述它的左右边界报文段 1、3 来完成的。而这个 1、3 实际上是表示序列号，所以描述一个丢失的报文段需要 64 位即 8 个字节（丢失分组的始末序号）的空间。那么可以推算整个选项字段最多描述 (40-2)/8=4 （首部长度字段决定了 TCP 的最大长度，TCP 首部固定部分为 20 字节，启用 SACK 选项需要 2 个功能字节，一个丢失的分组需要始末两个序号占 8 个字节以确定边界）个丢失的报文段。 时间戳选项：时间戳选项（Timestamps）：可以用来计算 RTT(往返时间)，发送方发送 TCP 报文时，把当前的时间值放入时间戳字段，接收方收到后发送确认报文时，把这个时间戳字段的值复制到确认报文中，当发送方收到确认报文后即可计算出 RTT。也可以用来防止回绕序号 PAWS，也可以说可以用来区分相同序列号的不同报文。因为序列号用 32 位表示，每 2^32 个序列号就会产生回绕，那么使用时间戳字段就很容易区分相同序列号的不同报文。 NOP：NOP(NO-Operation)：它要求选项部分中的每种选项长度必须是 4 字节的倍数，不足的则用 NOP 填充。同时也可以用来分割不同的选项字段。如窗口扩大选项和 SACK 之间用 NOP 隔开。TCP 可靠传输的实现在“可靠传输的工作原理”一节中已经宽泛的讲过了有关可靠传输的知识了。本节将只讲滑动窗口和超时重传时间的选择。 以字节为单位的滑动窗口现假定 A 收到了 B 发来的确认报文段，其中窗口字段值为 20（字节），而确认号是 31 （这表明 B 期望收到的下一个序号是 31，而序号 30 为止的数据已经收到了）。根据这两个数据，A 就构造出自己的发送窗口（发送窗口基序号为 31，大小为 20，因此末序号为 50）。其示意图如下：发送窗口里面的序号表示允许发送的序号。显然，窗口越大，发送方既可以在收到确认之前连续发送更多的数据，因而可能获得更高的传输效率。但接收方必须来得及处理这些收到的数据。发送窗口后沿的后面部分表示已发送且已收到了确认。这些数据显然不需要再保留了。而发送窗口前沿的前面部分表示不允许发送的，因为接收方都没有为这部分数据保留临时存放的缓存空间。发送串口的位置由窗口前沿和后沿的位置共同确定。而前沿则由对方发来的确认号决定，但后沿则相对复杂，由对方发来的确认数据报中的确认号和窗口字段值共同确定（确认号+窗口字段值 = 后沿）。当对方发来新的有效确认号时 前沿将前移（请看上图标注）到新的确认好所指序号；否则（即没有收到新的确认），原地不动； 后沿的移动相对复杂： 若窗口大小不变或变大，则前移； 若窗口值变小，可能出现后沿后移（可能导致已经发送的序号被从新放到了不允许发送的区域，可能导致错误，因而 TCP 的标准强烈不赞成这样做），也可能前移。 根据上面的描述可以将整个发送缓冲区分为两大块：发送窗口（当连接释放后可以为 0）和不允许发送部分。其中发送窗口在某时刻有课分为两部分：已经发送但为收到确认的部分，允许发送但还没有发送的部分（又称可用窗口或有效窗口，当发送窗口中的数据全部发送之后而又没有收到新的确认，此时该窗口可以为 0）。也就是说缓冲区被分成三段（假设将缓冲区看成一个首尾相接的循环队列），则每段至少有一个标志，换句话说，至少需要三个指针才能确定这三段的边界（每段的起始需要一个指针，这三段看成首尾相接构成环，则相邻段的起始也是邻居的终了位置，所以只需要三个指针）。接收方可能发生的情况： 接收到按序到达的分组，并根据其中收到的最大序号发送确认： 发送方收到确认，发送窗口位置可以改变； 发送方没有收到确认，发送窗口位置不变，并超时重传。 接收到未按序到达的分组，暂时保存在接收缓冲区内，但不针对这些分组发哦发送确认： 或者不发送确认； 或者选择确认。 实际上，接收方是上面两种情况的结合。如果收到的分组被检测出有差错，则要丢弃；如果接收应用程序来不及读取收到的数据，接收缓存最终就会被填满，使接收窗口减小到零。反之，如果接收应用程序能够及时从接收缓存中读取收到的数据，接收串口就可以增大，但是最大不能超过接收缓存的大小。可见，TCP 通信双方的传输效率和双方的缓存大小、处理数据的速率、网络拥塞情况和信道质量有关。为了进一步增加通信效率，通信双方尽可能采用捎带确认。 超时重传时间的选择超时重传时间的选择影响着通信效率，超时重传时间过短（确认分组还没来得及到达，分组就超时重发了）会导致重传增加；如果超时时间设置过长，则又使网络的空闲时间增大（若确认分组丢失，发送方就会等较长时间才重传，空闲时间自然增大），降低了传输效率。那么，运输层的超时计时器的超时重传时间究竟应设置多大呢？TCP 采用了一种自适应算法。它利用 TCP 确认分组的时间戳选项（详情请参考“TCP 首部格式”）记录的分组发送时间，在结合收到确认分组的时间作差就得出了报文段的往返时间 RTT。发送方 TCP 还保留了 RTT 的一个加权平均往返时间 RTTS（又称为平滑的往返时间）。每当第一次测量到 RTT 样本时，RTTS 取为所测量到的 RTT 样本值。但以后就按下列公式计算：不过发送方根本无法辨别确认还是确认确认（当数据被重传之后，确认分组到达，但这个确认分组可能是对原分组的确认，也可能是对重传分组的确认，因为确认分组也可能无序到达或迟到）。所以上述方法根据确认分组携带的时间截选项来确定 RTT 就会用两种情况出现： 收到的重传分组的确认被当做对原分组的确认，计算出来的 RTT 就偏小，当然 RTO 也偏小 若收到的确认是对原来报文的确认，却被当做是对重传报文的确认，则计算出的 RTT 就偏大。当然 RTO 也偏大。为此，需要对重传的报文做特殊处理。这里列举两种处理方式： 只要重传就不重新计算 RTO。当网络拥塞严重而重传发生时，需要更长的 RTO，而此方式（又称为Kam 算法）却不更新 RTO，将进一步导致重传，可能进一步加重网络拥塞。 Kam 算法修正法：报文段没重传一次，就把 RTO 增大一些。典型的做法是：取新的重传时间为 2 倍的旧的 RTO；当不再发生重传时，才根据前面的计算公式计算 RTO。实践证明，这种策略较为合理。必须考虑传输效率前面已经讲过，应用进程把数据传送到 TCP 的发送缓存后，剩下的发送任务就由 TCP 来控制了。可以用不用的机制来控制 TCP 报文段的发送时机。不过要清楚的是：TCP 的发送方发送时机是由发送方的发送机制和接收方发送确认的时机共同决定的。发送时机举例： TCP 保持一个变量，它等于最大报文段长度 MSS。只要混村中存放的数据达到 MSS 字节时，就组装成一个 TCP 报文段发送出去。 由发送方的应用进程指明要求发送报文段，即 TCP 支持的推送操作和紧急数据。 发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过 MSS）发送出去。但是，如何控制 TCP 发送报文段的实际仍然是一个较为复杂的问题。不过在 TCP 的实现中广泛使用 Nagle 算法。Nagle 算法：若发送应用进程把要发送的数据组个字节地发送到 TCP 的发送缓存，则发送方就把第一个数据字节先发送出去（可以探探路，以便为后面大量数据的发送收集相关信息），把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。Nagle 算法还规定，当到达的数据已达到发送窗口的大小的一般或已达到报文段的最大长度时，就立即发送一个报文段。发送确认报文的时机也将影响 TCP 发送方的发送时机算法的效率。比如糊涂窗口综合征，有时也会使 TCP 的性能变坏。糊涂窗口综合征：假设 TCP 接收方的缓存已满，而交互式的应用进程一次只从接受缓存中读取 1 个字节（这样就使接受缓存空间仅腾出 1 个字节），然后向发送方发送确认，并把窗口设置为 1 个字节（但发送的数据报是 40 字节长，数据占比太低了）。接着，发送方依照发送时机（比如按照 Nagle 算法）机制发来 1 个字节的数据（发送方发送的 IP 数据报是 41 字节长）。接收方发回确认，仍然将窗口设置为 1 个字节。这样进行下去，使网络的效率很低。要解决这个问题，可以让接收方等待一段时间，使得或接收缓存已有足够空间容纳一个最长的报文段，或者等待接受缓存已有一般空闲的空间。只要出现这两种情况之一，接收方就发出确认报文，并向发送方通知当前的窗口大小（此时超时重传时间算法就显得更重要了，因为确认发送要延迟，可能导致不必要的重传）。此外，发送方也不要（一接收到确认就）发送太小的报文段，而是把数据积累成足够大的报文段，或达到接收方缓存的空间的一半大小。TCP 的拥塞控制在计算机网络中链路容量（即带宽）、交换结点中的缓存和处理机、端系统等，都是网络的资源。若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。这种情况就叫做拥塞。可见防止拥塞可以有两个思考方向： 增加可用资源和资源的共享程度：这种方法，可能不但不能解决拥塞问题，而且还可能使网络的性能更坏（因为通信主体都会想尽办法尽可能的占用可用资源） 孔子对资源的需求和恰当地分配可用资源。这种方法可以称为拥塞控制。所谓拥塞控制就是防止过多的数据注入到网络中，这样就可以使网络资源（有短板效应）不会过载。拥塞控制索要做的都有一个前提：网络能够承受现有的网络符合。拥塞控制是一个全局性的过程，设计到所有主机，所有的路由器，以及与降低网络传输性能有关的所有因素。应做到负载均衡、网络资源使用要匹配与协调。但 TCP 连接的端点只要迟迟不能收到对方确认信息，就猜想在当前网络中的某处很可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因。拥塞控制与流量控制的关系密切。不过流量控制往往指点对点通信量的控制，是个端到端的问题。流量控制索要做的就是保持通信双方保持尽可能的同步，抑制发送端发送数据的速率，以便接收端来得及接收和处理。可见，流量控制是局部的，不同的网络段和通信双方允许的带宽和本身速率不同，流量控制也将不同。拥塞控制和流量控制之所以常常被弄混，是因为某些拥塞控制算法是向发送端发送控制报文，并告诉发送端，网络已出现麻烦，必须放慢发送速率。这点又和流量控制是很相似的。进行拥塞控制需要付出代价，而且会打破原有的平衡，带来新的影响。所以在设计用撒控制策略时，必须全面衡量得失。实践证明，拥塞控制是很难设计的，因为它是一个动态的（而不是静态的）问题。一般是通过分组丢失程度来判断网络拥塞的，但分组的丢失是网络发生拥塞的征兆而不是原因。在许多情况下，甚至正是拥塞控制机制本身成为引起网络性能恶化甚至发生死锁的原因。这点应特别注意。在最宽泛的层次上，我们可根据网络层是否为运输层拥塞控制提供显式的帮助来区分拥塞控制方法： 端到端拥塞控制：此类方法中，网络层只提供了拥塞指标的信息，路由器没有直接采取措施来帮助拥塞控制。 网络辅助的拥塞控制：在该方法中，网络层组件（即路由器）向发送方提供关于网络中拥塞状态的显式反馈信息。这种反馈可以通过仅用一个比特来指示链路中的拥塞情况。路由器显式提供拥塞信息的方法有两种：直接反馈信息和间接反馈信息。 直接反馈信息可以由网络路由器（以阻塞分组的形式）发给发送方； 间接反馈信息是指路由器标记或更新流向接收方的分组中的拥塞的指示字段，一旦接收方收到该分组，就会通知发送方网络发生了拥塞。注意，这种方式的通知至少要经过一个完整的往返时间。 具体的拥塞控制的方法有：慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。慢开始和拥塞避免发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。而发送窗口（发送方的发送窗口一定不能超过对方给出的接收窗口）取决于接收方的就收和处理分组的能力与当时的状态。可见，在考虑拥塞控制这个层面来说，发送窗口是为了在传输层上数据传输双方的同步，而拥塞窗口则用来指明当时网络余下的容纳分组的能力。如此，发送窗口必然被要求小于等于拥塞窗口。注意拥塞窗口和发送窗口都是动态变化的。发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。一般具体采用 AIMD（加法递增乘法递减）控制法则来响应网络传来的拥塞信号，至于使用该法则的时机则由具体的算法来确定。 满开始算法：慢开始（又称慢启动）：当建立连接时，发送端用一个很小的初始化拥塞窗口，最多不超过 4 个段（早期采用初始值 1 MSS，后根据经验改成 4），然后发送端发送该初始窗口大小的数据，对于每个在超时重传前得到确认的段，拥塞窗口增加一个段（即每一个确认的段允许发送两个段：已经收到一个段，意味着网络中少了一个段，在超时前收到的，说明网络状态好，可以追加一个段）。可见，使用慢开始算法后，每经过一个传输轮次（原拥塞窗口中的数据全部发送完并都收到了确认，称为一个轮次），拥塞窗口就加倍。可以说，它根本不慢（呈指数增长），这个“慢”指的是达到较大的速率需要一定的时间，而不是一建立连接就开始大量发送数据。随着速率的增长，拥塞就会出现，超时时间就会发生，为了防止拥塞窗口 cwnd 增长过快引起网络拥塞（实际上就是为了控制注入网络中的数据不能一下子太多），还需要设置一个慢开始门限（或阈值）ssthresh。在达到慢开始门限之前使用慢开始算法，在慢开始门限之后将采用拥塞避免算法。拥塞避免算法：虽然满开始算法和拥塞避免算法都遵循加法递增乘法递减的法则，但它们使用该法则的时机是不同的。慢开始算法使用加法递增的时机是：超时事件出现前收到的确认报文。而拥塞算法使用加法递增的时机是：RTT 。拥塞避免（并非指完全能够避免拥塞，只是使网络不容易出现拥塞而已）算法的思想是：当到了慢开始门限后，（只要没有发生超时重传事件）每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 增加一段。可见，拥塞窗口将线性缓慢增长。对超时事件的反应：前面说的算法是没有发生超时事件的情况下使用的加法递增。不论处于慢开始还是拥塞避免阶段，只要发生超时（其依据的 RTT 最好使用最慢的路径的精准时间，这个可以通过发送方收到的确认分组中得出）事件就需使用乘法递减。但不同算法对超时事件的反应是不一样的： 不采用快速重传机制TCP 马上把拥塞窗口 cwnd 减小到 1，并重新（从头再来）执行慢开始算法，同时把慢开始门限值 ssthresh 减半。 使用快速重传算法：快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认而不要等待自己发送数据时才进行捎带确认（如接收方收到 1，3 而没有收到 2，则立即发送确认表明 2 没有收到，然后收到了 4，继续发送确认表明 2 仍然没有收到，以此类推）。与快重传配合使用的还有快恢复算法。 快恢复算法：当发送方接收到三个重复确认时，说明这种情况与发生超时事件不同，至少某些报文已经被发送方收到了（只是失序而已），说明网络已经腾出了空间，还可以交付一些报文段。快恢复算法的思想：执行乘法减小，把慢开始门限 ssthresh 减半，拥塞窗口设置为更新后的 ssthresh 值（而不是 1 MSS），然后开始执行拥塞避免（“加法增大”）算法（而不是慢开始算法）。随机早期检测 RED由于 TCP 拥塞控制算法大都以分组丢失的情况作为拥塞程度的判断依据。所以网络层路由器的分组丢弃策略将会影响到拥塞控制算法的实施效果。一般分组的处理按照队列“先进先出”原则来进行处理的。分组丢弃策略： 尾部丢弃策略：当网络出现拥塞时，采用尾部丢弃策略（当队列已满时，以后再到达的所有分组将都被丢弃，如果队列未满，则会被放在队列的尾部）将会导致大量的分组短时间内接连丢失（因为路由器转发分组需要时间，在这期间到达的分组都将被丢弃），使得很多条 TCP 连接出现重传的情况，从而可能都进入到慢开始状态或发送数据量都大幅度减少（称之为全局同步）。全局同步使得全网的通信量突然下降很多，而在网络恢复正常后，其通信量又突然增大很多。如此增大了出现拥塞的可能性和加剧了拥塞程度。为了避免发生网络中的全局同步现象，可以在路由器采用随机早期检测 RED（又叫“随机早期丢弃”）的措施。实现 RED 的要点如下：在出现尾部大面积丢弃（引起全局同步效应）之前，就先以概率 p 随机丢弃个别的分组，让拥塞控制只在个别的 TCP 连接上进行，因而避免发生全局性的拥塞控制。算法中使用平均队列长度的原因是：计算机数据具有突发性的特点，路由器中队列长度经常会出现很快的起伏变化。TCP 的运输连接管理TCP 运输连接有三个阶段：连接建立、数据传送和连接释放。运输连接的管理就是使运输连接的建立和释放都能正常地进行。TCP 连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做客户，而被动等待连接建立的应用进程叫做服务器。TCP 的链接建立TCP 的连接建立过程叫做三次握手或三次联络。为什么 A 还要发送一次确认（即进行第三次握手）呢？这主要是为了防止已失效的连接请求报文段（A 可能为了与 B 建立连接，尝试了多次，但 B 都没有回应，这些请求可能已经消失，也可能释放连接后还滞留在网络中，当然这是一种极端情况，通信了很久，请求报文还在网络中。不过，协议就是要全面考虑各种情况）突然又传到了 B（通过确认号可以辨别这种情况），因而产生错误，导致 B 误以为 A 要发送数据，就一直打开进程等着，导致 B 的许多资源浪费了。有了第三次握手的约定，由于 A 已经释放连接，就不可能回应 B。那么 B 过约一分钟就会自动回收资源。TCP 的连接释放数据传输结束后，通信双方中任何一方都可以主动提出释放连接请求，发出连接释放报文段。下图以客户主动释放为例。为什么 A 在 TIME-WAIT 状态必须等待 2MSL 的时间能？这有两个理由： A 发出的最后一个确认报文到达 B 需要时间，同时可能丢失。一旦丢失，B 会超时重发 FINACK 报文段（如果此时 A 不等，而是直接关闭了，即不会有任何回应，那么 B 将会一直重传，知道达到重传上限才会自动关闭连接），而 A 则会重传最后一个确认报文段，从而使 B 能正常进入关闭状态。 确保本次连接双方发出的报文段已经没有在网络滞留的可能性。以便净化下一次重新建立连接的环境。TCP 的有限状态机为了更清晰第看出 TCP 连接的各种状态之间的关系，绘制了下面的 TCP 连接的有限状态机。其中粗实线箭头表示对客户进程的正常变迁，粗虚线箭头表示对服务器进程的正常变迁，另一种细线箭头表示异常变迁。应用层除了应用层的其他各层都是为计算机网络提供通信服务的，而应用层则是利用这些通信服务解决应用问题。每个应用层协议都是为了解决某一类应用问题，而问题的解决又往往是通过不同主机中的多个应用进程之间的通信和协同工作来完成的。应用层的具体内容就是规定应用进程在通信时所遵循的协议。应用层的许多协议都是基于客户服务器方式。即使是对等通信方式，实质上也是一种特殊的客户服务器方式。客户和服务器都是指通信中所涉及的两个应用进程。客户服务器方式所描述的是进程之间服务和被服务的关系。这里最主要的特征就是：客户是服务请求方，服务器是服务提供方。域名系统 DNSDNS 是把主机域名解析为 IP 地址的系统。解决了 IP 地址难记的问题。该系统是由解析器和域名服务器组成的。DNS 工作方式：为了将一个名字映射成 IP 地址，应用程序调用一个名为解析器的库程序，并将名字作为参数传递给此程序。而解析器则向本地 DNS 服务器发送一个包含改名字的请求报文；本地 DNS 服务器查询（不过有不同的查询方式，详见后面介绍）该名字，并且返回一个包含该名字对应 IP 地址的响应报文给解析器，然后解析器在将 IP 地址返回给调用方。查询报文和响应报文都作为 UDP 数据报发送。有了 IP 地址以后，应用程序就可以与目标主机进行通信了。DNS 主要基于 UDP 协议，较少情况下使用 TCP 协议，端口号均为 53。域名系统由三部分构成：DNS 名字空间、域名服务器、DNS 客户机。DNS 名字空间DNS 系统（也称为因特网上的目录服务）属于分层式命名系统，即采用的命名方法是层次树状结构。连接在 Internet 上的主机或路由器都有一个唯一的层次结构名，即域名。域名可以由若干个部分组成，每个部分代表不同级别的域名并使用“.”号分开。完整的结构为：主机. …….三级域名.二级域名.顶级域名.。顶级域名后的“.”号表示根域，通常可以不用写。顶级域名由 ICANN （Internet 名字与数字地址分配机构）负责管理，并由 ICANN 委任的注册机构负责运行。域名可以是绝对的，也可以是相对的。绝对域名总是以句点作为结束，而相对域名则不然。相对域名必须在一定的上下文环境中被解释才有的真正含义。无论是绝对域名还是相对域名，一个域名对应于域名树中一个特定的结点，以及他下面的所有结点。域名不区分大小写，各组成部分的名字最多可以有 63 个字符，整个路径的名字不得超过 255 个字符。每个域自己控制如何分配它下面的子域。为了创建一个新域，创建者必须得到包含该新域的上级域的许可。命名机制遵循的是以组织为边界，而不是以武力网络为边界。域名服务器DNS服务器没有采用集中式数据库，因为这会造成单点故障、通信容量瓶颈、远距离延迟、数据库庞大难以维护等。为了处理规模问题，DNS 使用了大量的 DNS 服务器，它们以层次方式组织，并且分布在全世界范围内。，没有一台 DNS 服务器具有因特网上所有主机的映射，相反，该映射分布在所有的 DNS 服务器上。每一个域名服务器都只对域名体系中的一部分进行管辖，并且尽量就近进行解析。大致说来，有 4 种类型的 DNS 服务器：根 DNS 服务器、顶级域名 DNS 服务器、权限（权威） DNS 服务器和本地域名服务器（默认域名服务器）。域名解析过程DNS 查询有两种方式：递归查询和迭代查询。 递归查询主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向其他根域名服务器继续发出查询请求报文（即代替主机继续查询），而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是索要查询的 IP地址，或者是报错，表示无法查询到所需的 IP 地址。 迭代查询本地域名服务器向根域名服务器的查询通常是采用迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出索要查询的 IP 地址，要么告诉本地域名服务器能够解析该域名的 DNS 服务器 IP 地址，然后让本地域名服务器进行后续的查询（而不是代替本地域名服务器进行后续查询）。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询；顶级域名服务器在收到本地域名服务器的查询请求后，要么根除索要查询的 IP 地址，要么告诉本地域名服务器下一步应当向哪一个权限域名服务器进行查询。本地域名服务器就这样进行迭代查询。最后，知道了所要解析的域名的 IP 地址，然后把这个结果返回给发起查询的主机。当然本地域名服务器也可以采用递归查询。这取决于最初的查询请求报文的设置是要求使用哪一种查询方式。DNS 高速缓存为了提高 DNS 查询效率，并减少域名服务器的负荷和减少因特网上的 DNS 查询报文数量，在域名服务器中广泛地使用了高速缓存（有时也称为高速缓存域名服务器）。高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录。不但本地域名服务器中需要高速缓存，在主机中也很需要。许多主机在启动时从本地域名服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。文件传送协议 FTPFTP 提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限。FTP 屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传送文件。FTP 特点基于 TCP 的 FTP 和基于 UDP 的 TFTP，它们都是文件共享协议的一大类，即复制整个文件。其特点是：若要存取一个文件，就必须先获得一个本地的文件副本（即先下载到本地）；如果要修改文件，只能对文件的副本进行修改，然后再将修改后的整个文件副本传回到原结点。另一类文件共享协议是联机访问。联机访问意味着允许多个程序同时对一个文件进行存取，和数据库系统不同之处是用户不需要调用一个特殊的客户进程，而是由操作系统提供对远地共享文件进行访问的服务，就如同对本地文件的访问一样（即“透明存取”）。例如，网络文件系统 NFS 就属于此类。FTP 工作原理：FTP 只提供文件传送的一些基本服务，使用 TCP 可靠的运输服务。其主要功能是减少或消除在不同操作系统下处理文件的不兼容性。不兼容性主要表现如下：FTP 使用客服服务器方式，一个 FTP 服务器进程可同时为多个客户进程提供服务。FTP 服务器进程由两大部分组成：一个主进程，负责接收新的请求；另外有若干个从属进程，负责处理单个请求。从属进程中又可分为控制进程和数据传送进程。在进程文件传输时，FTP 的客户和服务器之间要建立两个并行的 TCP 连接：控制连接和数据连接。控制连接在整个会话期间一直保持打开，用于发送和接收控制信息；实际用于传输文件的是数据连接。由于 FTP 使用了一个分离的控制进程，因此 FTP 控制信息是带外传送的。使用两个独立的连接的主要好处是：使协议更加简单和更容易实现，同时在传输文件时还可以利用控制连接（如终止传输）。FTP 的适用场合：FTP 并非对所有的数据传输都是最佳的。如在大文件尾部追加一小段内容。然而，NFS 采用另一种思路：NFS 允许应用进程打开一个远地文件，并能在该文件的某一个特定的位置上开始读写数据，如此在网络上传送的只是少量的修改数据。远程终端协议 TELNETTELNET 是一个简单的远程终端协议。是 Internet 远程登陆服务的标准协议。Telnet 协议的目的是提供一个相对通用的，双向的，面向八位字节的通信方法，允许界面终端设备和面向终端的过程能通过一个标准过程进行互相交互。应用 Telnet 协议能够把本地用户所使用的计算机变成远程主机系统的一个终端。TELNET 使用了一种对称的数据表示，当每个客户机发送数据时，把它的本地终端的字符表示影射到 NVT （网络虚拟终端）的字符表示上，当接收数据时，又把NVT的表示映射到本地字符集合上。NVT 的格式定义很简单，所有的通信都使用 8 位一个字节。在运转时，NVT 使用 7 位 ASCII 码传送数据，而当高位置 1 时用作控制控制命令。TELNET 还有选项协商，这使得可以使用更多终端功能。" }, { "title": "数据结构基础", "url": "/2016/09/data-struct-basic.html", "categories": "算法", "tags": "Algorithm", "date": "2016-09-23 17:30:37 +0800", "snippet": " 数据结构在计算机科学中是一门综合性的专业基础课。数据结构的研究不仅涉及到计算机硬件（特别是编码理论、存储装置和存取方法等）的研究范围，而且和计算机软件的研究有着更密切的关系，无论是编译程序还是操作系统，都涉及到数据元素在存储器中的分配问题。数据结构不尽是一般程序设计的基础，而且是设计和实现编译程序、操作系统、数据库系统及其他系统程序和大型应用程序的重要基础。 数据结构实质 基本概念 ...", "content": " 数据结构在计算机科学中是一门综合性的专业基础课。数据结构的研究不仅涉及到计算机硬件（特别是编码理论、存储装置和存取方法等）的研究范围，而且和计算机软件的研究有着更密切的关系，无论是编译程序还是操作系统，都涉及到数据元素在存储器中的分配问题。数据结构不尽是一般程序设计的基础，而且是设计和实现编译程序、操作系统、数据库系统及其他系统程序和大型应用程序的重要基础。 数据结构实质 基本概念 抽象数据类型 算法 算法的设计要求 算法效率的度量 算法的存储空间需求 线性表 顺序表 链表 循环里链表 双向链表 栈和队列 栈 队列 队列的表示和实现 树和二叉树 树的定义和基本术语 二叉树 特殊二叉树 完全二叉树 二叉树存储结构、 二叉树遍历 遍历方式 遍历二叉树的应用 线索二叉树 树和森林 森林与二叉树的转换 树和森林的遍历 树的应用 树的计数 图 图的基本概念 图的存储结构 邻接矩阵(数组)表示法 邻接链表法（简称邻接表） 十字链表法 邻接多重表 图的边表存储结构 图的遍历 深度优先搜索算法 广度优先搜索算法 图的连通性问题 无向图 图的生成树和生成森林算法 最小生成树 普里姆算法 克鲁斯卡尔(Kruskal)算法 关节点和重连通分量 有向图 有向无环图及其应用 拓扑排序 有向图的拓扑排序 关键路径 最短路径 单源点最短路径 每一对顶点间的最短路径 查找 静态查找表 顺序表的查找 有序表的查找 动态查找表 哈希表 哈希表的冲突现象 哈希函数的构造 处理冲突的方法 哈希表的查找 内部排序 基本概念 排序评判标准 插入排序 直接插入排序 折半插入排序 2- 路插入排序 表插入排序 希尔排序 交换排序 冒泡排序 快速排序 选择排序 简单选择排序 树形选择排序 堆排序 归并排序 计数排序 桶排序 基数排序 链式基数排序 排序方法比较 外排序 多路平衡归并的实现 胜者树 败者树 置换-选择排序 最佳归并树 数据结构实质一般来说，用计算机解决一个具体问题时，大致需要经过下列几个步骤： 从具体问题抽象出一个适当的数学模型或物理模型 然后设计一个解词数学模型的算法 用程序实现该算法 测试、调整程序和算法直至得到最终答案。需求数学模型的实质是：从中提取操作的对象，并找出这些操作对象之间含有的关系然后用数学的语言加以描述从而数据结构的实质是：数据结构的实质就是操作对象之间的各种关系基本概念 数据数据是对客观事物的符号表示，在计算机科学中是指所有能输入到计算机中并被计算机程序处理的符号的总称。它是计算机程序加工的“原料”。对计算机科学而言，数据的含义极为广泛，如图像、声音等都可以编码而归之于数据的范畴。 数据元素数据元素是数据的基本单元，在计算机程序中通常作为一个整体进行考虑和处理。有时，一个数据元素可由若干个数据项组成。而数据项是数据不可分割的最小单位。 数据对象数据对象是性质相同的数据元素的集合，是数据的一个子集。如整数集、字符串 数据项、数据元素、数据对象或数据结构之间的关系数据项—&gt;数据元素（元素或结点）—&gt;数据对象或数据结构 数据结构数据结构是相互之间存在一种或多种特定关系（这种关系称为结构）的数据元素的集合。根据数据元素之间关系的不同特性，通常有下列 4 类节本结构： 集合：结构中数据元素之间除了“同属于一个集合”的关系外，别无其他关系 线性结构：结构中的数据元素之间存在一个对一个的关系 树形结构：结构中数据元素之间存在一个对多个的关系； 图状结构或网状结构：结构中的数据元素之间存在多个对多个的关系。数据结构的形式定义为：数据结构是一个文员组：Data_Structure = (D,S)其中：D 是数据元素的有限集，S 是 D 上关系的有限集。 逻辑结构上述数据结构的定义仅是对操作对象的一种数学描述，换句话说，是从操作对象抽象出来的数学模型。结构定义中“关系”描述的是数据元素之间的逻辑关系，因此又称为数据的逻辑结构。然而，讨论数据结构的目的是为了在计算机中实现对它的操作，因此还需研究如何在九三级中表示它。 物理结构数据结构在计算机中的表示（又称映像）称为数据的物理结构，又称为存储结构，它包括数据元素的表示和关系的表示。元素或结点可看成是数据元素在计算机中的映像数据元素之间的关系在计算机中有两种不同的表示方式：顺序映像和非顺序映像，并且由此得到两种不同的存储结构：顺序存储结构和链式存储结构。 顺序映像顺序映像的特点是借助元素在存储器中的相对位置来表示数据元素之间的逻辑关系。 非顺序映像非顺序映像的特点是借助指示元素存储地址的指针表示数据元素之间的逻辑关系。数据的逻辑结构和物理结构是密切相关的两个方面后面通过不断地学习，任何一个算法的设计取决于选定的数据（逻辑）结构，而算法的实现依赖于采用的存储结构。 数据类型数据类型是一个值得集合和定义在这个值集上的一组操作的总称。按“值”的不同特性，高级程序语言中的数据类型可分为两类：一类是非结构的原子类型。原子类型的值是不可分解的，例如 C 语言中的基本类型（整性、实型、字符型和枚举类型）、指针类型和空类型。另一类是结构类型。结构类型的值是由若干成分按某种结构组成的，因此是可以分解的，并且它的成分可以是非结构的，也可以是结构的。实际上，在计算机中，数据类型的概念并非局限于高级语言中，每个处理器（包括计算机硬件系统、操作系统、高级语言、数据库等）都提供了一组原子类型或结构类型。因此，从某种意义上，数据结构可以看成是“一组具有相同结构的值”，则结构类型可以看成由一种数据结构和定义 在其上的一组操作组成抽象数据类型抽象数据类型（简称 ADT）是指一个数学模型以及定义在该模型上的一组操作（比如类）。抽象数据类型的定义取决于它的一组逻辑特性，而与其在计算机内部如何表示和实现无关，即不论其内部结构如何变化，只要它的数学特性不变，都不影响外部使用。抽象数据类型和数据类型实质上是一个概念不论它们在不同系统中实现方法不同，但它们在用户看来都是相同的。因此，抽象的意义在于数据类型的数学抽象特性另一方面，抽象数据类型的范畴更广，它不再局限于前述各处理器中已定义并且实现的数据类型（也可称这类数据类型为固有数据类型），还包括用户在设计软件系统时自己定义的数据类型。所定义的数据类型的抽象层次越高，含有该抽象数据类型的软件模块的复用程度也就越高如前所述，抽象数据类型的定义由一个值域和定义在该值域上的一组操作组成。若按其值得不同特性，可细分为下列 3 中类型： 原子类型原子类型属原子类型的变量的值是不可分解的。 固定聚合类型固定聚合类型属该类型变量，其值由确定数目的成分按某种结构组成。 可变聚合类型可变聚合类型和固定聚合类型相比较，构成可变聚合类型“值”的成分的数目不确定。例如，可定义一个“有序整数序列”的抽象数据类型，其中序列的长度是可变的。显然，后两种类型可统称为结构类型。和数据结构的形式定义相对应，抽象数据类型可用以下三元组表示：(D, S, P)其中，D 是数据对象，S 是 D 上的关系集，P 是 D 的基本操作集。 多形数据类型多形数据类型是指其值得成分不能确定的数据类型。例如模板，和 typedef 工具。然而，不论其元素具有何种特性，元素之间的关系相同，基本操作也相同。从抽象数据类型的角度看，具有相同的数学特性，故称之为多形数据类型。抽象数据类型的表示与实现抽象数据类型可通过固有数据类型来表示和实现。即利用处理器中已存在的数据类型来说明新的结构，用已经实现的操作来组合新的操作。算法算法是对特定问题求解步骤的一种描述，它是指令的有限序列，其中每一条指令标识一个或多个操作；此外，一个算法还具有下列 5 个重要特性： 有穷性：一个算法必须总是（对任何合法的输入值）在执行有穷步之后结束，且每一步都可在有穷时间内完成。 确定性算法中每一条指令必须有确切的含义，理解起来不产生二义性。并且，在任何条件下，算法只有唯一的一条执行路径，即对于相同输入只能得到相同的输出。 可行性一个算法是可行的，及算法描述的操作都是可以通过已经实现的基本运算执行有限次来实现的。 输入一个算法有零个或多个的输入，这些输入取自于某个特定的对象的集合， 输出一个算法有一个或多个的输出，这些输出是同输入有着某些特定关系的量。算法的设计要求要设计一个“好”的算法应考虑达到以下目标： 正确性： 有以下几个层次，一般达到倒数第二个层次视为合格。 程序不含语法错误 程序对于机组输入数据能够得到满足规格说明要求的结果 程序对于精心选择的典型、苛刻而带有刁难性的几组输入数据能够得出满足规格说明要求的结果 程序对于一切合法的输入数据都能产生满足规格说明要求的结果。 可读性算法主要是为了人的阅读与交流，其次才是机器执行。可读性好有助于人对算法的理解；晦涩难懂的程序易于隐藏较多错误，难以调试和修改。 健壮性当输入非法时，算法也能适当地做出反应或进行处理，而不会产生莫名其妙的输出结果。并且，处理出错的方法应是返回一个表示错误或错误性质的值，而不是打印错误信息或异常，并终止程序执行，以便在更高的抽象层次上进行处理。 效率与低存储量需求通俗地说，效率指的是算法执行的时间，对于同一个问题如果有多个算法可以解决，执行时间短的算法效率高。存储量需求是指算法执行过程中所需要的最大存储空间。效率与低存储量需求这两者都与问题的规模有关。算法效率的度量算法执行时间需通过依据该算法编制的程序在计算机上运行时所消耗的时间来度量。而度量一个程序的执行时间通常有两种方法。 事后统计的方法编制好程序之后在计算机上实际运行并计时，这样不同算法的程序可通过一组或若干组相同的统计数据来分辨优劣。但这种方法有两个缺陷： （1）必须先运行依据算法编制的程序 （2）所得时间的统计量依赖于计算机的硬件、软件等环境因素，有时候容易掩盖算法本身的优劣。因此人们常常采用另一种事前分析估算的方法。一个用高级程序语言编写的程序在计算机上运行时间取决于下列因素： ①依据的算法选用何种策略 ②问题的规模 ③书写程序的语言，对于同一个算法，实现语言的级别越高，执行效率就越低 ④编译程序所产生的机器代码的质量 ⑤机器执行指令的速度 事前分析估算的方法劈开前面提到的与计算机硬件、软件有关的因素，可以认为一个特定算法“运行工作量”的大小，只依赖于问题的规模（通常用整数量n 表示），或者说，它是问题规模的函数。一个算法是由控制结构（顺序、分支和循环 3 种）和原操作（指固有数据类型的操作）构成的，则算法时间取决于两则的综合效果。为了便于比较同一问题的不同算法，通常的做法是，从算法选取一种对于所研究的问题（或算法类型）来说是基本操作的原操作，以该基本操作重复执行的次数作为算法的时间量度。一般情况下，算法中基本操作重复执行的次数是问题规模 n 的某个函数 f(n) ,算法的时间量度记作T(n) = O(f(n))它表示随问题规模 n 的增大，算法执行时间的增长率和 f(n) 的增长率相同，称做算法的渐近时间复杂度，简称时间复杂度。显然，被称做问题的基本操作的原操作应是其重复执行次数和算法的执行时间成正比的原操作，多数情况下它是循坏内的语句中的原操作。它的执行次数和包含它的语句的频度相同。语句的频度指的是该语句重复执行的次数。由于算法的时间复杂度考虑的对于问题规模 n 的增长率，则在难以精确计算基本操作执行次数（或语句频度）的情况下，只需求出它关于 n 的增长率或阶即可。有的情况下，算法中基本操作重复执行的次数还随问题的输入数据集不同而不同。如何解决这个问题呢？这里有两种方法： 计算它的平均值，即考虑它对所有可能的输入数据集的期望值，此时相应的时间复杂度为算法为算法的平均时间复杂度。 讨论算法在最坏情况下的时间复杂度。即分析最坏情况以估算算法执行时间的一个上界。算法的存储空间需求对于空间复杂度作为算法所需存储空间的量度，记作S(n) = O(f(n))其中 n 为问题的规模（或大小）一个上机的程序除了需要存储空间来寄存本身所用指令、常熟、变量和输入数据外，也需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。若输入数据所占空间只取决于问题本省，和算法无关，则只需要分析除输入和程序之外的额外空间，否则应同时考虑输入本身所需空间（和输入数据的表示形式有关）。若额外空间相对于输入数据量来说是常熟，则称此算法为原地工作。线性表线性结构的特点：在数据元素的非空有限集中， 存在唯一的一个被称作“第一个”的数据元素； 存在唯一的一个被称做“最后一个”的数据元素 除第一个之外，集合中的每个数据元素均只有一个前驱 除最后一个之外，集合中每个数据元素均只有一个后继线性表是最常见的一种数据结构。简言之，一个线性表 n 个数据元素的有限序列。至于每个数据元素的具体含义，，在不同的情况下各不相同，它可以是一个数或一个符号，也可以是一页书，甚至其他更复杂的信息。在稍复杂的线性表中，一个数据元素可以由若干个数据项组成。在这种情况下，常把数据元素称为记录，含有大量记录的线性表又称文件。线性表中的数据元素可以是各种各样的，但同一线性表中的元素必定具有相同特性，即属=同一数据对象，相邻数据元素之间存在着序偶关系，若将线性表记为(a[1],...,a[i-1],a[i],a[i+1],...,a[n])则表中 a[i-1] 领先于 a[i]，a[i] 领先于 a[i+1] ，称 a[i-1] 是 a[i] 的直接前驱，反过来是直接后继。当 i = 1,2,…,n-1 时，a[i] 有且仅有一个直接后继，当 i = 2,3,…,n 时，a[i] 有且仅有一个直接前驱。线性表中元素的个数 n （n&gt;=0)定义为线性表，n = 0 时称为空表。在非空表中的每个数据元素都有一个确定的位置，第几个称之为表中的位序（区别于数组的下标）。顺序表线性表的顺序表示指的是用一组地址连续的存储单元依次存储线性表的数据元素。其逻辑上连续关系是用物理上的连续存储来实现的。数据元素的存储位置之间满足关系：等差数列，其中首项为顺序表的首地址，公差为单个元素所占的存储空间，某个元素的存储位置可以代入等差数列的通项得到。线性表的这种机内表示称为线性表的顺序存储结构或顺序映像，通常，称这种存储结构的线性变为顺序表。它的特点是：以元素在计算机内“物理位置相邻”来表示线性表中数据元素之间的逻辑关系。每一个数据元素的存储位置都和线性表的起始位置相差一个和数据元素在线性表中的位序成正比的常数。由此，只要确定了存储线性表的起始位置，线性表中任一数据元素都可随机存取顺序表示一种随机存取的存储结构由于高级程序设计中的数组类型也有随机存取的特性，因此，通常都用数组来描述数据结构中的顺序存储结构。顺序表的优缺点顺序表利用了数组元素在物理位置上的邻接关系来表示线性表中数据元素之间的逻辑关系，这使得顺序表具有下列优点： ⑴ 无需为表示表中元素之间的逻辑关系而增加额外的存储空间； ⑵ 可以快速地存取表中任一位置的元素（即随机存取）。同时，顺序表也具有下列缺点： ⑴ 插入和删除操作需移动大量元素。在顺序表上做插入和删除操作，等概率情况下，平均要移动表中一半的元素。 ⑵ 表的容量难以确定。由于数组的长度必须事先确定，因此，当线性表的长度变化较大时，难以确定合适的存储规模。 ⑶ 造成存储空间的“碎片”。数组要求占用连续的存储空间，即使存储单元数超过所需的数目，如果不连续也不能使用，造成存储空间的“碎片”现象。链表线性表的链式存储结构的特点是用一组任意的存储单元存储线性表的数据元素（这组存储单元可以是连续的，也可以是不连续的）。元素本身的信息和元素间关系，这两部分信息组成数据元素的存储映像，称为结点。它包括两个域： 存储数据元素信息的域称为数据域 存储直接后继存储位置的域称为指针域链表是这样表示线性关系的： 头指针指示链表中第一个结点的存储位置 指针域指示下一个（相邻）结点的存储位置 最后一个数据元素没有直接后继，所以其指针域设为“空”。可见，单链表（每个结点只有一个指针域）可由头指针唯一确定。有时，我们在单链表的第一个结点之前附设一个结点，称之为头结点。头结点的数据域可以不存储任何信息，也可以存储如线性表的长度等附加信息，头结点的指针域存储指向第一个结点的指针（即第一个元素结点的存储位置）。若线性表为空，则头结点的指针域为空。链表依靠指针域进行依次查找，因此链表是废随机存取的存储结构 建立单链表的方法有：头插法和尾插法静态链表用结构体数组来模拟链表（的数据域和指针域），其中用一个整型来存储结构体的下标（游标域）以模拟指针域。可见，静态链表用结构体数组的一个分量表示一个结点，同时用结点中的游标域（指示下一个结点的下标）指示结点在数组中的相对位置。数组的零分量可看做头结点，其游标域指示链表的第一个结点。静态链表优缺点： 优点：在插入和删除操作时，只需要修改游标，不需要移动元素，从而改进了在顺序存储结构中的插入和删除操作需要大量移动元素的缺点。 缺点： 1)失去了顺序存储结构随机存取的特性。 2)没有解决连续存储分配(数组)带来的表长难以确定的问题。 循环里链表循环链表是另一种形式的链式存储结构，它的特点是表中最后一个结点的指针域指向头结点，整个链表形成一个环。由此，从表中任一结点出发均可找到表中其他结点。类似地，还可以有多重链的循环链表。循环链表的操作和线性链表基本一致，差别仅在于算法中的循环条件不是 p 或 p-&gt;next 是否为空，而是它们是否等于头指针。但有时候，若在循环链表中设立尾指针而不设头指针，可使某些操作简化。双向链表单链表只有一个指示直接后继的指针域，由此，从某个结点触发只能顺指针往后寻差其他结点。若要寻查结点的直接前驱，则需从表头指针出发。为克服单链表这种单向性的缺点，课利用双向链表。在双向链表的结点中有两个指针域，其一指向直接后继，另一指向直接前驱和单链表类似，双向链表也可以有循环表。在双向链表中在插入、删除时有很大不同，需同时修改两个方向上的指针。一元多项式的表示和相加是线性表的典型应用栈和队列栈和队列是两种重要的线性结构，它们是操作受限的线性表。栈栈是限定仅在表尾（栈顶）进行插入或删除操作的线性表。，不含元素的空栈称为空栈栈的修改是按后进先出的原则进行的，因此，栈又称为后进先出的线性表（简称 LIFO ）栈的基本操作栈的基本操作除了在栈顶进行插入或删除外，还有栈的初始化、判空及栈顶元素等。称插入元素的操作为入栈，删除栈顶元素的操作为出栈。栈的实现方式 顺序栈：顺序栈具有栈特性的顺序表。一般来说，在初始化设空栈时不应限定栈的最大容量。一个较合理的做法是：先为栈分配一个基本容量，然后再应用过程中，当栈的空间不够使用时再逐段扩大。 链栈：具有栈特性的链表栈的应用举例有：数制转换、括号匹配的检验、行编辑程序、迷宫求解、表达式求值（为实现算法优先算法，可以使用两个工作栈，一个 OPTR 用以寄存运算符，一个 OPND 用以寄存操作数或运算结果）、递归的消除等队列和栈相反，队列是一种先进先出（ FIFO ）的线性表。它只允许在标的一端（队尾）进行插入，而在另一端（对头）删除元素。队列的操作与栈的操作类似，不同的是队列的删除操作是在表的头部（对头）进行的。除了栈和队列之外，还有一种限定性数据结构是双端队列。双端队列有： 输出受限的双端队列 输入受限的双端队列 如果限定双端队列从某个端点插入的元素只能从该端点删除，则该双端队列就蜕变为两个栈底相邻接的栈了。队列的表示和实现 链队列用链表表示的队列简称为链队列。一个链队列显然需要两个分别指向队头和队尾的指针（分别称为队头指针和队尾指针）才能唯一确定。这里和线性表的单链表一样，为了操作方便起见（使第一个结点的操作方式和其他结点一样。不需要特别处理），我们也给链队列添加、一个头结点，并令指针指向头结点。由此，空的链队列的判决条件为头指针和尾指针均指向头结点。链队列的操作即为单链表的插入和删除操作的特殊情况，只是尚需修改尾指针或头指针。 循环队列和顺序栈相类似，在队列的顺序存储结构中，除了用一组地址连续的存储单元依次存放从队列头到队列尾的元素之外，尚需附设两个指针 front 和 rear 分别指示队列头元素及队列尾元素的位置。我们约定：初始化建空队列时，令 front = rear = 0，每当插入新的队列尾元素时，“尾指针增 1”；每当删除队列头元素时，“头指针增 1”。因此，在非空队列中，头指针始终指向队列头元素，而尾指针始终指向对尾元素的下一个位置。顺序队列会出现“假满”的情况，解决该现象的一个较巧妙的办法是将顺序队列臆造为一个环状的空间，称之为循环队列，此时出现“空”和“满”的判决条件是一样的，为了区分，这里有两种处理方法： 另设一个标志位以区别队列是“空”还是“满”； 或者少用一个元素空间，约定以“队列头指针在队列尾指针的下一位置（值环状的下一位置）上”作为队列呈“满”状态的标志。在 C 语言中不能用动态分配的一维数组来实现循环队列。如果用户的应用程序中设有循环队列，则必须为它设定一个最大队列长度；若用户无法预估所用队列的最大长度，则应采用链队列。队列的应用广泛，如离散事件的模拟、操作系统的作业队列等树和二叉树树型结构是类重要的非线性数据结构。其中以树和二叉树最为常用，直观看来，树是以分支关系定义的层次结构。一般来说，分等级的分类方案都可用层次结构来表示，也就是说，都可导致一个数结构。树的定义和基本术语 树的定义树是n（n≥0）个结点的有限集合。若n=0，则称为空树；否则，有且仅有一个特定的结点被称为根，当n&gt;1时，其余结点被分成m（m&gt;0）个互不相交的子集T1，T2，…，Tm，每个子集又是一棵树。由此可以看出，树的定义是递归的。树的基本术语 ① 结点：数据元素的内容及其指向其子树根的分支统称为结点。 ② 结点的度：结点的分支数。 ③ 终端结点（叶子）：度为0的结点。 ④ 非终端结点：度不为0的结点。 ⑤ 结点的层次：树中根结点的层次为1，根结点子树的根为第2层，以此类推。 ⑥ 树的度：树中所有结点度的最大值。 ⑦ 树的深度：树中所有结点层次的最大值。 ⑧ 有序树、无序树：如果树中每棵子树从左向右的排列拥有一定的顺序，不得互换，则称为有序树，否则称为无序树。 森林：森林是m棵互不相交的树的集合。对一棵树来说，其所有子树的集合就是一个森林，可以用森林和树的相互递归来描述树：任何一棵树是一个二元组Tree=(root , F),其中root是数据元素，称为树的根结点，F是m（m&gt;=0）棵树的森林，F =(T1,T2,…,Tm)，其中Ti= (ri, Fi) 称为树的第i棵子树，当m&lt;&gt;0时，树根和子树存在如下关系：RF＝{&lt;root , ri&gt; | i = 1,2,…,m, m&gt;0} 。在树结构中，结点之间的关系又可以用家族关系描述，定义如下： ① 孩子、双亲：结点子树的根称为这个结点的孩子，而这个结点又被称为孩子的双亲。 ② 子孙：以某结点为根的子树中的所有结点都被称为是该结点的子孙。 ③ 祖先：从根结点到该结点路径上的所有结点。 ④ 兄弟：同一个双亲的孩子之间互为兄弟。 ⑤ 堂兄弟：双亲在同一层的结点互为堂兄弟。 ① 树的根结点称为第一层，结点的最大层次称为树的深度。 ② 树的结点拥有的子树数目称为结点的度（degree），最大的结点度称为树的度。没有子树的结点称为叶子结点，同级结点互称兄弟。 ③ 树中各结点的位置从左到右是有次序的（不能互换），该树称为有序树，否则称为无序树。二叉树属于有序树。二叉树 二叉树的定义二叉树是另一种树形结构。其特点为：每个结点最多有两个子树，子树有左右之分（即使只有单支），次序不能颠倒。二叉树中不存在度大于2 的结点。二叉树的主要特性： ① 二叉树有五种基本形态：空二叉树、只有一个结点的二叉树、只有左子树的二叉树、只有右子树的二叉树、具有左右子树的二叉树.特殊二叉树完全二叉树 结构特点 叶结点仅可能出现在二叉树的最高两层上，如： 对任一结点，若某右分支的子孙最大层次为L，则其左分支的最大层次为 L 或 L＋1 重要性质二叉树存储结构、二叉树有两种存储结构：顺序存储结构和链式存储结构。 顺序存储结构可以用一组地址连续的存储单元依次自上而下、从左到右存储完全二叉树上的结点元素，即将完全二叉树上编号为 i 的结点，保存在一维数组中下标为 i-1 的分量中。这种顺序存储结构仅适用于完全二叉树，因为： 链式存储结构为充分利用空间，可以采取链式存储结构来保存一棵二叉树。有二叉链表法、三叉链表法等 二叉链表法：链表结点有三个域组成：数据域、指向左子树的指针域、指向右子树的指针域。该方法对 Child 操作比较方便，但寻找双亲结点需要遍历整个链表。 三叉链表法：为解决二叉链表中寻找双亲结点不方便的问题，可在二叉链表的基础上再增加一个指针域，让该指针域指向当前结点的双亲结点这就是三叉链表法。在含有 n 个结点的二叉链表中有 n+1 个空链域。可以利用这些空链域存储其他有用信息，从而得到另一种链式存储结构—–线索链表。二叉树遍历二叉树是一种非线性的数据结构，在对它进行操作时，总是需要逐一对每个数据元素实施操作，这样就存在一个操作顺序问题，由此提出了二叉树的遍历操作。所谓遍历二叉树就是按某种顺序访问二叉树中的每个结点一次且仅一次的过程。这里的访问可以是输出、比较、更新、查看元素内容等各种操作。遍历方式二叉树的遍历方式分为两大类：一类按根、左子树和右子树三个部分进行访问；另一类按层次访问。下面我们将分别进行讨论。 按照左右子树访问“先左后右”的方式，有如下三种遍历方式： ① 先序遍历：访问根结点，访问左子树、访问右子树； ② 中序遍历：访问左子树，访问根结点、访问右子树； ③ 后序遍历：访问左子树，访问右子树，访问根结点。访问左右子树时，仍然按照先序、中序、遍历中规定的访问顺序。遍历二叉树的应用 表达式求解：利用二叉树，给出表达式的中缀、前缀（波兰式）和后缀表示（逆波兰式） 表达式之间的转换所谓表达式之间的转换，指的是中缀表达式、前缀表达式和后缀表达式之间的转换。有两种方法，第一种称为“直接转换法”，第二种称为“二叉树辅助转换法”。 直接转换法：该方法适用于将中缀表达式转化为前缀表达式或后缀表达式，过程为： 1&gt; 考虑表达式中操作符的优先级和结合性，适当添加括号。表达式最外层也添加括号。 2&gt; 由最内层括号开始，将括号中的所有操作符依次自左向右取代与之最相邻的左括号（如要转化为前缀表达式）或右括号（如要转化为前缀表达式），直到最外层的括号为止。 3&gt; 将表达式中剩余的所有右括号全部去掉。 二叉树辅助转化法除了以上方法外，表达式之间还可以通过先化成二叉树，再利用二叉树的遍历过程，得到前缀、后缀表达式。这样的二叉树称为表达式二叉树。该方法也是已知中缀表达式，然后求前缀、后缀表达式。 根据二叉树的前序遍历和中序遍历，或者后序遍历和中序遍历，给出二叉树的结构。利用前序遍历和中序遍历求二叉树结构。步骤为： 1&gt; 利用前序遍历的特点（根、左子树、右子树）找出根结点；说明：前序遍历中，根结点一定是最左侧的结点，因为根是第一个被遍历到的结点。 2&gt; 利用1&gt;中找到的根结点，在中序遍历中以根为中心，其左侧为左子树所有结点，其右侧为右子树所有结点，此时可将中序遍历分为三部分：根，左子树、右子树。 3&gt; 利用上述方法，再分别处理左子树和右子树，直至处理完毕。 利用后序遍历和中序遍历求二叉树结构。步骤为： 1&gt; 利用后序遍历的特点（左子树、右子树、根）找出根结点；说明：后序遍历中，根结点一定是最右侧的结点，因为根是最后一个被遍历到的结点。 2&gt; 利用1&gt;中找到的根结点，在中序遍历中以根为中心，其左侧为左子树所有结点，其右侧为右子树所有结点，此时可将中序遍历分为三部分：根，左子树、右子树。 3&gt; 利用上述方法，再分别处理左子树和右子树，直至处理完毕。线索二叉树遍历二叉树是以一定规则将二叉树中结点排列成一个线性序列，得到二叉树中结点的先序序列或中序序列或后序序列。这实质上是对一个非线性结构进行线性化操作，使每个结点（除第一个和最后一个外）在这些线性序列中有且只有一个直接前驱和直接后继。线索化的原因二叉树的二叉链表表示法有n+1个空链。同时，二叉链表（或三叉链表）虽然能方便的找到当前结点的双亲结点或左、右子结点，但如果要求寻找当前结点的前驱结点或者后继结点（按照某种遍历方法），则上述方法就不方便了，只能在遍历过程中动态得到。如将二叉链表法中的 n+1 个空链利用起来，让其指向当前结点的前驱结点（如果指向左子树的指针域为空）或后继结点（如果指向右子树的指针域为空），则可解决以上问题，这就是线索二叉树提出的原因。如何保存在遍历过程中得到的信息呢？一个最简单的办法是在每个结点上增加两个指针域 fwd 和 bkwd，分别指示结点在依任一次序遍历时得到的前驱和后继信息。显然，这样做使得结构存储密度大大降低。另一方面，在有 n 个结点的二叉链表中必定存在 N+1 个空链域。由此摄像能够利用这些空链域来存放结点的前驱和后继的信息。由于可能改变原来左右指针域的实际意义，因此如果要实现以上想法，必须额外增加两个指示域 Ltag 和 Rtag，并分别定义如下：LTag：取值为0时，作用不变（指向左孩子），取值为1时，指示当前结点的前驱结点；RTag：取值为0时，作用不变（指向右孩子），取值为1时，指示当前结点的后继结点；则结点结构为：以上这种结点结构构成的二叉链表作为二叉树的存储结构，叫做线索链表，其中指向结点前驱和后继的指针，叫做线索。加上线索的二叉树称之为线索二叉树。对二叉树以某舟次序遍历使其变为线索二叉树的过程叫做线索化以中序遍历为例：重要说明： 1&gt; 增加了一个头结点，该头结点的左指针指向二叉树的根结点A，右指针指向最后一个结点； 第一个结点D的前驱可设定为头结点，最后一个结点C的后继也可设定为头结点。 在线索二叉树中找后继结点和前驱结点（以中序线索二叉树为例） 后继结点的查找方法：若结点的右链标志为1（说明该结点是叶子结点）,则右链域指向的就是结点的直接后继；若结点的右链标志为0（说明该结点不是叶子结点）,则遍历其右子树是最先访问的结点（右子树的最左下结点）即是其直接后继。 前驱结点的查找方法：若结点的左链标志为1（说明该结点是叶子结点）,则左链域指向的结点就是结点的直接前驱；若结点的左链标志为0（说明该结点不是叶子结点）,则遍历其左子树时最后访问的一个结点（左子树最右下的结点）为其前驱。树和森林有关树的存储结构，有以下几种： 双亲表示法：属于顺序存储，用一组连续地址空间存储树的结点，同时在每个结点中附设一个指示器，该指示器指示其双亲结点在表中的位置。说明：本结构可方便实现查找 parent 的操作，但不方便查找 child 的操作。 孩子表示法：利用线性表的顺序存储及链式存储相结合的方式：每个树结点都对应一个单链表，该单链表中保存的是其所有孩子结点的位置结点，位置结点中有一个指向下一个孩子的链域。说明：1&gt; 本结构易于实现child操作，但是不方便parent操作。2&gt; 可以将以上两种方法合并起来。 孩子兄弟表示法用二叉链表作为树的存储结构，链表结点的两个指针域意义发生变化：原左子树指针域指向当前结点的第一个孩子结点，原右子树指针指向当前结点的第一个兄弟结点。从另一个角度出发，当前结点的左子树的右子树，实际上是当前结点的其它孩子结点。说明：可根据本方法将树转化为二叉树存储，转换后的二叉树一定没有右子树，森林与二叉树的转换由于二叉树和树都可用二叉链表作为存储结构，则以二叉链表作为媒介可导出树与二叉树之间一个对应关系。也就是说，给定一棵树，可以找到唯一的一颗二叉树与之对应，从物理结构来看，它们的二叉链表是相同的，只是解释不同而已。一般树转化为二叉树基本原理是树的孩子兄弟表示法，我们可以采用如下方法进行转化： ① 将树中结点的所有兄弟结点用水平线连接起来； ② 除保留当前结点同其最左子结点的连接之外，将所有同其余子结点的连接线全部删除；同时将当前结点同其最左子结点的连接线修改为垂直连接； ③ 将得到的图形顺时针旋转45度，即得二叉树。（或将当前纸面逆时针旋转45度，即得） 重要说明以上转化过程实际上将一般树中某个结点的最左孩子视为该结点在二叉树中的左孩子（关系未变），将该结点的其余子结点视为“该结点的左孩子的右孩子”（关系改变，该结点在一般树中的其余子结点的层次在二叉树中下降了，而且子结点的在树中的原位置越向右，在转化后的二叉树中层次就越向虾）。说明：将一棵树转换成二叉树实际上就是将这棵树用孩子兄弟表示法存储即可，此时，树中的每个结点最多有两个指针：一个指针指向第一个孩子，另一个指针指向右侧第一个兄弟。当你将这两个指针看作是二叉树中的左孩子指针和孩子右指针时，就是一棵二叉树了。一棵树转换成二叉树后，根结点没有右孩子。森林转化为二叉树将森林转换成二叉树的方法与一棵树转换成二叉树的方法类似，只是把森林中所有树的根结点看作兄弟关系，并对其中的每棵树依次转换。转化步骤为： ① 将森林中所有的树都转化为二叉树； ② 第一棵树T1的根结点作为 T 的根结点，T1 的根结点的子树转化为T的左子树，森林的其它树T2，T3，…Tn 转化为T的右子树。二叉树转化为森林如果 B = (root, LB, RB) 是一颗二叉树，则可按如下规则转换成森林 F=(T1,T2,…,Tm)； （1）若 B 为空，则 F 为空； （2）若 B 非空，则 F 中第一颗树 T1 的根 ROOT(T1) 即为二叉树 B 的根 root；T1 中根结点的子树森林 F1 是由 B 的左子树 LB转换而成的森林；F 中除 T1 之外其余树组成的森林 F’ = {T1, T2, … , Tm} 是由 B 的右子树 RB 转换而成的森林。从上述递归定义容易写成相互转换的递归算法。同时，森林和树的操作亦可转换成二叉树的操作来实现。树和森林的遍历由树结构的定义可以引出两种次序遍历树的方法： ① 先根(次序)遍历: 若树不空，则先访问根结点，然后依次先根遍历各棵子树。 后根(次序)遍历: 若树不空，则先依次后根遍历各棵子树，然后访问根结点。 森林的遍历先序遍历 1&gt; 若森林不空，则访问森林中第一棵树的根结点； 2&gt; 先序遍历森林中第一棵树的子树森林； 3&gt; 先序遍历森林中(除第一棵树之外)其余树构成的森林。即：依次从左至右对森林中的每一棵树进行先根遍历。中序遍历 1&gt; 若森林不空，则中序遍历森林中第一棵树的子树森林； 2&gt; 访问森林中第一棵树的根结点； 3&gt; 中序遍历森林中(除第一棵树之外)其余树构成的森林。即：依次从左至右对森林中的每一棵树进行后根遍历。树的应用 等价类问题 哈夫曼树 1) 结点之间的路径长度：树上结点之间的分支数目，称为结点之间的路径长度。 2) 树的路径长度：从树的根结点到每一个终端结点的路径长度之和。 3) 树的带权路径长度：如果终端结点带权，则有： ① 结点的带权路径长度：从树根到该结点的路径长度与结点上权值的乘积。 ② 树的带权路径长度：树中所有终端结点的带权路径长度之和。 记作：WPL＝W1 * L1 +W2 * L2 +…+Wn * Ln 哈夫曼树(Huffman Tree)：假设有n个权值｛w1,w2,…wn｝，构造一棵具有n个叶子结点的二叉树，每个叶子结点的权值为wi（i=1,…n），则其中带权路径长度最小的二叉树称为最优二叉树，也称赫夫曼树(Huffman Tree)。构造Huffman树的步骤：（Huffman算法） ① 对给定的n个权值按照非递减顺序排列，构造n棵只有一个结点的二叉树的集合F＝｛T1,T2,…Tn｝； ② 在F中选定两棵根结点的权值最小的两个二叉树作为左右子树，构造一棵新的二叉树，新的二叉树的根结点的权值设为其左右子树根结点的权值之和； ③ 从F中删除原来的两棵二叉树，同时将新二叉树插入其中； ④ 重复执行（2）和（3），直到F中剩余一棵二叉树，这棵树就是所求的Huffman树，结束。 说明：为方便构造，可有如下方法，供参考。 ① 将叶子结点用圆圈起来，在圆圈内部写上该叶子结点的权值，按照权值由小到大的顺序依次排列。非叶结点（其权值由计算所得）也用圆圈表示，在圆圈的右侧写上计算得出的权值； ② 构造过程中，可遵从“左子树根结点权值&lt;＝右子树根结点权值”的原则； ③ 构造过程中，如果出现相同权值的情况，可任意选择； Huffman编码：构造出Huffman树后，左向分支标志为“0”，右向分支标志为”1”，则从根结点到叶结点之间的路径上分支字符组成的编码即为Huffman编码，该编码必为前缀编码。前缀编码：任何一个字符的编码都不是另一个字符的编码的前缀。例如0、10、110、111即为前缀编码。树的计数不同形态的二叉树的数目恰好是前序序列均为 12…n 的二叉树所能得到的中序序列的数目。二中序遍历的过程实质上是一个结点近栈和出栈的过程。由前序序列 12…n 所能得到的中序序列的数目恰为数列 12…n 按不同顺序进栈和出栈所能得到的排列的数目。这个数目为：图图(Graph)是一种比线性表和树更为复杂的数据结构。 在线性表中：数据元素之间仅有线性关系，每个数据元素只有一个直接前驱和一个直接后继； 在树形结构中：数据元素之间有着明显的层次关系，并且每一层上的数据元素可能和下一层中多个元素（即其孩子结点）有关，但只能和上一层中一个元素（即其双亲结点）有关； 在图中：是研究数据元素之间的多对多的关系。在这种结构中，任意两个元素之间可能存在关系。即结点之间的关系可以是任意的，图中任意元素之间都可能相关。图的基本概念一个图(G)定义为一个偶对 (V,E) ，记为 G=(V,E) 。其中： V 是顶点(Vertex)的非空有限集合，记为 V(G)；E是无序集V&amp;V的一个子集，记为 E(G) ，其元素是图的弧(Arc)。将顶点集合为空的图称为空图。其形式化定义为：G=(V ，E)V={v|vdata object}E={&lt;v,w&gt;| v,wV∧p(v,w)}P(v,w) 表示从顶点 v 到顶点 w 有一条直接通路。 弧(Arc) ：弧(Arc)表示两个顶点 v 和 w 之间存在一个关系，用顶点偶对 &lt;v,w&gt; 表示。通常根据图的顶点偶对将图分为有向图和无向图。 有向图(Digraph)：若图G的关系集合 E(G) 中，顶点偶对 &lt;v,w&gt; 的 v 和 w 之间是有序的，称图 G 是有向图。在有向图中，若 &lt;v,w&gt;∈ E(G) ，表示从顶点 v 到顶点 w 有一条弧。 其中：v 称为弧尾 (tail) 或始点 (initial node)，w 称为弧头(head)或终点(terminal node) 。 无向图(Undigraph)：若图 G 的关系集合 E(G) 中，顶点偶对 &lt;v,w&gt; 的 v 和 w 之间是无序的，称图 G 是无向图。在无向图中，若任一&lt;v,w&gt; ∈ E(G) ，有&lt;w,v&gt; ∈ E(G) ，即 E(G) 是对称，则用无序对 (v,w) 表示 v 和 w 之间的一条边(Edge)，因此 (v,w) 和 (w,v) 代表的是同一条边。 完全无向图：对于无向图，若图中顶点数为 n ，用 e 表示边的数目，则e ∈ [0，n(n-1)/2] 。具有 n(n-1)/2 条边的无向图称为完全无向图。完全无向图另外的定义是： 完全有向图：对于有向图，若图中顶点数为n ，用e表示弧的数目，则e ∈ [0，n(n-1)] 。具有n(n-1)条边的有向图称为完全有向图。完全有向图另外的定义是： 稀疏图和稠密图有很少边或弧的图（e&lt;n㏒n）的图称为稀疏图，反之称为稠密图。 权权(Weight)：与图的边和弧相关的数。权可以表示从一个顶点到另一个顶点的距离或耗费。 子图和生成子图：设有图 G=(V，E) 和 G’=(V’，E’)，若V‘⊆ V且E’⊆ E ，则称图 G’是 G 的子图；若V’=V 且 E’⊆ E，则称图 G’是 G 的一个生成子图。 顶点的邻接(Adjacent)：对于无向图 G=(V，E)，若边(v,w)E，则称顶点 v 和 w 互为邻接点，即 v 和 w 相邻接。边 (v,w) 依附(incident)与顶点 v 和 w 。对于有向图 G=(V ，E)，若有向弧 &lt;v,w&gt; ∈ E，则称顶点 v “邻接到”顶点 w，顶点 w “邻接自”顶点 v ，弧 &lt;v,w&gt; 与顶点 v 和 w “相关联” 。 顶点的度、入度、出度： 路径(Path)、路径长度、回路(Cycle) ： 连通图、图的连通分量： 生成树、生成森林：关于无向图的生成树的几个结论： ◆ 一棵有n个顶点的生成树有且仅有n-1条边； ◆ 如果一个图有n个顶点和小于n-1条边，则是非连通图； ◆ 如果多于n-1条边，则一定有环； ◆ 有n-1条边的图不一定是生成树。有向图的生成森林是这样一个子图，由若干棵有向树组成，含有图中全部顶点。有向树是只有一个顶点的入度为0 ，其余顶点的入度均为1的有向图。 网：每个边(或弧)都附加一个权值的图，称为带权图。带权的连通图(包括弱连通的有向图)称为网或网络。网络是工程上常用的一个概念，用来表示一个工程或某种流程。图的存储结构图的存储结构比较复杂，其复杂性主要表现在： ◆ 任意顶点之间可能都存在联系：无法以数据元素在存储区中的物理位置来表示元素之间的关系。即图没有顺序映像的存储结构，但可以借助数组的数据类型表示元素之间的关系，比如邻接矩阵。 ◆ 图中顶点的度不一样：用多重链表表示图是自然的事，它是一种最简单的链式映像结构，即以一个由一个数据域和多个指针域组成的结点表示图中一个顶点，其中数据域存储该顶点的信息，指针域存储指向其邻接点的指针。但，有的顶点度有可能相差很大，若按度数最大的顶点设计结构，则会浪费很多存储单元，反之按每个顶点自己的度设计不同的结构，又会影响操作。因此，和树类似，在实际应用中不宜采用这种结构，而应根据具体的图和需要进行的操作，设计恰当的结点结构和表结构。图的常用的存储结构有：邻接矩阵、邻接链表、十字链表、邻接多重表和边表。邻接矩阵(数组)表示法基本思想：对于有 n 个顶点的图，用一维数组 vexs[n] 存储顶点信息，用二维数组 A[n][n] 存储顶点之间关系的信息。该二维数组称为邻接矩阵。在邻接矩阵中，以顶点在 vexs 数组中的下标代表顶点，邻接矩阵中的元素 A[i][j] 存放的是顶点 i 到顶点 j 之间关系的信息。以二维数组表示有 n 个顶点的图时，需存放 n 个顶点信息和 n^2 个弧信息的存储量。若考虑无向图的邻接矩阵的对称性，则可以采用压缩存储的方式只存入矩阵的下三角（或上三角）元素。构造一个具有 n 个顶点和 e 条边的无向网 G 的时间复杂度是 O(n^2 + e*n), 其中对邻接矩阵 G.arcs 的初始化耗费了 O(n^2) 的时间。 无向图的数组表示 无权图的邻接矩阵 带权图的邻接矩阵无向图邻接矩阵的特性 ◆ 邻接矩阵是对称方阵； ◆ 对于顶点Vi，其度数是第 i 行的非 0 元素的个数； ◆ 无向图的边数是上(或下)三角形矩阵中非 0 元素个数。 有向图的数组表示 有向无权图的邻接矩阵 带权有向图的邻接矩阵有向图邻接矩阵的特性 ◆ 对于顶点 Vi，第 i 行的非0元素的个数是其出度 OD(Vi)；第 i 列的非0元素的个数是其入度 ID(Vi) 。 ◆ 邻接矩阵中非 0 元素的个数就是图的弧的数目。 图的邻接矩阵的操作图的邻接矩阵的实现比较容易，定义两个数组分别存储顶点信息(数据元素)和边或弧的信息(数据元素之间的关系) 。 图的顶点定位图的顶点定位操作实际上是确定一个顶点在vexs数组中的位置(下标) ，其过程完全等同于在顺序存储的线性表中查找一个数据元素。 向图中增加顶点向图中增加一个顶点的操作，类似在顺序存储的线性表的末尾增加一个数据元素。 向图中增加一条弧根据给定的弧或边所依附的顶点，修改邻接矩阵中所对应的数组元素。邻接链表法（简称邻接表）基本思想：对图的每个顶点建立一个单链表，存储该顶点所有邻接顶点及其相关信息。每一个单链表设一个表头结点。第 i 个单链表表示依附于顶点 Vi 的边(对有向图是以顶点 Vi 为头或尾的弧)。链表中的结点称为表结点，每个结点由三个域组成，其中邻接点域(adjvex)指示与顶点 Vi 邻接的顶点在图中的位置(顶点编号)，链域(nextarc)指向下一个与顶点 Vi 邻接的表结点，数据域(info)存储和边或弧相关的信息，如权值等。对于无权图，如果没有与边相关的其他信息，可省略此域。每个链表设一个表头结点(称为顶点结点)，由两个域组成，链域(firstarc)指向链表中的第一个结点，数据域(data) 存储顶点名或其他信息。在图的邻接链表表示中，所有顶点结点用一个向量 以顺序结构形式存储，可以随机访问任意顶点的链表，该向量称为表头向量，向量的下标指示顶点的序号。用邻接链表存储图时，对无向图，其邻接链表是唯一的：对有向图，其邻接链表有两种形式，即：正邻接表和逆邻接表若无向图中有 n 个顶点、e 条边，则它的邻接表需 n 个头结点和 2e 个表结点。在邻接表上容易找到任一顶点的第一个邻接点和下一个邻接点，但要判定任意两个顶点（Vi 和 Vj）之间是否有边或弧相连，则需要搜索第 i 个或第 j 个链表，因此，不及邻接矩阵方便。在建立邻接表或逆邻接表时，若输入的顶点信息即为顶点的编号，则建立邻接表的时间复杂度为 O(n+e)，否则，需要通过查找才能得到顶点在图中位置，则时间复杂度为 O(n*e)。邻接表法的特点： ◆ 表头向量中每个分量就是一个单链表的头结点，分量个数就是图中的顶点数目； ◆ 在边或弧稀疏的条件下，用邻接表表示比用邻接矩阵表示节省存储空间； ◆ 在无向图，顶点Vi的度是第i个链表的结点数； ◆ 对有向图可以建立正邻接表或逆邻接表。正邻接表是以顶点Vi为出度(即为弧的起点)而建立的邻接表；逆邻接表是以顶点Vi为入度(即为弧的终点)而建立的邻接表； ◆ 在有向图中，第i个链表中的结点数是顶点Vi的出 (或入)度；求入 (或出)度，须遍历整个邻接表； ◆ 在邻接表上容易找出任一顶点的第一个邻接点和下一个邻接点；十字链表法十字链表(Orthogonal List)是有向图的另一种链式存储结构，是将有向图的正邻接表和逆邻接表结合起来得到的一种链表。在这种结构中，每条弧的弧头结点和弧尾结点都存放在链表中，并将弧结点分别组织到以弧尾结点为头(顶点)结点和以弧头结点为头(顶点)结点的链表中。 ◆data域：存储和顶点相关的信息； ◆指针域firstin：指向以该顶点为弧头的第一条弧所对应的弧结点； ◆指针域firstout：指向以该顶点为弧尾的第一条弧所对应的弧结点； ◆尾域tailvex：指示弧尾顶点在图中的位置； ◆头域headvex：指示弧头顶点在图中的位置； ◆指针域hlink：指向弧头相同的下一条弧； ◆指针域tlink：指向弧尾相同的下一条弧； ◆Info域：指向该弧的相关信息；邻接多重表邻接多重表(Adjacency Multilist)是无向图的另一种链式存储结构。邻接表是无向图的一种有效的存储结构，在无向图的邻接表中，一条边(v,w)的两个表结点分别初选在以v和w为头结点的链表中，很容易求得顶点和边的信息，但在涉及到边的操作会带来不便。邻接多重表的结构和十字链表类似，每条边用一个结点表示；邻接多重表中的顶点结点结构与邻接表中的完全相同 ◆Data域：存储和顶点相关的信息； ◆指针域firstedge：指向依附于该顶点的第一条边所对应的表结点； ◆标志域mark：用以标识该条边是否被访问过； ◆ivex和jvex域：分别保存该边所依附的两个顶点在图中的位置； ◆info域：保存该边的相关信息； ◆指针域ilink：指向下一条依附于顶点ivex的边； ◆指针域jlink：指向下一条依附于顶点jvex的边； 邻接多重表与邻接表的区别：后者的同一条边用两个表结点表示，而前者只用一个表结点表示；除标志域外，邻接多重表与邻接表表达的信息是相同的，因此，操作的实现也基本相似。图的边表存储结构在某些应用中，有时主要考察图中各个边的权值以及所依附的两个顶点，即图的结构主要由边来表示，称为边表存储结构。在边表结构中，边采用顺序存储，每个边元素由三部分组成：边所依附的两个顶点和边的权值；图的顶点用另一个顺序结构的顶点表存储。#define INFINITY MAX_VAL /* 最大值∞ */#define MAX_VEX 30 /* 最大顶点数 */#define MAX_EDGE 100 /* 最大边数 */typedef struct ENode{ int ivex, jvex; /* 边所依附的两个顶点 */ WeightType weight; /* 边的权值 */}ENode; /* 边表元素类型定义 */typedef struct{ int vexnum, edgenum; /* 顶点数和边数 */ VexType vexlist[MAX_VEX]; /* 顶点表 */ ENode edgelist[MAX_EDGE]; /* 边表 */}ELGraph;图的遍历图的遍历(Travering Graph)：从图的某一顶点出发，访遍图中的其余顶点，且每个顶点仅被访问一次。图的遍历算法是各种图的操作的基础。 ◆复杂性：图的任意顶点可能和其余的顶点相邻接，可能在访问了某个顶点后，沿某条路径搜索后又回到原顶点。 ◆解决办法：在遍历过程中记下已被访问过的顶点。设置一个辅助向量 Visited[1…n](n为顶点数)，其初值为 0，一旦访问了顶点 Vi 后，使 Visited[i] 为 1 或为访问的次序号。图的遍历算法有深度优先搜索算法和广度优先搜索算法。采用的数据结构是(正)邻接链表。深度优先搜索算法深度优先搜索(Depth First Search–DFS)遍历类似树的先序遍历，是树的先序遍历的推广。假设初始状态是图中所有顶点未曾被访问，则深度优先搜索可从图中某个顶点 v 出发，访问此顶点，然后依次从 v 的未被访问的邻接点出发深度优先遍历图，直至图中所有和 v 有路径相通的顶点都被访问到；若此时图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。算法思想设初始状态时图中的所有顶点未被访问，则：算法分析：在遍历图时，对图中每个顶点之多调用一次 DFS 函数，因为一旦某个顶点被标志成已被访问，就不再从它出发进行搜索。因此，遍历图的过程实质上是对每个顶点查找其邻接点的过程。其耗费的时间则取决于所采用的存储结构。当臫二维数组表示邻接矩阵作图的存储结构时，查找每个顶点的邻接点所需时间为 O(n^2)，其中 n 为图中顶点数。而当以邻接表作图的存储结构时，找邻接点所需时间为 O(e)，其中 e 为无向图中边的数或有向图中弧的数。由此，当以邻接表作存储结构时，深度优先搜索遍历图的时间复杂度为 O(n+e)。广度优先搜索算法广度优先搜索(Breadth First Search–BFS)遍历类似树的按层次遍历的过程。假设从图中某顶点 v 出发，在访问了 v 之后依次访问 v 的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使“先被访问的顶点的邻接点”先于“后被访问的顶点的邻接点”被访问，直至图中所有已被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到位置。换句话说，广度优先搜索遍历图的过程是以 v 为起始点，由近至远，依次访问和 v 有路径相同且路径长度为 1,2,… 的顶点。算法思想：设初始状态时图中的所有顶点未被访问，则：算法分析：每个顶点至多进依次队列。遍历图的过程实质上是通过边或弧找邻接点的过程。因此广度优先搜索遍历图的时间复杂度和深度优先搜索遍历相同，两者不同之处仅仅在于对顶点访问的顺序不同。图的遍历可以系统地访问图中的每个顶点，因此，图的遍历算法是图的最基本、最重要的算法，许多有关图的操作都是在图的遍历基础之上加以变化来实现的。图的连通性问题无向图 无向图的连通分量对于无向图，对其进行遍历时： ◆ 若是连通图：仅需从图中任一顶点出发，就能访问图中的所有顶点； ◆ 若是非连通图：需从图中多个顶点出发。每次从一个新顶点出发所访问的顶点集序列恰好是各个连通分量的顶点集； 生成树若G=(V,E)是无向连通图， 顶点集和边集分别是V(G) ，E(G) 。若从G中任意点出发遍历时， E(G)被分成两个互不相交的集合：T(G) ：遍历过程中所经过的边的集合；B(G) ：遍历过程中未经过的边的集合；显然： E(G)=T(G)∪B(G) ，T(G)∩B(G)=Ø显然，图 G’=(V, T(G))是 G 的极小连通子图，且 G’是一棵树。G’称为图 G 的一棵生成树。从任意点出发按 DFS 算法得到生成树 G’称为深度优先生成树；按 BFS 算法得到的 G’称为广度优先生成树。 生成森林注意：当给定无向图要求画出其对应的生成树或生成森林时，必须先给出相应的邻接表，然后才能根据邻接表画出其对应的生成树或生成森林。图的生成树和生成森林算法对图的深度优先搜索遍历 DFS(或BFS)算法稍作修改，就可得到构造图的 DFS 生成树算法。在算法中，树的存储结构采用孩子—兄弟表示法。首先建立从某个顶点 V 出发，建立一个树结点，然后再分别以 V 的邻接点为起始点，建立相应的子生成树，并将其作为 V 结点的子树链接到 V 结点上。显然，算法是一个递归算法。最小生成树 生成树的代价：如果连通图是一个带权图，则其生成树中的边也带权，生成树中所有边的权值之和称为生成树的代价。 最小生成树(Minimum Spanning Tree) ：带权连通图中代价最小的生成树称为最小生成树。最小生成树在实际中具有重要用途，如设计通信网。设图的顶点表示城市，边表示两个城市之间的通信线路，边的权值表示建造通信线路的费用。n 个城市之间最多可以建 nX(n-1)/2 条线路，如何选择其中的 n-1 条，使总的建造费用最低?构造最小生成树的基本原则： ◆ 尽可能选取权值最小的边，但不能构成回路； ◆ 选择n-1条边构成最小生成树。以上的基本原则是基于 MST 的如下性质：设G=(V，E)是一个带权连通图，U是顶点集V的一个非空子集。若u∈U ，v∈V-U，且(u, v)是U中顶点到V-U中顶点之间权值最小的边，则必存在一棵包含边(u, v)的最小生成树。以上性质证明如下：设图 G 的任何一棵最小生成树都不包含边 (u,v)。设 T 是 G 的一棵生成树，则 T 是连通的，从 u 到 v 必有一条路径 (u,…,v)，当将边 (u,v) 加入到T中时就构成了回路。则路径 (u, …,v) 中必有一条边 (u’,v’) ，满足 u’∈U ，v’∈V-U 。删去边 (u’,v’) 便可消除回路，同时得到另一棵生成树T’。由于 (u,v) 是U中顶点到 V-U 中顶点之间权值最小的边，故 (u,v) 的权值不会高于 (u’,v’) 的权值，T’的代价也不会高于T， T’是包含 (u,v) 的一棵最小生成树，与假设矛盾。普里姆算法（Prim）和克鲁斯卡尔（Kruskal）算法是两个利用 MST 性质构造最小生成树的算法。普里姆算法从连通网N=(U，E)中找最小生成树T=(U，TE) 算法思想 ⑴ 若从顶点 v0 出发构造，U={v0}，TE={}； ⑵ 先找权值最小的边 (u，v)，其中 u ∈U 且 v ∈V-U，并且子图不构成环，则 U= U ∪{v}，TE=TE ∪{(u，v)} ； ⑶ 重复⑵，直到 U=V 为止。则TE中必有 n-1 条边， T=(U，TE) 就是最小生成树。下面是具体例子演示： 算法实现说明为实现这个算法虚附设一个辅助数组 closedge，以记录从 U 到 V-U 具有最小代价的边。对每个顶点 v0 ∈V-U，在辅助数组中存在一个相应分量closedge[i-1]，它包括两个域，其中 lowcost 存储该边上的权，vex 域存储该边依附的在 U 中的顶点。显然，closedge[i-1].lowcost = Min{cost(u,vi) | u ∈ U}下图是普里姆算法的机内演示：初始状态时，由于 U={v0}，则到 V-U 中各顶点的最小边，即为从依附于顶点 1 的各条边中，找到一条代价最小的边 (u0,v0)=(1,3) 为生成树上的第一条边，同时将 v0(=v1) 并入集合 U。然后修改辅助数组中的值。首先将 closedge[2].lowcost 改为 ‘0’ ，以示顶点 v0 已并入 U。然后，由于边 (v0,v2) 上的权值小于 closedge[4] 和 closedge[5]。依次类推，直到 U=V 。 算法分析：设带权连通图有 n 个顶点，则算法的主要执行是二重循环： 求 closedge 中权值最小的边，频度为 n-1； 修改 closedge 数组，频度为 n 。因此，整个算法的时间复杂度是 O(n^2)，与边的数目无关。因此，适合于求边稠密的网的最小生成树。克鲁斯卡尔(Kruskal)算法 算法思想设 G=(V, E) 是具有n个顶点的连通网，T=(U, TE) 是其最小生成树。初值：U=V，TE={} 。对 G 中的边按权值大小从小到大依次选取。 ⑴ 选取权值最小的边 (vi，vj)，若边 (vi，vj) 加入到 TE 后形成回路，则舍弃该边 (边(vi，vj) ；否则，将该边并入到 TE 中，即 TE=TE ∪{(vi，vj)} 。 ⑵ 重复⑴，直到 TE 中包含有 n-1 条边为止。下面是一个具体的例子演示： 算法实现说明Kruskal 算法实现的关键是：当一条边加入到 TE 的集合后，如何判断是否构成回路?简单的解决方法是：定义一个一维数组 Vset[n] ，存放图 T 中每个顶点所在的连通分量的编号。 ◆ 初值：Vset[i]=i，表示每个顶点各自组成一个连通分量，连通分量的编号简单地使用顶点在图中的位置(编号)。 ◆ 当往T中增加一条边 (vi，vj) 时，先检查 Vset[i] 和 Vset[j] 值：若Vset[i]≠Vset[j]，则加入此边不会形成回路，将此边加入到生成树的边集中。若 Vset[i]=Vset[j]：表明 vi 和 vj 处在同一个连通分量中，加入此边会形成回路； ◆ 加入一条新边后，将两个不同的连通分量合并：将一个连通分量的编号换成另一个连通分量的编号。 算法分析设带权连通图有 n 个顶点，e 条边，则算法的主要执行是： ◆ Vset 数组初始化：时间复杂度是 O(n) ； ◆ 边表按权值排序：若采用堆排序或快速排序，时间复杂度是 O(e㏒e) ； ◆ while 循环：最大执行频度是 O(n)，其中包含修改 Vset 数组，共执行 n-1 次，时间复杂度是 O(n^2) ；整个算法的时间复杂度是O(e㏒e+n^2) 。关节点和重连通分量 关节点假若在删去顶点 v 以及和 v 相关联的各边之后，将图的一个连通分量分割成两个或两个以上的连通分量，则称顶点 v 为该图的一个关节点(articulation point) 。 重连通图一个没有关节点的连通图称为重连通图(biconnected graph) 。在重连通图上，任意一对顶点之间至少存在两条路径，则在删去某个顶点以及依附于该顶点的各边时也不破坏图的连通性。若在连通图上至少删去 k 个顶点才能破坏图的连通性，则称此图的连通度为k。关节点和重连通图在实际中较多应用。 显然，一个表示通信网络的图的连通度越高，其系统越可靠，无论是哪一个站点出现故障或遭到外界破坏，都不影响系统的正常工作； 又如，一个航空网若是重连通的，则当某条航线因天气等某种原因关闭时，旅客仍可从别的航线绕道而行； 再如，若将大规模的集成电路的关键线路设计成重连通的话，则在某些元件失效的情况下，整个片子的功能不受影响，反之，在战争中，若要摧毁敌方的运输线，仅需破坏其运输网中的关节点即可。 重连通判定利用深度优先搜索便可求得图的关节点，并由此可判别图是否是重连通的。图中实线表示树边，虚线表示回边（即不在生成树上的边）。对树中任一顶点 v 而言，其孩子结点为在它之后搜索到的邻接点，而其双亲结点和由回边连接的祖先结点是在它之前搜索到的邻接点。由深度优先生成树可得出两类关节点的特性： （1）若生成树的根有两棵或两棵以上的子树，则此根顶点必为关节点。因为图中不存在联结不同子树中顶点的边，因此，若删去根顶点，生成树便变成生成森林。如上图中的顶点 A。 （2）若生成树中某个非叶子顶点 v，其某棵子树的根和子树中的其它结点均没有指向 v 的祖先的回边，则 v 为关节点。因为，若删去v，则其子树和图的其它部分被分割开来。如上图中的顶点 B 和 G 。若对图 Graph＝(V，{Edge}) 重新定义遍历时的访问函数 visited，并引入一个新的函数 low，则由一次深度优先遍历便可求得连通图中存在的所有关节点。定义 visited[v] 为深度优先搜索遍历连通图时访问顶点 v 的次序号；定义：若对于某个顶点 v，存在孩子结点w 且 low[w] ≧visited[v]，则该顶点 v 必为关节点。因为当 w 是 v 的孩子结点时，low[w] ≧visited[v]，表明 w 及其子孙均无指向 v 的祖先的回边。由定义可知，visited[v] 值即为 v 在深度优先生成树的前序序列的序号，只需将 DFS 函数中头两个语句改为 visited[v0]=++count（在 DFSTraverse 中设初值 count=1）即可；low[v] 可由后序遍历深度优先生成树求得，而 v 在后序序列中的次序和遍历时退出 DFS 函数的次序相同，由此修改深度优先搜索遍历的算法便可得到求关节点的算法。其中 J 是第一个求得 low 值的顶点，由于存在回边（J,L），则 low[J]=Min{visited[J]、visited[L]}=2。顺便提一句，上述算法中将指向双亲的树边也看成是回边，由于不影响关节点的判别，因此，为使算法简明起见，在算法中没有区别之。由于上述算法的过程就是一个遍历的过程，因此，求关节点的时间复杂度仍为O（n+e）。有向图对于有向图，在其每一个强连通分量中，任何两个顶点都是可达的。任意V ∈ G，与 V 可相互到达的所有顶点就是包含 V 的强连通分量的所有顶点。求有向图G的强连通分量的基本步骤是： ⑴ 对 G 进行深度优先遍历，生成 G 的深度优先生成森林 T。 ⑵ 对森林 T 的顶点按中序遍历顺序进行编号。 ⑶ 改变 G 中每一条弧的方向，构成一个新的有向图 G’。 ⑷ 按 ⑵中标出的顶点编号，从编号最大的顶点开始对 G’进行深度优先搜索，得到一棵深度优先生成树。若一次完整的搜索过程没有遍历 G’的所有顶点，则从未访问的顶点中选择一个编号最大的顶点，由它开始再进行深度优先搜索，并得到另一棵深度优先生成树。在该步骤中，每一次深度优先搜索所得到的生成树中的顶点就是G的一个强连通分量的所有顶点。 ⑸ 重复步骤 ⑷ ，直到 G’中的所有顶点都被访问。在算法实现时，建立一个数组 in_order[n] 存放深度优先生成森林的中序遍历序列。对每个顶点 v，在调用 DFS 函数结束时，将顶点依次存放在数组 in_order[n] 中。图采用十字链表作为存储结构最合适。由此，每一次调用 DFS 作逆向深度优先遍历所访问到的顶点基便是有向图 G 中一个强连通分量的顶点集。显然，利用遍历求强连通分量的时间复杂度亦和遍历相同有向无环图及其应用一个无环的有向图称做有向无环图（directed acycline praph）。简称 DAG 图。DAG 图是一类较有向树更一般的特殊有向图。主要用于研究工程项目的工序问题、工程时间进度问题等。有向无环图是描述含有公共子式的表达式的有效工具。例如下述表达式：((a+b)*(b*(c+d)+(c+d)*e)*((c+d)*e)可以二叉树来表示，仔细观察该表达式，可发现有一些相同的子表达式，如(c+d)和(c+d)*e 等，在二叉树中，它们也重复出现。若利用有向无环图，则可实现对相同子式的共享，从而节省存储空间。如下图：检查图是否存在坏检查一个有向图是否存在环要比无向图复杂。对于无向图来说，若深度优先遍历过程中遇到回边（即指向已访问过的顶点的边），则必定存在环；而对于有向图来说，这条回边有可能是指向深度优先生成森林中另一棵生成树上顶点的弧。但是，如果从有向图上某个顶点 v 出发的遍历，在 dfs(v) 结束之前出现一条从顶点 u 到顶点 v 的回边，由于 u 在生成树上是 v 的子孙，则有向图必定存在包含顶点 v 和 u 的环。有向无环图是描述一项工程或系统的进行过程的有效工具。除最简单的情况之外，几乎所有的工程（project）都可分为若干个称作活动（activity）的子工程，而这些子工程之间，通常受着一定条件的约束，如其中某些子工程的开始必须在另一些子工程完成之后。对整个工程和系统，人们关心的是两个方面的问题： 一是工程能否顺利进行： 二是估算整个工程完成所必须的最短时间。 AOV 网对工程的活动加以抽象：图中顶点表示活动，有向边表示活动之间的优先关系，这样的有向图称为顶点表示活动的网(Activity On Vertex Network ，AOV网) 。拓扑排序 基本概念 拓扑排序(Topological Sort) ：拓扑排序由某个集合上的一个偏序得到该集合上的一个全序的操作。 ◆ 集合上的关系：集合 A 上的关系是从 A 到 A 的关系 (AXA) 。 ◆ 关系的自反性：若 a ∈A 有(a，a) ∈ R，称集合 A 上的关系 R 是自反的。 ◆ 关系的对称性：如果对于a，b∈A ，只要有 (a，b) ∈ R 就有 (b，a) ∈ R ，称集合 A 上的关系 R 是对称的。 ◆ 关系的对称性与反对称性：如果对于a，b ∈A ，只要有(a，b)∈R 就有 (b，a)∈R ，称集合 A 上的关系R是对称的。如果对于 a，b∈A ，仅当 a=b 时有 (a，b)∈R 和 (b，a)∈R ，称集合 A 上的关系R是反对称的。 ◆ 关系的传递性：若 a，b，c∈A，若 (a，b)∈R，并且 (b，c)∈R ，则(a，c)∈R ，称集合 A 上的关系 R 是传递的。 ◆ 偏序：若集合 A 上的关系 R 是自反的，反对称的和传递的，则称 R 是集合 A 上的偏序关系。 ◆ 全序：设 R 是集合 A 上的偏序关系，a，b∈A，必有 aRb 或 bRa， 则称 R 是集合 A 上的全序关系。即偏序是指集合中仅有部分元素之间可以比较，而全序是指集合中任意两个元素之间都可以比较。有向图的拓扑排序在 AOV 网中，若有有向边 &lt;i, j&gt;，则 i 是 j 的直接前驱，j 是 i 的直接后继；推而广之，若从顶点 i 到顶点 j 有有向路径，则 i 是 j 的前驱，j 是 i 的后继。在 AOV 网中，不能有环，否则，某项活动能否进行是以自身的完成作为前提条件。检查方法：对有向图的顶点进行拓扑排序，若所有顶点都在其拓扑有序序列中，则无环。有向图的拓扑排序有向图的拓扑排序：构造 AOV 网中顶点的一个拓扑线性序列(v’1,v’2, ⋯,v’n)，使得该线性序列不仅保持原来有向图中顶点之间的优先关系，而且对原图中没有优先关系的顶点之间也建立一种(人为的)优先关系。拓扑排序算法 （1）在有向图中选一个没有前驱的顶点且输出之 （2）从图中删除该顶点和所有以它为尾的弧。重复上述两步，直至全部顶点均已输出，或者当前图中不存在无前驱的顶点为止。后一种情况则说明有向图中存在坏。拓扑排序计算机实现针对上述两步操作，我们可采用邻接表作有向图的存储结构，且在头结点中增加一个存放顶点入度的数组(indegree)。入度为零的顶点即为没有前驱的顶点，删除顶点及以它为尾的弧的操作，则可换以弧头顶点的入度减 1 来实现。为了避免重复检测入读为零的顶点，可另设一栈暂存所有入读为零的顶点。拓扑算法分析设AOV网有n个顶点，e条边，则算法的主要执行是： ◆ 统计各顶点的入度：时间复杂度是O(n+e) ； ◆ 入度为0的顶点入栈：时间复杂度是O(n) ； ◆ 排序过程：顶点入栈和出栈操作执行n次，入度减1的操作共执行e次，时间复杂度是O(n+e) ；因此，整个算法的时间复杂度是O(n+e) 。当有向图无坏时，也可利用深度优先遍历进行拓扑排序，因为图中无坏，则由图中某店出发进行深度优先搜索遍历时，最先推出 DFS 函数的顶点即出度为零的顶点，是拓扑有序中最后一个顶点。由此，按退出 DFS 函数的先后记录下来的顶点序列（如同求强连通分量时 finished 数组中的顶点序列）即为逆向拓扑有序序列。关键路径与 AOV 网相对应的是 AOE(Activity On Edge) ，是边表示活动的有向无环图，顶点表示事件(Event)，每个事件表示在其前的所有活动已经完成，其后的活动可以开始；弧表示活动，弧上的权值表示相应活动所需的时间或费用。 与AOE有关的研究问题 ◆ 完成整个工程至少需要多少时间? ◆ 哪些活动是影响工程进度(费用)的关键? AOE网的性质： （1）只有某顶点所代表的事件发生后，从该顶点出发的各活动才能开始。 （2）只有进入某顶点的各活动都结束，该顶点所代表的事件才能发生。工程完成最短时间：从起点到终点的最长路径长度(路径上各活动持续时间之和) 。长度最长的路径称为关键路径，关键路径上的活动称为关键活动。关键活动是影响整个工程的关键。设 v0 是起点，从 v0 到 vi 的最长路径长度称为事件 vi 的最早发生时间，即是以 vi 为尾的所有活动的最早发生时间。若活动ai是弧&lt;j, k&gt;，持续时间是dut(&lt;j, k&gt;)，设： ◆ e(i)：表示活动 ai 的最早开始时间； ◆ l(i)：在不影响进度的前提下，表示活动 ai 的最晚开始时间； 则 l(i)-e(i) 表示活动 ai 的时间余量，若 l(i)-e(i)=0，表示活动 ai 是关键活动。 ◆ ve(i)：表示事件 vi 的最早发生时间，即从起点到顶点 vi 的最长路径长度； ◆ vl(i)：表示事件 vi 的最晚发生时间。则有以下关系：上面的 ve 和 vl 连个递推公式的计算必须分别在拓扑有序和逆拓扑有序的前提下进行。也就是说，ve(j-1) 必须在 vj 的所有前驱的最早发生时间求得之后才能确定，而 vl(j-1) 则必须在 vj 的所有后继的最迟发生时间求得之后才能确定。因此，可以在拓扑排序的基础上计算 ve(j-1) 和 vl(j-1) 。求关键路径（活动）的算法思想 ① 利用拓扑排序求出 AOE 网的一个拓扑序列； ② 从拓扑排序的序列的第一个顶点(源点)开始，按拓扑顺序依次计算每个事件的最早发生时间 ve(i) ； ③ 从拓扑排序的序列的最后一个顶点(汇点)开始，按逆拓扑顺序依次计算每个事件的最晚发生时间 vl(i) ；算法分析：设 AOE 网有 n 个事件，e 个活动，则算法的主要执行是： ◆ 进行拓扑排序：时间复杂度是O(n+e) ； ◆ 求每个事件的ve值和vl值：时间复杂度是O(n+e) ； ◆ 根据ve值和vl值找关键活动：时间复杂度是O(n+e) ；因此，整个算法的时间复杂度是O(n+e) 。求关键路径的例子：提前完成非关键活动并不能加快工程的进度。但，关键活动的速度提高是有限度的。只有在不改变网的关键路径的情况下，提高关键活动的速度才有效。另一方面，若网中有几条关键路径，那么，单是提高一条关键路径上的关键路径上的关键活动的速度，还不能导致整个工程缩短工期，而必须提高同时在几条关键路径的活动的速度。最短路径若用带权图表示交通网，图中顶点表示地点，边代表两地之间有直接道路，边上的权值表示路程(或所花费用或时间) 。从一个地方到另一个地方的路径长度表示该路径上各边的权值之和。问题： ◆ 两地之间是否有通路? ◆ 在有多条通路的情况下，哪条最短?考虑到交通网的有向性，直接讨论的是带权有向图的最短路径问题，但解决问题的算法也适用于无向图。将一个路径的起始顶点称为源点，最后一个顶点称为终点。单源点最短路径对于给定的有向图 G=(V，E) 及单个源点 Vs，求 Vs到 G 的其余各顶点的最短路径。针对单源点的最短路径问题，Dijkstra 提出了一种按路径长度递增次序产生最短路径的算法，即迪杰斯特拉(Dijkstra)算法。Dijkstra 算法Dijkstra（迪杰斯特拉）算法是典型的最短路径路由算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。Dijkstra算法能得出最短路径的最优解，但由于它遍历计算的节点很多，所以效率低。 基本思想从图的给定源点到其它各个顶点之间客观上应存在一条最短路径，在这组最短路径中，按其长度的递增次序，依次求出到不同顶点的最短路径和路径长度。即按长度递增的次序生成各顶点的最短路径，即先求出长度最小的一条最短路径，然后求出长度第二小的最短路径，依此类推，直到求出长度最长的最短路径。 算法思想说明 算法步骤 算法实现 算法分析Dijkstra算法的主要执行是： ◆ 数组变量的初始化：时间复杂度是 O(n) ； ◆ 求最短路径的二重循环：时间复杂度是 O(n^2) ；因此，整个算法的时间复杂度是 O(n^2) 。Dijkstar 不能处理负权边。不过可以通过一定的映射使其全部变成非负权边 具体例子每一对顶点间的最短路径用Dijkstra 算法也可以求得有向图 G=(V，E) 中每一对顶点间的最短路径。方法是：每次以一个不同的顶点为源点重复 Dijkstra 算法便可求得每一对顶点间的最短路径，时间复杂度是 O(n^3) 。弗罗伊德(Floyd)提出了另一个算法，其时间复杂度仍是 O(n^3) ， 但算法形式更为简明，步骤更为简单，数据结构仍然是基于图的邻接矩阵。弗罗伊德(Floyd)算法 算法思想Floyd 算法的基本思想如下：从任意节点 A 到任意节点 B 的最短路径不外乎 2 种可能： 直接从 A 到 B， 从 A 经过若干个节点到 B，所以，我们假设 dist(AB) 为节点 A 到节点 B 的最短路径的距离，对于每一个节点K，我们检查 dist(AK) + dist(KB) &lt; dist(AB) 是否成立，如果成立，证明从 A 到 K 再到B的路径比 A 直接到 B 的路径短，我们便设置 dist(AB) = dist(AK) + dist(KB)，这样一来，当我们遍历完所有节点 K，dist(AB) 中记录的便是 A 到 B 的最短路径的距离。具体思想：参考教材《数据结构（C语言版）》 例子查找由于本文以基础为主，不会过多的涉及到算法，只会讲解其中的思想，而具体算法会在相应的文章中详细给出。 基本概念 查找表由同一类型的数据元素（或记录）构成的集合。由于“集合”中的数据元素之间存在着完全松散的关系，因此查找表是一种非常灵便的数据结构。对查找表经常进行的操作有：* 1）查询某个“特定的”数据元素是否在查找表中；* 2）检索某个“特定的”数据元素的各种属性；* 3）在查找表中插入一个数据元素；* 4）从查找表中删去某个数据元素。 静态查找表: 仅作查询和检索（统称为查找）操作的查找表。 动态查找表 有时在查询之后，还需要将“查询”结果为“不在查找表中”的数据元素插入到查找表中；或者从查找表中删除其“查询”结果为“在查找表中”的数据元素。 关键字关键字（Key）是数据元素（或记录）中某个数据项的值，用它可以标识（识别）一个数据元素（或记录）。若此关键字可以唯一地标识一个记录，则称此关键字为主关键字（对不同的记录，其主关键字均不同）。反之，称用以识别若干记录的关键字为次关键字。当数据元素只有一个数据项时，其关键字即为该数据元素的值。 查找根据给定的某个值，在查找表中确定一个其关键字等于给定值的记录或数据元素。若表中存在这样的一个记录，则称查找表是成功的，此时查找结果为给出整个记录的信息，或指示该记录在查找表中的位置；若表中不存在关键字等于给定值的记录，则称查找不成功，此时查找结果可给出一个“空”记录或“空”指针。 查找考虑的因素显然，在一个结构中查找某个数据元素的过程依赖于这个数据元素在结构中所处的地位。因此，对表进行查找的方法取决于表中数据元素依何种关系（这个关系是认为地加上的）组织在一起。同样，在计算机中进行查找的方法也随存储这些数据的数据结构不同而不同。由于查找表中数据元素之间仅存在着“同属一个集合”的松散关系，给查找带来不便。为此，需在数据元素之间人为地加上一些关系，以便按某种规则进行查找，即以另一种数据结构来表示查找表。 平均查找长度为确定记录在查找表中的位置，需和给定值进行比较的关键字个数的期望值称为查找算法在查找成功时的平均查找长度。注意有时候各个记录的查找概率并不相等。对记录的查找概率不等的查找表若能预先得知每个记录的查找概率，则应先对记录的查找概率进行排序，使表中记录按查找概率由小至大重新排列，以便提高查找效率。然而，在一般情况下，记录的查找概率预先无法测定，为了提高查找效率，我们可以在每个记录中附设一个访问频度域，并使顺序表中的记录始终保持按访问频度非递减有序的次序排列，使得查找概率大的记录在查找过程中不断往后移，以便在以后的逐次查找中减少比较次数，或者在每次查找之后都将刚查找到的记录直接移至表尾静态查找表静态查找表可以有不同的表示方法，在不同的表示方法中，实现查找操作的方法也不同。顺序表的查找以顺序表或线性链表表示静态查找表，则 Search 函数可用顺序查找来实现。 顺序查找顺序查找的查找过程为：从表中最后一个记录开始，逐个进行记录的关键字和给定值的比较，若某个记录的关键字和给定值比较相等，则查找成功，找到所查记录；反之，若直至第一个记录，其关键字和给定值比较都不等，则表明表中没有所查记录，查找不成功。顺序查找的基本操作： 将所有记录的关键字逐一和给定值进行比较 比较的起点是第一个，终点是找到了或最后一个记录（未找到） 算法分析把待查关键字存入表头（一般在数组 0 号元素）或表尾（俗称“哨兵”），这样可以加快执行速度。 缺点平均查找长度较大，特别是当 n 很大时，查找效率较低。 优点算法简单且适应面广，它对表的结构无任何要求，无论记录是否按关键字有序均可应用，而且上述所有讨论对线性链表也同样适用。有序表的查找以有序表表示静态查找表时，Search 函数可用折半查找来实现。 折半查找折半查找的查找过程是：先确定待查记录所在的范围（区间），然后逐步缩小范围知道找到活找不到该记录为止。具体说来，先给数据排序（例如按升序排好），形成有序表，然后再将 key 与中间元素相比，若 key 小，则缩小至前半部内查找；若 key 大，则缩小至后半部内查找，直至新的区间中间位置记录的关键字等于给定值或查找区间的大小小于零时（表明查找不成功）为止。判定树折半查找过程可用这样的二叉树表示：树中每个结点表示表中一个记录，结点中的值为该记录在表中的位序。通常称这个描述查找过程的二叉树为判定树。请看下面 11 个数据的判定树。找到有序表中任一记录的过程就是走一条从根结点到与该记录相应的结点的路径，和给定值进行比较的关键字个数恰为该结点在判定树上的层次树。因此，折半查找法在查找成功时进行比较的关键字个数最多不超过树的深度，而具有 n 个结点的判定树的深度为 [log n]+1，所以，折半查找法在查找成功时和给定值进行比较的关键字个数之多为 [log n]+1。在上图中所有结点的空指针域加一个指向一个方形结点的指针，并且，称这些方形结点为判定树的外部结点（与之相对，称那些圆形结点为内部结点），那么折半查找时查找不成功的过程就是走了一条从根结点到外部结点的路径，和给定值进行比较的关键字个数等于该路径上内部结点个数。因此，折半查找在查找不成功时和给定值进行比较的关键字个数最多也不超过 [log n]+1。因此，折半查找的平均查找长度为：算法特点综上所述，折半查找的效率比顺序查找高，但折半查找只适用于有序表，且限于顺序存储结构（对线性链表无法有效地进行折半查找）。 斐波那契查找以有序表表示静态查找时，进行查找的方法除折半查找之外，还有斐波那契查找和插值查找。斐波那契查找与折半查找很相似，他是根据斐波那契序列的特点对有序表进行分割的。他要求开始表中记录的个数为某个斐波那契数小1，即 n=F(k)-1;开始将k值与第F(k-1）位置的记录进行比较(及mid=low+F(k-1)-1),比较结果也分为三种 1）相等，mid位置的元素即为所求 2）&gt; ,low=mid+1,k-=2;说明: low=mid+1 说明待查找的元素在 [mid+1,hign] 范围内，k-=2 说明范围 [mid+1,high] 内的元素个数为 n-F(k-1)= F(k)-1-F(k-1)=F(k)-F(k-1)-1=F(k-2)-1 个，所以可以递归的应用斐波那契查找 3)&lt; ,high=mid-1,k-=1;说明: low=mid+1 说明待查找的元素在 [low,mid-1] 范围内，k-=1说明范围 [low,mid-1] 内的元素个数为 F(k-1)-1 个，所以可以递归的应用斐波那契查找。大部分说明都忽略了一个条件的说明：n=F(k)-1， 表中记录的个数为某个斐波那契数小1。这是为什么呢？我想了很久，终于发现，原因其实很简单：是为了格式上的统一，以方便递归或者循环程序的编写。表中的数据是F(k)-1个，使用mid值进行分割又用掉一个，那么剩下F(k)-2个。正好分给两个子序列，每个子序列的个数分别是F(k-1)-1与F(k-2)-1个，格式上与之前是统一的。不然的话，每个子序列的元素个数有可能是F(k-1)，F(k-1)-1，F(k-2)，F(k-2)-1个，写程序会非常麻烦。算法示例// 斐波那契查找.cpp#include \"stdafx.h\"#include &lt;memory&gt;#include &lt;iostream&gt;using namespace std;const int max_size=20;//斐波那契数组的长度/*构造一个斐波那契数组*/void Fibonacci(int * F){ F[0]=0; F[1]=1; for(int i=2;i&lt;max_size;++i) F[i]=F[i-1]+F[i-2];}/*定义斐波那契查找法*/int Fibonacci_Search(int *a, int n, int key) //a为要查找的数组,n为要查找的数组长度,key为要查找的关键字{ int low=0; int high=n-1; int F[max_size]; Fibonacci(F);//构造一个斐波那契数组F int k=0; while(n&gt;F[k]-1)//计算n位于斐波那契数列的位置 ++k; int * temp;//将数组a扩展到F[k]-1的长度 temp=new int [F[k]-1]; memcpy(temp,a,n*sizeof(int)); for(int i=n;i&lt;F[k]-1;++i) temp[i]=a[n-1]; while(low&lt;=high) { int mid=low+F[k-1]-1; if(key&lt;temp[mid]) { high=mid-1; k-=1; } else if(key&gt;temp[mid]) { low=mid+1; k-=2; } else { if(mid&lt;n) return mid; //若相等则说明mid即为查找到的位置 else return n-1; //若mid&gt;=n则说明是扩展的数值,返回n-1 } } delete [] temp; return -1;}int _tmain(int argc, _TCHAR* argv[]){ int a[] = {0,16,24,35,47,59,62,73,88,99}; int key=100; int index=Fibonacci_Search(a,sizeof(a)/sizeof(int),key); cout&lt;&lt;key&lt;&lt;\" is located at:\"&lt;&lt;index; system(\"PAUSE\"); return 0;}算法特点斐波那契查找的平均性能比折半查找好，但最坏情况下的性能（虽然仍是 O(log n)）却比折半查找差。它还有一个优点就是分割时只需进行加、减运算。 插值查找另外，为什么一定要是折半而不是折四分之一或者折更多呢？mid = (low+high)/2 ;在这里如果将 mid 改为mid = low + (high - low) *(key - a[low])/(a[high]-a[low]);//这就是插值时间复杂度,也是O(logn),但是对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好很多.但是，如果数组中分布类似{0,1,2,2000,2001,……,999998,999999)这种极端不均匀的数据，用插值查找未必就很合适了.算法示例#include &lt;stdio.h&gt;int Bin_Search(int *a,int key,int n){\tint low,high,mid;\tlow = 0;\thigh = n - 1;\twhile(low &lt;= high)\t{\t\tmid = low + (high - low) * (key - a[low]) / (a[high] - a[low]); //此处于二分查找不同,套用插值公式 //如果key比插值小,把高位调整为插值下标的下一位\t\tif(a[mid] &gt; key)\t\t\thigh = mid - 1;\t\telse if(a[mid] &lt; key)\t\t\tlow = mid + 1;\t\telse\t\t\treturn mid;\t}\treturn -1;}int main(){\tint a[] = {1,5,17,25,33,38,46,55,69,75,99};\tint key;\tint len = sizeof(a) / sizeof(*a);\tprintf(\"请输入要查找的值:\\n\");\tscanf(\"%d\",&amp;key);\tint pos = Bin_Search(a,key,len);\tif(pos != -1)\t\tprintf(\"在数组的第%d个位置找到:%d\\n\",pos + 1,key);\telse\t\tprintf(\"未在数组中找到元素:%d\\n\",key);\treturn 0;} 静态树表的查找当有序表中各记录的查找概率不等时，按照之前的判定树进行折半查找，其性能未必是最优的。所以需要重新按照概率来构建另外的二叉树。查找效率最高即平均查找长度最小，根据前面所学知识，我们可以给出有序表在非等概率情况下应遵循的两个原则： 1、最先访问的结点应是访问概率最大的结点； 2、每次访问应使结点两边尚未访问的结点的被访概率之和尽可能相等。对于有序表建立二叉树，还需要遵循的原则是：左子树 &lt; 根 &lt; 右子树。以便充分利用有序和概率排序双项优势。核心：选出一个结点，使得它左右两侧的子数组的权值累加和之差的绝对值最小。把这个结点当做根节点，递归地用刚才的左右字数组构造它的左右子树。由于在构造次优查找树的过程中，没有考察当只有左（或右）子树的情况，则有可能出现被选为根的关键字的权值比与它相邻的关键字的权值小，此时应作适当调整：选取临近的权值较大的关键字作次优查找树的根结点。大量的实验研究表明：次优查找树和最优查找树的查找性能之差仅为 1%~2% ，很少超过 3%，而且构造次优查找树的算法的时间复杂度为 O(nlogn)。 次优查找树查找过程次优查找树的查找过程类似于折半查找。若次优查找树为空，则查找不成功，否则，首先将给定值 key 和其根结点的关键字相比，若相等，则查找成功，该根结点的记录即为所求；否则将根据给定值 key 小于或大于根结点的关键字而分别在左子树或右子树中继续查找直至查找成功或不成功为止（算法类似儿茶排序树）。由于查找过程掐是走了一条从根到待查记录所在结点（或叶子结点）的一条路径，进行过比较关键字个数不超过树的深度。因此，次优查找树的平均查找长度和 logn 成正比。可见，在记录的查找概率不等时，可用次优查找树表示静态查找树，故又称静态树表。 索引顺序表若以索引顺序表表示静态查找表，则 Search 函数可用分块查找来实现。分块查找又称索引顺序查找，这是顺序表查找的一种改进方法。在此查找法中，储表本身以外，尚需建立一个“索引表”。将整个表分成若干子表，对没法子表（或称快）建立一个索引项，其中包括两项内容：关键字项（其值为该子表内的最大关键字和指针项（指示该子表的第一个记录在表中位置）。有了这两项内容实际上就确定了每个子表的边界。索引表按关键字有序，则表或者有序或者分块有序。所谓分块有序指的是第二个子表中所有记录的关键字均大于第一个子表中的最大关键字，地三个子表中的所有关键字均大于第二个子表中的最大关键字，……，依次类推。分块查找过程：分块查找过程需分两步进行： 待查关键字与索引表的关键字比较（可以顺序查找也可折半查找等）确定坐在的快（子表） 通过索引表的指针域从已经确定的字表的第一个开始进行顺序查找，直到：找到或者出现比该快的最大关键字大或者到了整个表尾（对于最后一块子表而言）动态查找表动态查找表的特点是：表结构本身是在查找过程中动态生成的，即对于给定值 key，若表中存在其关键字等于 key 的记录，则查找成功返回，否则插入关键字等于 key 的记录。 二叉排序树二叉排序树或是一棵空树；或者是具有如下性质的非空二叉树： （1）左子树的所有结点均小于根的值； （2）右子树的所有结点均大于根的值； （3）它的左右子树也分别为二叉排序树。二叉排序树查找过程：二叉排序树又称二叉查找树，根据上述定义的结构特点可见，它的查找过程和次有二叉树类似。即：若二叉排序树为空，则查找不成功；否则， 1）若给定值等于根结点的关键字，则查找成功； 2）若给定值小于根结点的关键字，则继续在左子树上进行查找； 3）若给定值大于根结点的关键字，则继续在右子树上进行查找。从上述查找过程可见，在查找过程中，生成了一条查找路径： 从根结点出发，沿着左分支或右分支逐层向下直至关键字等于给定值的结点;——查找成功 从根结点出发，沿着左分支或右分支逐层向下直至指针指向空树为止。——查找不成功 二叉排序树的插入和删除和次优二叉树相对，二叉排序树是一种动态树表。其特点是，树的结构通常不是一次生成的，而是在查找过程中，当树种不存在关键字等于给定值的结点时再进行插入。若二叉排序树为空树，则新插入的结点为新的根结点；否则，新插入的结点一定是一个新添加的叶子结点，并且是查找不成功时查找路径上访问的最后一个结点和左孩子或右孩子结点。例子：容易看出，中序遍历二叉排序树可得到一个关键字的有序序列（这个性质是由二叉排序树的定义决定的）。这就是说，一个无序序列可以通过构造一颗二叉排序树而变成一个有序序列，构造树的过程即为对无序序列进行排序的过程。不仅如此，从上面的插入过程还可以看到，每次插入的新结点都是二叉排序树上新的叶子结点，则在进行插入操作时，不必易懂其他结点，仅需改动某个结点的指针，由空变为非空即可。这就相当于在一个有序序列上插入一个记录而不需要易懂其他记录。因此，二叉排序树既拥有类似于折半查找的特性，又采用了链表做存储结构，因此是动态表的一种适宜表示。 二叉排序树删除结点对于一般的二叉树来说，删去树种一个结点是没有意义的。因为它将使以被删结点为根的子树称为森林，破坏了整棵树的结构。然而，对于二叉排序树，删去树上一个结点相当于删去有序序列中的一个记录，只要在删除某个结点之后依旧保持二叉排序树的特性即可。算法分析二叉排序树上查找某关键字等于结点值的过程，其实就是走了一条从根到该结点的路径。 比较的关键字次数＝此结点的层次数; 最多的比较次数＝树的深度（或高度）。然而，折半查找（静态查找）的判定树是唯一的，而二叉排序树（动态查找）却是不唯一的，它和输入序列的有序程度有关。时间复杂度最好的情况和折半查找一致，最坏的情况（输入序列本来已经就有序了）和顺序查找一样。为了改善上面所说的情况，可以对二叉排序树进行平衡化处理。也就是下面所说的平衡二叉树。 平衡二叉树平衡二叉树又称 AVL 树。它或者是一颗空树，或者是具有下列性质的二叉树：它的左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值不超过 1。若将二叉树结点的平衡因子 BF 定义为该结点的左子树的深度减去它的右子树的深度，则平衡二叉树上所有结点的平衡因子只可能是 -1, 0 和 1。*只要二叉树有一个结点的平衡因子的绝对值大于 1，则该二叉树就是不平衡的。我们希望由任何初始序列构成的二叉排序树都是 AVL 树（原因见前面的排序二叉树算法分析）。因为 AVL 树上任何结点的左右子树的深度之差都不超过 1，则可以证明它的深度和 logn 是同数量级的（其中 n 为结点个数）。由此，它的平均查找长度也和 logn 同数量级。构造平衡二叉树构建过程类似于二叉排序树的建立过程，即在二叉排序树的建立过程每当插入一个结点后，立刻检查该树是否平衡，如果平衡：继续；否则：进行相应的调整！ 1）LL平衡旋转： 2）RR平衡旋转： 3）LR平衡旋转： 4）RL平衡旋转：注意：顺时针旋（向右旋转）平衡因子减 1，逆时针旋（向左旋转）平衡因子假 1.LR（LL等）平衡旋转中的 LR 指的是插入位置所在子树的左右。旋转先从下层开始直到所有平衡因子的绝对值不大于 1 为止，比如：LR 平衡旋转，R 在 L 的下层，所以先消除 R，消除 R 的方法就是左旋，变成 LL 平衡旋转，然后再消除 LL，此时需要右旋。具体例子如下：平衡二叉树插入新结点的算法平衡树查找分析在平衡树上进行查找的过程和排序树相同，因此，在查找过程中和给定值进行比较的关键字个数不超过树的深度。那么，含有 n 个关键字的平衡树的最大深度是多少呢？为解答这个问题，我们先分析深度为 h 的平衡树所具有的最少结点数。上述对二叉排序树和平衡树的查找性能讨论都是在等概率的前提下进行，若概率不等，则需要先对记录序列进行排序，再按照概率构造次优二叉树。显然，次有查找树也是一颗二叉排序树，但次优二叉树不能再查找过程中插入结点生成，而二叉排序树（或称二叉查找树）是动态树表，最优或次优查找树是静态树表。 B-树B 树（实际应用的是平衡二叉树）指的是二叉排序树（或称二叉查找树或二叉搜索树），一般适合在内存中进行查找。而 B- 树是一种多路搜索树（并不是二叉的）。其定义如下：注意：非叶子结点的关键字个数=指向儿子的指针个数-1B- 树查找过程在 B- 树上进行查找的过程和二叉排序树的查找类似，是一个顺指针查找结点和在结点的关键字中进行查找交叉进行的过程。首先从根结点开始重复如下过程：若比结点的第一个关键字小，则查找在该结点第一个指针指向的结点进行；若等于结点中某个关键字，则查找成功；若在两个关键字之间，则查找在它们之间的指针指向的结点进行；若比该结点所有关键字大，则查找在该结点最后一个指针指向的结点进行；若查找已经到达某个叶结点，则说明给定值对应的数据记录不存在，查找失败。B- 树主要用于文件索引，依次它的查找往往涉及外存的存取，下面是其两种基本操作： 在 B- 树种找结点（磁盘上进行） 在结点中找关键字（内存中进行）即在磁盘上找到指针所指结点后，先将结点中的信息读入内存，然后再利用顺序查找或折半查找查询待查关键字。显然，在磁盘上进行一次查找比在内存中进行一次查找耗费的时间多得多，因此，在磁盘上进行查找的次数，即待查关键字所在结点在 B- 树上的层次数，是决定 B- 树查找效率的首要因素。B- 树插入关键字由于 B~ 树结点中的关键字个数必须 &gt;=ceil(m/2)-1 和 &lt;=m。因此和平衡二叉树不同，每一次插入一个关键字并不是在树中添加一个结点，而是首先在最低层的某个非终端结点中添加一个关键字，若该结点的关键字个数不超过 m-1，则插入完成。否则，要产生结点的”分裂” 。插入的过程分两步完成： 找到插入位置利用前述的B-树的查找算法查找关键字的插入位置。若找到，则说明该关键字已经存在，直接返回。否则查找操作必失败于某个最低层的非终端结点上。 插入判断该结点是否还有空位置。即判断该结点的关键字总数是否满足 n&lt;=m-1。若满足，则说明该结点还有空位置，直接把关键字 k 插入到该结点的合适位置上。若不满足，说明该结点己没有空位置，需要把结点分裂成两个。分裂的方法是：生成一新结点。把原结点上的关键字和 k 按升序排序后，从中间位置把关键字（不包括中间位置的关键字）分成两部分。左部分所含关键字放在旧结点中，右部分所含关键字放在新结点中，中间位置的关键字连同新结点的存储位置插入到父结点中。如果父结点的关键字个数也超过（m-1），则要再分裂，再往上插。直至这个过程传到根结点为止。具体例子：B- 树种删除关键字在 B- 树上要删除一个关键字，必须要满足 B- 树的定义，所以在最下层的非终端结点（认为空结点为终端结点）和非最下层的处理是不一样的，同时对于原来的待删关键字所在结点的关键字数是否不小于 ceil(m/2) 的处理也是不同的。因此需要分情况进行处理：首先应找到该关键字所在结点，然后按以下情况进行删除操作： 若该结点为最下层的非终端结点，且其中的关键字数目（而不是子树数目）不小于 ceil(m/2)（即使删除该关键字之后，关键字数目依然满足要求），则删除完成，否则要进行“合并”结点的操作。 假若所删关键字为非终端结点中的 Ki，则可以用指针 Ai 所指子树中（整个字数）的最小关键字 Y 替代 Ki，然后在相应的结点中删除 Y，总之，设所删关键字为非终端结点中的Ki，则可以指针Ai所指子树中的最小关键字Y代替Ki，然后在相应结点中删除Y。对任意关键字的删除都可以转化为对最下层关键字的删除。。只需讨论删除最下层非终端结点中关键字的情形。有下列 3 种可能： （1）被删关键字所在结点中的关键字数目不小于 ceil(m/2) 则只需从该节点中删去该关键字 Ki 和相应指针 Ai，树的其他部分不变。 （2）被删关键字所在结点中的关键字数目等于 ceil(m/2)-1（刚刚满足关键字数目要求，但一旦删除一个关键字就不行了 。则需将其兄弟结点中的最小（或最大）的关键字上移至双亲结点中，而将双亲结点中小于（或大于）且紧靠该上移关键字的关键字下移至被删关键字所在结点中。 （3）倍删关键字所在结点和其相邻的兄弟结点中关键字数目均等于 [m/2]-1。假设结点有右兄弟，且其右兄弟结点地址由双亲结点中的指针 Ai 所指，则在删去关键字之后，它所在结点中剩余的关键字和指针，加上双亲结点中的关键字 Ki 一起，合并到 Ai 所指兄弟结点中（若没有右兄弟，则合并至左兄弟结点中）。具体例子如下： B+ 树B+ 树是应文件系统所需而出现的一种 B- 树的变型树。一颗 m 阶的 B+ 树和 m 阶的 B- 树的差异在于： 有 n 颗子树的结点含有 n 个关键字。 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针且叶子结点本身依关键字的大小自小而大顺序链接。 所有的非终端结点可以看成是索引部分，结点中仅含有其子树（根结点）中的最大（或最小）关键字。如上图，通常在 B+ 树上有两个头指针，一个指向根结点，另一个指向关键字最小的叶子结点。因此，可以对 B+ 树进行两种查找运算： 一种是从最小关键字起顺序查找、 另一种是从根结点开始，进行随机查找在 B+ 树上进行随机查找、插入和删除的过程基本上与 B- 树类似。只是在查找时，若非终端结点上的关键字等于给定值，并不终止，而是继续向下直到叶子结点。因此，在 B+ 树，不管查找成功与否，每次查找都是走了一条从根到叶子结点的路径。B+ 插入示例B+ 删除示例 键树键树又称数字查找树（Digital Search Tree）。它是一棵度大于等于2的树，树中的每个结点中不是包含一个或几个关键字，而是只含有组成关键字的符号。例如，若关键字是数值，则结点中只包含一个数位；若关键字是单词，则结点中只包含一个字母字符。这种树会给某种类型关键字的表的查找带来方便。假设有如下 16 个关键字的集合{CAI、CAO、LI、LAN、CHA、CHANG、WEN、CHAO、YUN、YANG、LONG、WANG、ZHAO、LIU、WU、CHEN}可对此集合作如下的逐层分割。首先按其首字符不同将它们分成 5 个子集：{CAO、CAO、CHA、CHANG、CHAO、CHEN}，{WEN、WANG、WU}，{ZHAO}，{LI、LAN、LONG、LIU}，{YUN、YANG}。然后对其中 4 个关键字个数大于 1 的子集再按其第二个字符不同进行分割。所所得子集的关键字多于 1 个，则还需按其第三个字符不同进行再分割。以此类推，直至每个小子集中只包含一个关键字为止。该例子的键树如下图：从根到叶子结点路径中结点的字符组成的字符串表示一个关键字，叶子结点中的特殊符号$表示字符串的结束。在叶子结点中还含有指向该关键字记录的指针。为了查找和插入方便，我们约定键树是有序树，即同一层中兄弟结点之间依所含符号自左至右有序，并约定$小于任何字符。键树的深度h则取决于关键字中字符或数位的个数。通常，键树可有两种存储结构，分别称为双链树和 Trie 树。键树的存储结构 双链树以树的孩子兄弟链表来表示键树，则每个分支结点包括三个域： symbol 域：存储关键字的一个字符； first 域：存储指向第一棵子树根的指针； next 域：存储指向右兄弟的指针。同时，叶子结点不含 first 域，它的 infoptr 域存储指向该关键字记录的指针。此时的键树又称双链树。在双链树中插入或删除一个关键字，相当于在树中某个结点上插入或删除一棵子树。结点的结构中可以设置一个枚举变量表示结点的类型，叶子结点和分支结点。叶子结点和分支结点都有 symbol 域和 next 域。不同的一个域可以用联合表示，叶子结点包含 infoptr 指向记录，而分支结点是 first 域指向其第一棵子树。双链树的查找假设给定值为 K.ch(0..num-1), 其中 K.ch[0] 至 K.ch[num-2] 表示待查关键字中 num-1 个字符， K.ch[num-1] 为结束符 $。从双链树的根指针出发，顺 first 指针找到第一棵子树的根结点，以K.ch[0] 和此结点的 symbol 域比较，若相等，则顺 first 域再比较下一字符，否则沿 next 域顺序查找。若直至空仍比较不等，则查找不成功。查找算法分析键树中每个结点的最大度 d 和关键字的“基”有关，若关键字是单词，则 d=27（26个字母和一个结束符），若关键字是数值。则 d=11 。键树的深度 h 则取决于关键字中字符或数位的个数。假设关键字为随机的（即关键字中每一位取基内任何值的概率相同），则在双链树中查找每一位的平均长度为 (1+d)/2。又假设关键字中字符（或数位）的个数都相等，则在双链树中进行查找的平均查找长度为 h(1+d)/2。 Trie 树若以树的多重链表表示键树，则树的每个结点中应含有d个指针域，此时的键树又称 Trie树。若从键树中某个结点到叶子结点的路径上每个结点都只有一个孩子，则可将该路径上所有结点压缩成一个“叶子结点”，且在该叶子结点中存储关键字及指向记录的指针等信息。在 Trie 树中有两种结点： 分支结点：含有d个指针域和一个指示该结点中非空指针域的个数的整数域。在分支结点中不设数据域，每个分支结点所表示的字符均有其父结点中指向该结点的指针所在位置决定。 叶子结点：含有关键字域和指向记录的指针域。 Trie 树查找从根结点出发，沿和给定值相应的指针逐层向下，直至叶子结点，若叶子结点中的关键字和给定值相等，则查找成功，若分支结点中和给定值相应的指针为空，或叶子结点中的关键字和给定值不相等，则查找不成功。从上述查找过程可见，在查找成功时走了一条从根到叶子结点的路径。还可限制 Trie 树的深度。如下 Trie 树（请和之前的 h=5 的Trie 树做比较）：在 Trie 树上易于进行插入和删除，只是需要相应地增加和删除一些分支结点。当分支结点中 num 域的值减为 1 时，便可被删除。双链树和 Trie 树是键树的两种不同的表示方式，它们有各自的特点。从其不同的存储结构特性可见，若键树中结点的度较大，则采用 Trie 树结构胶双链树更为合适。哈希表在前面讨论的各种结构（线性表、树等）中，记录在结构中的相对位置是随机的，和记录的关键字之间不存在确定的关系。因此，在结构中查找记录时需要进行一系列和关键字的比较，这一类查找方法建立在“比较”的基础上。查找的效率依赖于查找过程中所进行的比较次数。理想的情况是希望不经过任何比较，一次存取便能得到所查记录，那就必须在记录的存储位置和它的关键字之间建立一个确定的对应关系f（关键字到存储位置的映射） ，使每个关键字和结构中一个唯一的存储位置相对应。因而在查找时，只根据这个对应关系 f 找到给定值 K 的像 f(K)。若结构中存在关键字和 K 相等的记录，则必定在 f(K) 的存储位置上，由此，不需要进行比较便可直接取得所查记录。在此，我们称这个对应关系 f 为哈希函数，按这个思想建立的表为哈希表。散列方法（哈希表）不同于顺序查找、二分查找、二叉排序树及B-树上的查找。它不以关键字的比较为基本操作，采用直接寻址技术。在理想情况下，无须任何比较就可以找到待查关键字，查找的期望时间为 O(1)。散列函数选择标准散列函数的选择有两条标准：简单和均匀。 简单指散列函数的计算简单快速； 均匀指对于关键字集合中的任一关键字，散列函数能以等概率将其映射到表空间的任何一个位置上。也就是说，散列函数能将子集 K 随机均匀地分布在表的地址集{0，1，…，m-1}上，以使冲突最小化。哈希表是种数据结构，它可以提供快速的插入操作和查找操作。元素特征转变为数组下标的方法就是散列法。哈希表的优点：不论哈希表中有多少数据，查找、插入、删除（有时包括删除）只需要接近常量的时间即0(1）的时间级。实际上，这只需要几条机器指令。哈希表运算得非常快，在计算机程序中，如果需要在一秒种内查找上千条记录通常使用哈希表（例如拼写检查器)哈希表的速度明显比树快，树的操作通常需要O(N)的时间级。哈希表不仅速度快，编程实现也相对容易。如果不需要有序遍历数据，并且可以提前预测数据量的大小。那么哈希表在速度和易用性方面是无与伦比的。哈希表的缺点它是基于数组的，数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重，所以程序员必须要清楚表中将要存储多少数据（或者准备好定期地把数据转移到更大的哈希表中，这是个费时的过程）。哈希表的冲突现象 冲突两个不同的关键字，由于散列（哈希）函数值相同，因而被映射到同一表位置上。该现象称为冲突(Collision)或碰撞。发生冲突的两个关键字称为该散列函数的同义词(Synonym)。 完全避免冲突的条件：最理想的解决冲突的方法是安全避免冲突。要做到这一点必须满足两个条件： 关键字集合不大于哈希表地址集合 选择合适的哈希函数 这只适用于关键字集合比较小、且关键字均事先已知的情况，此时经过精心设计哈希函数 h 有可能完全避免冲突。 冲突不可能完全避免通常情况下，h是一个压缩映像。虽然待存关键字的个数不大于哈希表地址数，但关键字全体集合不小于哈希表地址集合，故无论怎样设计 h，也不可能完全避免冲突。因此，只能在设计h时尽可能使冲突最少。同时还需要确定解决冲突的方法，使发生冲突的同义词能够存储到表中。 影响冲突的因素冲突的频繁程度除了与h相关外，还与表的填满程度相关。设 m 和 n 分别表示表长和表中填人的结点数，则将 α=n/m 定义为散列表的装填因子(Load Factor)。α越大，表越满，冲突的机会也越大。通常取 α≤1。 散列函数的构造方法。哈希函数的构造常用的构造哈希函数的方法有： 直接地址法思想：取关键字或关键字的某个线性函数值为散列地址。即 H(key)=key 或 H(key)=a·key + b，其中 a，b 为常数。这种哈希函数叫做自身函数。特点：对于不同的关键字不会产生冲突，缺点是由于关键字集合很少是连续的，会造成空间的大量浪费。 数字分析法思想：假设关键字是以 r 为基的数（如十进制），并且哈希表中可能出现的关键字都是事先知道的，则可选取关键字的若干数位组成哈希地址。特点：需要对关键字进行分析，以确定取哪几位最好（冲突最少）。 平方取中法思想：先通过求关键字的平方值扩大相近数的差别，然后根据表长度取中间的几位数作为散列函数值。通常在选定哈希函数时不一定能知道关键字的全部情况，取其中的哪几位也不一定合适，而一个数平方后的中间几位数和数的每一位都相关，由此使随机分布的关键字得到的哈希地址也是随机的（这样产生的散列地址较为均匀）。取的位数由表长决定。例子将一组关键字(0100，0110，1010，1001，0111)平方后得：(0010000，0012100，1020100，1002001，0012321) 若取表长为1000，则可取中间的三位数作为散列地址集： (100，121，201，020，123)。该例子的实现代码如下：int Hash(int key){ //假设key是4位整数 key*=key； key/=100； //先求平方值，后去掉末尾的两位数 return key％1000； //取中间三位数作为散列地址返回} 折叠法思想：将关键字分割成位数相同的几部分（最后一部分的位数可以不同），然后取这几部分的叠加和（舍去进位）作为哈希地址。特点：关键字位数多，而且关键字中每一位上数字分布大致均匀时，可以采用折叠法得到哈希地址。 除留余数法思想：取关键字被某个不大于散列表表长 m 的数 p 除后所得的余数为散列地址。即 H(key)=key mod p， p≤m。不仅可以对关键字直接取模，也可在折叠法、平方取中法等运算之后取模。特点：对 p 的选择很重要，一般取小于 m 的最大素数（或不包含小于 20 的质因数的合数），若 p 选择不好，容易产生冲突。 随机数法选择一个随机函数，取关键字的随机函数值为它的散列地址，即H(key)=random(key)其中 random 为随机函数，但要保证函数值是在 0 到 m-1 之间。通常，当关键字长度不等时采用此法构造哈希函数较为恰当。 选择哈希函数需要考虑的因数：实际工作中需视不同的情况采用不同的哈希函数。通常，考虑的因素有： 计算哈希函数所需时间（包括硬件指令的因素）； 关键字的长度； 哈希表的大小； 关键字的分布情况； 记录的查找频率。处理冲突的方法均匀的哈希函数可以减少冲突，但不能避免，因此，如何处理冲突是哈希表不可缺少的另一方面。通常用的处理冲突的方法有下列几种： 开放地址法用线性探查法解决冲突时，当表中 i,i+1，…，i+k 的位置上已有结点时，一个散列地址为 i，i+1，…，i+k+1 的结点都将插入在位置 i+k+1 上。把这种散列地址不同的结点争夺同一个后继散列地址的现象称为聚集或堆积(Clustering)。这将造成不是同义词的结点也处在同一个探查序列之中，从而增加了探查序列的长度，即增加了查找时间。若散列函数不好或装填因子过大，都会使堆积现象加剧。 再哈希法 拉链法（链地址法）拉链法解决冲突的做法是：将所有关键字为同义词的结点链接在同一个单链表中。若选定的散列表长度为 m，则可将散列表定义为一个由 m 个头指针组成的指针数组 T[0..m-1]。凡是散列地址为 i 的结点，均插入到以 T[i] 为头指针的单链表中。T 中各分量的初值均应为空指针。在拉链法中，装填因子α可以大于1，但一般均取α≤1。拉链法的优点：与开放定址法相比，拉链法有如下几个优点： (1)拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短； (2)由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况； (3)开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间； (4)易于删除结点。在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结点的空间置为空，否则将截断在它之后填人散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元(即开放地址)都是查找失败的条件。因此在用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。拉链法的缺点指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。 公共溢出区法将凡是发生冲突的都放在一个表中，在查找的时候，对给定值通过散列函数计算出散列地址后，先与基本表的相应位置进行对比，如果相等，则查找成功，如果不相等，则到溢出表去进行顺序查找。如果相对于表而言，有冲突的数据很少的情况下，公共溢出区的结构对查找性能来说还是非常高的！哈希表的查找在哈希表上进行查找的过程和哈希造表的过程基本一致。给定 K 值，根据造表时设定的哈希函数求得哈希地址，若表中此位置上没有记录，则查找不成功；柔则比较关键字，若和给定值相等，则查找成功；否则根据造表时设定的处理冲突的方法找“下一地址”，直至哈希表中某个位置为“空”或者表中所填记录的关键字等于给定值时为止。内部排序简单地说，排序就是把一组记录按照某个（或某几个）字段的值以递增（由小到大）或递减（由大到小）的次序重新排列的过程。（如按年龄从小到大排序）基本概念 排序码作为比较基础的一个(或多个)字段，称为排序码。排序码可以是数值、符号或符号串。排序码不一定是关键码，关键码可以作为排序码。关键码是唯一的，但排序码不一定唯一。排序码不唯一时，排序的结果可能不唯一。 记录参与排序的对象，称为记录。一个记录可以包含多个字段。如果记录集合中存在多个排序码相同的记录，经过排序后，排序码相同的记录的前后次序保持不变，则这种排序方法称为是稳定的，否则是不稳定的。 内、外排序在排序过程中，全部记录存放在内存，则称为内排序，如果排序过程中需要使用外存，则称为外排序。排序评判标准排序方法可以分为五种∶插入排序、选择排序、交换排序、分配排序和归并排序。评价排序算法好坏的标准 执行算法所需的时间 执行算法所需要的附加空间 算法本身的复杂程度也是考虑的一个因素其中，排序的时间开销是算法好坏的最重要的标志。排序的时间开销衡量标准: 算法执行中的比较次数（必须）。 算法执行中的移动次数（有可能避免）。插入排序将无序序列中的一个或几个记录“插入”到有序的序列中，从而增加记录的有序序列的长度。主要思想是将第一个元素看做是有序的，从第二个元素起将待排序的元素插入到有序序列中的合适位置，使序列逐渐扩大，直到所有的元素都插入到有序序类中。根据查找插入位置的不同可以有多种插入排序方法，如直接插入、折半插入、表插入等。直接插入排序 基本思想： 假定前面 m 个元素已经排序； 取第 (m+1) 个元素，插入到前面的适当位置； 一直重复，到 m=n（共 n 个记录） 为止。（初始情况下，m = 1） 算法分析直接插入排序的算法简洁，容易实现，对记录的存储方式没有要求。直接插入排序算法最好情况下的时间复杂度为 O(n),最坏情况的时间复杂度和平均时间复杂度为 O(n^2)。func insertionSort(arr []int) []int {\tfor i := range arr {\t\tpreIndex := i - 1\t\tcurrent := arr[i]\t\tfor preIndex &gt;= 0 &amp;&amp; arr[preIndex] &gt; current {\t\t\tarr[preIndex+1] = arr[preIndex]\t\t\tpreIndex -= 1\t\t}\t\tarr[preIndex+1] = current\t}\treturn arr}当待排序记录的数量 n 很小时，这是一种很好的排序方法。但是，通常记录数量很大，则不宜采用直接插入排序。所以有必要对其进行改造。在直接插入排序的基础上，从减少“比较”和“移动”这两种操作的次数着眼就有了后面的各种插入排序方法。折半插入排序由于插入排序的基本操作是在一个有序表中进行查找和插入。如果“查找”插入位置的操作利用“折半查找”，则这种插入排序便成了折半插入排序。折半查找明显减少了关键字的“比较”次数，单记录的移动次数不变，故时间复杂度仍为O(n^2)。折半查找或二分查找可参考 动图理解二分搜索的实现细节2- 路插入排序2- 路插入排序是在折半插入排序的基础上再改进之，其目的是减少排序过程中移动记录的次数，但为此需要 n 个记录的辅助空间。基本思想是另设一数组 d，将R[1]复制给 d[1]（将该值作为每次排序的参照，大于等于这个参照值就后插，小于参照值就前插。），并将 d[1] 看做排好序的“中间”记录，从第二个起依次将关键字小于 d[1] 的记录插入到 d[1] 之前的有序序列中，将关键字大于 d[1] 的记录插入到 d[1] 之后的有序序列中。同时定义两个游标 first 和 final 分别指向临时数组当前最小值和最大值所在位置。这样 first、final 和 参考值 d[1] 就分成了2-路，这 2-路分别为：first-d[1] 和 d[1]-final 。然后分别采用折半查找来确定插入位置。可参见 【4】算法排序 （2路插入排序）算法分析：在 2- 路插入排序中，移动记录的次数约为 (n^2)/2 。因此，2-路插入排序只能减少移动记录的次数，而不能绝对避免移动记录。并且，当 d[1] 是待排序记录中关键字最小或最大的记录时，2-路插入排序就完全退化成折半插入排序了。因此，若希望在排序过程中不移动记录，只有改变存储结构，进行（链）表插入排序。表插入排序为了减少在排序过程中“移动”记录的操作，必须改变排序过程中采用的存储结构。利用静态链表进行排序，并在排序之后，一次性地调整各个记录之间的位置，即将每个记录都调整到他们应该在的位置上，这样的排序方法称为表插入排序。表插入排序则可以避免元素移动。但它需要建立数据结构，并且需要额外的空间首先给出表结构，定义如下：详见 表插入排序#define SIZE 100typedef struct{\tint value;\tint next;}SLNode;typedef struct{\tSLNode numbers[SIZE];\tint length;}SLinkList;假设以上述说明的静态链表类型作为待排记录序列的存储结构，并且，为了插入方便起见，设数组中下标为“0”的分量为表头结点，并令表头结点记录的关键字取最大整数 MAXINT，则表插入排序的过程描述如下：首先将静态链表中数组下标为“1”的分量（结点）和表头结点构成一个循环链表，然后依次将下标为“2”至“n”的分量按记录关键字非递减有序插入到循环链表中（注意这一步是通过修改游标 next 域来实现的）。从表插入排序的过程可见，表插入排序的基本操作仍是将一个记录插入到已排好序的有序表中。和直接插入排序相比，不同之处仅是以修改 2n 次指针值代替移动记录，排序过程所需进行的关键字间的比较次数相同。因此，表插入排序的时间复杂度仍是 O(n^2)。另一方面，表插入排序的结果只是求得一个有序链表，则只能对它进行顺序查找，不能进行随机查找，为了能够实现有序表的折半查找，尚需对记录进行重新排列。重排记录的做法是：顺序扫描有序链表，将链表中第 i 个结点移动至数组的第 i 个分量中。表插入排序示例如下：希尔排序希尔排序又称“缩小增量有序”，它也是一种属于插入排序类的方法，但在时间效率上较前述几种排序方法有较大的改进。从对直接插入排序的分析得知，其算法时间复杂度为 O(n^2)，但是，若待排记录序列为“正序”时，其时间复杂度可提高至 O(n)。如此，可设法将记录序列先按排序码“基本有序”之后需要再进行排序的序列就少了。由于直接插入排序算法简单，则在 n 值很小时效率也比较高。希尔排序正式从这点出发对直接插入排序进行改进得到的一种插入排序方法。基本思想：希尔排序的基本思想是：先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，等整个序列中的记录“基本有序”时，再对全体记录进行一次直接插入排序。具体说来，将无序数组分割为若干个子序列，子序列不是逐段分割的，而是相隔特定的增量的子序列，对各个子序列进行插入排序；然后再选择一个更小的增量，再将数组分割为多个子序列进行排序……最后选择增量为1，即使用直接插入排序，使最终数组成为有序。增量的选择：在每趟的排序过程都有一个增量，至少满足一个规则 增量关系 d[1] &gt; d[2] &gt; d[3] &gt;..&gt; d[t] = 1 (t趟排序)；根据增量序列的选取其时间复杂度也会有变化。但需要注意的是：应使得增量序列中的值没有除 1 之外的公因子，并且最后一个增量必须等于 1.希尔排序示例：func shellSortStep(arr []int, start int, gap int) []int {\tlength := len(arr)\t// 插入排序的变种\tfor i := start + gap; i &lt; length; i += gap {\t\t// 备份待插入的数据\t\tbackup := arr[i]\t\t// 初始化待插入位置\t\tj := i - gap\t\t// 待插入数据，小于前面的数据\t\tfor j &gt;= 0 &amp;&amp; backup &lt; arr[j] {\t\t\t// 从前往后移动\t\t\tarr[j+gap] = arr[j]\t\t\tj -= gap\t\t}\t\tarr[j+gap] = backup\t}\treturn arr}func ShellSort(arr []int) []int {\tlength := len(arr)\t// 数组为空或者只有一个元素\tif length &lt;= 1 {\t\treturn arr\t}\t// 步长\tgap := length / 2\tfor gap &gt; 0 {\t\t// 处理每个元素的步长\t\tfor i := 0; i &lt; gap; i++ {\t\t\tshellSortStep(arr, i, gap)\t\t}\t\tgap /= 2\t}\treturn arr}算法分析希尔排序的执行时间依赖于增量序列，有人通过大量的实验，给出了目前较好的结果：当 n 较大时，比较和移动的次数约在 n^l.25 到1.6n^1.25 之间。当 n 在某个特定范围内，希尔排序所需的比较和移动次数约为n^1.3 ，当 n →∞时，可减少到 n(log n)^2 。交换排序交换排序的基本思想是：两两比较待排序记录的关键字，发现两个记录的次序相反时即进行交换，直到没有反序的记录为止。应用交换排序基本思想的主要排序方法有：冒泡排序（Bubble sort）和快速排序（Quick sort）。冒泡排序冒泡排序的基本思想：冒泡排序是交换排序中一种简单的排序方法。它的基本思想是对所有相邻记录的关键字值进行比较，如果是逆序（a[j]&gt;a[j+1]），则将其交换，最终达到有序化。其处理过程为： （1）将整个待排序的记录序列划分成有序区和无序区，初始状态有序区为空，无序区包括所有待排序的记录。 （2）对无序区从前向后依次将相邻记录的关键字进行比较，若逆序将其交换，从而使得关键字值小的记录向上”飘浮”（左移），关键字值大的记录好像石块，向下“堕落”（右移）。每经过一趟冒泡排序，都使无序区中关键字值最大的记录进入有序区，对于由 n 个记录组成的记录序列，最多经过 n-1 趟冒泡排序，就可以将这n个记录重新按关键字顺序排列。第一趟定位第n个记录，此时有序区只有一个记录；第二趟定位第n-1个记录，此时有序区有两个记录；以此类推，func BubbleSort(data []int) {\tvar swapped = true\tj := 0\tfor swapped {\t\tswapped = false\t\tfor i := 1; i &lt; len(data)-j; i++ {\t\t\tif data[i-1] &gt; data[i] {\t\t\t\tdata[i], data[i-1] = data[i-1], data[i]\t\t\t\tswapped = true\t\t\t}\t\t}\t\tj++\t}}冒泡排序的改进措施举例： 不需要进行 n-1 趟冒泡排序，当某一趟没有进行交换操作，就可以结束排序过程。 缩小一趟冒泡排序进行的范围。 可以考虑减少交换次数，比如改进得到后面要介绍的选择排序。在上面给出的冒泡排序算法的基础上，如果同时记录第 i 趟冒泡排序中最后一次发生交换操作的位置m（m&lt;=n-i），就会发现从此位置以后的记录均已经有序，即无序区范围缩小在 a[1]～a[m] 之间，所以在进行下一趟排序操作时，就不必考虑 a[m+1]～a[n] 范围内的记录了，而只在 a[1]～a[m] 范围内进行。 算法分析在时间复杂度：若待排序的序列为完全逆序，则每次都需要进行元素之间的交换，所以时间复杂度为 O(n^2)，若待排序为顺序，也就是不需要交换元素，但是需要扫描，所以还是需要 O(n) 的时间复杂度，平均情况下时间复杂度为 O(n^2) 。空间复杂度：只需要一个用于交换的临时存储空间，所以空间复杂度为 O(1)。快速排序快速排序采用分治策略对冒泡排序进行了改进。通过一趟排序将待排记录分割成独立两部分，其中一部分记录的关键字均比另一部分记录的关键小，则可以分别对这两部分记录继续进行排序，以达到整个序列有序。快速排序是找出一个元素（理论上可以随便找一个）作为基准(pivot),然后对数组进行分区操作,使基准左边元素的值都不大于基准值,基准右边的元素值 都不小于基准值，如此作为基准的元素调整到排序后的正确位置。递归快速排序，将其他 n-1 个元素也调整到排序后的正确位置。最后每个元素都是在排序后的正 确位置，排序完成。所以快速排序算法的核心算法是分区操作，即如何调整基准的位置以及调整返回基准的最终位置以便分治递归。该方法的基本思想是： 1．先从数列中取出一个数作为基准值。 2．分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。 3．再对左右区间重复第二步，直到各区间只有一个数。“基准值”的选择有很多种方法。最简单的是使用第一个记录的关键字值。但是如果输入的数组是正序或者逆序的，就会将所有的记录分到“基准值”的一边。较好的方法是随机选取“基准值”，这样可以减少原始输入对排序造成的影响。但是随机选取“基准值”的开销大。 一趟快速排序（或一次划分）为了实现一次划分，我们可以从数组（假定数据是存在数组中）的两端移动下标，必要时交换记录，直到数组两端的下标相遇为止。为此，我们附设两个指针（下角标）low 和 high， 通过 high 从当前序列的有段向左扫描，越过不小于基准值的记录。当遇到小于基准值的记录时，扫描停止。通过 low 从当前序列的左端向右扫描，越过小于基准值的记录。当遇到不小于基准值的记录时，扫描停止。之后交换两个方向扫描停止的记录 a[j] 与 a[i]（本质上类似于冒泡排序中的“逆序”）。然后，继续扫描，直至 low == high 相遇为止。当扫描和交换的过程结束，这时， low 左边的记录的关键字值都小于基准值，右边的记录的关键字值都不小于基准值。快速排序算法分析 时间复杂度当基数值不能很好地分割数组，即基准值将数组分成一个子数组中有一个记录，而另一个子组组有 n-1 个记录时，下一次的子数组只比原来数组小 1，这是快速排序的最差的情况。如果这种情况发生在每次划分过程中，那么快速排序就退化成了冒泡排序，其时间复杂度为O(n^2)。在最好情况下，每次划分所取的基准都是当前无序区的”中值”记录，划分的结果是基准的左、右两个无序子区间的长度大致相等。总的关键字比较次数：0(nlgn)尽管快速排序的最坏时间为O(n^2)，但就平均性能而言，它是基于关键字比较的内部排序算法中速度最快者，快速排序亦因此而得名。它的平均时间复杂度为O(nlgn)。 空间复杂度快速排序需要栈空间来实现递归，如果数组按局等方式被分割时，则最大的递归深度为 log n，需要的栈空间为 O(log n)。最坏的情况下在递归的每一级上，数组分割成长度为0的左子数组和长度为 n - 1 的右数组。这种情况下，递归的深度就成为 n，需要的栈空间为 O(n)。因为快速排序在进行交换时，只是根据比较基数值判断是否交换，且不是相邻元素来交换，在交换过程中可能改变相同元素的顺序，因此是一种不稳定的排序算法。 快速排序较快的原因为什么说快速排序是冒泡排序的一种改进，为什么比较呢？快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。通过两个不相邻元素交换，可以一次交换消除多个逆序，加快排序速度。快速排序方法在要排序的数据已经有序的情况下最不利于发挥其长处。 快速排序示例func quickSort(arr []int) []int { arr = shuffling(arr) sort(arr, 0, len(arr)-1) return arr}func sort(arr []int, low int, high int) { if high &lt;= low { return } j := partition(arr, low, high) sort(arr, low, j-1) sort(arr, j+1, high)}func partition(arr []int, low int, high int) int { i, j := low+1, high for true { for arr[i] &lt; arr[low] { i++ if i == high { break } } for arr[low] &lt; arr[j] { j-- if j == low { break } } if i &gt;= j { break } exchange(arr, i, j) } exchange(arr, low, j) return j}func exchange(arr []int, a int, b int) { arr[a], arr[b] = arr[b], arr[a]}// 随机打乱func shuffling(slice []interface{}) { r := rand.New(rand.NewSource(time.Now().Unix())) for len(slice) &gt; 0 { n := len(slice) randIndex := r.Intn(n) slice[n-1], slice[randIndex] = slice[randIndex], slice[n-1] slice = slice[:n-1] }}选择排序选择排序的基本思想：每一趟（第 i 趟）在 n-i+1 (i=1,2,…,n-1)个记录中选取关键字最小的记录作为有序序列中第 i 个记录。其中 i 表示第 i 趟。其中最简单的是简单选择排序。简单选择排序冒泡排序交换次数过多，而选择排序可以在排序时找到合适的关键字再做交换，并且只移动一次就能完成相应关键字的排序定位。基本思想：简单选择排序（Simple Selection Sort）是通过 n-i 次关键字之间的比较，从 n-i+1 个记录中选出关键字最小（大）的记录，并和第i（1≤i≤n）个记录交换。func selectionSort(arr []int) []int {\tlength := len(arr)\tfor i := 0; i &lt; length-1; i++ {\t\tmin := i\t\tfor j := i + 1; j &lt; length; j++ {\t\t\tif arr[min] &gt; arr[j] {\t\t\t\tmin = j\t\t\t}\t\t}\t\tarr[i], arr[min] = arr[min], arr[i]\t}\treturn arr}这种排序算法简单直观，首先从未排序序列中找到最小（大）元素，存放到排序序列的起始位置。然后再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。算法分析：选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，它们当中至少有一个将被移到其最终位置上，因此对n个元素的表进行排序总共进行至多 n-1 次交换（3(n-1)次移动操作）。然而，无论记录的初始排序如何，所需进行的关键字间的比较次数相同，均为 n(n-1)/2。因此，总的时间复杂度也是 o(n^2)。简单选择排序需要改进的地方：从上述可见，选择排序的主要操作是进行关键字的比较，因此改进简单选择排序应从如何减少”比较“出发考虑。显然，在 n 个关键字选出最小值，至少进行 n-1 次比较，然而，继续在剩余的 n-1 个关键字中选择次小值就并非一定要进行 n-2 次比较，若能利用前 n-1 次比较所得信息，则可减少以后各趟选择排序中所用的比较次数。这一点请看后面的选择排序方法。树形选择排序树形选择排序又名锦标赛排序，算法思想与体育比赛类似， 首先将 n 个数据元素两两分组，分别按关键字进行比较，得到 n／2 个比较的优胜者(关键字小者)，作为第一步比较的结果保留下来， 然后对这 n／2 个数据元素再两两分组，分别按关键字进行比较，如此重复，直到选出一个关键字最小的数据元素为止。树形选择排序构成的树是满二叉树。实际算法中，我们把需要比较的记录全部作为叶子，然后从叶子开始两两比较，从底向上最后形成一棵完全二叉树。在我们选择出最小关键字后，根据关系的传递，只需要将最小关键字的叶子节点改成无穷大，重新从底到上比较一次就能够得出次小关键字。树形选择排序示例：算法分析：但是，这种排序方法也有一些缺点，比如辅助存储空间较多，并且需要和“最大值（无穷大）”进行多余的比较。为了弥补，另一种选择排序被提出——堆排序。堆排序树形选择排序需要的辅助空间较多，而堆排序只需要一个记录大小的辅助空间。 堆定义若将和此序列对应的一维数组（即以一维数组作此序列的存储结构）看成是一个完全二叉树，则堆的含义表明，完全二叉树中所有非终端结点的值均不大于（或不小于）其左、右孩子结点的值。由此，若序列{k1，k2，…,kn}是堆，则堆顶元素（或完全二叉树的根）必为序列中n个元素的最小值（或最大值）。 堆的存储一般都用数组来表示堆，i 结点的父结点下标就为 (i – 1) / 2。它的左右子结点下标分别为 2 * i + 1 和 2 * i + 2。如第 0 个结点左右子结点下标分别为 1 和 2（请参考顺序存储的完全二叉树）。 堆排序思想利用大顶堆(小顶堆)堆顶记录的是最大关键字(最小关键字)这一特性，使得每次从无序中选择最大记录(最小记录)变得简单。1) 建堆将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆（或小顶堆），此堆为初始的无序区；2)输出堆顶记录将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n];3)调整堆由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。// Heap 定义堆排序过程中使用的堆结构type Heap struct { arr []int // 用来存储堆的数据 size int // 用来标识堆的大小}// adjustHeap 用于调整堆，保持堆的固有性质func adjustHeap(h Heap, parentNode int) { leftNode := parentNode*2 + 1 rightNode := parentNode*2 + 2 maxNode := parentNode if leftNode &lt; h.size &amp;&amp; h.arr[maxNode] &lt; h.arr[leftNode] { maxNode = leftNode } if rightNode &lt; h.size &amp;&amp; h.arr[maxNode] &lt; h.arr[rightNode] { maxNode = rightNode } if maxNode != parentNode { h.arr[maxNode], h.arr[parentNode] = h.arr[parentNode], h.arr[maxNode] adjustHeap(h, maxNode) }}// createHeap 用于构造一个堆func createHeap(arr []int) (h Heap) { h.arr = arr h.size = len(arr) for i := h.size / 2; i &gt;= 0; i-- { adjustHeap(h, i) } return}// heapSort 使用堆对数组进行排序func heapSort(arr []int) { h := createHeap(arr) for h.size &gt; 0 { // 将最大的数值调整到堆的末尾 h.arr[0], h.arr[h.size-1] = h.arr[h.size-1], h.arr[0] // 减少堆的长度 h.size-- // 由于堆顶元素改变了，而且堆的大小改变了，需要重新调整堆，维持堆的性质 adjustHeap(h, 0) }}func main() { // 测试代码 arr := []int{9, 8, 7, 6, 5, 1, 2, 3, 4, 0} fmt.Println(arr) heapSort(arr) fmt.Println(arr)} 堆排序的实现实现堆排序需要解决两个问题： 1.如何由一个无序序列建成一个堆？ 2.如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？先考虑第二个问题，一般在输出堆顶元素之后，视为将这个元素排除，然后用表中最后一个元素填补它的位置，自上向下进行调整：首先将堆顶元素和它的左右子树的根结点进行比较，把最小的元素交换到堆顶；然后顺着被破坏的路径一路调整下去，直至叶子结点，就得到新的堆。我们称这个自堆顶至叶子的调整过程为“筛选”。从无序序列建立堆的过程就是一个反复“筛选”的过程。 建堆或调整堆在最开始构造堆时，实际上就是将待排序的整个序列看成是一个完全二叉树，然后从最后一个非终端结点（第 n/2 个元素）往上进行“筛选”直到序列的第一个结点为止。如此就构造了一个“堆”。调整堆：当前面的堆得到一个堆顶元素后，将该堆顶元素与本堆（假设为 d[0]~d[n-1] ）（因为每次待调整堆的序列个数在逐渐减少）最后一个结点元素进行交换，然后再对剩余的待排序的序列建堆（此时待排序序列为 d[0]~d[n-2]）即可。 进行堆排序但是“堆”并不是一个完全排序的序列，因为“堆”只保证了父节点与子节点的位置关系，但并不保证左右子节点的位置关系。那么我们如何进行“堆排序”呢？由于一个“堆”的根节点必然是整个序列中最大的元素，因此对于一个排序的序列而言，每个“堆”中我们只能得到一个有效的元素。如果我们拿掉根节点，再对剩下的序列重新排列组成一个“堆”，反复如此，我们就可以依次得到一个完整的排序序列了。当然，为了简化操作，每次我们只需要把根节点与最后一个位置的节点交换，然后把最后一个位置排除之外，有了初始堆之后就可以进行排序了。堆排序是一种选择排序。建立的初始堆为初始的无序区。排序开始，首先输出堆顶元素（因为它是最值），将堆顶元素和最后一个元素交换，这样，第 n 个位置（即最后一个位置）作为有序区，前 n-1 个位置仍是无序区，对无序区进行调整，得到堆之后，再交换堆顶和最后一个元素，这样有序区长度变为 2 ……不断进行此操作，将剩下的元素重新调整为堆，然后输出堆顶元素到有序区。每次交换都导致无序区 -1，有序区 +1。不断重复此过程直到有序区长度增长为 n-1，排序完成。 堆排序示例首先，建立初始的堆结构如图：然后，交换堆顶的元素和最后一个元素，此时最后一个位置作为有序区（有序区显示为黄色），然后进行其他无序区的堆调整，重新得到大顶堆后，交换堆顶和倒数第二个元素的位置……重复此过程：最后，有序区扩展完成即排序完成：由排序过程可见，若想得到升序，则建立大顶堆，若想得到降序，则建立小顶堆。 堆排序算法分析堆排序方法对记录数较少的文件并不值得提倡，但对n较大的文件还是很有效的。因为其运行时间主要耗费在建初始堆和调整建新堆时进行的反复“筛选”上。堆排序在最坏的情况下，其时间复杂度也为 O(nlogn)。相对于快速排序来说，这是堆排序的最大优点。此外，堆排序仅需一个记录大小的供交换用的辅助存储空间。归并排序归并排序(Merge Sort)是利用”归并”技术来进行排序。归并是指将若干个已排序的子序列合并成一个更大的有序序列。常用的是 2-路归并排序。其原理是：假设初始序列有 n 个记录，则可以看成是 n 个有序的子序列，每个子序列的长度为 1，然后两两归并，得到 ⌈n/2⌉ 个长度为 2 或 1 的有序子序列；再两两归并，……，如此重复，直至得到一个长度为 n 的有序序列为止，这种排序方法称为 2-路归并排序。实现方法：设两个有序的子序列(相当于输入序列)放在同一序列中相邻的位置上：array[low..m]，array[m + 1..high]，先将它们合并到一个局部的暂存序列 temp (相当于输出序列)中，待合并完成后将 temp 复制回 array[low..high]中，从而完成排序。package mergeSort;//在某趟归并中，设各子表的长度为 gap，//则归并前 R[0...n-1] 中共有 n/gap 个有序的子表：//R[0...gap-1], R[gap...2*gap-1], ... , R[(n/gap)*gap ... n-1]。//调用Merge将相邻的子表归并时，必须对表的特殊情况进行特殊处理。//若子表个数为奇数，则最后一个子表无须和其他子表归并（即本趟处理轮空）：//若子表个数为偶数，则要注意到最后一对子表中后一个子表区间的上限为 n-1。public class MergeSort { public void Merge(int[] array, int low, int mid, int high) { int i = low; // i是第一段序列的下标 int j = mid + 1; // j是第二段序列的下标 int k = 0; // k是临时存放合并序列的下标 int[] array2 = new int[high - low + 1]; // array2是临时合并序列 // 扫描第一段和第二段序列，直到有一个扫描结束 while (i &lt;= mid &amp;&amp; j &lt;= high) { // 判断第一段和第二段取出的数哪个更小，将其存入合并序列，并继续向下扫描 if (array[i] &lt;= array[j]) { array2[k] = array[i]; i++; k++; } else { array2[k] = array[j]; j++; k++; } } // 若第一段序列还没扫描完，将其全部复制到合并序列 while (i &lt;= mid) { array2[k] = array[i]; i++; k++; } // 若第二段序列还没扫描完，将其全部复制到合并序列 while (j &lt;= high) { array2[k] = array[j]; j++; k++; } // 将合并序列复制到原始序列中 for (k = 0, i = low; i &lt;= high; i++, k++) { array[i] = array2[k]; } } public void MergePass(int[] array, int gap, int length) { int i = 0; // 归并gap长度的两个相邻子表 for (i = 0; i + 2 * gap - 1 &lt; length; i = i + 2 * gap) { Merge(array, i, i + gap - 1, i + 2 * gap - 1); } // 余下两个子表，后者长度小于gap if (i + gap - 1 &lt; length) { Merge(array, i, i + gap - 1, length - 1); } } public int[] sort(int[] list) { for (int gap = 1; gap &lt; list.length; gap = 2 * gap) { MergePass(list, gap, list.length); System.out.print(\"gap = \" + gap + \":\\t\"); this.printAll(list); } return list; } // 打印完整序列 public void printAll(int[] list) { for (int value : list) { System.out.print(value + \"\\t\"); } System.out.println(); } public static void main(String[] args) { int[] array = { 9, 1, 5, 3, 4, 2, 6, 8, 7 }; MergeSort merge = new MergeSort(); System.out.print(\"排序前:\\t\\t\"); merge.printAll(array); merge.sort(array); System.out.print(\"排序后:\\t\\t\"); merge.printAll(array); }}前面提到的是非递归的思想，下面说一下归并排序的递归思想。归并排序的递归思想：归并排序的也遵循分治的思想。直观上其操作如下： 分解：分解（分割）待排序的n个元素的序列成各具 n/2 个元素的子序列。 解决：使用归并排序递归地排序两个子序列。 合并：合并两个已排序的子序列以产生已排序的答案。当待排的序列长度为1时，递归“开始回升”，在这种情况下不要做任何工作，因为长度为 1 的每个序列都已排好序。 归并排序递归实现归并排序算法的关键操作是“合并步骤”中两个已排序序列的合并。我们通过调用一个辅助过程 Merge(A,p,q,r) 来完成合并，其中 A 是一个数组，p,q,r 是数组下标，满足 p≤q＜r。该过程假设子数组 A[p,…,q] 和 A[q+1,…,r] 都已经排好序。它合并这两个子数组形成单一的已排好序的子数组并代替当前的子数组 A[p,…,r]。过程 Merge 的思想如下：取两个已排序的输入数组 A[p,…,q] 和 A[q+1,…,r] 以及一个临时输出数组B，令 i=p，表示的是 A[p,…,q] 的索引；j=q+1，表示的是 A[q+1,…,r] 的索引；k=0，表示的是临时输出数组B的的索引。A[i] 和 B[j] 的较小者被复制到 B 的下一个位置，相关计数器向前推进一步。当两个输入表有一个用完的时候，则将领一个表中的剩余部分拷贝到 C 中。递归形式的 2-路归并排序形式虽然较简洁，但效率和实用性很差。具体代码：void Merge(int *, int, int, int);void MergeSort(int A[], int p, int r) { if (p &lt; r) { int q = (p + r) / 2; MergeSort(A, p, q); MergeSort(A, q + 1, r); Merge(A, p, q, r); }}void Merge(int A[], int p, int q, int r) { int *B = new int[r - p + 1]; int i = p, j = q + 1, k = 0; while (i &lt;= q &amp;&amp; j &lt;= r) { if (A[i] &lt;= A[j]) { B[k++] = A[i++]; } else { B[k++] = A[j++]; } } while (i &lt;= q) { B[k++] = A[i++]; } while (j &lt;= r) { B[k++] = A[j++]; } for (k = 0; k &lt; r - p + 1; k++) A[p + k] = B[k]; delete []B;} 归并排序算法分析归并排序的效率达到了巅峰：时间复杂度为O(nlogn)，这是基于比较的排序算法所能达到的最高境界。它同时是一种稳定的算法（快速排序是不稳定的算法）。归并排序是最常用的外部排序方法，也可用于内部排序，但在一般情况下，很少利用 2-路归并排序进行内部排序。归并排序需要O(n)的辅助空间，而与之效率相同的快排和堆排分别需要 O(logn) 和 O(1) 的辅助空间，在同类算法中归并排序的空间复杂度略高。虽然归并排序的运行时间是 O(NlogN),但是它很难用于主存（内部）排序，主要问题在于合并两个排序的表需要线性附加内存，在整个算法中还要花费将数据复制到临时数组再复制回来这样一些附加的工作，其结果是严重减慢了排序的速度。计数排序可参见 一文弄懂计数排序算法！、计数排序桶排序可参见 算法从入门到“放弃”（11）- 桶排序、桶排序算法详解基数排序前面说过的插入排序、快速排序、堆排序、快速排序等都是基于比较的排序（即仅通过元素间比较确定元素间的顺序）。通过决策树的分析可知，这些基于比较的排序算法，其最坏情形下的时间开销最小也要 O(nlogn)。而基数排序不是基于比较的排序，所以它可以突破比较排序的时间复杂度下限，可以达到线性级别 O(kn)。基数排序中的“基数”指的是某个“数位”的取值范围，例如，若该数位上是数字，则“基”为“10”（0~9），若是字母，则“基”为“26“。 基本思想：基数排序（Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。基数排序是稳定性的排序。基数排序是一种借助多关键字排序的思想对单逻辑关键字按“位”（和采用的进制有关，如十进制也可转化为二进制再来排序）进行排序的方法。它是这样实现的：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。基数排序的方式可以采用 LSD（Least sgnificant digital）或 MSD（Most sgnificant digital），LSD 的排序方式由键值的最右边开始，而 MSD 则相反，由键值的最左边开始。LSD 的基数排序适用于位数小的数列，如果位数多的话，使用 MSD 的效率会比较好，MSD 的方式恰与 LSD 相反，是由高位数为基底开始进行分配，其他的演算方式则都相同。注意：一般将 LSD 排序方法称为：基数排序链式基数排序用数组来实现基数排序的话，所需辅助存储量（“基”X N个记录空间, 实际上是一个二维数组，即使“基”为字母等也可以用类似哈希函数的形式映射到二维数组中行维的下标集里面）太大，后面有人提出用“计数”代替“分配”才使基数排序得以在计算机上实现，但此时仍需要 n 个记录（和原来的 n 个记录空间一起轮回暂时“收集”好的记录，如，按个位收集好后放在辅助空间中，然后对辅助空间中的记录按十位进行收集，并存储在原存储空间，如此轮回直到排序结束）和 2 X “基”个计数单元的辅助空间（该方法的思路是将所用的“收集桶”拼接在一起用 n 个记录空间形成的一维数组表示，这样就需要知道某个“基”对应桶的起始位置，某个记录存在该段桶的具体位置还需要从起始位置外后面计数，所以需要 2X”基“个计数单元的辅助空间，其中的 1X“基”计数空间用于记载某个“桶”中记录的个数 ，另一组计数空间用于累加前面所有“桶”中记录的个数 ，从而得到某个“桶”的起始位置，当该段桶存入记录 后，要修改起始位置，此时可以认为“起始位置”起着游标的作用）。此后，有人提出用链表做存储结构，则又省去了 n 个记录的辅助空间（通过修改指针来代替前面提到的临时向辅助空间转存记录）。链式基数排序思想前面提到了计数基数排序的做法，实际上链式基数排序是计数基数排序的改进版。计数基数排序的“分配”用的是“计数”方法，“收集”用的是“一维数组”自然收集而成。而连式基数排序的“分配”用的是“基”个头指针，“收集”用的是“基”个对应的尾指针，而成对的头尾指针构成了“桶”，用指针修改（注意链入指针和尾指针都要修改）来链入后面入“桶”的记录。当所有记录都分配完之后，就要进行“收集”工作。其实“收集”很简单，就是用前一个“桶”的尾指针指向下一个“桶”的头指针，如此直到把所有的“桶”都串起来为止，这样“基”个链表就变成了一个大的链表，也就完成了“收集”工作。然后进行下一次“分配”和“收集”（一般需要重新申请头尾指针），直到“最高位”完成收集操作，此时整个连式基数排序也就收官了。需要注意的是：不同的“位”分配和收集需要的头尾指针个数可能不同，因为各自的“基”可能不同。如：扑克牌的花色只有 4 种，而点数就不止了。 链式基数排序的实现请参考前面的思想，这里只是说下：可以完全用自己的代码实现，也可以借助高级语言自身带的逊汗链表类实现，因为逊汗链表本身有头尾指针，该类已经实现了基本操作，我们只需要直接拿来用就可以了。需要注意的是“分配”和“收集”用到的循环链表类基本操作中具体操作不同，需要使用不同的函数。不过可以参考视频：连式基数排序视频教程 例子 算法分析对于 n 个记录（假设每个记录含 d 个关键字或位，每个关键字的取值范围为 r 个值，事实上不同的关键字可能具有不同的取值范围）进行链式基数排序的时间复杂度为 O(d(n+r))，其中每一趟分配的时间复杂度为 O(n)，每一趟收集的时间复杂度为 O(r)，整个排序需进行 d 趟分配和收集。所需辅助空间为 2r 个队列指针。当然，由于需用链表作存储结构，则相对于其他以顺序结构存储记录的排序方法而言，还增加了 n 个指针域的空间。基数排序对大数据量排序很快，并且代码简单，易于维护。但是，与快速排序不同，基数排序的数据局部性不好，因此充分优化的快速排序算法在现代计算机上，更适应当前的内存存储架构。在计算机处理中，对整数排序不会使用10作为基数，因为计算机里的整数都是二进制的数，因此可以使用16或256为基数来处理，因为这样可以使用位操作来取出整数中对应的位，效率比取十进制的位要高。通常，基数排序在数据非常多的时候排序效率才会很高，一般需要超过几十万条甚至上百万条记录时，基数排序的效率才比归并排序好。排序方法比较影响排序效果的因素：因为不同的排序方法适应不同的应用环境和要求，所以选择合适的排序方法应综合考虑下列因素： 待排序的记录数目 n 多少； 记录的大小（规模和占用的空间大小）； 关键字的结构及其初始状态（有序程度等）； 对稳定性的要求； 语言工具的条件； 存储结构（顺序存储、链式存储等）； 时间和辅助空间复杂度等； 不同条件下排序方法的选择 从平均时间性能而言，快速排序最佳，其所需时间最省，但快速排序的最坏情况下的时间性能不如堆排序和归并排序。而后两者相比较的结果是：在 n 较大时，归并排序所需时间较堆排序省，但它所需的辅助存储量最多。 当序列中的记录“基本有序”或 n 值较小时，直接插入排序是最佳的排序方法，因此常将它和其他的排序方法，诸如快速排序、归并排序等结合在一起使用。 基数排序的时间复杂度也可写成 O(d·n)。因此，它最适合于 n 值很大而关键字较小的序列。若关键字也很大，而序列中大多数记录的“最高位关键字”均不同，则亦可先按“最高位关键字”不同将序列分成若干“小”的子序列，而后进行直接插入排序。 从方法的稳定性来比较，基数排序是稳定的内排方法，所有时间复杂度为 O(n^2) 的简单排序法也是稳定的，然而，快速排序、堆排序和希尔排序等时间性能较好的排序方法都是不稳定的。 一般来说，排序过程中“比较”是在“相邻的两个记录关键字”间进行的排序方法是稳定的，值得提出的是，稳定性是由方法本身决定的，对不稳定的排序方法而言，不管其描述形式如何，总能举出一个说明不稳定的实例来。反之，对稳定的排序方法，总能找到一种不引起不稳定的描述形式。由于大多数情况下排序是按记录的主关键字进行的，则所用的排序方法是否稳定无关紧要。若排序按记录的次关键字（或多关键字）进行，则应根据问题所需慎重选择排序方法及其描述算法。总之，前面提到的多数排序算法是在顺序存储结构上实现的，因此在排序过程中需进行大量记录的移动。当记录很大（即每个记录所占空间较多）时，时间耗费较大，此时可采用静态链表做存储结构，如表插入排序、链式基数排序，以修改指针代替移动记录。但是，有的排序方法，如快速排序和堆排序，无法实现表排序。在这种情况下可以进行“地址排序”，即另设一个地址向量指示相应记录；同时在排序过程总不移动记录而移动地址向量中相应分量的内容，最后才移动记录。地址排序示例：外排序在说外排序之前先说一下外部存储区的存取特性。磁盘是直接存取的设备，在磁盘中存取信息需要的时间包括：寻道时间、等待时间（找到磁道之后，磁头移动到数据信息所在的起始位置所需时间）和传输时间（即读或写数据所需要的时间）。磁带是顺序存取的设备。在磁带上信息按字符组(记录)存放，而不是按字符存放的。在磁带上读写信息的所需时间由2部分组成：延迟时间（读/写头到达传输信息所在物理块起始位置所需时间）和传输时间。顺序存取设备主要用于处理变化少、只进行顺序存取的大量数据。磁带常用于大量数据的备份。需要用到内、外存交换数据的排序叫外排序。 外部排序组成外部排序基本上由两个相对独立的阶段组成。 内部排序构造归并段按可用内存大小，将外存上含 n 个记录的文件分成若干长度为 L 的子文件或段，依次读入内存并利用有效的内部排序方法对它们进行排序，并将排序后得到的有序子文件重新写入外存。通常称这些有序子文件为归并段或顺串。 归并过程对第一阶段产生的归并段进行逐趟归并，使归并段(有序的子文件)逐渐由小至大，直至得到整个有序文件为止。 外排序时间耗费对统一文件而言，进行外排序时所需读/写外存的次数和归并的趟数 s 成正比。而在一般情况下，对 m 个初始归并段进行 k-路平衡归并时，归并的趟数为可见，若增加 k 或减少 m 便能减少 s。多路平衡归并的实现前面提到增加 k 可以减少 s，从而减少外存读写的次数。但是单纯增加 k 将导致内部归并时间的增加，从而出现矛盾。使用“败者树”可以解决这个矛盾。请看下面的分析：可见，在做 k-路归并的时候，每次都需要做 k-1 次比较才能找出所要的记录，代价较大。胜者树胜者树用完全二叉树作为存储结构。 选手或叶结点用数组L[1…n]表示，内部结点用数组B[1…n-1]表示 数组B中实际存放的是数组L的索引。 通过比较两个选手的分数确定一场比赛的赢家从树最底层开始，每两个树叶之间进行比赛，输的选手被淘汰，赢的继续向上进行竞赛，树根记录了整个比赛的胜者。 如果选手L[i]的分值改变，可以修改这棵赢者树沿着从L[i]到根结点的路径修改二叉树，而不必改变其它比赛的结果 胜者树的构建 胜者树的调整 胜者树存在的问题从上图可以看出，胜者树中存在较多的重复信息，换句话说，没有充分记录下比较得到的信息。从而导致胜者树调整时需要通过比较获取更多的信息，也就是说，调整时需要额外（重复）的比较。这些问题将在“败者树”中得到解决。败者树败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让获胜者去参加更高阶段的比赛。另外，根结点B[0]处加入一个结点来记录整个比赛的胜者。采用败者树是为了简化重构的过程。 比赛过程 将新进入树的结点与其父结点进行比赛 把败者存放在父结点中 而把胜者再与上一级的父结点进行比赛 这样的比赛不断进行，直到结点B[1] 把败者的索引放在结点B[1] 把胜者的索引放到结点B[0] 败者树的构建初始化包含k个选手的败方树需要 O(k)的时间 败者树的调整在一般情况下，若输入文件有 n 个对象，生成初始归并段的时间开销是 O(nlogk)，这是因为每输出一个对象，对败者树进行调整需要时间为 O(logk)最后需要提及的一点是，k 值的选择并非越大越好，如何选择合适的 k 是一个需要综合考虑的问题。置换-选择排序前面已经说过，归并的趟数不尽和 k 成反比（从归并过程角度—外排序的第二阶段来考虑），也和 m（初始归并段个数）成正比，因此，减少 m 是减少 s（归并趟数）的另一条途径。然而产生初始归并段的一般内部排序方法，受到内存工作区大小的限制，通常产生的初始归并段的长度是确定的（除了最后一个初始归并段）。可见，要减少 m ，必须增加单个初始归并段的长度，只能需求新的排序方法。置换-选择排序是在树形选择排序的基础上得来的，它的特点是：在整个排序（得到所有初始归并段）的过程中，选择最下（或最大）关键字和输入、输出交叉（或平行）进行。 操作过程 1) 从 FI 输入 w 个记录到工作区 WA； 2) 在FO中标记一个归并段开始； 3) 从 WA 中选出最小关键字记录，记为 MINMAX 记录； 4) 将 MINMAX 记录输出到 FO 中； 5) 从 FI 输入下一个记录到 WA 中； 6) 在 WA 中的关键字比 MINMAX 大的记录中选出关键字最小的记录 6.1) 若不能选到，在FO中标记一个归并段结束；若由于WA为空而未选出，则结束处理； 否则，标记下一个归并段开始，转 3) 6.2) 否则，将选出的记录作为新的 MINMAX 记录，转 4) 可见，通过置换-选择产生的初始归并段通常不等长。而在 WA 中选择 MINMAX 记录的过程需利用“败者树”来实现。 置换-选择排序中败者树败者树在置换-选择排序中用所不同，具体说明如下： 内存工作区中的记录作为败者树的外部结点，而败者树中根结点的双亲结点指示工作区中关键字最小的记录 为了便于选出 MINMAX 记录，为每个记录附设一个所在归并段的序号，在进行关键字的比较时，先比较段号，段号小的位胜者；段号相同的则关键字小的为胜者； 败者树的建立败者树的建立可从设工作区中所有记录的段号均为“零”开始，然后从 FI 逐个输入 w 个记录到工作区时，自下而上调整败者树，由于这些记录的段号为“1”，则它们对于“零”段的记录而言均为败者，从而逐个填充到败者树的各结点中去。处理步骤设 rnum 为所属归并段的段号；key 为从记录中抽取的关键字；ls 为败者树；w 为内存工作区 WA 能容纳的记录数。 1)初始化败者树： 1.1)所有外部结点： rnum=0; key=0；所有内部结点置 0； 1.2)对外部结点从编号 w-1 至 0 从外存 FI 读入记录，置段号为 1，并调整败者树 2)置当前段号为 1； 3)若 ls[0] 指示的外部结点属于当前段，输出该记录； 否则,当前段号 +1，输出段标后再输出该记录； 4)若 FI 未空，从 FI 补充记录， 若补充的 key&lt;此前输出记录的key，则 rnum=当前段号+1 否则 rnum=当前段号 若 FI 为空，则补虚记录：key= ∞; rnum=当前段号+1； 5)调整败者树 转3）直至所有记录被输出 具体实例（败者树） 算法分析用置换-选择排序方法产生的初始归并段通常不等长。当输入文件记录的关键字大小随机分布时，初始归并段的平均长度为内存工作区大小 w 的两倍。若不计输入、输出的时间，则对 n 个记录的文件而言，生成所有初始归并段所需时间为 O(nlogw)。最佳归并树文件经过置换-选择排序之后，得到长度不等的初始归并段，进行 k-路归并时，初始归并段的不同搭配，会导致归并过程中 I/O 的次数不同。那么怎样搭配所需 I/O 次数最少呢？这就需要借助最佳归并树了。归并方案不同，所得归并树亦不同，树的带权路径长度（或外读写次数）亦不同。在“哈夫曼树”一节中曾讨论过，有 n 个叶子结点的带权路径长度最短的二叉树称为哈夫曼树。同理，存在有 n 个叶子结点的带权路径长度最短的 k 叉树，亦称为 k 叉哈夫曼树。因此，若对长度不等的 m 个初始归并段，构造一颗哈夫曼树作为归并树，便可使在进行外部归并时所需对外存进行读写次数达到最少。这样的归并树便称为最佳归并树。不过需要注意的是，当初始归并段的数目不足时，需附加长度为零的“虚段”，按照哈夫曼树构成的原则，权为零的叶子应离树根最远。如何添加“虚段”在一般情况下，设 m 为初始归并段的个数，对 k-路归并而言，容易推算得到：若 (m-1) MOD (k-1)=0，则不需要加虚段，否则需附加 k-1-[(m-1) MOD (k-1)] 个虚段。换句话说，第一次归并为 [(m-1) MOD (k-1)]+1 路归并。 最佳归并树的构造最佳归并树即k叉(阶)哈夫曼树。设初始归并段为 m 个，进行 k-路归并。则如下进行： 1）若 (m-1) mod (k-1) ≠0 则需附加(k-1)- (m-1) mod (k-1) 个长度为 0 的虚段，以使每次归并都可以对应 k 个段 2）按照哈夫曼树的构造原则（权值越小的结点离根结点越远）构造最佳归并树。 最佳归并树例子假定由置换－选择分类法生成了 9 个初始归并段，记录数分别为 9、30、12、18、3、17、2、6、24 。如果进行 3-路归并，则其最佳归并树如下：途中每个圆圈表示一个初始归并段，圆圈中数字表示归并段的长度。假设去掉上例中的最后一个初始归并段（即长度为 30 的归并段），则其最佳归并树为： 最佳归并树算法分析由于磁带寻找具有最少记录的初始归并段，必须反复倒带。所以，实用性不强。在磁盘的情况下，需要有段包含的记录数信息、段的位置信息等。文件如集中放置在几个相邻的柱面上的情况比较合适。" }, { "title": "C++ 输入和输出", "url": "/2016/09/C++-io.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-21 17:19:48 +0800", "snippet": " C++ 使用了很多较为高级的语言特性来实现输入和输出，其中包括类、派生类、函数重载、虚函数、模板和多重继承。换句话说，C++ 输入和输出技术实际上是C++ 类技术的应用而已，所以在学习这方面的东西时应该有意地往这方面去想。 流和缓冲区 流处理 缓冲区 iostream 文件 重定向 cin 流状态 ...", "content": " C++ 使用了很多较为高级的语言特性来实现输入和输出，其中包括类、派生类、函数重载、虚函数、模板和多重继承。换句话说，C++ 输入和输出技术实际上是C++ 类技术的应用而已，所以在学习这方面的东西时应该有意地往这方面去想。 流和缓冲区 流处理 缓冲区 iostream 文件 重定向 cin 流状态 设置状态 为何需要重设流状态 输出格式控制 I/O 常用控制符 文件的输入和输出 简单的文件 I/O 流状态价差和 is_open() 文件模式 文件格式 随机存取 用于文件输入喝输出的 C++ 工具都是基于 cin 和 cout 所基于的基本类定义。但 C 和 C++ 都没有将输入和输出建立在语言中。 C 语言最初把 I/O 留给了编译器实现人员。这样做的一个原因是为了让实现人员能够自由的设计 I/O 函数，使之最适合于目标计算机的硬件要求。然而， C++ 依赖于 C++ 的 I/O 解决方案，而不是 C 语言的解决方案。C++ 自带了一个标准类库，实现了输入和输出的类库，所以要详细了解输入和输出方面的东西请参考其帮助文件。这里这是讲一下基本的思想而已，不会过多涉及到细节。流和缓冲区C++ 程序把输入和输出看作字节流。输入时，程序从输入流中抽取字节；输出时，程序将字节插入到输出流中。对于面相文本的程序，每个字节代表一个字符。更通俗地说，字节可以构成字符或数值的二进制表示。输入流中的字节可以来自键盘，也可能来自存储设备（如硬盘）或其他程序。同样，输出流中的字节可以流向屏幕、打印机、存储设备或其他程序。流充当了程序和流源或流目标之间的桥梁。这使得 C++ 程序可以以相同的方式对待来自键盘的输入和来自文件的输入。C++ 程序只是检查字节流，而不需要知道字节来自何方。同理，通过使用流，C++ 程序处理输出的方式将独立于其去向。因此管理输入包括两步： 将流与输入去向的程序关联起来 将流与文件连接起来换句话说，输入流需要两个连接，每端各一个。文件端连接提供了流的来源，程序端连接将流的流出部分转储到程序中（文件端连接可以是文件、也可以是设备，如键盘）同样，对输出的管理包括将输出流连接到程序以及将输出目标与流关联起来。这方面的理解请看后面的例子。流处理C++ 将输出（输入）看作字节流（根据实现平台不同，可能是 8 位，16 位或 32 位 的字节，但都是字节），但在程序中，很多数据被组织成比字节更大的单位，例如，int 类型由 16 位或 32 位的二进制值表示；double 值由 64 位的二进制表示。但在将字节流发送给屏幕时，希望每个字节表示一个字符值。也就是说，要在屏幕上显示数字 -2.34，需要将 5 个字符（-, 2, ., 3, 4），而不是这个值得 64 位内部浮点表示发动到屏幕上。因此， ostream 类最重要的任务之一是将数值类型转换位以文本形式表示的字符流。事实上输入也是类似的处理，本质上是一种翻译，道理类似源程序到机器码的编译。缓冲区通常，通过使用缓冲区可以更高效地处理输入和输出。缓冲区是用作中介的内存块，它是将信息从设备传输到程序或从程序传输给设备的临时存储工具。主要是解决字符设备和块设备之间的高效传输问题，这可以匹配总线、内存、硬盘、CPU等的工作方式，从而最大程度地利用这些设备。iostream 文件管理流和缓冲区的工作有点复杂，但 iostream 文件中包含了一些专门设计用来实现、管理流和缓冲区的类。C++ 提供了 I/O 管理方面的类模板。通过使用typedef 工具，C++ 使得这些模板 char 具体化能够模仿传统的非模板 I/O 实现。 管理标准的输入/输出流的类为：istream(输入)、ostream(输出)、iostream(输入输出)，其中 istream 和 ostream 直接从 ios 中继承，iostream 多重继承了 istream 和 otream。而 cin 是 STL 中定位的一个用于输入的 istream 对象，cout、cerr、clog 是三个用于输出的 ostream 对象。其中 cout 对象也被称为标准输出，用于正常的输出，cerr 用来输出警告和错误信息，因为被称为标准错误，而 clog 用来输出程序运行时的一般性信息。cerr 和 clog 之间的不同之处在于 cerr 是不经过缓冲区直接向显示器输出有关信息，而 clog 则是先把信息放在缓冲区，缓冲区满后或遇上 endl 时向显示器输出。 管理文件流的类为：ifstream(文件输入)、ofstream(文件输出)和 fstream(文件的输入/输出)。其中 ifstream 是从 istream 中继承的类，ofstream 是从 ostream 中继承的类，fstream 是从 iostream 继承的类。 管理字符串流的类为：istringstream(字符串输入)、ostringstream(字符串输出)和stringstream(字符串的输入/输出)。其中 istringstream 是从 istream 中继承的类，ostringstream 是从 ostream 中继承的类，stringstream 是从 iostream 继承的类。要使用这些工具，必须使用适当的类对象。例如，使用 ostream 对象 （如 cout）来处理输出。创建这样的对象将打开一个流，自动创建缓冲区，并将其与流关联起来，同时使得能够使用类成员函数。C++ 的 iostream 类库管理了很多细节。例如，在程序中包含 iostream 文件将自动创建 8 个流对象（4 个用于窄字符流，4 个用于宽字符流）。现在列举如下： cin：标准输入流对象，键盘为其对应的标准设备。带缓冲区的，缓冲区由streambuf类对象来管理。 cout：标准输出流对象，显示器为标准设备。带缓冲区的，缓冲区由streambuf类对象来管理。 cerr 和 clog ：标准错误输出流，输出设备是显示器。为非缓冲区流，一旦错误发生立即显示。重定向由于标准输入和输出流默认连接着键盘和屏幕，所以当换成其他输入输出设备时，必须进行重定向。这里推荐两种方法： 在源代码中，将设备与流进行关联，然后正常使用流就可以了 只有可执行文件，使用操作系统命令行工具的重定向命令cin输入操作原理程序的输入都建有一个缓冲区，即输入缓冲区。一次输入过程是这样的，当一次键盘输入结束时会将输入的数据存入输入缓冲区，而 cin 函数直接从输入缓冲区中取数据。正因为 cin 函数是直接从缓冲区取数据的，所以有时候当缓冲区中有残留数据时，cin 函数会直接取得这些残留数据而不会请求键盘输入，这就是例子中为什么会出现输入语句失效的原因！cin 输入结束的条件：Enter、Space、Tab。cin 对这些结束符的处理：丢弃缓冲区中这些字符。与 cin.get(）不同。 cin » 该操作符是根据后面变量的类型读取数据。 输入结束条件 ：遇到Enter、Space、Tab键。 对结束符的处理 ：丢弃缓冲区中使得输入结束的结束符(Enter、Space、Tab) com.get(字符数组名, 提取长度, 结束符)其中结束符为可选参数，读入的字符个数最多为（长度-1）个，结束符规定结束字符串读取的字符，默认为 ENTER, 若要读取字符，直接cin.get(char ch)或ch=cin.get()即可 ch=cin.get() 与 cin.get(ch) 输入结束条件：Enter 键 对结束符处理：不丢弃缓冲区中的 Enter cin.getline()cin.getline(数组名，长度，结束符) 大体与 cin.get(数组名，长度，结束符)类似.区别在于cin.get()当输入的字符串超长时，不会引起cin函数的错误，后面的cin操作会继续执行，只是直接从缓冲区中取数据。但是cin.getline()当输入超长时，会引起cin函数的错误，后面的cin操作将不再执行。 C 语言中 getchar、get、gets、getline它们都能识别空格，读取输入直到回车后，getline 会丢弃回车，而 getchar、get和gets 不丢弃保留在输入缓冲中！这个特性导致如果 get 下面还有一句 get 或 gets，必须用 get() 或 getchar() 接受掉这个回车，否则下面的 get 或 gets 就当已经收到了回车字符而跳过了。因此在循环中使用 get 或 gets 要注意。而 getchar 的话虽然回车也留在缓冲中，但因为循环条件是 !=’\\n’，所以就无所谓了。流状态C++ 的输入输出实际上就是对流的操作，所以了解流的状态时非常必要的，比如可以根据流的状态做不同的输入输出处理，有时候检测错误输入等。设置状态上边中提供了两种方法。clear() 和 setstate() 很相似，它们都重置状态，但采取的方式不同。 clear()clear() 方法将状态设置为它的参数，因此，下面的调用将使用默认参数 0.这将清除全部 3 个状态位（eofbit, badbit, 和 failbit）：clear();同样，下面的调用将状态设置为 eofbit：也就是说， eofbit 将被设置，另外两个状态位被清除：clear(eofbit);为何需要重设流状态对于程序员来说，最常见的理由是，在输入不匹配或到达文件尾时，需要使用不带参数的 clear() 重新打开输入。这样做是否有意义，取决于程序要执行的任务。setstate() 的主要用途是当出现致命错误时为输入和输出函数提供一种修改状态的途径。设置流状态位有一个非常重要的后果：流将对后面的输入或输出关闭，直到位被清除输出格式控制setprecision(n) 可控制输出流显示浮点数的数字个数。C++ 默认的流输出数值有效位是6，所以不管数据是多少，都只输出六位。如果 setprecision(n) 与 setiosflags(ios::fixed) 或者 setiosflags(ios_base::fixed) 合用，可以控制小数点右边的数字个数。setiosflags(ios::fixed) 是用定点方式表示实数。 如果与 setiosnags(ios::scientific) 合用，可以控制指数表示法的小数位数。setiosflags(ios::scientific) 是用指数方式表示实数。I/O 常用控制符使用控制符时，在程序开头加投文件#include C++有两种方法控制格式输出： 用格式控制符； 成员函数 在新版本的 c++中 头文件已经用 iomanip 取代了 iomanip.h。可以不使用#include&lt;iomanip&gt;的文件的输入和输出文件本身是存储在某种设备（光盘、硬盘等）上的一系列字节。通常，操作系统管理文件，跟踪它们的位置、大小、创建时间等。除非在操作系统级别上编程，否则通常不必担心这些事情。需要的只是将程序与文件相连的途径、让程序读取文件内容的途径以及程序创建和写入文件的途径。重定向可以提供一些文件支持，但它比显式程序中的文件 I/O 局限性更大。另外，重定向来自操作系统，而非 C++ ，因此并非所有系统都有这样的功能。C++ I/O 类软件包处理文件输入和输出方式与处理标准输入和输出的方式非常相似。 要写入文件，需要创建一个 ofstream 对象，并使用 ofstream 方法，如 « 插入运算符或 write()。 要读取文件，需要创建一个 ifstream 对象，并使用 ifstream 方法，如 » 抽取运算符或 get().然而，与标准输入和输出相比，未见管理更为复杂。例如，必须将新打开的文件和流关联起来（标准输入输出已经默认关联了），要设置访问模式，操作文件内指针位置等、简单的文件 I/O要让程序写入文件，必须这样做： 包含头文件 fstream； 创建一个 ofstream 对象来管理输出流； 将该对象与特定的文件关联起来； 以使用 cout 的方式使用该对象，唯一的区别是输出将进入文件，而不是屏幕。因为 ostream 是 ofstream 类的基类，因此可以使用所有的 ostream 方法，包括各种输入运算符定义、格式化方法和控制符。ofstream 类使用被缓冲的输出，因此程序在创建像 fout 这样的 ofstream 对象时，将为输出缓冲区分配空间。如果创建两个 ofstream 对象，程序将创建两个缓冲区，每个对象一个。以默认模式打开文件进行输出将自动把文件的长度截短为零，这相当于删除已有的内容。读取文件的要求与写入文件相似： 包含头文件 fstream 创建一个 ifstream 对象来管理输入流（输入和输出相对于操作系统或程序） 将该对象与特定的文件关联起来 以使用 cin 的方式使用该对象。 例子：// fileio.cpp -- saving to a file#include &lt;iostream&gt; // not needed for many systems#include &lt;fstream&gt;#include &lt;string&gt;int main(){ using namespace std; string filename; cout &lt;&lt; \"Enter name for new file: \"; cin &gt;&gt; filename;// create output stream object for new file and call it fout ofstream fout(filename.c_str()); fout &lt;&lt; \"For your eyes only!\\n\"; // write to file cout &lt;&lt; \"Enter your secret number: \"; // write to screen float secret; cin &gt;&gt; secret; fout &lt;&lt; \"Your secret number is \" &lt;&lt; secret &lt;&lt; endl; fout.close(); // close file// create input stream object for new file and call it fin ifstream fin(filename.c_str()); cout &lt;&lt; \"Here are the contents of \" &lt;&lt; filename &lt;&lt; \":\\n\"; char ch; while (fin.get(ch)) // read character from file and cout &lt;&lt; ch; // write it to screen cout &lt;&lt; \"Done\\n\"; fin.close(); // std::cin.get(); // std::cin.get(); return 0;}流状态价差和 is_open()C++ 文件流类从 ios_base 类哪里继承了一个流状态成员。正如前面指出的，该成员存储了指出流状态的消息：一切顺利、已到文件尾、I/O 操作失败等。这一节详细内容强参考情面的“流状态”，下面是“流状态”中的一张图文件模式文件模式描述的是文件将被如何使用：读、写、追加等。将流与文件关联时（无论是使用文件名初始化文件流对象，还是使用 open()方法），都可以提供指定文件模式的第二个参数，例如ifstream fin(\"banjo\",model);// constructor with mode argumentofstream fout();fout.open(\"harp\",mode2);// open() with mode argumentsios_base 类定义了一个 openmode 类型，用于表示模式；与 fmtflags 和 iostate 类型一样，它也是一种 bitmask 类型，可以使用 ios_base 类中定义的多个常熟来指定模式。现列表如下： ios_base::in 打开文件做读操作 ios_base::out 打开文件做写操作 ios_base::app 在每次写之前找到文件尾 ios_base::ate 打开文件后立即定位在文件尾 ios_base::trunc 打开文件时清空已存在的文件流 ios_base::binary 以二进制模式进行IO操作注意：ios_base::ate 和 ios_base::app 都将文件指针指向打开的文件尾。二者的区别在于，ios_base::app 模式只允许将数据添加到文件尾，而 ios_base::ate模式将指针放到文件尾。文件格式 文本文件以字符格式存储所有的信息，例如，数字值将被转换为字符表示。常规的插入和抽取运算符以及 get() 和 getline() 都支持这种模式。 二进制文件二进制文件使用计算机内部使用的二进制表示来存储信息。与文本文件相比，二进制文件存储数据（尤其是浮点值）更为精确、简洁，但可移植性较差。 read() 和 write() 方法都支持二进制输入和输出。随机存取seekg() 和 seekp() 函数提供对文件的随机存取。这些类方法使得能够将文件指针放置到相对于文件开头、文件尾和当前位置的某个位置。tellg() 和 tellp() 方法报告当前的文件位置。顺序存取请参考文件模式。" }, { "title": "C++ 异常处理机制", "url": "/2016/09/C++-Exception.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-20 18:29:18 +0800", "snippet": " 程序中的错误分为编译时的错误和运行时的错误。编译时的错误主要是语法错误，而运行时的错误则不容易修改，因为其中的错误是不可预料的，或者可以预料但无法避免的，比如内存空间不够，或者在调用函数时，出现数组越界等错误。我们把程序运行时的错误统称为异常，对异常处理称为异常处理。C++中所提供的异常处理机制结构清晰，在一定程度上可以保证程序的健壮性。 概述 C++ 异常处理过程 C++ 异常处...", "content": " 程序中的错误分为编译时的错误和运行时的错误。编译时的错误主要是语法错误，而运行时的错误则不容易修改，因为其中的错误是不可预料的，或者可以预料但无法避免的，比如内存空间不够，或者在调用函数时，出现数组越界等错误。我们把程序运行时的错误统称为异常，对异常处理称为异常处理。C++中所提供的异常处理机制结构清晰，在一定程度上可以保证程序的健壮性。 概述 C++ 异常处理过程 C++ 异常处理机制组成 try throw 抛出异常 catch 匹配 将对象作为 栈解退 其他异常特性 exception 类 异常何时回迷失方向 有关异常的注意事项 RTTI（待续） RTTI机制的产生 概述异常，让一个函数可以在发现自己无法处理的错误时抛出一个异常，希望它的调用者可以直接或者间接处理这个问题。而传统错误处理技术，检查到一个局部无法处理的问题时: 1.终止程序(例如atol,atoi,输入NULL，会产生段错误，导致程序异常退出,如果没有core文件，找问题的人一定会发疯) 2.返回一个表示错误的值(很多系统函数都是这样，例如malloc，内存不足，分配失败，返回NULL指针) 3.返回一个合法值，让程序处于某种非法的状态(最坑爹的东西，有些第三方库真会这样) 4.调用一个预先准备好在出现”错误”的情况下用的函数。第一种情况是不允许的，无条件终止程序的库无法运用到不能当机的程序里。第二种情况，比较常用，但是有时不合适，例如返回错误码是int，每个调用都要检查错误值，极不方便，也容易让程序规模加倍(但是要精确控制逻辑，我觉得这种方式不错)。第三种情况，很容易误导调用者，万一调用者没有去检查全局变量errno或者通过其他方式检查错误，那是一个灾难，而且这种方式在并发的情况下不能很好工作。至于第四种情况，本人觉得比较少用，而且回调的代码不该多出现。使用异常，就把错误和处理分开来，由库函数抛出异常，由调用者捕获这个异常，调用者就可以知道程序函数库调用出现错误了，并去处理，而是否终止程序就把握在调用者手里了。但是，错误的处理依然是一件很困难的事情，C++的异常机制为程序员提供了一种处理错误的方式，使程序员可以更自然的方式处理错误。C++ 异常处理过程C++中处理异常的过程是这样的：在执行程序发生异常，可以不在本函数中处理，而是抛出一个错误信息，把它传递给上一级的函数来解决，上一级解决不了，再传给其上一级，由其上一级处理。如此逐级上传，直到最高一级还无法处理的话，运行系统会自动调用系统函数 terminate，由它调用 abort 终止程序(这个过程称之为栈展开)。这样的异常处理方法使得异常引发和处理机制分离，而不在同一个函数中处理。这使得底层函数只需要解决实际的任务，而不必过多考虑对异常的处理，而把异常处理的任务交给上一层函数去处理。在栈展开的时候，会退出某个函数，释放当前内存并撤销局部对象，这时会调用对象的析构函数，如果析构函数抛出异常，将会调用标准库 terminate 函数，强制整个程序非正常退出。所以析构函数应该从不抛出异常。被调用者抛出异常，调用者（递归向上）处理异常C++ 异常处理机制组成C++的异常处理机制有3部分组成：try(检查)，throw(抛出)，catch(捕获)。把需要检查的语句放在try模块中，检查语句发生错误，throw 抛出异常，发出错误信息，由 catch 来捕获异常信息，并加以处理。一般 throw 抛出的异常要和 catch 所捕获的异常类型所匹配。异常处理的一般格式为：try　　{　　　　被检查语句　　　　throw 异常　　}　　catch(异常类型1)　　{　　　　进行异常处理的语句1　　}　　catch(异常类型2)　　{　　　　进行异常处理的语句2　　} . . . catch(...)  //捕获所有异常处理    {         默认异常处理    }如果在执行try语句模块时，没有发生异常，则catch语句块不起作用，流程转到其后的语句继续执行。tryC++ 应用程序中，try 关键字后的代码块中通常放入可能出现异常的代码。随后的 catch 块则可以是一个或者多个；catch 块主要用于异常对应类型的处理。try 块中代码出现异常可能会对应多种异常处理情况，catch 关键字后的圆括号中则包含着对应类型的参数。try 块中代码体作为应用程序遵循正常流程执行。一旦该代码体中出现异常操作，会根据操作的判断抛出对应的异常类型。随后逐步的遍历 catch 代码块，此步骤与 switch 控制结构有点相像。当遍历到对应类型 catch 块时，代码会跳转到对应的异常处理中执行。如果 try 块中代码没有抛出异常，则程序继续执行下去。try 体中可以直接抛出异常，或者在 try 体中调用的函数体中间接的抛出。throw 抛出异常C++ 程序中异常抛出是采用关键字 throw 实现的。通常 throw 关键字后会跟随着一个操作数，该操作数可以是一个表达式、一个 C++ 内置类型数据或者为类类型的对象等。最常见的异常抛出都会放在 try 代码块中。当然，C++ 也允许抛出异常的地方在函数中供 try 块中的代码调用。正常情况下异常抛出点的定义不要放在 try 块外部无关的地方，因为那样通常会引起编译器默认的终止程序处理。最好的情况下，异常抛出点直接或者间接的定义在 try 块中。try 块中可以包含一个或者多个异常抛出点。但是需要注意的是，异常只要一抛出，对应的 catch 块捕捉到后，该 try 块中以下的代码体执行会被终止。代码执行直接进入对应的 catch 块中，最后 catch 块执行处理完异常后直接跳转至所有当前 try 块对应的 catch 块之后。catch 匹配在查找匹配的 catch 期间，找到的 catch 不必是与异常最匹配的那个 catch，相反，将选中第一个找到的可以处理该异常的 catch。因此，在 catch 子句列表中，最特殊的 catch 必须最先出现，否则没有执行的机会。进入 catch 的时候，用异常对象初始化 catch 的形参。因为基类的异常说明符可以捕获派生类的异常对象。如果异常对象是引用，则可以使用多态，调用基类的 virtual 将执行派生类的覆盖的函数。若 catch 的异常说明符是对象，则将派生类对象分割为它的基类对象。异常匹配除了必须要是严格的类型匹配外，还支持下面几个类型转换． 允许从派生类到基类的类型转换 允许数组被转换为数组指针，允许函数被转换为函数指针 允许非常量到常量的类型转换，也就是说可以抛出一个非常量类型，然后使用 catch 捕捉对应的常量类型版本异常处理的一个例子：#include \"stdafx.h\"#include &lt;iostream&gt;template &lt;typename T&gt;T Div(T x,T y){ if(y==0) throw y;//抛出异常 return x/y;}int main(){ int x=5,y=1; double x1=5.5,y1=0.0; try    { //被检查的语句        std::cout &lt;&lt; x &lt;&lt; \"/\"&lt;&lt; y &lt;&lt;\"=\" &lt;&lt; Div(x,y) &lt;&lt; std::endl;        std::cout &lt;&lt; x1 &lt;&lt; \"/\" &lt;&lt; y1 &lt;&lt; \"=\" &lt;&lt; Div(x1,y1) &lt;&lt; std::endl;    } catch(...)//捕获任意类型异常    { try        {            std::cout &lt;&lt; \"任意类型异常！\"&lt;&lt; std::endl; throw;//抛出当前处理异常信息给上一层catch        } catch(int)//异常类型        {            std::cout &lt;&lt; \"除数为0,计算错误！\"&lt;&lt; std::endl;//异常处理语句        } catch(double)//异常类型        {            std::cout &lt;&lt; \"除数为0.0,计算错误！\" &lt;&lt; std::endl;//异常处理语句        }    } return 0;}将对象作为通常，引发异常的函数将传递一个对象。这样做的重要优点是： 可以使用不同的异常类型来区分不同函数在不同情况下引发的异常。 对象可以携带信息，程序员可以根据这些信息来确定引发异常的原因，同时，catch 块可以根据这些信息来决定采取什么样的措施。栈解退现在假设函数由于出现异常（而不是由于返回）而终止，则程序也将释放栈中的内存，但不会在释放栈的第一个返回地址后停止，而是继续释放栈，直到找到一个位于 try 块中的返回地址。随后，控制权将转到块尾的异常处理程序，而不是函数调用后面的第一条语句。这个过程称为栈解退。引发机制的一个非常重要的特性是：和函数返回一样，对于栈中的自动类对象，类的析构函数将被调用。然而，函数返回仅仅处理该函数放在栈中的对象，而 throw 语句则处理 try 块和 throw 之间整个函数调用序列放在栈中的对象。如果没有栈解退这种特性，则引发异常后，对于中间函数调用放在栈中的自动类对象，其析构函数将不会被调用。程序进行栈解退以回到能够捕获异常的地方时，将释放栈中的自动存储型变量，如果变量是类对象，将为该对象调用析构函数//error5.cpp -- unwinding the stack#include &lt;iostream&gt;#include &lt;cmath&gt; // or math.h, unix users may need -lm flag#include &lt;string&gt;#include \"exc_mean.h\"class demo{private: std::string word;public: demo (const std::string &amp; str) { word = str; std::cout &lt;&lt; \"demo \" &lt;&lt; word &lt;&lt; \" created\\n\"; } ~demo() { std::cout &lt;&lt; \"demo \" &lt;&lt; word &lt;&lt; \" destroyed\\n\"; } void show() const { std::cout &lt;&lt; \"demo \" &lt;&lt; word &lt;&lt; \" lives!\\n\"; }};// function prototypesdouble hmean(double a, double b);double gmean(double a, double b);double means(double a, double b);int main(){ using std::cout; using std::cin; using std::endl; double x, y, z;\t{ demo d1(\"found in block in main()\"); cout &lt;&lt; \"Enter two numbers: \"; while (cin &gt;&gt; x &gt;&gt; y) { try { // start of try block z = means(x,y); cout &lt;&lt; \"The mean mean of \" &lt;&lt; x &lt;&lt; \" and \" &lt;&lt; y &lt;&lt; \" is \" &lt;&lt; z &lt;&lt; endl; cout &lt;&lt; \"Enter next pair: \"; } // end of try block catch (bad_hmean &amp; bg) // start of catch block { bg.mesg(); cout &lt;&lt; \"Try again.\\n\"; continue; } catch (bad_gmean &amp; hg) { cout &lt;&lt; hg.mesg(); cout &lt;&lt; \"Values used: \" &lt;&lt; hg.v1 &lt;&lt; \", \" &lt;&lt; hg.v2 &lt;&lt; endl; cout &lt;&lt; \"Sorry, you don't get to play any more.\\n\"; break; } // end of catch block } d1.show(); } cout &lt;&lt; \"Bye!\\n\"; // cin.get(); // cin.get(); return 0;}double hmean(double a, double b){ if (a == -b) throw bad_hmean(a,b); return 2.0 * a * b / (a + b);}double gmean(double a, double b){ if (a &lt; 0 || b &lt; 0) throw bad_gmean(a,b); return std::sqrt(a * b);}double means(double a, double b){ double am, hm, gm; demo d2(\"found in means()\"); am = (a + b) / 2.0; // arithmetic mean try { hm = hmean(a,b); gm = gmean(a,b); } catch (bad_hmean &amp; bg) // start of catch block { bg.mesg(); std::cout &lt;&lt; \"Caught in means()\\n\"; throw; // rethrows the exception } d2.show(); return (am + hm + gm) / 3.0;}其他异常特性虽然 throw-catch 机制类似于函数参数和函数返回机制，但还是有些不同之处。 返回的具体位置不同函数 fun() 中的返回语句将控制权返回到调用 fun() 的函数，但 throw 语句将控制权向上返回到第一个这样的函数：包含能够捕获相应异常的 try-catch 组合。 引发异常时编译器总是创建一个临时拷贝，即使异常规范和 catch 块中指定的是引用，例如：class problem {...};...void super() throw (problem){ ... if (oh_no) [ problem oops; // construct object throw oops; // throw it ... ] ... try { super(); } catch(problem &amp; p) { // statements }}p 将指向 oops 的副本而不是 oops 本身。这是件好事，因为函数 super() 执行完毕后， oops 将不复存在。不过如果将引发异常和创建对象组合在一起将更简单throw problem();// construct and throw default problem object既然返回的是副本，为何代码中使用引用呢？将引用作为返回值得通常原因是避免创建副本以提高效率。答案是，引用还有另一个重要特征；基类引用可以执行派生类对象。假设有一组通过继承关联起来的异常类型，则在异常规范中只需列出一个基类引用，它将于任何派生类对象匹配。而且这样是合理的，因为在一般情况下回自动判断将使用的是基类还是派生类方法。这意味着 catch 块的排列顺序应该与派生顺序相反例子如下：class bad_1 {...};class bad_2 : public bad_1 {...};call bad_3 : public bad_2 {...};...void duper(){ ... if (oh_no) throw bad_1(); if (rats) throw bad_2(); if (drat) throw bad_3();}...try { duper();}catch(bad_3 &amp;be){ ...}catch(bad_2 &amp;be){ ...}catch(bad_1 &amp;be){ ...}exception 类本文只是简单介绍 exception 类及其标准异常类，详细学习请查阅 C++ 帮助文件及其中的示例和说明。C++语言本身或者标准库抛出的异常都是 exception 的子类，称为标准异常（Standard Exception）。你可以通过下面的语句来匹配所有标准异常：try{ //可能抛出异常的语句}catch(exception &amp;e){ //处理异常的语句}exception 类位于 头文件中，它被声明为：class exception {public: exception () throw(); //构造函数 exception (const exception&amp;) throw(); //拷贝构造函数 exception&amp; operator= (const exception&amp;) throw(); //运算符重载 virtual ~exception() throw(); //虚析构函数 virtual const char* what() const throw(); //虚函数}这里需要说明的是 what() 函数。what() 函数返回一个能识别异常的字符串，正如它的名字“what”一样，可以粗略地告诉你这是什么异常。不过C++标准并没有规定这个字符串的格式，各个编译器的实现也不同，所以 what() 的返回值仅供参考。异常何时回迷失方向如果异常不是在函数中引发（或者函数没有异常规范），则必须捕获它。如果没被捕获（在没有 try 块或没有匹配的 catch 块时，将出现这种情况），则异常被称为未捕获异常。在默认情况下，这将导致程序异常终止。然而，可以修改程序对意外异常和未捕获异常的反应。详细列表如下： 意外异常：异常，如果是在带异常规范的函数中引发的，则必须与规范列表里的某个异常匹配，若没有匹配的，则为意外异常，默认情况下，会导致程序异常终止 未捕获异常：异常如果不是在函数中引发的（或者函数没有异常规范），则它必须被捕获。如果没被捕获（没有try块或没有匹配的的catch块），则为未捕获异常。默认情况下，将导致程序异常终止修改默认设置 未捕获异常：此异常不会导致程序立刻终止（terminate()、set_terminate() 都在 exception 头文件中声明）程序首先调用函数 terminate()—-&gt; 默认情况下，terminate()调用 abort()函数，可以通过 set_terminate() 函数指定 terminate()调用的函数，修改这种行为。若 set_terminate()函数调用多次，则 terminate()函数将调用最后一次 set_terminate()设置的函数例如：set_terminate(MyQuit);void MyQuit(){…}此时若出现未捕获异常，程序将调用 terminate()，而 terminate()将调用 MyQuit() 意外异常发生意外异常时，程序将调用unexcepted()函数—&gt;unexpected()将调用terminate()函数—&gt;terminate()在默认情况下调用abort()函数可以通过set_unexcepted()函数，修改这种默认行为，但unexpected()函数受限更多 1）过terminate()、abort()、exit()终止程序 2）引发异常 引发的异常与原来的异常规范匹配，则可以用预期的异常取代意外异常 引发的异常与原来的异常不匹配，且异常规范中没有包括bad_exception类型（继承自exception类），则程序将调用terminate() 引发的异常与原来的异常不匹配，且原来的异常规范中包含了bad_exception类型，则不匹配的异常将被bad_exception异常所取代 总之，如果要不好所有的异常（不管是预期还是意外异常），则可以这样做： 确保异常头文件的声明可用：#include &lt;exception&gt;using namespace std; 设计一个替代函数，将意外异常转换为 bad_exception 异常，该函数的原型如下：void myUnexception(){ throw std::bad_exception(); // or just throw}仅适用 throw，而不指定异常将导致重新引发原来的异常。然而，如果异常规范中包含了这种类型，则该异常将被 bad_exception 对象所取代。 在程序的开始位置，将意外异常操作指定为调用该函数（原理类似 linux 下的驱动模块入口出口函数）: set_unexcepted(myUnexception); 将 bad_exception 类型包括在异常规范中，并添加如下 catch 块序列：double Argh(double, double) throw(out_of_bounds, bad_exception);...tru { x = Argh(a, b);}catch(out_of_bounds &amp; ex){ ...}catch(bad_exception &amp; ex){ ...}有关异常的注意事项应在设计程序时就加入异常处理功能，而不是以后再添加。这样做有些缺点。例如，使用异常会增加程序代码，降低程序运行速度。异常规范不适用于模板，因为模板函数引发的异常可能随特定的具体化而异。异常和动态分配并非总能协同工作（主要是因为异常捕获后将跳过其后的所有代码，如果 delete 正好在这个位置，将导致指针被释放但所执行的内存却没有被释放，导致内存泄漏，不过可以在异常处理代码中添加该代码，类似的 JAVA 使用 finally 进行处理这种情况）总之，虽然异常处理对于某些项目极为重要，但它也会增加编程的工作量、增大程序、降低程序的速度。另一方面，不进行错误检查的代价可能非常高。不过个人的建议是，有针对性的进行处理，选择最为严重的最开始进行处理。要开发优秀的软件，必须花时间了解库和类中的复杂内容，就像必须花时间学习 C++ 本身一样。通过库文档和源代码了解到的异常和错误处理细节将将使程序和他的软件受益。RTTI（待续）RTTI(Run Time Type Identification)即通过运行时类型识别，程序能够使用基类的指针或引用来检查着这些指针或引用所指的对象的实际派生类型。RTTI的常见的使用场合 异常处理(exceptions handling)、 动态转类型(dynamic casting) 、 模块集成、 对象I/O 。等用到以上场合时在完成“待续”。RTTI机制的产生为什么会出现 RTTI 这一机制，这和 C++ 语言本身有关系。和很多其他语言一样，C++ 是一种静态类型语言。其数据类型是在编译期就确定的，不能在运行时更改。然而由于面向对象程序设计中多态性的要求，C++ 中的指针或引用(Reference)本身的类型，可能与它实际代表(指向或引用)的类型并不一致。有时我们需要将一个多态指针转换为其实际指向对象的类型，就需要知道运行时的类型信息，这就产生了运行时类型识别的要求。和 Java 相比，C++ 要想获得运行时类型信息，只能通过 RTTI 机制，并且 C++ 最终生成的代码是直接与机器相关的。我对 Java 的运行时类型识别不是很熟悉，所以查了一下相关资料：Java 中任何一个类都可以通过反射机制来获取类的基本信息（接口、父类、方法、属性、Annotation 等），而且 Java 中还提供了一个关键字，可以在运行时判断一个类是不是另一个类的子类或者是该类的对象，Java 可以生成字节码文件，再由 JVM（Java虚拟机）加载运行，字节码文件中可以含有类的信息。" }, { "title": "Cpp 类", "url": "/2016/09/cpp-class.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-12 04:44:33 +0800", "snippet": " C++的主要特点是: 抽象和封装，继承和派生，多态性。而这些特性主要是通过类实现的。所以有必要详尽总结一下类的特性。 类总体思想 访问控制 成员函数 构造函数 析构函数 const 成员 静态成员函数 特殊成员函数 实现类成员函数 this 指针 对象数组 重载运算符 ...", "content": " C++的主要特点是: 抽象和封装，继承和派生，多态性。而这些特性主要是通过类实现的。所以有必要详尽总结一下类的特性。 类总体思想 访问控制 成员函数 构造函数 析构函数 const 成员 静态成员函数 特殊成员函数 实现类成员函数 this 指针 对象数组 重载运算符 运算符重载限制 重载运算符的多种方式 友元 创建友元 类型转换 隐式转换 转换函数 创建转换函数 动态内存 深度（显式）复制构造函数 显式赋值函数 在构造函数中使用 new 时的注意事项 定位 new 运算符 类继承 函数库 类继承概述 什么不能被继承 派生类 派生类构造函数 派生类和基类之间的特殊关系 有关使用基类方法的说明 类与类之间的关系 公有继承：is-a 关系 多态公有继承 静态联编和动态联编 关于虚函数和重定义的几点说明 多重继承 （组合或）包含对象成员的类 has-a 关系 私有继承和组合的比较 使用 using 重新定义访问权限 初始化顺序 抽象基类 抽象基类理念 类模板 模板别名（C++11） 模板类和友元函数 友元类 相互友元 共同的友元 嵌套类在编译阶段出现错误优于在运行阶段出现的错误；应该把诸多细节集中起来处理，便于程序的维护。类总体思想采用过程性编程方法时，首先考虑要遵循的步骤，然后考虑如何表示这些数据（并不需要程序一直运行，用户可能希望能够将数据存储在一个文件中，然后从这个文件中读取数据）。而采用 OOP 方法时，首先从用户的角度考虑对象——描述对象所需的数据以及描述用户与数据交互所需的操作。完成对接口的描述后，需要确定如何实现接口和数据存储。面向对象编程强调的是程序如何表示数据，使用 OOP 方法解决编程问题的第一步是根据它与程序之间的接口来描述数据，从而指定如何使用数据。C++ 的目标之一是让使用类对象就像使用标准（内建）类型一样。 说到类型，那如何确定类型？借鉴 C 语言的思想可知有一下两点： 根据数据的外观（在内存中如何存储）来考虑数据类型。 根据要对它执行的操作来定义数据类型。 可见指定基本类型完成了三项工作： 决定数据对象需要的内存数量； 决定如何解释内存中的位（都是二进制，但解读不一样） 决定可使用数据对象执行的操作或方法。 对于内置类型来说，有关操作的信息被内置到编译器中。但在 C++ 中定义用户类型时，必须自己提供这些信息。付出这些劳动来获得根据实际需要定制新数据类型的强大功能和灵活性。为了达到和内部类型一样的使用方法同时兼顾 OOP 思想的限制，必须提出一些新的关键字和新的约定，方能保持 OOP 的同时被编译器识别。类与 C/C++ 内置类型的相似性如下表：   内置类型 类 声明 int n; className name; 定义 int m; int n=1; 默认构造函数（或默认值初始化函数）和重载构造函数 赋值 m = n; 默认赋值函数和重载赋值函数 运算 m += n; 重载运算符 函数 全局作用域 类作用域 访问方式 默认公有成员 默认私有数据成员 信息隐藏 局部变量 类私有数据成员 代码块重用 函数 类（包括成员函数） 重用方式 库函数调用 类库、继承、虚函数、接口、模板等 数据保护方式 作用域和 const 访问控制符，类作用域，友元，继承等 接口 函数参数和返回值 另外加成员函数本身等 内存管理 系统自动释放 析构函数 不同类型处理方式 typedef 和函数重载 类模板，成员函数重载 指针类型 完全匹配 基类可以指向派生类 类型转换 隐性或强制 转换函数或单参数构造函数 函数调用 直接调用 使用对象调用函数 类型指示   this指针自动引入函数 函数声明位置 调用者之前 类内部 函数定义 无需限定符 使用类限定符 封装 头文件声明和函数实现分开 类声明和成员函数定义分开 多态 函数重载 基类和派生类、不同派生类之间行为不同 从上表的确可以看出，类不断地通过封装、重载、多态等更好地向内置类型靠拢。使得类的使用与内置类型尽量的靠近。这给我们的启示是：首先按照思维惯性像使用内置类型一样使用类，然后不同的地方或效率问题再重新学习。从而最大限度地利用已有的技能。后面将从设计思想上讲解，类是如何做到使用习惯和内置类型尽量靠近的。访问控制C++ 有 3 个关键字用于访问控制，它们分别是 private、public、protected。下面列表说明：访问控制符用于修饰类中的名称（变量、常量、方法等）访问控制符对一下几个作用域进行了不同的设定：类本身（类内）、派生类、类对象(类外)、友元。   public protected private 类本身 可访问 可访问 可访问 类对象 可访问 不可 不可 派生类 可访问 可访问 不可 友元 可访问 可访问 可访问 private 数据成员实现了数据隐藏。数据隐藏（将数据放在私有部分中）是一种封装，数据隐藏不仅可以防止直接访问数据，还可让开发者（类的用户）无需了解数据时如何表示的。从使用类的角度看，只需要知道成员函数接收什么样的参数以及返回什么类型的值，原则是将实现细节从接口设计中分离出来。如果以后找到了更好的实现数据表示成员函数细节的方法，可以对这些细节进行修改，而无需修改程序接口，这些修改对于使用者而言是隐藏的，从而使程序维护起来更容易继承方式有三种：public、protected、private访问控制符的访问由窄变宽依次是：private &lt; protected &lt; public继承之后的权限以最窄（严格）的为准，具体见下面说明：父类的友元是不可继承的。因为友元不属于类成员 公有继承： 不改变从父类继承来的访问控制符 保护继承： 从父类继承来的 public 变成 protected，而父类的 private 和 protected 不变 私有继承： 从父类继承来的所有名称都变成 private继承过来之后，这些关键字对类本身、类对象。派生类、友元的作用域请参考前面的说明。最好对类数据成员采用私有访问控制，不要使用保护访问控制；同时通过基类方法使派生类能够访问基类的数据然而，对于成员函数来说，保护访问控制很有用，它让派生类能够访问公众不能使用的内部函数。成员函数public 成员函数是类对类内类外（类对象）和子类访问数据的公开接口，而 protected 是对子类和类内公开接口，而 private 只是类内的接口。私有成员函数的主要价值在于：通过使用函数调用，而不是每次重新输入相同代码。构造函数数据部分的访问状态为私有的，这意味着程序不能直接访问数据成员，只能通过成员函数来访问。因此需要设计合适的成员函数才能成功第将对象初始化。为此，C++ 提供了一个特殊的成员函数—–类构造函数，专门用于构造新对象，将值赋给它们的数据成员。构造函数的原型没有返回值（也不用 void），而且名称和类名相同，其他的和普通成员函数一样。当然构造函数也可以重载。无法使用对象来调用构造函数，因为在构造函数构造出对象之前，对象不存在的。因此构造函数被用来创建对象，而不能透过对象来调用。默认构造函数默认构造函数是在未提供显式初始值时，用来创建对象的构造函数。不过需要注意的是，当且仅当没有定义任何构造函数时，编译器才会提供默认构造函数。如此，为类定义了构造函数后，程序员就必须为它提供默认构造函数，否则不带参数的创建对象会出错。程序员自定义默认构造函数的方式有两种： 给已有的构造函数的所有参数提供默认值。如 stock(const string &amp; co = \"Error\", int n = 0, double pr = 0.0); 通过函数重载定义一个没有参数的构造函数。如 Stock::Stock(){ company = \"no name\"; shares = 0; share_val = 0.0; total_val = 0.0;} 提示：在设计类时，通常应提供对所有类成员做隐式初始化的默认构造函数。 在 C++11 中可以将列表初始化（如结构体初始化）语法用于类，只要提供与某个构造函数的参数列表匹配的内容，并用大括号将它们括起来。析构函数析构函数比构造函数更特殊，其名称是在类名前加上 ~。析构函数没有参数和返回值，也不允许重载。由于在类对象过期时析构函数将自动被调用，因此必须有一个析构函数。如果程序员没有提供析构函数，编译器将隐式地声明一个默认析构函数，并在发现导致对象被删除的代码后，提供默认析构函数的定义。不过，在构造函数中使用了 new，必须要自定义一个析构函数中使用 delete ；奥释放什么时候应调用析构函数呢？这由编译器决定，通常不应在代码中显式地调用析构函数（在定位 new 运算符时有例外）。 自动存储类对象如果创建的是静态存储类对象，则其析构函数将在程序执行结束时自动被调用。 自动存储类对象如果创建的是自动存储对象，则其析构函数将在程序执行代码块时自动被调用。 new 对象如果对象是通过 new 创建的，则它将驻留在栈内存货自由存储区中，当使用 delete 来释放内存时，其析构函数将自动被调用。 临时对象程序可以创建临时对象来完成特定的操作，在这种情况下，程序将在结束对该对象的使用时自动调用其析构函数。提示：如果既可以通过初始化，也可以通过赋值来设置对象的值，则应蚕蛹初始化方式。通常这种方式效率更高（减少临时对象的创建）。const 成员const 用法请参考《Cpp 常用关键字总结》，这里只给出以下原则：要像尽可能将 const 引用和指针用作函数形参一样，只要类方法不修改调用对象，就应将其声明为 const。静态成员函数可以将成员函数声明为静态的（函数声明必须包包含关键字 static）。这样做有两个重要的后果： 不能使用 this 指针不能通过对象调用静态成员函数：实际上，静态成员函数甚至不嫩使用 this 指针。如果静态成员函数是在公有部分声明的。则可以使用类名和作用域解析运算符来调用它。例如：原型如下：static int HowMany(){ return num_strings; }调用它的方式如下：int count = String::HowMany(); 只能使用静态数据成员由于静态成员函数不与特定的对象相关联。因此只能使用静态数据成员。特殊成员函数如果累中没有自定义以下成员函数，则编译器会自动特供如下特殊成员函数： 默认构造函数 默认析构函数 复制构造函数 赋值运算符 地址运算符 何时调用复制构造函数： 新建一个对象并将其初始化为同类现有对象时，复制构造函数都被调用。 每当程序生成对象副本时，编译器都将使用复制构造函数。具体说来，当函数按值传递对象或函数返回对象时，都将使用复制构造函数。 默认复制构造函数的功能默认的复制构造函数组个复制非静态成员（因为静态成员是同类所有对象共享的，不需要每个对象都创建），复制的是成员的值，这种被称为浅复制。当构造函数中使用了 new 时，则需要深度复制，也就是说必须自定义复制构造函数。实现类成员函数成员函数定义与常规函数定义非常相似（除内联函数在类外定义需要额外加 inline 关键字外，其他的非常规函数关键字都不能再在定义时重复），它们有函数头和函数体，也可以有返回类型和参数。但是它们还有两个特殊的特征： 定义成员函数时，使用作用域解析运算符（::）来标识函数所属的类； 类方法可以访问类的 private 组件。this 指针this 指针指向用来调用成员函数的对象（this 被作为隐藏参数传递给方法）。一般来说，所有类方法都将 this 指针设置为调用它的对象的地址。注意每个成员函数（包括构造函数和析构函数）都有一个 this 指针。this 指针指向调用对象。如果方法需要引用整个调用对象，则可以使用表达式 *this。在函数括号后使用 const 限定符将 this 限定为 const，这样讲不能使用 this 来修改对象的值。然而，要返回的并不是 this，因为 this 是对象的地址，而是对象本身，即 this（将解除引用运算符 用于指针，将得到指针指向的值）。对象数组对象数组的声明定义和普通数组是一样的，只不过初始化的时候可以使用显式构造函数或列表初始化。初始化对象数组的方案是：首先使用默认构造函数创建数组元素，然后花括号中的构造函数将创建临时对象，然后将临时对象的内容复制到相应的元素中。注意：要创建类对象数组，则这个类必须有默认构造函数。重载运算符要重载运算符，需使用被称为运算符函数的特殊函数形式。其格式如下：返回值 operator运算符(argument-list)，如Time operator+(const Time &amp; t) const运算符重载限制多数 C++ 运算符都可以重载。重载运算符（有些例外情况）不必是成员函数，但至少有一个操作数是用户定义的类型。下面详细介绍 C++对用户自定义的运算符重载的限制： 操作数限制重载后的运算符必须至少一个操作数是用户定义类型，这将防止用户为标准类型重载运算符。 句法规则限制使用运算符时不能违反运算符原来的句法规则，如两目运算符不能重载为一目运算符。 运算符优先级限制运算符重载不改变运算符本身的优先级 不能创建新运算符 不能重载下面的运算符 sizeof . 成员运算符 .* 成员指针运算符 :: 作用域解析运算符 ?: 条件运算符 typeid 一个 RTTI 运算符 const_cast 强制类型转换运算符 dynamic_cast reinterpret_cast static_cast 下面的运算符只能通过成员函数进行重载 = 赋值运算符 () 函数调用运算符 [] 下标运算符 -&gt; 通过指针访问类成员的运算符 可重载的运算符见下图：重载运算符的多种方式Time operator+(const Time U t) const 和friend Time operator+(const Time &amp; ta, const Time &amp; t2);这两种格式是等效的，所以只能选择其中的一种格式，否则被视为二义性。 对于成员函数版本：一个操作数通过 this 指针隐式地传递，另一个操作数作为函数参数显式地传递 对于友元版本来说：两个操作数都作为参数传递。友元C++ 控制对类对象私有部分的访问，通常，公有成员函数是提供的唯一访问途径。但友元提供了另外一种访问途径。友元有 3 种： 友元函数 友元类 友元成员函数通过让函数成为类的友元，可以赋予该函数与类的成员函数相同的访问权限。前面提到了重载运算符，那是其中的一种方式，该方式只能使用如 A = B * 2.75 形式的调用方式，如果使用如 A = 2.75 * B的方式是错误的，因为 2.75 不是对象，不能调用成员方法。如何解决这个问题，友元函数提供了解决问题的方法。大多数运算符都可以通过成员或非成员（友元）函数来重载。非成员函数不是由对象调用的，它使用的所有值（包括对象）都是显式参数。要想使用非成员函数访问类的私有成员，应该将其声明为友元函数。创建友元创建友元的第一步是将其原型放在类声明中，并在原型声明前加上关键字 friend，如friend Time operator*(double m, const Time &amp; t);该原型意味着以下两点： 虽然 operator*()函数是在类声明中声明的，但它不是成员函数，因此不能使用成员运算符来调用。 虽然 operator*()函数不是成员函数，但它与成员函数的访问权限相同。第二步是编写函数定义。因为它不是成员函数，所以不要使用 Time:: 限定符。另外，不要在定义中使用关键字 friend（因为 friend 是相对于类而言，既然在声明中已经使用，而且在定义时不能使用类限定符，这连个特征完全可以区别于成员函数和普通函数，所以基于简洁的宗旨，是不能再用 friend 的）。友元是否有悖于 OOP友元函数应看作类的扩展接口的组成部分。而且，只有类声明可以决定哪一个函数时友元，因此类声明仍然控制了哪些函数可以访问私有函数。总之，类方法和友元只是表达类接口的两种不同机制。提示：如果要为类重载运算符，并将非类的项作为其第一个操作数，则可以用友元函数来反转操作数的顺序。类型转换可以将类定义成与基本类型或另一个类（典型的是基类和派生类）相关，使得从一种类型转换为另一种类型是有意义的。在这种情况下，程序员可以指示 C++ 如何自动进行转换，或通过强制类型转换来完成。隐式转换如果定义了一个参数的构造函数，当定义对象或赋值时，只要参数匹配，就可以进行隐式转换。如Stonewt mycat; //create a Stonewt objectmycat = 19.6; //use Stonewt(double) to convert 19.6 to Stonewt程序将使用构造函数 Stonewt(double) 来创建一个临时的 Stonewt 对象，并将 19.6 作为初始化值，随后，采用逐成员赋值的方式将临时对象的内容复制到 myCat 中。这就是隐式转换，因为它是自动进行的，而不需要显式强制类型转换。只有接受一个参数的构造函数才能作为转换函数如何关闭这种自动隐式转换的特性？C++ 新增了关键字 explicit 用于关闭这种自动转换特性可以这样声明构造函数：explicit Stonewt(double lbs); // no implicit conversions allowed不过个人建议，最好使用关键字 explicit 进行限定单个参数的构造函数，以免发生以下隐式转换： 将 Stonewt 对象初始化为 double 值时 将 double 值赋给 Stonewt 对象时 将 double 值传递给接受 Stonewt 参数的函数时 返回值被声明为 Stonewt 的函数视图返回 double 值时 在上述任一一种情况下，使用可转换为 double 类型的内置类型时（当且仅当转换不存在二义性时，才会进行这种二步转换）转换函数前面的隐式转换已经提到，构造函数只用于从某种类型到类类型的转换（因为构造函数就是为了创建类对象的）。要进行相反的转换，必须使用特殊的 C++ 运算符函数——转换函数转换函数是用户定义的强制类型转换，可以像使用强制类型转换那样使用它们。创建转换函数要转换为 typeName 类型，需要使用这种形式的转换函数：operator typeName();例如，operator double();请注意以下几点（事实上，typeName 已经制定了返回类型的信息）： 转换函数必须是类方法（隐式传递 this 指针为参数） 转换函数不能指定返回类型 转换函数不能有参数（通过 this 已经传入，没必要） 注意事项： 当类只定义了一种转换时，编译器会自动应用类型转换 当类定义了两种或更多的转换时，仍可以用显式强制类型转换来指出要使用哪个转换函数（语法和 C 语言的强制类型转换一样的），但编译器不会自动应用类型转换动态内存有些情况下，内存需要多少是很难事先确定的，只能按照最大需求申请，这样必然造成大量的浪费，所以最好是能在运行时根据需要进行申请。C++ 使用 new 和 delete 运算符来动态控制内存。遗憾的是，在类中使用这些运算符将导致许多新的编程问题。在这种情况下，析构函数是必不可少的。当对象过期时，构造函数中的指针也将过期，该指针会被自动释放，但其指向的内存仍被分配，除非使用 delete 将其释放。删除对象可以释放对象本身占用的内存，但并不能自动释放属于对象成员的指针指向的内存。因此，必须使用析构函数，在析构函数中使用 delete 语句可确保对象过期时，由构造函数使用 new 分配的内存被释放。 注意事项：在构造函数中使用 new 来分配内存时，必须在相应的析构函数中使用 delete 来释放内存。如果使用 new[]（包括中括号）来分配内存，则应使用 delete[]（包括中括号）来释放内存。深度（显式）复制构造函数当构造函数使用了 new，则默认的复制构造函数的浅复制只复制了指针变量的地址，而没有复制该指针指向的内存中的值，而该对象并不能访问其他对象中的值（或者已经被释放），如此必然造成访问错误。解决这一问题办法是，提供一个显式的复制构造函数，该构造函数的参数为本类形式对象。警告：如果类中包含了使用 new 初始化的指针成员，应当定义一个复制构造函数，以复制指向的数据，而不是指针，这被称为深度复制。复制的另一种形式（默认复制构造函数提供的成员复制或浅复制）只是复制指针值。浅复制仅浅浅地复制指针信息，而不会深入“挖掘”以复制指针引用的结构。具体见下面的例子：StringBad::StringBad(const StringBad &amp; st){ num_strings++; len = st.len; str = new char [len + 1]; std::strcpy(str,st.str);}显式赋值函数与默认复制构造函数相似，赋值运算符的隐式实现（默认赋值函数）也只是对成员进行组个复制，如果成员本身就是类对象，则程序将使用为这个类定义的赋值运算符来复制该成员，但静态数据成员不受影响。当构造函数中使用了 new，则默认的赋值函数将出现问题（原因见前面的复制构造函数），解决办法是提供显式的赋值运算符（进行深度复制）定义。其实现与复制构造函数相似，但也有一些区别： 由于目标对象可能引用了以前分配的数据，所以函数应使用 delete[] 来释放这些数据 函数应当避免对象赋给自身；否则，给对象重新赋值前，释放内存操作可能删除对象的内容。 函数返回一个指向调用对象的引用通过返回一个对象，函数可以像常规赋值操作那样，连续进行赋值。例如：StringBad &amp; StringBad::operator=(const StringBad &amp; st){ if (this == &amp;st) return *this; delete [] str; len = st.len; str = new char [len + 1]; std::strcpy(str,st.str); return *this;}在构造函数中使用 new 时的注意事项根据前面的描述，已经知道了使用 new 初始化对象的指针成员时必须特别小心。具体说来，应当这样做： 如果在构造函数中使用 new 来初始化指针成员，则应在析构函数使用 delete new 和 delete 必须相互兼容，new 对应于 delete，new[] 对应于 delete[] 如果有多个构造函数，则必须以相同的方式使用 new，要么都带中括号，要么都不带。因为只有一个析构函数，所有的构造函数都必须与它兼容。然而，可以在一个构造函数中使用 new 初始化指针，而在另一个构造函数中将指针初始化为空（0 或 C++11 中的 nullptr），这是因为 delete （无论是带中括号还是不带中括号的）可以用于空指针。 应定义一个复制构造函数，通过深度复制将一个对象初始化为另一个对象。具体说来，复制构造函数应分配足够空间来存储复制的数据，并复制数据，而不仅仅是数据的地址。另外，还应该更新所有受影响的静态类成员。 应当定义一个赋值运算符，通过深度复制将一个对象复制给另一个对象。具体说来，该方法应完成这些操作：检查自我赋值的情况，释放成员指针以前指向的内存，复制数据而不仅仅是数据的地址，并返回一个指向调用对象的引用。定位 new 运算符new 负责在堆中找到一个足以能够满足要求的内存块。new 运算符还有另一种变体，被称为定位 new 运算符，它让你能够指定要使用的位置（可以看做是已经分配的内存空间的二次分配），程序员可能使用这种特性来设置其内存管理规程、处理需要通过特定地址进行访问的硬件或在特定位置创建对象。定位 new 运算符的另一种用法是：将其与初始化结合使用，从而将信息放在特定的硬件地址处。基本上，它只是返回传递给它的地址，并将其强制转换为 void *，以便能够赋给任何指针类型。定位 new 运算符的例子：#include &lt;new&gt;//使用 定位 new 运算符必须包含该头文件char buffer1[50];char buffer2[500];struct chaff{ char dross[20]; int slag;};chaff *p1, *p2;int *p3, *p4;p1=new chaff; //place structure in heapp3=new int[20]; //place int array in heapp2=new (buffer1) chaff; //place structure in buffer1p4=new (buffer2) int[20]; //place int array in buffer2使用定位 new 运算符注意事项 用定位 new 运算符分配的内存不能使用 delete 释放。事实上， 必须全部先显式调用析构函数（内建类型除外），最后释放一次分配（可能通过 new 分配，也可能自动分配）的内存就好（定位 new 运算符属于二次分配）。 程序员要把一块大的已分配的内存空间使用定位 new 运算符化成多个小块时，必须使用其中的不同的内存单元，需要提供位于缓冲区的不同地址，并确保这些小块没有重叠的区域，否则会相互覆盖。 注意事项，具体见下面的例子#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;new&gt;using namespace std;const int BUF = 512;class JustTesting{ private: string words; int number; public: JustTesting(const string &amp; s = \"Just Testing\",int n = 0) { words = s; number = n; cout &lt;&lt; words &lt;&lt; \" constructed\\n\"; } ~JustTesting() { cout &lt;&lt; words &lt;&lt; \" destroyed\\n\"; } void Show() const { cout &lt;&lt; words &lt;&lt; \", \" &lt;&lt; number &lt;&lt; endl; }};int main(){ char * buffer = new char[BUF]; // get a block of memory JustTesting *pc1,*pc2; pc1 = new (buffer) JustTesting; // place object in buffer pc2 = new (buffer) JustTesting(\"Heap1\",20) // place object on heap cout &lt;&lt; \"Memory block addresses:\\n\" &lt;&lt; \"buffer: \" &lt;&lt; (void *) buffer &lt;&lt; \" heap: \" &lt;&lt; pc2 &lt;&lt; endl; cout &lt;&lt; \"Memory contents:\\n\"; cout &lt;&lt; pc1 &lt;&lt; \": \"; pc1-&gt;Show(); cout &lt;&lt; pc2 &lt;&lt; \": \"; pc2-&gt;Show(); JustTesting *pc3,*pc4; // fix placement new location pc3 = new (buffer + sizeof(JustTesting)) JustTesting(\"Better idea\",6); pc4 = new JustTesting(\"Heap2\",10); cout &lt;&lt; \"Memory contents:\\n\"; cout &lt;&lt; pc3 &lt;&lt; \": \"; pc3-&gt;Show(); cout &lt;&lt; pc4 &lt;&lt; \": \"; pc4-&gt;Show(); delete pc2; // free Heap1 delete pc4; // free Heap2 // explicitly destroy placement new object pc3 -&gt; ~JustTesting(); // destroy object pointed to by pc3 pc4 -&gt; ~JustTesting(); // destroy object pointed to by pc4 delete [] buffer; // free buffer cout &lt;&lt; \"Done\\n\"; return 0;}类继承面向对象编程的主要目的之一是提供可重用的代码。重用经过测试的代码比重新编写代码要好得多。使用已有的代码可以节省时间，由于已有的代码被使用和测试过，一次有助于避免在程序中引入错误。另外，必须考虑的细节越少，使越能专注于程序的整体策略。友元不是成员函数，不能使用作用域解析运算符来调用，也不能继承。派生类使用基类友元的方法是：使用强制类型转换成基类，以便匹配原型时能够选择正确的函数函数库传统的 C 函数库通过预定义、预编译的函数提供了可重用性。然而，函数库也有局限性，除非产商提供了库函数的源代码（通常是不提供的），否则将无法根据自己特定的需求，对函数进行扩展或修改，而必须根据库函数的情况修改自己的程序，即使厂商提供了源代码，在修改时也有一定的风险，如不经意地修改了函数的工作方式或改变了库函数之间的关系。类继承概述C++ 类提供了更高层的重用性，目前，很多厂商提供了类库，类库由类声明和实现构成，因为类组合了数据表示和类方法，因此提供了比函数库更加完整的程序包。比修改源代码更好的方法来扩展和修改类的方法有类继承。它能够从已有的类派生出新的类，而派生类继承了原有类（称为基类）的特征，包括方法，但不影响对原来的类的使用。下面是可以通过继承完成的一些工作： 可以在已有类的基础上添加功能（新方法） 可以给类添加数据（新数据成员） 可以修改类方法的行为（函数重定义）当然，可以通过赋值原始类代码，并对其进行修改完成上述工作。但继承机制只需提供新特性，甚至不需要范文源代码就可以派生出类（只需要添加类声明或修改原头文件）。因此，如果购买的类库只提供了类方法的头文件和编译后代码，仍可以使用库中的类派生出新的类。而且可以在不公开实现的情况下将自己的类分发给其他人，同时允许其他人在类中添加新特性。什么不能被继承基类的构造函数，析构函数，赋值运算符。派生类派生出的类将具有以下特征： 派生类对象存储了基类的数据成员（派生类继承了基类的实现）； 派生类对象可以使用基类的方法（派生类继承了基类的接口）。需要在继承特性中添加： 派生类需要自己的构造函数 派生类可以根据需要添加额外的数据成员和成员函数 构造函数必须给新成员（如果有）和继承的成员提供数据。派生类构造函数派生类不能直接访问基类的私有成员，而必须通过基类方法进行访问。因此，派生类构造函数必须使用基类构造函数。创建派生类对象时，程序首先创建基类对象。从概念上说，这意味着基类对象应当在程序进入派生类构造函数之前被创建。C++ 使用成员初始化列表语法来完成这种工作，派生类构造函数例子：// 新旧数据成员应都在派生类的构造函数列表中，并且旧数据成员用基类构造函数来初始化RatedPlayer::RatedPlayer( unsigned int r, const string &amp; fn, const string &amp; ln, bool ht) : TableTennisPlayer(fn, ln, ht){ rating = r; // 对新的数据成员初始化}必须首先创建基类对象，如果不调用基类构造函数，程序将使用默认的基类构造函数，如下：RatedPlayer::RatedPlayer( unsigned int r, const string &amp; fn, const string &amp; ln, bool ht) //: TableTennisPlayer(){ rating = r; // 对新的数据成员初始化}有关派生类构造函数的要点如下： 首先创建基类对象（建初始化列表） 派生类构造函数应通过成员初始化列表将基类信息传递给基类构造函数。 派生类构造函数应初始化派生类新增的数据成员 释放对象的顺序与创建对象的顺序相反，即首先执行派生类的析构函数，然后自动调用基类的析构函数（类似栈）。派生类和基类之间的特殊关系派生类与基类支架有一些特殊关系，列举如下： 派生类对象可以使用基类的非私有方法 基类指针可以在不进行显式类型转换的情况下指向派生类对象。 基类引用可以在不进行显式类型转换的情况下引用派生类对象 但是，基类指针或引用只能用于调用基类方法以上第2，3中基类和派生类的位置反过来是不成立的，因为这意味着派生类（指针或）引用能够为基对象调用派生类方法，这样讲出现问题。毕竟，基类对象中不存在某些派生类独有的方法。为什么编译器不根据对象来调用方法呢？编译器是根据指针和引用类型来调用方法而不是根据指针或引用所指向的对象类型有关使用基类方法的说明以公有方式派生的类对象可以通过多种方式来使用基类的方法。 派生类对象自动使用继承而来的非私有基类方法（如果派生类没有重定义该方法） 派生类的构造函数自动调用基类的构造函数（但需要初始化列表） 派生类的构造函数自动调用基类的默认构造函数，如果初始化列表中没有指定基类构造函数 派生类构造函数显式地调用成员初始化列表指定的基类构造函数 派生类方法可以使用作用域解析运算符来调用公有的和受保护的基类方法 派生类的友元函数可以通过强制类型转换，将派生类引用或指针转换为基类引用或指针，然后使用该引用或指针来调用基类的友元函数。类与类之间的关系类与类之间的关系有：包含（组合或层次化），公有继承、私有或保护继承，多重继承。公有继承：is-a 关系C++ 有 3 种继承方式：公有继承、保护继承和私有继承。公有继承建立了一种 is-a 关系即派生类对象也是一个特殊的基类对象，可以对基类对象执行的任何操作，也可以对派生类对象执行。如，香蕉是一种水果，香蕉可以从、水果类中派生出来。为阐明 is-a 关系，下面列举一些与该模型不符的例子 公有继承不建立 has-a 关系。如，午餐有水果 公有继承不能建立 is-like-a 关系（它不采用明喻）。如，帝国主义是纸老虎 公有继承不建立 is-implemented-as-a（用……来实现） 关系。如，栈可以用数组来实现，但栈不是数组。从 Array 类派生出 Stack 类是不合适的。正确的方法是，通过让栈包含一个私有 Array 对象成员来隐藏数组实现 公有继承不建立 use-a 关系。如，计算机可以使用打印机。但从 computer 类派生出 Printer 类（或反过来）是没有意义的。然而，可以使用友元函数或类来处理Printer 和 Computer 对象之间的通信。继承和动态内存分配的关系和注意事项请参考 new多态公有继承这里的多态是指同一个方法在派生类和基类中的行为是不同的，也就是说，方法的行为应取决于调用该方法的对象，即同一个方法的行为随上下文而异。有两种重要的机制可用于实现多态公有继承： 在派生类中重新定义基类的方法 基类使用虚方法如果没有使用 virtual 关键字 ，程序将根据引用类型或指针类型选择方法；如果使用了 virtual，程序将根据引用或指针指向的对象的类型来选择方法。当然也可以使用类解析运算符明确指出调用的是哪个方法。因此，经常在基类中将派生类会重新定义的方法声明为虚方法。方法在基类中声明为虚的后，它在派生类中将自动成为虚方法。然而，在派生类中使用关键字 virtual 来再次指出哪些函数是虚函数也不失为一个号方法。最好为基类声明虚析构函数。以确保释放派生类对象时，按正确的顺序调用析构函数 在派生类中，标准技术是使用作用域解析运算符来调用基类方法为何需要虚析构函数？这是由编译器根据指针或引用类型（而不是指向的对象类型）来调用方法的规则造成的，如果不适用虚析构函数，则将只调用对应于指针类型的析构函数而不调用基类的析构函数。基类指针或引用可以指向任意派生出的类对象（即使多层次派生），称之为“隐式向上强制转换”但是，反过来（向下强制转换）是不允许的隐式向上强制转换使基类指针或引用可以指向基类对象或派生类，因此需要动态联编。C++ 使用虚成员函数来满足这种需求。静态联编和动态联编编译器对非虚函数使用静态联编，对虚函数使用动态联编。使用非虚函数有两方面的好处： 效率更高 指出不要重新定义该函数（虽然不能组织这样做） 虚函数的工作原理通常，编译器处理虚函数的方法是：给每个对象添加一个隐藏成员来保存一个指向函数地址数组的指针。这种数组称为虚函数表。虚函数表中存储了为类对象进行声明的虚函数的地址。但需要注意的是：无论类中包含的虚函数是一个还是多个，都只需要在对象中添加一个地址成员，只是表的大小不同而已使用虚函数的成本如下： 每个对象都将增大，增大量为存储地址的空间 对于每个类，编译器都创建一个虚函数地址表（数组） 对于每个函数调用，都需要执行一项额外的操作，即到表中查找特定虚函数地址关于虚函数和重定义的几点说明 派生类不继承基类的构造函数，所有将类构造函数声明为虚的没什么意义 析构函数应当为虚函数，除非类不用做基类（也可声明为虚函数，只是效率问题）即使基类不需要显式析构函数提供服务，也不应依赖默认析构函数，而应提供虚析构函数，即使他不执行任何操作。 友元不能是虚函数友元不是类成员，不能是虚函数。如果由于这个原因引起了设计问题，可以通过让友元函数使用虚成员函数来解决。 重新定义将隐藏方法重新定义继承的方法并不是重载。如果在派生类中重新定义函数，将不是使用相同的函数特征标覆盖基类声明，而是隐藏所有同名的基类方法，不管参数特征标如何。如果重新定义继承的方法，应确保与原来的原型完全相同，但如果赶回类型是基类引用或指针，则可以修改为指向派生类的引用或指针（被称为返回类型协变）如果基类方法声明被重载了，则应在派生类中重新定义所有的基类版本。否则，同名的其他基类方法将被隐藏而不能被派生类使用多重继承多重继承（MI）描述的是，有多个直接基类的类，与单继承一样，公有MI（必须使用关键字 public 来限定每一个基类，类似指针） 表示的也是 is-a 关系。MI 可能会带来很多新问题，主要有两方面： 从两个不同的基类继承同名方法这个问题实际上导致函数调用的二义性。可以使用类作用域解析运算符来明确指出使用的方法 从两个或更多相关基类那里继承同一个类的多个实例这个问题的实质是，基类指针或引用指向派生对象使用基类方法时将出现二义性（公有继承可以这样隐式这样转换）。因为这样的继承将出现多个同样的基类副本。第一种解决方法：虚基类虚基类使得从多个类（它们的基类相同）派生出的对象只继承一个基类对象。可以通过在类声明中使用关键字 virtual(类似关键字重载) 。例如，class Singer : virtual public Worker {...};class Waiter : public virtual Worker {...};然后class SingingWaiter : public Singer, public Waiter {...};对于使用虚基类，派生类即使不使用类作用域解析运算符，也不会导致二义性，因为这种情况下，编译器采用就近原则（派生类中的名称优先于直接或间接祖先类中的相同名称，类似“局部变量”规则）。但是，如果没有派生关系，将出现二义性，而且这种二义性与访问控制规则无关（一个私有，一个公有也算二义性）。非虚基类多重继承产生多个基类副本的原因是：构造函数的自动调用，而构造函数的调用将创建对象实体。从而，多个副本产生了。但是虚基类阻断了这种自动调用机制。接着，必须以不同的方式写一些代码。另外，使用虚基类还可能需要修改已有的代码。 构造函数C++ 在基类是虚的时，精致信息通过中间类自动传递给基类。所以所有的类都要在初始化列表中初始化，否则将启用默认构造函数。例如： SingingWaiter (const Worker &amp; wk, int p = 0, int v = Singer::other) : Waiter(wk, p), Singer(wk, v) {} 虚基类总结:在祖先相同时，使用 MI 必须引入虚基类，并修改构造函数初始化列表的规则。另外，如果在编写这些类时没有考虑到 MI ，则还可能需要重新编写它们。原因见前面的分析。将所有的数据组件（最好是方法）都设置为保护的，而不是私有的例子如下：workermi.h 头文件#indef WORKERMI_H#define WORKERMI_H#include &lt;string&gt;class Worker{ private: std::string fullname; long id; protected: virtual void Data() const; virtual void Get(); public: Worker() : fullname(\"no one\"), id(01) {} Worker(const std::string &amp; s, long n) : fullname(s), id(n) {} virtual Worker() = 0; virtual void Set() = 0; virtual void Show() = 0;};class Waiter : virtual public Worker{ private: int panache; protected: void Data() const; void Get(); public: Waiter() : Worker(), panache(0) {} Waiter(const Worker &amp; wk, int p = 0) : Worker(wk), panache(p) {} void Set(); void Show() const;};class Singer : virtual public Worker{ protected: enum {other, alto, contralto, soprano, bass, baritone, tenor}; enum {Vtypers = 7}; void Data() const; void Get(); private: static char *pv(Vtypers); int voice; public: Singer() : Worker(), voice(other) {} Singer(const StringBad::String &amp; s, long n, int v = other) : Worker(wk), voice(v) {} void Set(); void Show() const;};class SingingWaiter : public Singer, public Waiter{ protected: void Data() const; void Get(); public: SingingWaiter() {} SingingWaiter(const std::string &amp; s, long n, int p = 0, int v = other) : Worker(s,n), Waiter(s,n,p), Singer(s,n,v) {} SingingWaiter(const Worker &amp; wk, int p = 0,int v = other) : Worker(wk), Waiter(wk,p),Singer(wk,v) {} SingingWaiter(const Waiter &amp; wt, int v = other) : Worker(wt),Waiter(wt),Singer(wt,v) {} SingingWaiter(const Singer &amp; wt,int p = 0) : Worker(wt),Waiter(wt,p),Singer(wt) {} void Get(); void Show() const;};#endifworkermi.cpp 文件#include \"workermi.h\"#include &lt;iostream&gt;using std::cout;using std::cin;using std::endl;Worker::Worker() {}void Worker::Data() const{ cout &lt;&lt; \"Name: \" &lt;&lt; fullname &lt;&lt; endl; cout &lt;&lt; \"Employee ID: \" &lt;&lt; id &lt;&lt; endl;}void Worker::Get(){ getline(cin,fullname); cout &lt;&lt; \"Enter worker's ID: \"; cin &gt;&gt; id; while (cin.get() != '\\0') continue;}void Waiter::Set(){ cout &lt;&lt; \"Enter Waiter's name: \"; Worker::Get(); Get();}void Waiter::Show() const{ cout &lt;&lt; \"Category: Waiter\\n\"; Worker::Data(); Data();}void Waiter::Data() const{ cout &lt;&lt; \"Panache rating: \" &lt;&lt; panache &lt;&lt; endl;}void Waiter::Get(){ cout &lt;&lt; \"Enter Waiter's panache rating: \"; cin &gt;&gt; panache; while (cin.get()! != '\\n') continue;}char * Singer::pv(Singer::Vtypes) = {\"other\",\"alto\",\"contralto\", \"soprano\",\"bass\",\"baritone\",\"tenor\"};void Singer::Set(){ cout &lt;&lt; \"Enter Singer's name: \"; Worker::Get(); Get();}void Singer::Show() const{ cout &lt;&lt; \"Category: Singer\\n\"; Worker::Data(); Data();}void Singer::Data() const{ cout &lt;&lt; \"Vocal range: \" &lt;&lt; pv(voice) &lt;&lt; endl;}void Singer::Get(){ cout &lt;&lt; \"Enter number for Singer's vocal range::\\n\"; int i; for(i = 0; i&lt; Vtypers; i++) { cout &lt;&lt; i &lt;&lt; \": \" &lt;&lt; pv[i] &lt;&lt; \" \"; if ( i % 4 == 3 ) cout &lt;&lt; endl; } if ( i % 4 != 0 ) cout &lt;&lt; '\\n'; cin &gt;&gt; voice; while (cin.get( != '\\n' ) continue;}void SingingWaiter::Data() const{ Singer::Data(); Waiter::Data();}void SingingWaiter::Get(){ Waiter::Get(); Singer::Get();}void SingingWaiter::Set(){ cout &lt;&lt; \"Enter singing Waiter's name: \"; Worker::Get(); Get();}void SingingWaiter::Show() const{ cout &lt;&lt; \"Category: singing waiter\\n \"; Worker::Data(); Data();}workmi.cpp 文件#include &lt;iostream&gt;#include &lt;cstring&gt;#include \"workermi.h\"const int SIZE = 5;int main(){ using std::cin; using std::cout; using std::endl; using std::strchr; Worker * lolas[SIZE]; int ct; for (ct = 0;ct &lt; SIZE; ct++) { char choice; cout &lt;&lt; \"Enter the Employee Category:\\n\" &lt;&lt; \"w: Waiter s: Singer \" &lt;&lt; \"t: Singing Waiter q: quit\\n\"; cin &gt;&gt; choice; while (strchr(\"wstq\",choice) == NULL) { cout &lt;&lt; \"Please enter a w,s,t, or q:\"; cin &gt;&gt; choice; } if (choice == 'q') break; switch(choice) { case 'w': lolas[ct] = new Waiter; break; case 's': lolas[ct] = new Singer; break; case 't': lolas[ct] = new SingingWaiter; break; } cin.get(); lolas(ct)-&gt;Set(); } cout &lt;&lt; \"\\nHere is your staff:\\n\"; int i; for (i = 0; i &lt; ct; i++) { cout &lt;&lt; endl; lolas[i]-&gt;Show(); } for (i = 0; i &lt; ct; i++) delete lolas[i]; cout &lt;&lt; \"Bye.\\n\"; return 0;}（组合或）包含对象成员的类实际上，C++ 把类“视为”普通数据类型，所以箱普通类型一样使用类就可以了。接口和实现使用公有继承时，类可以继承接口，可能还有实现（基类的纯虚函数提供接口，但不提供实现）。获得接口是 is-a 关系的组成部分。而使用组合，类可以获得实现，但不能获得接口，不继承接口是 has-a 关系的组成部分包含主要解决的是 has-a 关系。对于 has-a 关系来说，类对象不能自动获得被包含对象的接口是一件好事： 可以使用包含类已经实现了的公有方法 不需要继承不需要的方法，也不需要了解不需要的部分 不需要像默写继承必须要实现的接口 不过被包含的类没有实现的接口可能对新类有意义，此时可考虑继承has-a 关系前面提到了实现 has-a 关系的一种方法组合。C++ 还有另一种 has-a 关系的途径—–私有继承。使用私有继承，基类的公有成员和保护成员都将成为派生类的私有成员。这意味着基类方法将不会成为派生类对象公有接口的一部分，但可以在派生类的成员函数中使用它们。私有继承可以可以在自己的接口中使用基类的非私有接口，但自己的类对象不能使用基类的接口，从而达到了能使用并隐藏了基类方法，因而可以只提供想提供的自己的方法（隐藏了基类细节）私有继承和组合的比较 使用私有继承，类将继承实现，但只能在类内使用 私有继承提供的特性和包含相同：或得实现，但不获得接口 实现 has-a 关系的方法不同：包含将对象作为一个命名的成员对象添加到类中，而私有继承对象作为一个未被命名的继承对象添加到类中。 使用原类方法的方式不同使用包含时将使用对象名来调用方法，而使用私有继承时将使用类名和作用域解析运算符来调用方法。如果私有继承要使用基类对象本身？如下：可以使用强制类型转换，使用 *this，为避免调用构造函数创建新的对象，可使用强制类型转换来创建一个引用。例子如下：const string &amp; Student::Name() const{ return (const string &amp;) *this;}在私有继承（有别于公有继承）中，在不进行显式类型转换的情况下，不能将指向派生类的引用或指针赋给基类引用或指针。 包含简单易懂，继承将会引发很多新问题需要处理（比如复制构造函数） 私有继承可以使用基类的保护部分，而包含不能 需要使用使用继承的情况是需要重新定义虚函数。派生类可以重新定义虚函数，但包含类不能。 综上得出结论：通常，应使用包含来建立 has-a 关系；如果新类需要访问原有类的保护成员，或需要重新定义类函数，则应使用私有继承。使用 using 重新定义访问权限之前已经知道了类的访问控制以及继承的访问控制规则。当有时需要暂时破例（之后恢复之前的规则）。假设要让基类的方法在派生类（不论如何派生）外可用，有一下方法可用破除访问限制： 定义一个使用该基类方法的派生类方法（公开方法使用类解析运算符调用非私有方法） 将函数调用包装在另一个函数调用中，即，使用一个 using 声明（就像名称空间那样）来指出派生类可以使用特定的基类成员，即使采用的是私有派生。 注意：using 声明只使用成员名——没有圆括号、函数特征标和返回类型。初始化顺序当初始化列表（构造函数头）包含多个项目时，这些项目被初始化的顺序为它们被声明的顺序，而不是它们在初始化列表中的顺序。抽象基类当两个类有很多共同点，但又不好使用单纯的继承，则可以将这些共同点放在一个虚基类中，然后分别继承这个抽象基类。当类声明中包含纯虚函数（纯虚函数声明的结尾处为=0）时，则不能创建该类的对象。包含纯虚函数的类只能用作基类（被称为抽象基类）。总之，在原型中使用 =0 指出类是一个抽象基类，在类中可以不定义该函数。抽象基类描述的是至少使用一个纯虚函数的接口，从抽象基类派生出的类将根据派生类的具体特征，使用常规虚函数来实现这种接口（不再用 =0 ，但原型一致并且一定要定义）。抽象基类理念可以将抽象基类看做是一种必须实施的接口，抽象基类具体派生类覆盖其纯虚函数—–迫使派生类遵循抽象基类设置的接口规则。如此，使用抽象基类使得组件设计人员能够制定“接口约定”，这样确保了从抽象基类派生的所有组件都至少支持抽象基类制定的功能。类模板可以通过 typedef 处理不同类型相同的需求。然而，这种方法有两个缺点： 每次修改类型时都需要编辑头文件 在每个程序中只能使用这种技术生成一种类型，即不能让 typedef 同时代表两种不同的类型。C++ 的类模板为生成通用的类声明提供了一种更好的方法。模板提供参数化类型，即能够将类型名最为参数传递给接收方来建立类或函数（类是创建对象的模板，而类模板是声明类的模板）。 类模板声明格式template &lt;class Type1, ...&gt;（不推荐）或template &lt;typename Type1, ...&gt;吧上面的声明放在类（普通类声明）之前，然后再类中使用其中的 Type 进行变量声明即可（相当于把其当做和 int 一般的已知类型）。实例如下：注意：用到 Type 的地方必须带上 template&lt;typename Type&gt;放在函数头或是类头因为它们是一个整体，而且不同的模板，其typeName 后的 Type 可以相同。所以必须以一个整体出现才能表明其为特定模板。template &lt;typename Type&gt;bool Stack&lt;Type&gt;::push(const Type &amp; item){ ....}模板必须实例化或具体化（即用真实的类型替代 Type）,而且必须实例化和模板放在一起，由于模板不是函数，它们不能单独编译。仅仅在程序中包含模板并不能生成模板类，而必须请求实例。泛型标识符类似于变量，但它们必须是类型（而不能是数字等）。而且必须显式提供（编译器无法推断出）所需的类型，这与常规函数模板是不同的，因为编译器可以根据函数的参数类型确定要生成哪种函数。请看下面例子：stacktp.h 头文件#ifndef STACKTP_H#define STACKTP_Htemplate &lt;typename Type&gt;class stack{ private: enum {MAX = 10;} Type items[MAX]; int top; public: stack(); bool isempty(); boolisfull(); bool push(const Tupe &amp; item); bool pop(Type &amp; item);}template &lt;typename Type&gt;Stack&lt;Type&gt;::Stack(){ top = 0;}template &lt;typename Type&gt;bool Stack&lt;Type&gt;::isempty(){ return top == 0;}template &lt;typename Type&gt;bool Stack&lt;Type&gt;::isfull(){ return top == MAX;}template &lt;typename Type&gt;bool Stack&lt;Type&gt;::push(const Type &amp; item){ if (top &lt; MAX) { items[top++] = item; return true; } else return false;}template &lt;typename Type&gt;bool Stack&lt;Type&gt;::pop(Type &amp; item){ if (top &gt; 0) { item = items[--top]; return true; } else return false;}注意：类模板的目标是：和常规类一样，通用所有技术所以，只要遵守其声明规则就可以随心所欲的用就可以了另外，C++标准制定者试图不改变以前的编程思想和编程习惯。使得函数模板和类模板极其相似，也就是说，函数模板的技术也可以迁移到类模板中来。更有趣的是，设计者还试图统一普通函数和函数模板，所以普通函数的一切技术也可迁移过来。总之，九九归一，一通百通！比如，普通函数提供默认参数值，模板函数提供部分实例化，模板函数可以被调用，普通函数可以重载等。类模板之于类，类之于普通类型，只要具备扎实的普通类型和普通函数等知识，对 C++ 的特性或新特性想怎么来就怎么来，只怕觉得生疏、不顺手啊。 可以递归使用类模板（视为普通类，包含）如 Array&lt; Array&lt;int,5&gt;, 10&gt; towdee;不过在模板语法中，维的顺序与等价的二维数组相反。 使用多个类型参数（毕竟类中用到的不止一种数据类型） 默认类型模板参数如 template &lt;typename T1, class T2 = int&gt; class Topo {…}虽然可以为类模板类型参数提供默认值，但不能为函数模板参数提供默认值，因为类模板必须具体化才生成类声明，而函数模板可以重载，可能导致二义性。然而，可以为非类型参数提供默认值，这对于类模板和函数模板都是适用的。 模板的具体化类模板与函数模板很相似，因为可以有隐式实例化。显式实例化和显式具体化，它们统称为具体化。模板以泛型的方式描述类，而具体化是试用具体的类型生成类声明 隐式实例化如 ArrayTP&lt;int, 100&gt; stuff; 古国编译器在需要对象之前，不会生成类的隐式实例化。ArrayTP&lt;double,10&gt; * pt;// a pointter, no object needed yetpt = new ArrayTP&lt;double,30&gt;;// now an object is needed 显式实例化当试用关键字 template 并指出所需类型来声明类时，编译器将生成类声明的显式实例化。声明必须位于模板定义所在的名称空间。如template class ArrayTP&lt;string, 100&gt;;// generate ArrayTP&lt;string, 100&gt; class在这种情况下，虽然没有创建或提及类对象，编译器也将生成类声明（包括方法定义）。和隐式实例化一样，也将根据通用模板来生成具体化。 显式具体化显式具体化是特定类型（用于替换模板中的泛型）的定义。有时候，可能需要在为特殊类型实例化时，对模板进行修改，使其行为不同。在这种情况下，可以创建显式具体化。当具体化模板和通用模板都与实例化请求匹配时，编译器将使用具体化版本。具体化类模板定义如下：template &lt;&gt; class ClassName&lt;specialized-type-name&gt; {...};具体例子如下：template &lt;&gt; class SortedArray&lt;const char *&gt;{ ...} 部分具体化前面是完全具体化，如果还保留了至少一个泛型，则为部分具体化。例如// general templatetemplate &lt;class T1, class T2&gt; class Pair {...}// specialization with T2 set to inttemplate &lt;class T1, class Pair&lt;T1, int&gt; {...}如果有多个模板可供选择，编译器将使用具体化程度最高的模板 模板可用作结构、类或模板类的成员。 将模板用作参数，如template &lt;template &lt;typename T&gt; class Thing&gt;class Grab 可以混合使用模板参数和常规参数，如template &lt;template &lt;typename T&gt; class Thing, typeName U, typeName V&gt;class Grab{ private: Thing&lt;U&gt; s1; Thing&lt;v&gt; s2; ....}模板别名（C++11）可以像以前一样使用 typedef 为模板具体化指定别名：typedef std::array&lt;double,12&gt; arrd;typedef std::array&lt;int,12&gt; arri;arrd gallons;arri days;C++11 新玩法，使用模板提供一系列别名，如：template&lt;typename T&gt; using arrtype = std::array&lt;T,12&gt;;arrtype&lt;double&gt; gallons;arrtype&lt;int&gt; days;总之， arrtype 表示类型 std::array&lt;T,12&gt;C++11 允许将语法 using= 用于非模板，用于非模板时，这种语法与常规 typedef 等价：typedef const char * pc1; //typedef syntaxusing pc2 = const char *; // using = syntaxtypedef const int *(*pa1) [10]; // typedef syntaxusing pa2 = const int *(*) [10]; // using = syntax模板类和友元函数 模板类的非模板友元函数template &lt;class T&gt;class HasFriend{ public: friend void counts(); // friend to all HasFriend instantiations}上述声明使 counts() 函数成为了模板所有实例化的友元。例如，它将是类 HasFriend 和 HasFriend 的友元假设要为友元函数提供模板类参数如下： friend void report(HasFriend &amp;); 这是不允许的！原因是，不存在 HasFriend 这样的对象，而只有特定的具体化，如 HasFriend,要提供模板类参数，必须指明具体化。例如，可以这样做：template &lt;class T&gt;class HasFriend{ friend void report(HasFriend&lt;T&gt; &amp;); ...}注意，report() 本身并不是模板类，而只是使用一个模板作参数，这意味着必须为要使用的友元定义显式具体化：void report (HasFriend&lt;short&gt; &amp;) {...}// explicit specialization for shortvoid report (HasFriend&lt;int&gt; &amp;) {...}// explicit specialization for int这两个 report() 函数分别是某个特定 HasFriend 具体化的友元。具体看下面示例：// frnd2tmp.cpp -- template class with non-template friends#include &lt;iostream&gt;using std::cout;using std::endl;template &lt;typename T&gt;class HasFriend{private: T item; static int ct;public: HasFriend(const T &amp; i) : item(i) {ct++;} ~HasFriend() {ct--; } friend void counts(); friend void reports(HasFriend&lt;T&gt; &amp;); // template parameter};// each specialization has its own static data membertemplate &lt;typename T&gt;int HasFriend&lt;T&gt;::ct = 0;// non-template friend to all HasFriend&lt;T&gt; classesvoid counts(){ cout &lt;&lt; \"int count: \" &lt;&lt; HasFriend&lt;int&gt;::ct &lt;&lt; \"; \"; cout &lt;&lt; \"double count: \" &lt;&lt; HasFriend&lt;double&gt;::ct &lt;&lt; endl;}// non-template friend to the HasFriend&lt;int&gt; classvoid reports(HasFriend&lt;int&gt; &amp; hf){ cout &lt;&lt;\"HasFriend&lt;int&gt;: \" &lt;&lt; hf.item &lt;&lt; endl;}// non-template friend to the HasFriend&lt;double&gt; classvoid reports(HasFriend&lt;double&gt; &amp; hf){ cout &lt;&lt;\"HasFriend&lt;double&gt;: \" &lt;&lt; hf.item &lt;&lt; endl;}int main(){ cout &lt;&lt; \"No objects declared: \"; counts(); HasFriend&lt;int&gt; hfi1(10); cout &lt;&lt; \"After hfi1 declared: \"; counts(); HasFriend&lt;int&gt; hfi2(20); cout &lt;&lt; \"After hfi2 declared: \"; counts(); HasFriend&lt;double&gt; hfdb(10.5); cout &lt;&lt; \"After hfdb declared: \"; counts(); reports(hfi1); reports(hfi2); reports(hfdb); // std::cin.get(); return 0;} 模板类的约束模板友元函数可以修改前一个示例，使友元函数本身成为模板，具体地说，为约束模板友元作准备，要使类的每一个具体化都获得与友元匹配的具体化。这比非模板友元复杂些。步骤（详细见后面的示例）： 在类定义的前面声明每个模板函数。template &lt;typename T&gt; void counts();template &lt;typename T&gt; void report(T &amp;); 在函数中再次将模板声明为友元。这些语句根据类模板参数的类型声明具体化template &lt;typename TT&gt;class HasFriend{ friend void counts&lt;TT&gt;(); friend void report&lt;&gt;(HasFriend&lt;TT&gt; &amp;);};声明中 &lt;&gt; 指出这是模板具体化，对于 report(), &lt;&gt; 可以为空，因为可以从函数参数推断出如下模板类型参数： HasFriend, 然而也可以使用 report&lt; HasFriend &gt;(HasFriend &amp;)但是，counts() 函数没有参数，因此必须使用模板参数语法 () 来指明其具体化，还需要注意的是， TT 是 HasFriend 类的参数类型。 必须满足的第三个要求是，为友元提供模板定义。 具体例子：// tmp2tmp.cpp -- template friends to a template class#include &lt;iostream&gt;using std::cout;using std::endl;// template prototypestemplate &lt;typename T&gt; void counts();template &lt;typename T&gt; void report(T &amp;);// template classtemplate &lt;typename TT&gt;class HasFriendT{private: TT item; static int ct;public: HasFriendT(const TT &amp; i) : item(i) {ct++;} ~HasFriendT() { ct--; } friend void counts&lt;TT&gt;(); friend void report&lt;&gt;(HasFriendT&lt;TT&gt; &amp;);};template &lt;typename T&gt;int HasFriendT&lt;T&gt;::ct = 0;// template friend functions definitionstemplate &lt;typename T&gt;void counts(){ cout &lt;&lt; \"template size: \" &lt;&lt; sizeof(HasFriendT&lt;T&gt;) &lt;&lt; \"; \"; cout &lt;&lt; \"template counts(): \" &lt;&lt; HasFriendT&lt;T&gt;::ct &lt;&lt; endl;}template &lt;typename T&gt;void report(T &amp; hf){ cout &lt;&lt; hf.item &lt;&lt; endl;}int main(){ counts&lt;int&gt;(); HasFriendT&lt;int&gt; hfi1(10); HasFriendT&lt;int&gt; hfi2(20); HasFriendT&lt;double&gt; hfdb(10.5); report(hfi1); // generate report(HasFriendT&lt;int&gt; &amp;) report(hfi2); // generate report(HasFriendT&lt;int&gt; &amp;) report(hfdb); // generate report(HasFriendT&lt;double&gt; &amp;) cout &lt;&lt; \"counts&lt;int&gt;() output:\\n\"; counts&lt;int&gt;(); cout &lt;&lt; \"counts&lt;double&gt;() output:\\n\"; counts&lt;double&gt;(); // std::cin.get(); return 0;} 模板类的非约束模板友元函数前面的约束模板友元函数是在类外面声明的模板的具体化。 int 类具体化获得 int 函数具体化，依此类推……通过在类内部声明模板，可以创建非约束友元函数，即每个函数具体化都是每个类具体化的友元。对于非约束友元，友元模板类型参数与模板类型参数是不同的：template &lt;typename T&gt;class ManyFriend{ template &lt;typename C, typeName D&gt; friend void show2(C &amp;, D &amp;);}该部分不详细讲解，请自行体会下面示例：// manyfrnd.cpp -- unbound template friend to a template class#include &lt;iostream&gt;using std::cout;using std::endl;template &lt;typename T&gt;class ManyFriend{private: T item;public: ManyFriend(const T &amp; i) : item(i) {} template &lt;typename C, typename D&gt; friend void show2(C &amp;, D &amp;);};template &lt;typename C, typename D&gt; void show2(C &amp; c, D &amp; d){ cout &lt;&lt; c.item &lt;&lt; \", \" &lt;&lt; d.item &lt;&lt; endl;}int main(){ ManyFriend&lt;int&gt; hfi1(10); ManyFriend&lt;int&gt; hfi2(20); ManyFriend&lt;double&gt; hfdb(10.5); cout &lt;&lt; \"hfi1, hfi2: \"; show2(hfi1, hfi2); cout &lt;&lt; \"hfdb, hfi2: \"; show2(hfdb, hfi2); // std::cin.get(); return 0;}友元类前面已经零散地讲过友元函数用于类的扩展接口，但类并非只能拥有友元函数，也可以将类作为友元。如此，友元类的所有方法都可以访问原始类的所有成员。当然，也可以做更严格的限制，只将特定的成员函数指定为另一个类的友元。友元类有时是很高效的，比如电视机和遥控器。声明友元的时候一定要注意 C++ 的原则：先声明或定义之后才能使用友元声明可以位于公有、私有或保护部分，其所在的位置无关紧要。因为它不属于类成员，但可以访问原始类的所有组件。类友元是一种自然用语，用于表示一些关系。换句话说，需要根据实体之间的自然关系来确定是否使用友元。友元成员函数友元类中的某些方法并不需要作为友元，确实可以选择仅让特定的类城城欲成为另一个类的友元，而不必让整个类成为友元，但这样做稍微有点麻烦，必须小心排列各种声明和定义的顺序。例如class Tv{ friend void Remote::set_chan(Tv &amp; t, int c); ...}Tv 要知道 Remote 则 Remote 要在 Tv 前声明或定义，而 set_chan() 提到了 Tv ，那么 Tv 又要在 Remote 之前，这样就形成了循环依赖。为了避开这种循坏依赖的方法是，使用前向声明。解决方案// 正确方案class Tv; // forward declarationclass Remote {...}calss Tv {...}// 错误方案class Remote; // forward declarationclass Tv {...}class Remote {...}第二个方案不行的原因是：不符合使用之前必须先声明或定义的原则。相互友元这个更加要注意声明或定义的顺序了，也必须遵循“使用之前必须事先声明或定义”的原则。例如：Tv 和 Remote 的相互友元关系class Tv{ friend class Remote; // Remote 是 Tv 的友元 public: void buzz (Remote &amp; r); // 可以盛勇前向声明， // 不过这里还没有定义，编译器不会检查类型 ...};class Remote{ friend class Tv; // 相互友元 public: void Bool volup(Tv &amp; t) { t_volup(); } ...};inline void Tv::buzz(Remote &amp; r){ ...}共同的友元需要使用友元的另一种情况是，函数需要访问两个雷的私有数据。从逻辑上看，这样的函数应是每个类的成员函数，但这是不可能的。它可以是一个类的成员。同时是另一个类的友元，但有时将函数作为两个雷的友元更合理。由于友元定义时是没有限定符的，既然是共同友元则应是同一个函数。例子如下：class Analyzer; // forward declarationclass Probe{ friend void sync(Analyzer &amp; a, const Probe &amp; p); // sync a to p friend void sync(Probe &amp; p, const Analyzer &amp; a); // sync p to a ...};class Analyzer{ friend void sync(Analyzer &amp; a, const Probe &amp; p); // sync a to p friend void sync(Probe &amp; p, const Analyzer &amp; a); // sync p to a}inline void sync(Analyzer &amp; a, const Probe &amp; p){ ...}inline void sync(Probe &amp; p, const Analyzer &amp; a){ ...}嵌套类在 C++ 中，可以将类声明放在另一个类中（可以参考结构体同样的做法）。在另一个类中声明的类被称为潜逃类，它通过提供新的类型类作用域来避免名称混乱。包含类的成员函数可以创建和使用被嵌套类的对象；而仅当声明位于公有部分，才能在包含类的外面使用嵌套类，而且必须使用作用域解析运算符。对垒进行嵌套与包含并不同，包含意味着将类对象作为另一个类的成员，而对垒进行嵌套不创建类成员，而是定义了一种类型，该类型仅在包含嵌套类声明的类中有效。说白了，嵌套类就像二级目录之于一级目录嵌套类和普通类一样只是要使用两次作用域解析运算符来提取而已模板也可以嵌套（模板嵌套普通类，嵌套模板类，类嵌套模板）" }, { "title": "Cpp 函数参数和返回值传递机制", "url": "/2016/09/cpp-parameter.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-11 23:19:14 +0800", "snippet": " 函数传递是 C/C++ 代码块重用和结构化设计的产物。当代码块封装成函数之后，就需要和“外界”交流，这就是信息传递（接收信息和放出信息）。信息传递由函数参数和函数返回值负责。 按值传递 指针传递 引用传递 三种参数传递的比较 实参和形参的关系 返回对象 返回指向 const 对象的引用 返回指向非 const 对象的引用 返回对象 ...", "content": " 函数传递是 C/C++ 代码块重用和结构化设计的产物。当代码块封装成函数之后，就需要和“外界”交流，这就是信息传递（接收信息和放出信息）。信息传递由函数参数和函数返回值负责。 按值传递 指针传递 引用传递 三种参数传递的比较 实参和形参的关系 返回对象 返回指向 const 对象的引用 返回指向非 const 对象的引用 返回对象 返回 const 对象 接收信息由函数参数承担，放出信息由函数返回值负责。为了不破坏封装性和最大限度保证信源的真实性，函数参数获取信息会首先选择信息拷贝（即按值传递），同时为了最大程度不干扰外界，函数返回值也遵循按值传递（即信息拷贝），如此就把函数中做的细节工作对外界隐藏了，只保留了入口和出口两种接口，同时这两种接口是信息拷贝，不影响信息发出者和接受者本身。从而保证了函数对数据加工的特性，同时达到了不污染信源的目的。函数参数和返回值传递方式非常类似，在这里只详细讲解函数参数的传递方式。在 C++ 中它有3中方式：1、按值传递2、指针传递3、引用传递按值传递按值传递在传递的时候，实参被复制了一份，然后在函数体内使用。拷贝之后就与实参失去了关联，它的改变不会返回给实参。换句话说，函数体内修改参数变量时修改的是实参的一份拷贝，而实参本身是没有改变的，所以如果想在调用的函数中修改实参的值，使用值传递是不能达到目的的，除非将这种改变通过返回值的形式再赋给实参（此法貌似只能改变一个实参）。当函数运行结束之后，那份拷贝（称之为“形参”）就被释放了（当然函数的其他变量也被释放了）。形参的运算顺序符合逗号法则，不过不建议使用表达式初始化形参，如int f(a++,a)，从左边开始计算还是从右边开始？最好的办法是在函数外先计算好再赋给形参。可见，按值传递实际上就是把实参的值赋给形参，然后形参在函数中起作用。说白了就是赋值运算，对于内部类型很快，但对于用户类型赋值操作就会涉及到构造函数和析构函数了，效率大打折扣，而且不一定会享受编译器对内部类型的优化措施。指针传递指针传递也可以看作是按值传递。指针里面存的是指向变量的地址，即指针的“值”就是变量的地址，如果按照“按值传递”的思路，实参传给形参的就是变量的地址。变量的地址被拷贝一份给形参，依照类型的匹配原则，该形参也应该是指针。这样在函数内部要使用形参（只能使用形参，不能使用实参，实参已经被隐藏）找到指向的变量（就是实参指向的变量）是一种间接寻址，单从这方面就比按值传递效率低了，如果这种操作很频繁，执行次数较多的话就会大大影响效率。使用指针传递还有一个隐患：在函数体类对指针操作不当可能其指向发生变化，而失去了对原指向变量的改变作用（即使返回该指针也是没有用的，因为指向改变了）。如果你不是为了改变它的指向，最好使用 const 限定该指针为常量指针（不能改变指向）。如果你不想改变指针指向的变量，又是内部类型，应优先考虑按值传递，即安全（编译器对其检查比指针检查要求更严格）有高效！引用传递引用一旦（必须定义时）初始化之后就不能改变指向。调用函数时，编译器会为引用开辟空间并绑定实参初始化（该空间存储实参的地址），从这种意义上讲，其效率和指针相当（都需要间接寻址），但其更像常量指针（不可改变指向），相对来说比一般指针更安全。而且引用传递时，对形参的操作等同于对实参的操作，即传递的不会是实参的副本，而就是实参。不像指针需要解除地址符来操作实参，引用传递没有这个步骤。引用传递的效率如何？这个要看编译器具体实现，引用传递最显然的实现方式是使用指针，这种情况下与指针的效率是一样的，而有些情况下编译器是可以优化的，采用直接寻址的方式，这种情况下，效率比传值（大量拷贝损失效率）调用和传址（地址拷贝和间接寻址）调用都要快，与上面说的采用全局变量方式传递的效率相当。 综上，某些情况下引用传递可能被优化，总体效率稍高于传址调用。符号表上对变量、指针、引用的不同处理 程序在编译时分别将指针和引用添加到符号表上，符号表上记录的是变量名及变量所对应地址。 指针变量在符号表上对应的地址值为指针变量的地址值。 引用在符号表上对应的地址值为引用对象的地址值。符号表生成后就不会再改。因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。三种参数传递的比较   按值传递 指针传递 引用传递 对实参作用 拷贝内容 拷贝地址间接操作 直接操作或同指针 改变实参 否 （解除地址符）可以 可以 指向   可变 不可变 类型安全 安全 不安全 安全 用户类型效率 最低 中等 最高 内部类型效率 最高 最低 中等 综上所述，得出以下原则： 内建的数据类型优先使用值传递，而对于自定义的数据类型，特别是传递较大的对象，那么请使用引用传递。 如果一个参数可能在函数中指向不同的对象，或者这个参数可能不指向任何对象，则必须使用指针参数。 引用参数的一个重要用法是，它允许我们在有效实现重载操作符的时，还能保证用法的直观性（因为不需要解除地址符）。 如果被返回的对象是被调用函数中的局部变量，则不应按应用方式返回它，因为在被调用函数执行完毕时，局部对象将调用析构函数。当控制权回到调用函数时，引用指向的对象将不再存在。在这种情况下，应返回对象而不是引用。 对于用户类型尽量使用引用和指针，因为这两个视为“内部类型”，编译器会像内部类型一样对其尽可能优化（比如使用寄存器）。实参和形参的关系原则上实参和形参是单向信息传递的关系，只能实参传给形参，不能反向传递。引用和指针实质上也是这么回事，传递的是地址，也是单向的，只不过形参可以通过这个地址改变实参（好像信息反向传递了，但是改变的内容而不是传过来的地址，所以仍然是单向传递）。 形参变量只有在被调用时才分配内存单元，在调用结束时，即刻释放所分配的内存单元。因此，形参只在函数内部有效。函数调用结束返回主调用函数后则不能再使用该形参变量。 实参可以是常量、变量、表达式、函数等，无论实参是何种类型的量，在进行函数调用时，它们都必须有确定的值，以便把这些值传送给形参。因此应预先用赋值，输入等办法使参数获得确定值。 实参和形参在数量上，类型上、顺序上应严格一致，否则就会发生类型不匹配的错误。 在一般传值调用的机制中只能把实参传送给形参，而不能把形参的值反向地传送给实参。因此在函数调用过程中，形参值发生改变，而实参中的值不会变化。而在引用调用的机制当中是将实参引用的地址传递给了形参，所以任何发生在形参上的改变实际上也发生在实参变量上。返回对象当成员函数或独立的函数返回对象时，有几种返回方式可供选择：1、返回指向对象的引用2、返回指向对象的 const 引用3、返回指向对象的 const 对象返回指向 const 对象的引用使用 const 引用的常见原因是旨在提高效率，但对于何时可以采用这种方式存在一些限制。 如果函数返回（通过调用对象的方法或将对象作为参数）传递给它的对象，可以通过返回引用来提高效率 如果函数要返回函数中创建的对象，则不能返回其引用，因为一旦函数运行结束该对象就被释放了。 函数返回引用的类型与被引用的对象必须一致，如 const 必须都为 const返回指向非 const 对象的引用两种常见的返回非 const 对象情形是：重载赋值运算符以及重载与 cout 一起使用的 « 运算符等。前者这样做旨在提高效率，而后者必须这样做。返回对象如果被返回的对象是被调用函数中的局部变量，则不能按引用方式返回它，因为在被调用函数执行完时，局部对象将调用其析构函数。因此，当控制权回到调用函数时，引用指向的对象将不再存在。在这种情况下，应返回对象而不是引用。通常，被重载的算术运算符属于这一类。返回 const 对象返回 const 对象就限定该对象不能作为左值，有助于编译器发现 “==” 被写成 “=” 的输入错误（如果不限定为 const 的话讲不报错）。总结： 返回对象如果方法或函数要返回局部对象，则应返回对象，而不是指向对象的引用。在这种情况下，将使用复制构造函数来生成返回的对象。 返回引用如果方法或函数返回一个没有公有复制构造函数的类（如 ostream 类）的对象，它必须返回一个指向这种对象的引用。 尽量返回引用有些方法或函数（如重载的赋值运算符）可以返回独享，也可以返回指向对象的引用，在这种情况下，应首选引用，因为其效率更高。" }, { "title": "Cpp 常用关键字总结", "url": "/2016/09/cpp-keywords.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-11 03:29:08 +0800", "snippet": " C++ 相对于 C 的很多新特性，都是通过类和新增关键字或扩充关键字的用法来获取的。所以有必要从设计思想的这个角度来解读关键字的一些重要细节。 class const const 的安全性 const 与之结合的不同效果 const 修饰函数 空指针 nullptrclasscla...", "content": " C++ 相对于 C 的很多新特性，都是通过类和新增关键字或扩充关键字的用法来获取的。所以有必要从设计思想的这个角度来解读关键字的一些重要细节。 class const const 的安全性 const 与之结合的不同效果 const 修饰函数 空指针 nullptrclassclass 是声明类的关键字，是对 struct 的扩充，是 C++ 从 C 的面向过程走向面向对象的重要一环。它将数据（信息）和方法（俗称函数，对数据的使用或操作）封装在一次。同时引入了类作用域，使得类中的变量和函数只能在类中起作用，这样即保护了类中的数据，也防止其中的名称（变量或函数）与外面其他的名称产生冲突，便于调试和查错，也易于维护和重用。C++ 中的 struct 已经扩充 和 class 相当，但是主要区别如下： struct 作为数据结构的实现体，它默认的数据访问控制是 public 的，而 class 作为对象的实现体，它默认的成员变量访问控制是 private 的。 class 继承默认是 private 继承，而 struct继承 默认是 public 继承。 class 这个关键字还用于定义模板参数，就像“typename”。但关键字“struct”不用于定义模板参数。 struct 更适合看成是一个数据结构的实现体，class 更适合看成是一个对象的实现体。constconst 的引入是为了让编译器对程序员的部分逻辑进行检查。具体说来，程序员本不想的改变的量可能会因为不当的操作而被改变，这属于逻辑问题，不加 const 编译器是不会检查的，而程序员可能很难察觉到时在哪里被改变的，是怎么改变，设置会因为这个出现大面积逻辑错误，调试排查是很艰难的。为此，在变量（或函数）的适当位置添加 const 可以保证不需要改变的东西不被改变，一旦有试图改变的操作，编译器就会报错。这样就满足了这个需求！const 的目的是实现数据改动保护，协助简单的逻辑检查C++ 和 C 中 const 的不同之处如下： C++中的 const 正常情况下是看成编译器的常量,编译器并不为 const 分配空间,只是在编译的时候将其值保存在名字表中,并在适当的时候折合在代码中 在 C 中, const 是一个不能被改变的普通变量,既然是变量,就要占用存储空间,所以编译器不知道编译时的值.而且,数组定义时的下标必须为常量，所以 const 常变量不能作为数组下标。 const int size;在 C 中 这个语句是正确的，因为它被 C 编译器看作一个声明,指明在别的地方分配存储空间.但在 C++ 中这样写是不正确的.C++ 中 const 默认是内部连接,如果想在 C++ 中达到以上的效果,必须要用 extern 关键字. C++ 中,const 默认使用内部连接.而 C 中使用外部连接. C++ 中,是否为 const 分配空间要看具体情况.如果加上关键字 extern 或者取 const 变量地址,则编译器就要为 const 分配存储空间const 的安全性 希望某个值不变，使用 const 不仅可以防止意外的更改提供安全措施，同时也消除了读存储器和读内存操作。因为在定义 const 变量的时候除非是要使用地址，或者是定义一个类或者是用户自定义的类型。否则编译器是不会为 const 分配地址的。直接将 const 所代表的值放在符号表中。若将用户自定义的类型放在符号表中未免太过复杂。 const可以定义数组，但是我们不能在编译期间使用数组中的值，因为在编译的时候编译器是不需要知道数组中的内容的。const 与之结合的不同效果const 与不同的类型的变量（或函数）结合以及放置的位置不同，产生的安全意义也不同，具体列表如下：注意，无特殊说明时，const 都表示不可改变的量，必须定义时初始化 结合的类型 例子 说明 非指针变量 const int i = 1; const 与类型名的位置可交换 修饰指针 int i = 1;int * const p_i = &amp;i; 指针为常指针，即其指向的地址不能变 修饰指针指向的变量 int i = 1;const int * p_i = &amp;i; *p_i 不能改变 i但 i 可以自身改变 修饰指针及其指向 const int i = 1;const int * const * p_i = &amp;i; p_i指向地址不变 *p_i 不能改变 i，i 自身也不能改变 修饰引用 double dVal = 3.1415;const int &amp;iVal = dVal; const 不能修饰引用本身，只能限定是否可以修改被引用的值 上表中，“修饰引用”一行的例子，编译器将 double 转换成一个临时的 int 对象（而指针必须类型相同，可见引用有一个隐性转换），然后让 const 引用绑定到这个临时对象，所以改变 dval 的值不会改变 refVal，也就是说 dval 仍然是非 const 变量，refVal 仍然是常量引用。const 修饰函数 修饰函数非引用参数： void function(const int Var); //传递过来的参数在函数内不可以改变(无意义，因为Var本身就是形参) void function(const char* Var); //参数指针所指内容为常量不可变 void function(char* const Var); //参数指针本身为常量不可变(也无意义， 因为char* Var也是形参) 修饰函数引用参数： void function(const MyClass&amp; Var); //同下（一个效果） void function(Myclass const&amp; Var); //防止传入的自定义对象在函数内发生改变 注意事项： 对于非内部数据类型的输入参数，应该将“值传递”的方式改为“const 引用传递”，目的是提高效率。例如将void Func(A a) 改为void Func(const A &amp;a)。 对于内部数据类型的输入参数，不要将“值传递”的方式改为“const 引用传递”。否则既达不到提高效率的目的，又降低了函数的可理解性。例如 void Func(int x) 不应该改为 void Func(const int &amp;x)。 修饰函数的返回值： 非指针非引用类型的返回值，加 const 没有意义，因为返回值是一个拷贝，而且不论这个返回值是否为 const 都可以赋给非 const 变量，同时该函数都不能作为左值。（不过特例除外，比如函数返回对象，加上 const ，可以防止其作为左值，预防判断符 == 写成 = 而很难排错） 对于是指针类型的返回值，加上 const（最前面） 就限定了接收该返回值的指针也必须是同类型的指针。这样就保护了函数返回的值不被左边的指针改变。 类似 int * const function(int *iVal);的 const 是没有任何意义的，因为返回的指针本身就是一个拷贝，也不需要作为左值。 修饰类成员函数const 置于函数头的最后面。const 修饰的成员函数表示成员函数是一个只读的作用，不改变数据成员（默认是可以修改的）。const 其实修饰成员函数的本质是修饰隐含参数 this 指针。 （1）const 修饰了 this，得到 const ClassType *this，this 指向一个“自认为”是 const 的对象(也就是本身），所以任何对象( const 或者非 const )都可以调用一个 const 成员函数，因为传入的指针都把自身这个对象看作是 const 对象，所以不能被修改。 （2）对于一个 const 对象，当其调用成员函数的时候，默认都传入 this 指针参数，因为 this 此时指向一个 const 对象(本身)，所以相当于成员函数被 const 修饰，成员函数是一个 const 成员函数，所以反过来说，const 对象只能调用 const 成员函数，因为非 const 修饰的成员函数，this 指针不是指向 const 对象。 （3）进一步，每个成员函数都可以调用其他成员函数，每个成员函数都传入 this 指针，所以成员函数相互调用必须保持 this 指针的一致性，所以 const 成员函数只能调用 const 成员函数，因为二者传入的 this 指针都是 const 修饰的。对于非 const 成员函数，其传入非 const 修饰的 this 指针，所以不能被调用。 一定要保持 const 成员函数传入的是 const 指针这个意识，对象调用就需要看对象（本身，指针，引用）是否是 const。空指针 nullptr有些程序员使用(void *)0来标识空指针（空指针本身的内部表示可能不是零，还有些程序员使用 NULL，这是一个表示空指针的C 语言宏。C++11 提供了更好的解决方案：引入新关键字 nullptr，用于表示空指针。" }, { "title": "cpp 多文件组织详解", "url": "/2016/09/cpp-multifile.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-09 18:31:55 +0800", "snippet": " 本文旨在说明 C++ 存在多个源文件和头文件时，是如何组织？或者说，如何把一个大的源文件分割成几个小的头文件和源文件，以增加其可读性、可维护性和减少调试的工作量，同时以使得其功能划分明确，便于其他文件包含以增加可重用性。 变量持续性、作用域和连接性 持续性 作用域 链接性 列表总结 声明和定义的区别 头文件 CPP 源文...", "content": " 本文旨在说明 C++ 存在多个源文件和头文件时，是如何组织？或者说，如何把一个大的源文件分割成几个小的头文件和源文件，以增加其可读性、可维护性和减少调试的工作量，同时以使得其功能划分明确，便于其他文件包含以增加可重用性。 变量持续性、作用域和连接性 持续性 作用域 链接性 列表总结 声明和定义的区别 头文件 CPP 源文件 include 指令 源文件的分割 makefile 组织编译变量持续性、作用域和连接性说到文件的组织，必须知道程序中个构件的链接性，而链接性（共享）又和持续性（时间）有关，同时持续性又和其存储位置（请参考《C++ 基础知识总结》之“内存空间划分”）有关，而存储位置又决定了其作用域。持续性持续性指的是变量（函数等）在内存中何时存在何时消失的时间持续性。可分为以下三种情况： 自动：程序开始执行相关函数或代码块时被创建，执行完函数或代码块时被释放 静态：程序整个运行过程中都存在 动态：new 分配时创建，人工使用 delete 时释放。需要注意以下事项：1、未被初始化的静态变量全部被置为 0 。2、只能使用常量表达式来初始化静态变量（包括字面值常量 const常量 enum常量 和sizeof操作符）作用域作用域说的是其作用范围，即变量（或函数）是否可见。 全局：（文件） 从声明位置到文件结尾之间可见 局部：（代码块）从声明位置到定义它的代码块的结尾可见 特殊： 函数原型作用域：包含参数列表的括号内可用 类作用域：类中声明的成员作用域为整个类 名称空间：名称空间中声明的变量作用域是整个名称空间 需要注意的是：作用域解析操作符 :: 表示使用全局版本链接性链接把不同编译单元产生的符号联系起来，链接性指的是变量（或函数等）的共享特性及共享范围。内部链接意味着对此符号的访问仅限于当前的编译单元中，对其他编译单元都是不可见的要让其影响程序的其他部分，可以将其放在.h文件中。此时在所有包含此 .h 文件的源文件都有自己的定义且互不影响外部链接意味着该定义不仅仅局限在单个编译单元中。它可以在.o文件中产生外部符号。可以被其他编译单元访问用来解析它们未定义的符号。因此它们在整个程序中必须是唯一的，否则将会导致重复定义。判断一个符号是内部链接还是外部链接的一个很好的方法就是看该符号是否被写入.o文件。 无链接性：不能共享（即只在代码块内有效） 内部链接：只能由同一个文件中的函数共享 外部链接：可在文件间共享 注意事项： 1、在其他文件中使用 extern 重新声明已经定义过的外部变量，使其在其他文件中可见 2、原始声明称为 定义声明 ，extern声明称为 引用声明 3、内部链接意味着对此符号的访问仅限于当前的编译单元中，对其他编译单元都是不可见的 4、带有 static、const 关键字、枚举类型、内联函数和类的定义的链接是内部的 说明1、内部链接性的东西可以放在头文件中重用2、外部链接性的东西极易引起重定义错误，应尽量不要放在头文件中！列表总结 位置 持续性 链接性 作用域 函数内自动变量 自动 无 局部 函数内 static 变量 静态 无 局部 函数外 static 变量 静态 内部 文件 函数外非 static 变量 静态 外部 程序 动态变量 动态 看位置 看位置 static 函数 静态 内部 文件 非static 函数 静态 外部 程序 带 const 的变量也是内部链接的，但它的存储只有一份。而 static 的变量只要被引用就会在该编译单元中新建一个副本。注意事项： 1、外部变量和自动变量同名时、局部变量与全局变量同名时：新定义暂时隐藏旧定义 2、不同文件间的同名的全局静态变量相互覆盖（自己的隐藏其他文件的） 3、静态局部变量只进行一次初始化，再次调用该函数时不再初始化声明和定义的区别需要指出的是，声明是面向编译器的，告诉编译器此时和接下来的相同变量（或函数）用的是之前定义过的变量，只是引用名称，运行阶段不需要重新分配内存。由于只作用于文件（而非程序）的声明只对当前编译单元有用，不产生外部符号。因此声明并不将任何东西写入 .o 文件。而定义是面向内存的，定义提供了一个实体在程序中的唯一描述，在其作用范围内相同的名称只能定义一次。在相同的作用域内变量、函数、结构等名称不能相同。因为编译器无法区分它们。定义实际上也附带了声明，但声明绝对不是定义。根据上面的描述可知，（即使在同一个作用域）声明可以有多个，但在同一个作用域内定义只能有一个！例外的是，在类中的成员函数和静态数据成员却是例外，虽然在类内它们都是声明，但是也不能有多个。因此： 定义性的东西不能放在头文件中，否则会极易引起“重定义”编译错误， 只是声明的东西可以放在头文件中供其他文件重用； 一般常量在 cpp 文件中定义，在相应的头文件中加extern（去掉等号及其后面的部分），其他形式保持不变，否则会被视为不同的变量（此时转化为定义）而造成“重定义”。头文件基于以上的分析，我们可以知道：将具有外部链接的定义放在头文件中几乎都是编程（编译或链接）错误。因为如果该头文件（头文件宏保护只能保证头文件不能重复包含，但对于源程序分别包含而引起的重定义错误毫无保护）中被多个源文件包含，那么就会存在多个定义，链接时就会出错。在头文件中放置内部链接的定义却是合法的，但不推荐使用的。因为头文件被包含到多个源文件中时，不仅仅会污染全局命名空间，而且会在每个编译单元中有自己的实体存在。大量消耗内存空间，还会影响机器性能。类的定义可以放在 .h 文件中。而类的实现可以放在同名的 cpp 文件中。编译器会自动寻找同名的 cpp 文件。由于 cpp 文件中存储的是成员函数的实现，而成员函数具有外部链接特性，会在目标文件产生符号。在此文件中此符号是定义过的。其他调用此成员函数的目标文件也会产生一个未定的符号。两目标文件连接后此符号就被解析。注意 static 数据成员应该放在 cpp 文件中。而不能放在 .h 文件。但 const static 数据成员可以放在头文件中。尽量不要使用全局函数或全局变量，实在要用，最好用静态全局变量或函数因为具有外部链接可能会与全局命名空间的其他符号名称存在潜在冲突其中静态变量和静态函数的作用域只是在本编译单元（.o文件），在不同的副本都保存了该静态变量和静态函数，正是因为 static 有以上的特性，所以一般定义 static 全局变量时，都把它放在原文件中而不是头文件，这样就不会给其他模块造成不必要的信息污染。头文件格式如下：/******************************************************************* * Copyright(c) 2000-2013 Company Name * All rights reserved. * * 文件名称: xiao.h * 简要描述: * * 当前版本:2.0 * 作者: * 日期: * 说明: * * 取代版本:1.0 * 作者: * 日期: * 说明: ******************************************************************/#ifndef XIAO_H#define XIAO_H#endif静态成员不能在类声明中初始化，这是因为：声明描述了如何分配内存，但并不分配内存。初始化是在方法文件（源文件）中，而不是在类声明文件（头文件）中进行的，这是因为类声明位于头文件中，程序可能将头文件包括在其他几个文件中。如果在头文件中进行初始化，将出现多个初始化语句副本，从而引发错误。对于不能在类声明初始化静态数据成员的一种例外情况是，静态数据成员为整型或枚举型 const 时注意：放在头文件中的内容是面向用户的（也就是提供给外部使用的），那么外部不需要的内容尽量不要放在头文件中，而是通过适当的设计模式将其他无关用户的内容隐藏起来，这样可以减少用户理解上的难度，增加可读性，同时可以不暴露额外的实现（这同时也意味着可以变化的东西和可能性更多，只要没有暴露给用户的理论上都可以改变）。CPP 源文件C++中程序的显著特点，有三部分构成，类的定义，类的实现，类的使用（主函数）。换句话说，C++多文件组织结构主要是头文件、头文件的实现文件（源文件）、主函数调用文件（源文件）。通常一个程序是由多个源程序文件构成，源程序文件又称为编译单元，每个源程序文件可以进行单独编写，编译，再进行连接。用C++编写一个稍大程序时，我们需要别写几个类和一些过程函数。为了文档的规整有序和程序的排错，文档比较合理的安排方法： 1、每个类的声明写在一个头文件中 2、将类的实现放在另一个文件中，取名为 classname.cpp（头文件和源文件同名，后缀名不同）。并且在该文件中的第一行包含类声明的头文件，如:#include”classname.h”(C++新标准不支持带.h的头文件)。然后在此文件中写类的实现代码。一般格式：#include”classname” 3、与类的相似，编写函数时，我们总是把函数的声明和一些常数的声明放在一个头件中；把函数的具体实现放在另一个源文件中。 4、一般地如果你在某个源文件中需要引入的头文件很多，或者为了源程序的简洁，你可以将头文件的引入写在另一个头文件中，在源程序的第一行引入这个头文件即可。 5，在文件中需要使用函数和类时，你只需要引入类和函数声明的头文件，而无需包含实现的文件。include 指令#include是一条编译预处理命令。什么叫编译预处理命令呢？我们知道，程序中的每一句语句会在运行的时候能得到体现。比如变量或函数的声明会创建一个变量或者函数，输出语句会在屏幕上输出字符。然而编译预处理命令却不会在运行时体现出来，因为它是写给编译器的信息，而不是程序中需要执行的语句。编译预处理命令不仅仅只有#include一条，在 C++ 中，所有以#开头的命令都是编译预处理命令，比如#if、#else、#endif、#ifdef、#ifndef、#undef 和 #define等等。当编译器遇到了 #include 命令后，就把该命令中的文件插入到当前的文件中。 #include 使用这种写法时，会在 C++ 安装目录的 include 子目录下寻找 &lt; &gt; 中标明的文件，通常叫做按标准方式搜索。 #include “文件名”使用这种写法时，会先在当前目录也就是当前工程的目录中寻找”“中标明的文件，若没有找到，则按标准方式搜索。源文件的分割当经过前面的处理之后，单个的实现文件依然较大时，怎么办？我们可以进一步做功能划分，将一个大的头文件按功能划分成许多小的头文件，然后再根据小的头文件去写各自相应的源文件。在头文件划分时，前提是类划分的较好，比如基类、子类等各自一个头文件，然后写各自的实现文件；当有大量的常量时可以把常量单独放在一个常量头文件中（甚至根据功能再划分到几个头文件中）。如果很多头文件需要综合使用时，可以新建一个头文件来包含这些头文件，不过除这种情况外最好不要在头文件中包含另一个头文件（可能导致重复包含错误，重定义错误）。注意事项： 1、分割的目的是为了功能清晰，便于调用和维护，以及调试排错（便于缩小错误范围）。 2、分割时，特别要注意头遵守文件规范，否则极易出现重定义或链接等错误。 3、文件大小处于可分割也可不分割状态时，尽量不分割 4、不建议使用（类外）全局函数，实在需要，应尽可能变成静态的，而且其生命最好单独放在一个头文件（其中最好不要有类定义等）中，如果头文件不大和常量也不多，则可以和（类外）常量、枚举类型、结构体等放在同一个头文件中。 大项目为了防止名称冲突，建议使用名称空间 makefile 组织编译对于多文件的编译需要 makefile 等工具，这部分内容后面会单独拿出来讲解。不过有些 IDE 或 自动 make 工具可以自动完成。" }, { "title": "C++ 函数详解", "url": "/2016/09/c++-function.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-08 03:11:42 +0800", "snippet": " 在博客《 C++ 基本知识》已经谈到了函数，但 C++ 还提供了许多新的函数特性，使之有别于 C 语言。新特性包括内联函数、按引用传递参数、默认的参数值、函数重载（多态）以及模板哈数 内联函数 函数重载 函数模板 模板函数 函数模板重载 模板的局限性 重载解析 函数模板的发展 函数重写（也称为覆盖） 函数重定...", "content": " 在博客《 C++ 基本知识》已经谈到了函数，但 C++ 还提供了许多新的函数特性，使之有别于 C 语言。新特性包括内联函数、按引用传递参数、默认的参数值、函数重载（多态）以及模板哈数 内联函数 函数重载 函数模板 模板函数 函数模板重载 模板的局限性 重载解析 函数模板的发展 函数重写（也称为覆盖） 函数重定义（也称为隐藏）内联函数内联函数的编译代码与其他程序代码“内联”起来。也就是说，编译器将使用相应的函数代码替换函数调用。对于内联代码，程序无需跳到函数定义处执行代码，再跳回来。因此，内联函数的运行速度比常规函数稍快，但代价是需要占用更多内存。如果程序在 10 个不同的地方调用同一个内联函数，则该程序将包含该函数代码的 10 个副本。应有选择地使用内联函数。如果执行函数代码时间比处理函数调用机制时间长，则节省的时间将占整个过程的很小一部分。如果代码时间执行时间很短，虽然节省时间的比例较大，但节省的时间绝对值并不大，除非该函数经常被调用。要使用内联函数，必须采取下述措施之一： 在函数声明前加上关键字 inline； 在函数定义前加上关键字 inline；宏不能按值传递，如果使用 C 语言的宏执行了类似函数的功能，应考虑将它们转换为 C++ 内联函数。内联函数的链接性是内部的，这意味着函数定义必须在使用函数的文件中。一般在使用函数的文件中包含(声明和定义了内联函数的)头文件可确保将定义放在正确的地方。也可以将定义放在实现文件中，但必须删除关键字 inline，这样函数的链接性将是外部的。函数重载函数多态（函数重载）让你能够使用多个同名的函数。术语“多态”指的是多种形式，因此函数多态允许函数可以有多种形式。类似地，术语函数重载指的是可以有多个同名的函数，因为对名称进行了重载。这两个术语是同一回事。可以通过函数重载来设计一系列函数—-它们完成相同的工作，但使用不同的参数列表。函数重载条件： 函数名相同 参数（不是参数名称）列表不同 参数个数不同 （或者）参数个数相同但对应位存在类型不同的情况 引用类型和类型本身，非指针和非引用类型带 const 与否，均视为同一个特征标（即视为参数相同） 对于指针或引用类型带 const 与否认为参数不同（主要是因为，将非 const 值赋给 const 变量是合法的，但反之是非法的） 返回值类型不是特征标虽然函数重载很吸引人，但也不要滥用。仅当函数基本上执行相同的任务，但使用不同形式的数据时，才应采用函数重载（实质上是为了重载函数名，而好的函数名是显示其功能）。事实上，C++ 通过名称修饰（如加后缀）来区分重载函数中不同的函数。函数模板前面提到的“函数重载”，重用了函数名和函数逻辑，但仍然要针对不同的数据类型写不同的函数（函数体）。那能不能针对不同的数据类型但参数个数相同的“函数重载”只用一个函数来表示呢？这就是函数模板出现时机。函数模板是通用的函数描述（使用泛型来定义函数）。由于模板允许以泛型（而不是具体类型）的方式编写程序，因此有时也称为参数化类型。不但普通函数可以声明为函数模板，类的成员函数也可以声明为函数模板。需要注意的是，函数模板不能缩短可执行程序，有几个模板实例就有几个独立的函数定义，就像以手工方式定义了这些函数一样。最终代码不包含任何模板，而只包含了为程序生成的实际函数。可见，函数模板将代表着不同类型的一组函数，它们都使用相同的代码。通常模板放在头文件中。使用模板的好处是，它使生成多个函数定义更简单、更可靠。模板函数 函数模板是模板函数的一个样板，它可以生成多个重载的模板函数，这些模板函数重用函数体代码。 模板函数是函数模板的一个实例。是函数模板的实例化（instantiation） 函数模板如下：template &lt;typename T1,typename T2&gt;void add(T1 a[],T2 b[],int size){ for(int i=0;i&lt;size;i++) b[i]+=a[i];}//另外一例//typename 或 class 均可（也可混合使用）template&lt;class stype&gt;void bubble(stype *item, int count){\tstype bubb;\tfor(int i=0;i&lt;=count-1;i++)\t\tfor(int j=i+1;j&lt;count;j++)\t\t\tif(item[i]&gt;item[j])\t\t\t{\t\t\t\tbubb=item[i];\t\t\t\titem[i]=item[j];\t\t\t\titem[j]=bubb;\t\t\t}}//模板函数template&lt;typename T&gt;T add(T a,T b){return a+b;}cout&lt;&lt;add&lt;int&gt;(3,5);//编译系统将生成如下的模板函数int add(int a,int b){return a+b;}函数模板重载函数模板只能简化（大部分） 参数个数相同的函数重载，但对于参数个数不同的函数重载没有办法。所以此时需要对函数模板进行重载，和常规重载一样，被重载的模板的函数特征标必须不同。模板的局限性编写的模板函数很可能无法处理某些类型（如含 &gt; 的模板对指针不管用），因为某些运算符不适合特定类型，甚至这样做是没有意义的。如果有意义的话，你可以： 通过重载运算符来解决此类问题 （或者）为特定类型提供具体化的模板定义普通函数和函数模板可以同名！匹配顺序是：先同名普通函数-&gt;同名函数模板同名普通函数（参数个数等也相同）可以看做函数模板的具体化。重载解析上述提到了函数重载、函数模板和函数模板重载，这三者的函数名都可以相同，那到底选哪一个呢？重载解析步骤如下： 创建候选函数列表（包括三者） 使用候选函数列表创建可行函数列表（函数模板实例化） 完全匹配顺序：普通函数-&gt;模板函数，指向非 const 数据的指针和引用 -&gt; 非 const 指针和引用 最佳(含类型转换)匹配顺序：普通函数-&gt;模板函数，转换最少优先 报错函数模板的发展前面提到的函数模板形式化了参数，但返回值可能是不同于形式化参数的类型（如两个 int 相除，出现 float 等）。C++ 给出了方案如下： 新增关键字 decltype 用于推断函数中运算得到的新类型 template &lt;typename T1, class T2&gt;{ decltype(x+y) xpy = x + y; //xpy 的类型由 decltype 智能确定（类似 auto ）} 后置返回类型```cpptemplate &lt;typename T1, typename T2&gt;?type? sum(T1 x, T2 y){ return x+y;}//此时还没有声明参数 x 和 y//不能将返回类型 decltype(x + y)//但可以用后置返回类型template &lt;typename T1, typename T2&gt;auto sum(T1 x, T2 y) -&gt; decltype(x + y){ return x+y;}//decltype 在参数声明后面//因此 x 和 y 位于作用域，可以使用它们```函数重写（也称为覆盖）之前的函数重载通常指同一个类中行为（也有非类成员函数）。而函数重写体现的是父类和子类之间的多态性、子类重新定义父类中有相同名称及参数列表的虚函数（虚函数只是一个声明）。重写函数必须具有相同的函数头（只是重写函数体及其访问修饰符而已） 被重写的函数不能是 static 的，必须是 virtual 的 重写函数必须有相同的类型、名称和参数列表（即相同的函数原型） 重写函数的访问修饰符可以不同，尽管 virtual 是 private 的，派生类可以重写为 public等函数重定义（也称为隐藏）子类重新定义父类中有相同名称的非虚函数（参数列表可以不同，貌似是重载和重写思想的杂交）。此时的同名函数匹配次序参照重载函数的匹配顺序，不过此时子类中函数的优先级要大于父类。父类和子类完全匹配（参照函数重载）时，直接调用子类中的函数，相当于父类的函数被隐藏。函数重定义只是名字相同而已，分别位于派生类与基类" }, { "title": "C++ 基础知识总结", "url": "/2016/09/C++-basic.html", "categories": "C++/C-心得", "tags": "Cpp", "date": "2016-09-05 23:36:02 +0800", "snippet": " C++ 在 C语言的基础上添加的类代表的面向对象语言、C++ 模板支持的泛型编程。从 C 过渡到 C++ 的学习量就像从头学习 C 语言一样大。而且需要摒弃一些编程习惯。C 提供了低级硬件访问， OOP 提供了高级抽象。 C 语言编程的思想 OOP（面向对象） 泛型编程 C++ 的基本元件 语句和数据类型 数组 ...", "content": " C++ 在 C语言的基础上添加的类代表的面向对象语言、C++ 模板支持的泛型编程。从 C 过渡到 C++ 的学习量就像从头学习 C 语言一样大。而且需要摒弃一些编程习惯。C 提供了低级硬件访问， OOP 提供了高级抽象。 C 语言编程的思想 OOP（面向对象） 泛型编程 C++ 的基本元件 语句和数据类型 数组 使用 typedef 简化声明 字符串 指针的危险 指针和 const 注释 转义序列 函数 库函数 递归函数 函数参数和按值传递 函数返回值 结构 循环结构 选择结构 break 和 continue 语句 头文件 命名(名称)空间 变量声明和变量命名规则 类 内存空间的划分 static 变量作用域 各类型变量的比较 C 语言编程的思想面向过程、结构化编程、自顶向下进行设计、任务分解。其中面向过程需要处理两个概念，即数据和算法。数据是程序使用和处理的信息，而算法是程序使用这些信息的方法。这种结构化编程理念提高了程序的清晰度、可靠性，并使之便于维护，但面对编写大程序时，还是面临很大的挑战。OOP（面向对象）OOP 提供了一种新方法。与强调算法的过程性编程不同的是，OOP 强调的是数据。OOP 不像过程性编程语言，试图使问题满足语言的过程性方法，而是试图让语言来满足问题的要求。其理念是设计与问题的本质特性相对应的数据格式（类）。在 C++ 中类是一种规范，它描述了这种新型数据格式，对象是根据这种规范构造的特定的数据结构。OOP 程序设计方法首先设计类，它们准确地表示了程序要处理的东西。但不仅仅是将数据和方法合并为类定义。还有比如信息隐藏、类扩展继承等。C++ 真正的优点之一就是，可以方便地重用和修改现有的、经过仔细测试的代码。泛型编程它与 OOP 的目标相同，都使得重用代码和抽象通用概念的技术更简单。不过 OOP 强调的是编程的数据方面，而泛型编程强调的是独立于特定数据类型，它们的侧重点不同。 OOP 是一个管理大型项目的工具，而泛型编程提供了执行常见任务（如数据排序）的工具。术语泛型指的是创建独立于类型的代码。C++ 的基本元件理解并掌握下面的基本元件，有助于将 C++ 内化，也有利于对其他的 OOP 语言的学习。语句和数据类型语句实际上是计算机的一条或多条机器指令的合集。数据类型是一种比较小的临时存储空间，这种空间就有首地址和存储大小，而且首地址由数据类型对应的变量指认，存储大小则由数据类型确定（如int、long所占空间不一样），同时数据类型绑定了运算（如int由四则运算，而string就没有）。C++ 中，任何值或任何有效的值与运算符的组合都是表达式。语句是表达式后面紧随分好(;),但语句去掉分号不一定是表达式，如 int count;需要注意的是，当使用不同编译器或跨平台时，编译器或其他操作系统定义的数据类型的长度不一样，会导致预想的表示范围有出入，很有可能导致越界处理失败，为了防止类似错误，可以使用sizeof 测试出关心的数据类型的长度。为了跨平台，建议使用比如，#define INT int 之类的方法，这样需要修改时，只用改一条语句就可以了（比如改成 #define INT long 以弥补表示范围的不同）数据类型中 int 是计算机中“最自然”的类型，没有特殊需要建议使用 int ，当大量数组出现时，能满足需要的情况下建议使用 short（因为跨平台时，若使用 int可能导致需要的内存加倍），只需要一个字节的数据，建议使用 char ，因为可以最大限度节约存储空间。还需要注意的是，常数后面最好使用后缀，如 const int n = 10u;，在使用浮点运算时，一定要注意计算机精度是有限的，此时必须知道浮点数在计算机中的表示。c++ 中存在隐性数据类型转换，不过其自动转换的原则是：保持数据的最大精度(小字节往大字节装，启用临时空间)，最后结果再强制类型转换。所以在自己强制转换时需要考虑精度损失。其中强制类型转换有两种方式： (int)dScore; static_cast(dScore);在国际编程一般使用宽字节类型 wchar_t, char16_t, char32_t数组数组可以看做同类型变量的集合，这些变量可以通过数组下标找到。c++ 11 提供了新特性。初始化可以省略 = ，如果不初始化，则编译器会自动初始化 0用指针遍历数组指针能遍历数组是因为：数组实质上是同类型的变量集合，也就是说有独立的地址，而且这些变量连续存储，间隔该类型的字节数，这样通过指针加减就可以引用数组中的变量了。【注意】 指针加 1 ，指的是下一个类型单元（如 int））。类型不同，一个类型单元代表的字节数一般也不同。使用指针引用数组时，要明确数组名是数组的首地址，指针名是地址,*指针名是指针指向的变量（内容）。数组的替代品 模板类 vectorvector 是使用 new 创建动态数组的替代品。实际上，vector 类确实使用 new 和 delete 来管理内存，但这种工作是自动完成的。 模板类 arrayarray 对象的长度和数组一样也是固定，也使用栈，但它使用起来更方便更安全（该类实现了一些基本的数组操作，如排序、整体赋值等）使用 typedef 简化声明typedef 让你能够创建类型别名，然后使用别名来简化代码。示例如下：字符串单引号（''）和双引号（\"\"）是不一样的，单引号表示字符，双引号表示字符串（系统自动添加'\\0'）。语句实际上是计算机的一条或多条机器指令的合集。数据类型是一种比较小的临时存储空间，这种空间就有首地址和存储大小，而且首地址由数据类型对应的变量指认，存储大小则由数据类型确定（如int、long所占空间不一样），同时数据类型绑定了运算（如int由四则运算，而string就没有）。计算机程序在存储数据时必须跟踪的3种基本属性，如下： 信息存储在何处 存储的值为多少 存储的信息是什么类型指针的危险在 C++ 中创建指针时，计算机将分配用来存储地址的内存，但不会分配用来存储指针所指向的数据内存，为数据提供空间是一个独立的步骤。如果没有指定指针指向的数据空间，则指向的空间是随机的（该指针单元里的内容可能是以前遗留下的，然后被解读为地址）。指针不是整型，虽然计算机通常把地址当作整数来处理。从概念上看，指针与整数是截然不同的类型，整数是可以执行四则运算等的数字，而指针描述的是位置，将两个地址相乘没有任何意义，可见，不能简单地将整数赋给指针，必须进行强制类型转化，如：int * pt = null;pt = (int *)0xB800000;我们知道，不论什么类型的指针，其本身所占的字节数是相等的，那为什么还必须声明指针所指向的类型呢？原因如下：地址（指针）本身只指出了数据存储地址的开始，而没有指出其类型（使用的字节数），这样就无法知道该存储空间的结束位置。指针和 const指针有点通配符的意味！关键字 const 用于指针有两种不同的方式： 让指针指向一个常量对象，以防止使用该指针来修改所指向的值。如下例： int iAge = 20;//iAge 可被修改 const int* p_iAge = &amp;iAge;// *p_iAge 不可修改 【注意】 常规指针不能指向常规常量地址！如下图： 将指针本身声明为常量，以防止改变指针指向的位置。示例如下：上图中，在最后一个声明中，关键字 const 的位置与以前不同。这种声明格式使得 finger 只能指向 sloth，但允许使用 finger 来修改 sloth 的值。中间的声明不允许使用 ps 来修改 sloth 的值，但允许将 ps 指向另一个位置。简而言之，finger 和 *ps 都是 const，而 *finger 和 ps 不是如何区分这两种情况： 根据优先级。* 的优先级高，在这里作为分割符 * 右边是指针名和指针类型（判断指针类型时，把指针名去掉），左边是指向的变量的类型 左边变量类型*右边指针类型，相当于变量 &lt;- 指针（&lt;-表示指向，即*）注释注释有//行注释和/*注释*/。注释的目的是增加程序可读性，不参与编译运行等程序操作。转义序列转义序列是为了输入在键盘上没有的特殊字符或者是那些已经被赋予特定含义的字符，当需要输入这些键盘上没有的字符或需要赋予其非特定意义时，就需要转义序列协助。函数函数是一个模块，它描述了与其他模块的交互接口，包括入口（函数名、参数）和出口（返回值），同时实现了入口到出口的处理逻辑（即函数体）。它实际上是面相过程语言对过程的一种封装，也是被引用的一种功能单元或内存区块。其中内存区块的首地址由函数名指认，区块大小由函数体所占字节确定，而且函数体的花括号制定了区块的边界。该区块一旦被调用之后就会失去动态特性，即函数体申请的空间都被释放而不能返回（因为其生命周期已经结束）不要混淆函数原型和函数定义。函数原型（函数头并加之后随分号）只是描述了函数接口，而函数定义则包含了函数的代码。要使用 C++ 函数，必须完成如下工作： 提供函数定义 提供函数原型 调用函数那为什么需要函数原型？原型描述了函数到编译器的接口。原型协助编译器高效捕获少参数或函数不存在等错误。有人会说，为什么不让编译器自己在源文件搜索，这样就知道了（因为函数原型可以认为是函数头尾随分号形成）。不过这样既低效，编译器在搜索文件的剩余部分时将必须停止对 main() 的编译。一个更严重的问题的是：函数甚至可能并不在文件中。C++ 允许讲一个程序放在多个文件中，单独编译这些文件，然后再将它们组合起来（这也是库函数为什么编译好，然后调用库函数要先包含对应的头文件—-函数原型已经写在里面了）。在这种情况下，编译器在编译 main() 时，可能无权访问函数代码（如库函数无源代码）。 避免使用函数原型的唯一方法是：在首次使用函数之前定义它。（但破坏了自顶向下的设计理念） 避免重复声明函数原型的方法：把函数原型写在不同的头文件中，然后包含进来。（没有用到的函数会被编译器过滤掉）库函数库函数是已经定义和编译好的函数，同时可以使用标准库投稳价提供其原型，因此只需正确地调用这种函数即可。递归函数如果递归函数调用自己，则被调用的函数也将调用自己，这将无限循环下去，除非代码中包含终止调用链的内容，通常的方法将递归调用放在 if 语句中。函数参数和按值传递上图告知，函数参数属于函数的局部变量，可以与其他函数中的变量重名（但作用域可以识别）。当函数参数为数组时，可以用数组名指出该参数是数组，在指明数组的长度。如：int sum_arr(int arr[], int n);//传递的是数组的首地址再如：int sum_arr(int *arr, int n);// arr 为数组名在用指针操作数组时，要记住下面两个恒等式： arr[i] == *(ar + i) // ar 为指向 arr 的指针 &amp;arr[i] == ar + i【注意】：接收数组名参数的函数访问的是原始数组，而不是其副本（只不过用来接收数组名的指针是副本而已）。void show_array(const int array[], int n);//加 const 禁止该函数对数组 array 进行修改void show_array(const int* begin, const int* end);函数返回值注意函数返回时只是拷贝了函数内部变量的值，并将其复制到新建的临时变量中，如果不是指针时可以得到想要的内容的，但如果返回的是指针： 指针指示的内存在栈区（如函数内部的临时数组），那么函数返回时只是复制了一份地址，但该地址指示的存储空间可能找不到或被系统自动释放或被覆盖。这样就得不到想要的结果了。 指针指示的内存在非堆区（如堆区、全局区等），那么是可以找到相应的存储位置的，返回结果有效。C++ 对于返回值的类型有一定的限制：不能是数组，但可以是其他任何类型—整数、指针等，甚至可以是结构和对象(即在函数内部定义的结构体等也可以返回，不过此时使用的是副本，所以但结构等比较大时，不建议这样做，因为此时复制成副本开销大)！有趣的是，虽然 C++ 函数不能直接返回数组，但可以将数组作为结构或对象成员部分来返回。当结构体等较大时，建议传递地址而不是结构体，以提高效率。但此时是对```原结构体等```进行操作！结构所谓结构指的是程序语句的组织逻辑。一般包括：顺序结构、选择结构、循环结构。这些结构都是可以相互嵌套的！循环结构循环实际上和函数类似，也是一种功能代码块，也有入口和出口及内部处理逻辑。只不过其入口和出口在循环块前面和后面。需要注意的，在循环内部声明的变量在循环块外部是不可用的，和函数内部声明的变量同属于局部变量，受制于花括号（一种作用域界定符）。 for 循环for 循环为执行重复的操作提供了循序渐进的步骤。这些步骤如下：1、设置初始值；2、执行测试、看看循环是否应当继续进行；3、执行循环操作；4、更新用于测试的值（可以借助步长）。基于范围的 for 循环这种基于范围的 for 循环简化了一种常见的循坏任务：对数组（或容器类、如 vector 何 array）的每个元素执行相同操作。示例代码如下：double prices[5] = {4.99, 10.99, 6.87, 7.88, 8.68};for (double x : prices) cout &lt;&lt; x &lt;&lt; std::endl; while 循环 do-while 循环选择结构 if if-else switch为提高可读性，可以结合枚举类型做 case 。示例如下：#include &lt;iostream&gt;enum {red, orange, yellow, green, blue, violet, indigo};int main(){ using namespace std; cout &lt;&lt; \"Enter color code (0-6): \"; int code; cin &gt;&gt; code; while (code &gt;= red &amp;&amp; code &lt;= indigo) { switch (code) { case red: cout &lt;&lt; \"red!\\n\"; break; case orange: cout &lt;&lt; \"orange!\\n\"; break; case yellow: cout &lt;&lt; \"yellow!\\n\"; break; case green: cout &lt;&lt; \"green!\\n\"; break; case blue: cout &lt;&lt; \"blue!\\n\"; break; case violet: cout &lt;&lt; \"violet!\\n\"; break; case indigo: cout &lt;&lt; \"indigo!\\n\"; break; } cout &lt;&lt; \"Enter color code (0-6): \"; cin &gt;&gt; code; } cout &lt;&lt; \"Bye\\n\"; return 0;}break 和 continue 语句Break 和 continue 语句都能够跳过部分代码。 可以在 switch 语句或任何循环中使用 break 语句，使程序跳到 switch 或循环后面的语句处执行。 continue 语句用于循环中，让程序跳过循环体重余下的代码，并开始新一轮循环上图程序中的 if 语句实际上相当于控制循环入口或出口的测试语句。由上图可知，break 和 continue 的区别。 都是跳过循环体中其后的代码 break 跳过之后不继续（即终止）循环，而 continue 则继续新的循环。头文件头文件可以看做是支持一组特定功能的工具，它会被包含在源文件或其他头文件中。编译时会原样替换#include指令所在的位置，链接时会查询包含该头文件的源文件中涉及到的库函数，如果没有包含头文件会编译或链接错误。需要注意的是自己写的头文件要用预处理指令防止被重复包含，否则会出现错误（可能出现重定义等，主要是作用域导致的）。之所以在 C++ 中要使用头文件，最主要的原因是 C++ 的同一个项目可能有多个源代码文件，要命的是这些源代码是分别单独编译的。也就是说，在编译其中一个文件时，编译器并不知道其它文件中定义的内容，如类、全局变量等。这就要求我们必须在要使用某个类、函数或变量的每个文件中声明它，否则 C++ 是无法找到它的。 很多文件可能都需要使用同一个函数。假设有一个文件 b.cpp 需要使用这个函数，那么，它必须先声明它，虽然不需要再重写。如果有很多文件都要使用这个函数，那么这会变得麻烦，特别的，如果你写了一个类，那么你需要维护大量的声明（对于每一个 public 对象），并且如果你的类的定义发生了改变，你可能不得不改变无数个声明。所以，C++ 语言提出了头文件的概念。你只需要在头文件中声明一次，在实现文件中定义一次，在所有需要用的文件中，就只需要引用这个头文件，相当于每个文件都包含了一个声明。为了防止头文件的重复包含，通常应该使用预处理指令 #define （定义符号）、#ifndef（如果没有定义）、#endif（结束判断）来书写头文件的内容。请理解如下的例子，它是对上个笔记中的 Xiao 类的改进。命名(名称)空间为了组织重用代码而引入的。前面我们谈到了头文件，可能出现你包含的两个头文件或源文件中含有同名的 public 方法，那么就产生二义性了，如果你想都用（可能这同名的方法功能不一样），那怎么办呢？最好的办法就是在方法前加不同的前缀，这样就可以区分了。这样就不怕重用来源不同的代码时出现命名冲突了。C++ 中用 using namespace 这个编译指令来实现命名空间的使用。如 using namespace std; 不过若只使用该命名空间的少量方法时，比如使用cout、cin等，可以： using namespace std::cout; using namespace std::cin;这样就可以直接使用cout，cin了，否则必须std::cout，std::cin。如果按前面 using namespace std; 这样的话，就会失去命名空间的意义了（无法避免冲突）。自定义命名空间的方法如下：namespace nsdebug //名字空间nsdebug是在别的文件里定义的{ int GetStringWidth(char* s); int GetCellValue(int x,int y);}假设不同命名空间有相同的方法，而且要在不同程序段使用。这样可以推荐两种方法： 命名空间::方法进行区别使用 using namespace 命名空间 1 ;//使用命名空间 1 中的方法之后再 using namespace 命名空间 2 ;使用命名空间 2 中的方法变量声明和变量命名规则声明通常指出了要存储的数据类型和程序对存储在这里的数据使用的名称。事实上，使用声明可以防止拼写错误，一旦拼写错误，由于该“错误拼写成的变量”没有声明就使用了，编译器会报错，从而提醒编程者出现了拼写错误。变量名命名时一定要做到见名知意，而且要遵守以下规则： 名称中只能含有字符、数字和下划线 名称第一个字符不能是数字 区分大小写字符 不能使用 C++ 关键字用作变量名 以两个下划线和大写字母打头的名称被保留给实现（编译器及其使用的资源）使用，以一个下划线开头的名称被保留给实现，用作全局标识符。 名称不易过长，过长会导致输入量变大、而且有些平台对长度有限制。 最好使用前缀表明该变量的类型（如int iCount）变量名命名时一定要做到见名知意，包括该变量的类型和意义。下面是具体的前缀规则： 数据类型 前缀 例子 int i int iCount; short s shout sValue; unsigned u unsigned int uiAge; long l long lValue; float f float fScore; double d double dValue; char ch char chChar; char [] sz char szName[30]; string str string strName; bool b bool bPass; 一级指针 p_ int *p_iValue; 二级指针 pp_ int **p2_iValue; 一维数组 a_ int a_iArray[20] 二级数组 a2_ int a2_iArray[2][4] byte by byte byInfo; 类成员变量 m_ int m_iValue; 全局变量 g_   静态变量 s_   vector v_ vector v_iValue; enum em enum emWeek; bit bt bit btBit struct st sruct stStudent; 函数 fn void fnProc(void); 常量 全部大写 const int iMAX=100; 指针数组 ap_ int *p[2]; 数组指针 pa_ int (*p)[2]; 类类是用户定义的一种数据类型，要定义类，就需要描述它能够表示什么信息和可对数据执行哪些操作。换句话说，类描述了一种数据类型的全部（静态和动态）属性（包括对这些属性执行的所有操作），对象是根据这些描述创建的实体。类和对象的关系，就像数据类型和变量的关系。数据类型定义了数据格式，但是没有数据，当然也就不能执行数据操作，可见数据类型是静态的，变量是动态的。内存空间的划分 栈区（stack，系统提供）：由编译器自动分配释放（如 auto 声明的变量） ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。 堆区（heap，函数库提供）：一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表int * pa_iSome = new int [10]; // get a block of 10 intsdelete [] pa_iSome;当程序使用完 new 分配的内存块时，应使用 delete释放它们。然而，对于 new 创建的数组，应使用另一种格式来释放（见上面的例子）。方括号告诉程序，应释放整个数组，而不仅仅是指针指向的元素。 全局区（静态static区）：全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束后有系统释放。该内存在程序编译时就已经分配好，并在程序的整个运行期间都存在。 文字常量区：常量字符串就是放在这里的。 程序结束后由系统释放。 程序代码区：存放函数体的二进制代码下面给出识别存储区域的例子： int a=1; a在栈区 char s[]=”123”; s在栈区，“123”在栈区，其值可以被修改 char *s=”123”; s在栈区，“123”在常量区，其值不能被修改 int *p=new int; p在栈区，申请的空间在堆区（p指向的区域） int *p=(int *)malloc(sizeof(int)); p在栈区，p指向的空间在堆区 static int b=0; b在静态区staticstatic 用来控制变量的存储方式和可见性我们知道存储空间有以下规则： 所属存储区域（如堆、栈等） 访问权限控制（如公有、私有等） 访问方式（如可读、可写） 存储空间大小（定义该空间的边界） 存储空间的首地址（保证可以找到该空间） 存储的内容类型（如整型、字符串等） 初始化方式（如只可初始化一次）。静态数据成员要在程序一开始运行时就必须存在，因为函数在程序运行中被调用，所以静态数据成员不能再任何函数内分配空间和初始化。这样，它的空间分配有三个可能的地方： 是作为类的外部接口的头文件，那里有类声明； 是类定义的内部实现，那里有类的成员函数定义； 是应用程序的main（）函数前的全局数据声明和定义处。静态数据成员要实际地分配空间，故不能在类的声明中定义（只能声明数据成员）。类声明只声明一个类的“尺寸和规格”，并不进行实际的内存分配，所以在类声 明中写成定义是错误的。它也不能在头文件中类声明的外部定义，因为那会造成在多个使用该类的源文件中，对其重复定义。static被引入以告知编译器，将变量存储在程序的静态存储区而非栈上空间，静态数据成员按定义出现的先后顺序依次初始化，注意静态成员嵌套时，要保证所嵌套的成员已经初始化了。消除时的顺序是初始化的反顺序。static函数与普通函数有什么区别：static函数与普通函数作用域不同，只在定义该变量的源文件内有效；变量作用域变量的有效作用域从它的定义点开始，到和定义变量之前最邻近的开括号配对的第一个闭括号。也就是说，作用域由变量所在的最近一对括号确定。需要提醒的是，文件的首末可以认为是一对花括号。 全局变量（本程序中共享）：全局变量是在所有函数体的外部定义的，程序的所在部分（甚至其它文件中的代码）都可以使用。全局变量不受作用域的影响（也就是说，全局变量的生命期一直到程序的结束）。如果在一个文件中使用extern关键字来声明另一个文件中存在的全局变量，那么这个文件可以使用这个数据。 局部变量（作用域为闭花括号为界）：局部变量出现在一个作用域内，它们是局限于一个函数或代码块（用{}包起来，如 for 循环）。局部变量经常被称为自动变量。它的作用域是从定义开始到最近的闭花括号结束。在函数原型作用域中：1、只在包含参数列表的括号内可用2、所以这些名称是什么以及是否出现都不重要 寄存器变量：寄存器变量是一种局部变量。关键字register告诉编译器“尽可能快地访问这个变量”。加快访问速度取决于现实，但是，正如名字所暗示的那样，这经常是通过在寄存器中放置变量来做到的。这并不能保证将变置在寄存器中，甚至也不能保证提高访问速度。这只是对编译器的一个暗示。使用 register 变量是有限制的： 不可能得到或计算register 变量的地址; register 变量只能在一个块中声明（不可能有全局的或静态的 register 变量）。然而可以在一个函数中（即在参数表中）使用 register 变量作为一个形式参数。一般地，不应当推测编译器的优化器，因为它可能比我们做得更好。因此，最好避免使用关键字 register。 静态变量（只初始化一次，下一次依据上一次结果值）：通常，函数中定义局部变量在函数中作用域结束时消失。当再次调用这个函数时，会重新创建变量的存储空间，其值会被重新初始化。关键字static有一些独特的意义。静态局部变量如果想使局部变量的值在程序的整个生命期里仍然存在，我们可以定义函数的局部变量为static(静态的)，并给它一个初始化。初始化只在函数第一次调用时执行，函数调用之间变量的值保持不变，这种方式，函数可以“记住”函数调用之间的一些信息片断。这也就是所谓的静态局部变量，具有局部作用域，它只被初始化一次，自从第一次被初始化直到程序运行结束都一直存在，它和全局变量的区别在于全局变量对所有的函数都是可见的，而静态局部变量只在定义自己的函数体内始终可见。static局部变量的优点是在函数范围之外它是不可用的，所以它不可能被轻易改变。这会使错误局部化。静态全局变量（仅本文件中可见）具有全局作用域，它与全局变量的区别在于如果程序包含多个文件的话，它作用于定义它的文件里，不能作用到其它文件里，即被static关键字修饰过的变量具有文件作用域。这样即使两个不同的源文件都定义了相同名字的静态全局变量，它们也是不同的变量。当 static 全局变量放在头文件中，并且两个源文件都包含了该头文件，那么该 static 全局变量的作用域分别是这两个源文件(而全局变量将为这两个源文件共享)。 外部变量extern 告诉编译器存在着一个变量和函数(不论是全局的还是静态全局的)，即使编译器在当前的文件中没有看到它。这个变量或函数可能在一个文件或者在当前文件的后面定义。例如 extern int i; 编译器会知道 i 肯定作为全局变量(或者静态全局)存在于某处。当编译器看到变量 i 的定义时，并没有看到别的声明，所以知道它在文件的前面已经找到了同样声明的 i 。外部变量的作用域(决定于它引用的变量作用域)：1、如该变量是全局变量(extern 后不能加 static)，则为本程序2、如该变量是静态全局变量(extern 后可以省略 static)，则为本文件 const 变量(只读，所以必须定义时初始化)const 告诉编译器这个名字表示常量，不管是内部的还是用户定义的数据类型都可以定义为 const。如果定义了某对象为常量，然后试图改变它，编译器将会产生错误。在 C++ 中一个 const 必须有初始值。const 变量的作用域：决定于它的定义位置，参照“局部变量”和“全局变量”。mutable关键字的作用：可以用它来指出，即使结构体(或类)变量为 const，用 mutable 关键字修饰的变量的值也是可以改变的。各类型变量的比较各类型变量(B)的比较，列表如下：   全局变量 静态全局B 局部变量 静态局部B 静态存储区 Y Y N (栈区) Y 存储位置数 一处 一文件一处   局部一处 作用域 本工程 本文件 定义-&gt;闭} 同局部B 定义处初始化   一次   一次 与extern结合 Y(不能加static) Y(可省static) N N 默认初始化 Y Y N Y 值是否可修改 Y Y Y Y " }, { "title": "vim 常规操作", "url": "/2016/07/vim-skill.html", "categories": "高效工具", "tags": "Vim", "date": "2016-07-09 06:21:49 +0800", "snippet": " 本文旨在介绍 vim 的操作技巧，以便最大程度的提高编码效率。 Ubuntu 终端快捷键 打开终端 终端 tab 管理 编辑 vim 快速配置 安装终端常用工具 配置vim 美化终端 插件便利功能 通用 go 语言 vim 高效率操作 ...", "content": " 本文旨在介绍 vim 的操作技巧，以便最大程度的提高编码效率。 Ubuntu 终端快捷键 打开终端 终端 tab 管理 编辑 vim 快速配置 安装终端常用工具 配置vim 美化终端 插件便利功能 通用 go 语言 vim 高效率操作 模式 普通模式 修改 删除 选择 复制 粘贴 移动 查找 折叠 缩进 撤销或重做 v 模式（块模式 Ctrl+v 或 字符模式 v） 命令模式（Esc+:） 插入模式（Esc+i） 补全菜单 行选模式（shift+v） 多文件或缓冲区 多缓冲区 多标签页 窗格分割 窗格关闭 调整窗口大小 切换和移动窗口 简便操作 重复操作（.） 数字的增减 命令配合数字使用 Ubuntu 终端快捷键这里我们会给出 Ubuntu 终端常用的快捷键。通常，我们会在终端下使用 vim，掌握这些终端快捷键可以节省多余操作，间接提高 vim 编程效率。打开终端 用户根目录下打开新的终端：Ctrl+Alt+T 打开新的终端 tab 页：Ctrl+Shift+T终端 tab 管理 跳转到指定编号的 tab（1-9）页： Alt + 1、Alt + 2 等 前一个/后一个 tab 页：ctrl + pageUp 或 ctrl + pageDown 关闭 tab 页：Ctrl+Shift+w 全屏：F11 独立屏幕之间切换：Alt+Tab 左移右移标签页：Shift+Ctrl+PgUp/PgDn 清除屏幕文字：Ctrl+L 搜索：~Ctrl+Shift+F` 屏幕向上/下滚动：Shift+PgUp/PgDn 暂停屏幕输出：Ctrl+S 继续屏幕输出：Ctrl+Q编辑 复制：Shift+Ctrl+C 粘贴：Shift+Ctrl+V 移动到行首：CTRL + A 移动到行末：CTRL + E 在输入历史中搜索：CTRL + R + 文本 向上显示缓存命令：Ctrl+p 终止当前任务：Ctrl+C 把当前任务放到后台运行（相当于运行命令时后面加&amp;）: Ctrl+Z 显示后台运行的任务: fg 向下显示缓存命令：Ctrl+n 删除此处至末尾的所有内容：Ctrl+k 删除此处至开始的所有内容：Ctrl+u 删除此处到左边的单词：Ctrl+w 删除当前字符：Ctrl+d 删除当前字符前一个字符：Ctrl+h 向回移动光标：Ctrl+b 向前移动光标：Ctrl+f 恢复删除的内容：Ctrl+&amp;vim 快速配置接下来用 macOS 作为例子，在新机器上，使用 vim 打造高效开发环境。安装终端常用工具使用 vim 打造开发环境，往往还需要借助终端组件或插件来实现。在安装过程中，需要根据提示设置环境变量等，以便能够找到相应的命令。 安装包管理工具brew：/bin/bash -c “$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)” 逐个安装以下工具软件，并根据提示设置环境变量# 安装gitbrew install gitcargo install git-deltabrew install lazygit# 把~/.ssh中的私钥公钥文件拷贝过来或者重新生成（注意文件权限要正确）# 执行命令 git config --global --edit# 把原有的 git config 配置拷贝进去，适当调整，不要有重复# 配置全局或仓库的user和email# 拉代码，并 git fetch —all 验证# 可能需要 git ls-remote -q origin in 路径，来产生fingerprint（会自动写入~/.ssh/known_hosts文件）# 配置可参考# https://github.com/dandavison/delta# https://code-winder.github.io/2022/04/git-jump.html# 安装rustbrew install rustupbrew install ruby-buildrustup component add rust-src rustup component add rust-analyzer# 安装 tmuxbrew install tmux# 配置 tmuxhttps://github.com/gpakosz/.tmux# 安装neovimbrew install neovimbrew install vim# 安装node.jsbrew install nodes# 安装dockerbrew install --cask docker# 安装截图工具brew install --cask snipaste# 安装搜索工具# agbrew install the_silver_searcher# ackbrew install ackbrew install ripgrep# 安装hosts管理工具# 从原来的switchhosts导出hosts再在新电脑中导入brew install --cask switchhosts# 安装sougo输入法brew install --cask sogouinput配置vim安装以下组件：# 安装 SpaceVim# 参考以下网址https://spacevim.org/cn/quick-start-guide/# 安装 vim-import-js# 参考以下网址https://github.com/Galooshi/vim-import-js# 配置开发工具brew install plantumlbrew install ctags# 用于编译 go 程序，特别是有linux依赖的docker pull golang# 配置jekyllgem install jekyllgen install bundler# 先clone博客项目# 在jekyll博客项目中执行bundler installjekyll s# 安装ycm依赖brew install cmakebrew install llvmbrew install monobrew install go@1.19brew install golangci-lintbrew install gometalinter# 配置go env，把之前的配置在新机器上配置一遍，特别是# go mod tidy 验证git 和 host 配置（可以ping 域名）brew install openjdk # 打开vim后会自动安装所需插件# 有问题时可参考 https://github.com/ycm-core/YouCompleteMe#installation# 如果nvim无法使用ycm，可以在nvim最下方的命令行执行 :CheckHealth 得到帮助修复# 如果编译ycm出错，可以根据提示解决或修改 third_pard/ycmd/build.py# 设置python3命令的路径，用which python3查看# let g:python3_host_prog='/opt/homebrew/bin/python3'配置 SpaceVim 工具。vi ~/.SpaceVim.d/init.toml 之后添加如下配置#=============================================================================# dark_powered.toml --- dark powered configuration example for SpaceVim# Copyright (c) 2016-2020 Wang Shidong &amp; Contributors# Author: Wang Shidong &lt; wsdjeg at 163.com &gt;# URL: https://spacevim.org# License: GPLv3#=============================================================================# All SpaceVim option below [option] section[options] # set spacevim theme. by default colorscheme layer is not loaded, # if you want to use more colorscheme, please load the colorscheme # layer # colorscheme = \"solarized8\" colorscheme = \"solarized8\" colorscheme_bg = \"dark\" # Disable guicolors in basic mode, many terminal do not support 24bit # true colors enable_guicolors = true # Disable statusline separator, if you want to use other value, please # install nerd fonts statusline_separator = \"arrow\" statusline_iseparator = \"arrow\" buffer_index_type = 4 enable_tabline_filetype_icon = true enable_statusline_mode = false bootstrap_before = \"myspacevim#before\" bootstrap_after = \"myspacevim#after\" autocomplete_method = \"ycm\" enable_ycm = true snippet_engine = \"ultisnips\" autocomplete_parens = true filemanager = \" \" #为了禁用报错的插件 nerdtree default_indent = 2 expand_tab = true # 注意：python 不能这么搞# disabled_plugins = [\"preservim/nerdtree\"]# [[custom_plugins]]# name = 'Xuyuanp/nerdtree-git-plugin'[[layers]] name = \"checkers\"[[layers]] name = \"colorscheme\"# solarize 主题[[custom_plugins]] repo = \"lifepillar/vim-solarized8\" merged = 0[[custom_plugins]] repo = \"flazz/vim-colorschemes\" merged = 0# Enable autocomplete layer[[layers]] name = 'autocomplete' auto_completion_return_key_behavior = \"complete\" auto_completion_tab_key_behavior = \"smart\" # cpp ycm 配置文件产生器，终端中makefile同级目录下 config_gen.py .# vim 中 :YcmRes 重启 ycm 服务[[custom_plugins]] name = \"rdnetto/YCM-Generator\"# [[layers]]# name = 'shell'# default_position = 'top'# default_height = 30[[layers]]name = 'lang#c'[[layers]]name = 'lang#go'[[custom_plugins]]name = \"fatih/vim-go\"[[layers]]name = 'lang#html'[[layers]]name = 'lang#javascript'# 如果 fzf 相关命令提示不存在，可以更新一下：SPUpdate fzf[[layers]]name = \"fzf\"# FFiles [PATH]# Ag [PATTERN]# Rg [PATTERN]]# History 历史buffer# History: 历史命令# Marks# Commits 搜索该仓库的提交记录# BCommits 与当前buffer相关的提交记录# Commands 可以使用的vim命令列表# Maps 快捷键列表[[custom_plugins]]name = \"junegunn/fzf.vim\"[[layers]] name = \"lang#toml\"[[layers]] name = \"lang#plantuml\"[[layers]] name = \"lang#xml\"# git 浏览插件# Git 为前缀，其他同 git# Gdiff 左右分栏比较当前文件改动很直观# Git log 很美观# 其他用 shell git 命令就行[[layers]]name = \"git\"git_plugin = 'fugitive'# 有多个 gitLab 地址的很难适配# Gbrowse 跳转到对应仓库网页[[custom_plugins]]name = \"shumphrey/fugitive-gitlab.vim\"# :Flog -all 查看各个分支之间的演化关系[[custom_plugins]]name = \"rbong/vim-flog\"[[layers]]name = \"tmux\"# Ack! 列出结果集且不消失[[custom_plugins]]name = \"mileszs/ack.vim\"# 异步浮动终端，# :fn yourCommand 执行命令# :fk 关闭浮动窗口# &lt;C-c&gt; 或者 :q 等也可以关闭[[custom_plugins]]name = \"voldikss/vim-floaterm\"#[[custom_plugins]]#name = \"tenfyzhong/CompleteParameter.vim\" # vim 中显示 cpp 帮助文档 [[custom_plugins]]name = \"gauteh/vim-cppman\"# 用下划线标注当前 word[[custom_plugins]]name = \"dominikduda/vim_current_word\"# 高亮单个文件感兴趣的word，结合 * 可以实现跨文件# 主要用到 \\k 和 \\K[[custom_plugins]]name = \"lfv89/vim-interestingwords\"# 注释代码# gcc: 注释一行或所选多行[[custom_plugins]]name = \"tpope/vim-commentary\"# Ranger 打开当前文件所在目录树状图[[custom_plugins]]name = \"francoiscabrol/ranger.vim\"# bd 关闭一个buffer[[custom_plugins]]name = \"rbgrouleff/bclose.vim\"# Deol 打开shell# exit 退出shell# :q 退出shell窗口[[custom_plugins]]name = \"Shougo/deol.nvim\"# git 结果美化工具[[custom_plugins]]name = \"dandavison/delta\"# 使用 \\\\ 前缀与 vim 常用的移动键，如 w、b、f、s、h、l 等# 例如定位一个字符 c，则可以 \\\\s 再根据提示输入c，再看提示# [[custom_plugins]]# name = \"easymotion/vim-easymotion\"[[custom_plugins]]name = \"ShengChangJian/a.vim\"[[custom_plugins]]name = \"ShengChangJian/vim-jekyll\"# 书签管理 https://github.com/MattesGroeger/vim-bookmarks# mm 对该行打mark或清除# mc 清除当前buffer的mark# mx 清除所有buffer的mark[[custom_plugins]]name = \"MattesGroeger/vim-bookmarks\"# undo 管理，命令前缀为 Mundo[[custom_plugins]]name = \"simnalamburt/vim-mundo\"[[custom_plugins]]name = \"gelguy/wilder.nvim\"# vim 中完成 LeetCode 刷题，命令前缀： LeetCode#[[custom_plugins]]#name = \"ianding1/leetcode.vim\"# 支持v模式，先选再对齐# gaip*= 对齐所有=# gaip2= 对齐第2个=# vipga=[[custom_plugins]]name = \"junegunn/vim-easy-align\"[[custom_plugins]]name = \"tmux-plugins/vim-tmux-focus-events\"# tmux 和 vim 窗口来回切换# &lt;C-h&gt;# &lt;C-j&gt;# &lt;C-k&gt;# &lt;C-l&gt;# &lt;C-p&gt;[[custom_plugins]]name = \"christoomey/vim-tmux-navigator\"# [[custom_plugins]]# name = \"907th/vim-auto-save\"配置自定义函数，vi ~/.SpaceVim.d/autoload/myspacevim.vimfunc! myspacevim#before() abort if has(\"termguicolors\") set t_8f=^[[38;2;%lu;%lu;%lum set t_8b=^[[48;2;%lu;%lu;%lum set termguicolors endif \" 设置python3命令的路径，用which python3查看 \" 供 ycm 使用 let g:python3_host_prog='/opt/homebrew/bin/python3' set cmdheight=2 \" Set cursor shape and color if &amp;term =~ \"xterm\" \" INSERT mode let &amp;t_SI = \"\\&lt;Esc&gt;[6 q\" . \"\\&lt;Esc&gt;]12;blue\\x7\" \" REPLACE mode let &amp;t_SR = \"\\&lt;Esc&gt;[3 q\" . \"\\&lt;Esc&gt;]12;black\\x7\" \" NORMAL mode let &amp;t_EI = \"\\&lt;Esc&gt;[2 q\" . \"\\&lt;Esc&gt;]12;green\\x7\" endif \" 1 -&gt; blinking block 闪烁的方块 \" 2 -&gt; solid block 不闪烁的方块 \" 3 -&gt; blinking underscore 闪烁的下划线 \" 4 -&gt; solid underscore 不闪烁的下划线 \" 5 -&gt; blinking vertical bar 闪烁的竖线 \" 6 -&gt; solid vertical bar 不闪烁的竖线 set cursorline cursorcolumn \" set wildmode=list:longest,full \" set wildmenu \" set wildmode=full \" set guifont=DroidSansMonoForPowerlinePlusNerdFileTypesMono:h14 set guifont=DejaVu\\ Sans\\ Mono\\ for\\ Powerline:h14 \"let g:spacevim_guifont = 'DejaVu\\ Sans\\ Mono\\ for\\ Powerline\\ 16' set guioptions-=r set tabstop = 2 filetype plugin indent on set rtp+=~/.fzfendffunc! myspacevim#after() abort \" a.vim 插件参数 let g:selfConfigPartPath= 'export:h:src' \"let g:alternateSearchPath= 'export,sfr:h,sfr:src,sfr' \" ianding1/leetcode.vim let g:leetcode_browser = 'firefox' let g:leetcode_china = 1 let g:leetcode_solution_filetype = 'golang' \" voldikss/vim-floaterm :cabbrev fn FloatermNew :cabbrev fk FloatermKill \" dominikduda/vim_current_word let g:vim_current_word#highlight_only_in_focused_window = 0 \" Twins of word under cursor: let g:vim_current_word#highlight_twins = 1 \" The word under cursor: let g:vim_current_word#highlight_current_word = 1 \"Ycm \"let g:ycm_confirm_extra_conf=0 let g:spacevim_enable_ycm = 1 let g:ycm_error_symbol = 'x' inoremap &lt;silent&gt;&lt;expr&gt; ( complete_parameter#pre_complete(\"()\") smap &lt;a-j&gt; &lt;Plug&gt;(complete_parameter#goto_next_parameter) imap &lt;a-j&gt; &lt;Plug&gt;(complete_parameter#goto_next_parameter) smap &lt;a-k&gt; &lt;Plug&gt;(complete_parameter#goto_previous_parameter) imap &lt;a-k&gt; &lt;Plug&gt;(complete_parameter#goto_previous_parameter) \"let g:ycm_collect_identifiers_from_comments_and_strings = 0 \"let g:ycm_add_preview_to_completeopt = 1 \"let g:ycm_autoclose_preview_window_after_completion = 1 \"let g:ycm_autoclose_preview_window_after_insertion = 1 nnoremap gt :YcmCompleter GoTo&lt;CR&gt; nnoremap gr :YcmCompleter GoToReferences&lt;CR&gt; nnoremap gv :YcmCompleter GetType&lt;CR&gt; nnoremap gc :YcmCompleter GetDoc&lt;CR&gt; \" 分词设置 set iskeyword=A-Z,97-122,48-57,95 \"set iskeyword-=*,&amp;,!,[,],&lt;,&gt;,=,(,),: set iskeyword-=33-47,58-64 set iskeyword-=: au FileType cpp set iskeyword-=33-47,58-64 au FileType cpp set iskeyword-=: au FileType cpp set iskeyword-=&lt; au FileType cpp set iskeyword-=&gt; au FileType cpp set iskeyword-=! au FileType cpp set iskeyword-=* au FileType cpp set iskeyword-=- au FileType cpp set iskeyword-=+ au FileType cpp set iskeyword-=/ au FileType go set iskeyword-=33-47,58-64 au FileType go set iskeyword-=: \" junegunn/vim-easy-align \" Start interactive EasyAlign in visual mode (e.g. vipga) xmap ga &lt;Plug&gt;(EasyAlign) \" \" Start interactive EasyAlign for a motion/text object (e.g. gaip) nmap ga &lt;Plug&gt;(EasyAlign) \" junegunn/fzf.vim :cabbrev Ag Ag &lt;C-R&gt;=expand(\"&lt;cword&gt;\")&lt;CR&gt;&lt;CR&gt; :cabbrev Rg Rg &lt;C-R&gt;=expand(\"&lt;cword&gt;\")&lt;CR&gt;&lt;CR&gt; \" Enable persistent undo so that undo history persists across vim sessions set undofile set undodir=~/.vim/undo command Todo Ack! '// TODO|// FIXME|// NOTE' \" lfv89/vim-interestingwords \" let g:interestingWordsRandomiseColors = 1 let g:interestingWordsTermColors = ['154', '121', '211', '137', '214', '222'] \" francoiscabrol/ranger.vim let g:ranger_replace_netrw = 1 \" open ranger when vim open a directory let g:ranger_command_override = 'ranger --cmd \"set show_hidden=true\"' \" ianding1/leetcode.vim let g:fugitive_gitlab_domains = ['https://git.bybit.com/'] \" ShengChangJian/vim-jekyll let g:jekyll_post_template = [ \\ '---', \\ 'layout: post', \\ 'title: \"JEKYLL_TITLE\"', \\ 'date: \"JEKYLL_DATE\"', \\ 'categories: \"JEKYLL_CATEGORIES\"', \\ 'tags: \"JEKYLL_TAGS\"', \\ '---', \\ ''] \" brew install ctags \" tagbar \" &lt;C-F2&gt; 打开tagbar窗口 let g:tagbar_type_go = { \\ 'ctagstype' : 'go', \\ 'kinds' : [ \\ 'p:package', \\ 'i:imports:1', \\ 'c:constants', \\ 'v:variables', \\ 't:types', \\ 'n:interfaces', \\ 'w:fields', \\ 'e:embedded', \\ 'm:methods', \\ 'r:constructor', \\ 'f:functions' \\ ], \\ 'sro' : '.', \\ 'kind2scope' : { \\ 't' : 'ctype', \\ 'n' : 'ntype' \\ }, \\ 'scope2kind' : { \\ 'ctype' : 't', \\ 'ntype' : 'n' \\ }, \\ 'ctagsbin' : 'gotags', \\ 'ctagsargs' : '-sort -silent' \\ } au FileType plantuml let g:plantuml_previewer#plantuml_jar_path = get( \\ matchlist(system('cat `which plantuml` | grep plantuml.jar'), '\\v.*\\s[''\"]?(\\S+plantuml\\.jar).*'), \\ 1, \\ 0 \\) \" Start NERDTree. If a file is specified, move the cursor to its window. \"将F3设置为开关NERDTree的快捷键 \" map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt; \"窗口位置 \" let g:NERDTreeWinPos='right' \"打开vim时自动打开NERDTree \" autocmd vimenter * NERDTree \"不显示隐藏文件 \" let g:NERDTreeHidden=0 \"打开vim时如果没有文件自动打开NERDTree \" autocmd vimenter * if !argc()|NERDTree|endif \"当NERDTree为剩下的唯一窗口时自动关闭 \" autocmd bufenter * if (winnr(\"$\") == 1 &amp;&amp; exists(\"b:NERDTree\") &amp;&amp; b:NERDTree.isTabTree()) | q | endif \" christoomey/vim-tmux-navigator let g:tmux_navigator_no_mappings = 1 noremap &lt;silent&gt; &lt;C-h&gt; :&lt;C-U&gt;TmuxNavigateLeft&lt;cr&gt; noremap &lt;silent&gt; &lt;C-j&gt; :&lt;C-U&gt;TmuxNavigateDown&lt;cr&gt; noremap &lt;silent&gt; &lt;C-k&gt; :&lt;C-U&gt;TmuxNavigateUp&lt;cr&gt; noremap &lt;silent&gt; &lt;C-l&gt; :&lt;C-U&gt;TmuxNavigateRight&lt;cr&gt; noremap &lt;silent&gt; &lt;C-p&gt; :&lt;C-U&gt;TmuxNavigatePrevious&lt;cr&gt; \" gelguy/wilder.nvim autocmd CmdlineEnter * ++once call s:wilder_init() | call wilder#main#start() function! s:wilder_init() abort call wilder#setup({ \\ 'modes': [':', '/', '?'], \\ 'enable_cmdline_enter': 0, \\ 'next_key': '&lt;C-n&gt;', \\ 'previous_key': '&lt;C-p&gt;', \\ 'accept_key': '&lt;C-l&gt;', \\ 'reject_key': '&lt;C-h&gt;', \\ }) call wilder#set_option('renderer', wilder#popupmenu_renderer(wilder#popupmenu_palette_theme({ \\ 'border': 'rounded', \\ 'max_height': '75%', \\ 'min_height': 0, \\ 'prompt_position': 'top', \\ 'reverse': 0, \\ }))) call wilder#set_option('pipeline', [ \\ wilder#branch( \\ wilder#python_file_finder_pipeline({ \\ 'file_command': ['find', '.', '-type', 'f', '-printf', '%P\\n'], \\ 'dir_command': ['find', '.', '-type', 'd', '-printf', '%P\\n'], \\ 'filters': ['fuzzy_filter', 'difflib_sorter'], \\ }), \\ wilder#cmdline_pipeline(), \\ wilder#python_search_pipeline(), \\ ), \\ ]) \" Default keys call wilder#set_option('pipeline', [ \\ wilder#branch( \\ wilder#cmdline_pipeline({ \\ 'fuzzy': 1, \\ 'set_pcre2_pattern': 1, \\ }), \\ wilder#python_search_pipeline({ \\ 'pattern': 'fuzzy', \\ }), \\ ), \\ ]) call wilder#set_option('renderer', wilder#popupmenu_renderer({ \\ 'highlighter': wilder#basic_highlighter(), \\ 'highlights': { \\ 'accent': wilder#make_hl('WilderAccent', 'Pmenu', [{}, {}, {'foreground': '#f4468f'}]), \\ }, \\ })) endfunctionendf美化终端 brew install ranger brew install highlight brew install tree brew install htop 配置zsh，参考https://github.com/ohmyzsh/ohmyzsh# 在 ~/.zshrc 文件中末尾添加# 只允许开一个 tmuxif [[ -z \"$TMUX\" ]] ;then ID=\"`tmux ls | grep -vm1 attached | cut -d: -f1`\" # get the id of a deattached session if [[ -z \"$ID\" ]] ;then # if not available create a new one tmux new-session else tmux attach-session -t \"$ID\" # if available attach to it fifiexport PATH=\"$HOME/go/bin:$PATH\"# 美化终端命令历史 ctrl-r[ -f ~/.fzf.zsh ] &amp;&amp; source ~/.fzf.zsh# 配置flog命令，使其与 vim 中的 flog -all 命令趋同alias flog='git log --graph --oneline --all --decorate'alias ll='ls -lha')tmux 与 vim 窗格间相互跳转，需在 ~/.tmux.conf 文件中配置:# Smart pane switching with awareness of Vim splits.# See: GitHub - christoomey/vim-tmux-navigator: Seamless navigation between tmux panes and vim splitsis_vim=\"ps -o state= -o comm= -t '#{pane_tty}' \\ | grep -iqE '^[^TXZ ]+ +(\\\\S+\\\\/)?g?(view|n?vim?x?)(diff)?$'\"bind-key -n 'C-h' if-shell \"$is_vim\" 'send-keys C-h' 'select-pane -L'bind-key -n 'C-j' if-shell \"$is_vim\" 'send-keys C-j' 'select-pane -D'bind-key -n 'C-k' if-shell \"$is_vim\" 'send-keys C-k' 'select-pane -U'bind-key -n 'C-l' if-shell \"$is_vim\" 'send-keys C-l' 'select-pane -R'tmux_version='$(tmux -V | sed -En \"s/^tmux ([0-9]+(.[0-9]+)?).*/\\1/p\")'if-shell -b '[ \"$(echo \"$tmux_version &lt; 3.0\" | bc)\" = 1 ]' \\ \"bind-key -n 'C-\\\\' if-shell \\\"$is_vim\\\" 'send-keys C-\\\\' 'select-pane -l'\" if-shell -b '[ \"$(echo \"$tmux_version &gt;= 3.0\" | bc)\" = 1 ]' \\ \"bind-key -n 'C-\\\\' if-shell \\\"$is_vim\\\" 'send-keys C-\\\\\\\\' 'select-pane -l'\"bind-key -T copy-mode-vi 'C-h' select-pane -Lbind-key -T copy-mode-vi 'C-j' select-pane -Dbind-key -T copy-mode-vi 'C-k' select-pane -Ubind-key -T copy-mode-vi 'C-l' select-pane -Rbind-key -T copy-mode-vi 'C-\\' select-pane -lset -g focus-events on插件便利功能在“vim快速配置”一节中引入了有用的插件，本章节将列举一些高效的操作。通用 BLines和Lines：列出包含所查内容的所有行，可跳转 Todo：列出含有 TODO 的文件和行 Marks：列出所有被标注的行 Commands：所有支持的vim命令 Ranger：打开文件管理器 Ack或Rg或Ag：搜索当前单词或函数名 Tagbar：打开tagbar Files：查找文件 Buff：查找buff Ctrl+]：函数跳转到定义或声明处 gr：函数被引用的所有地方 Ctrl+o和Ctrl+t：光标回退 history: 历史命令 History: 历史buffer Commits： 搜索该仓库的提交记录 BCommits： 与当前buffer相关的提交记录 Gdiff： 左右分栏比较当前文件改动很直观 Git log和GcLog和Git log -p %： 很美观 GitGutterLineHighlightsToggle：高亮或取消高亮有改动的行 GitGutterFold：把未改动的行折叠 Flog -all： 查看各个分支之间的演化关系 fn yourCommand： 执行命令 fk： 关闭浮动窗口 \\k 和 \\K：高亮单个文件感兴趣的word，结合 * 可以实现跨文件 gcc: 注释一行或所选多行 bd： 关闭一个buffer Deol： 打开shell mm：对该行打mark或清除 mc：清除当前buffer的mark mx：清除所有buffer的mark undo 管理，命令前缀为 Mundo gaip*= 对齐所有= gaip2= 对齐第2个= vipga= 可视模式下对齐=go 语言命令基本上以 Go 开头（输入:Go 之后按 ctrl+n 启用命令行情模糊筛选） GoFillStruct: 在输入struct名称{}后，输入该命令回车，可以默认值自动填充结构体 GoAddTags json和GoRemoveTags：在struct内部输入该命令，可自动加或删 json tag GoIfErr：自动生成 err 的模板代码 GoTests：自动生成所在行对应函数的测试函数 GoTestFunc、GoTest、GoTestFile：单元测试 GoAlternate：在源文件和测试文件之间来回跳转 GoCallers和GoCallees：显示函数调用关系 GoDebug 前缀: go debug 命令 go 编程效率工具 jmoiron/sqlx：通过配置文件自动生成mysql的go操作代码 orlangure/gnomock：各种中间件的mock，单元测试或集成测试时不再需要自己写mock了 Redis Memcached MySQL MariaDB PostgreSQL MongoDB RabbitMQ Kafka Elasticsearch alicebob/miniredis：纯go的用于单测的redis服务端代码 cjsaylor/sqlfixture：纯go的用于单测的mysql服务端代码 tokopedia/gripmock：通过proto文件来mock任意的grpc服务 k1LoW/grpcstub：grpc测试打桩 smallnest/rpcx：rpc工具vim 高效率操作掌握常用的 vim 技巧可以大大减少鼠标的使用，从而使十指保持在主键盘上，减少切换的频率，最终提升编码效率，同时减少精力损耗。模式普通模式修改 i： 在光标前插入；一个小技巧：按 8，再按 i，进入插入模式，输入 =， 按 esc 进入命令模式，就会出现8个=。 这在插入分割线时非常有用，如30i+就插入了36个+组成的分割线。 I： 在当前行第一个非空字符前插入； gI： 在当前行第一列插入； a： 在光标后插入； A： 在当前行最后插入； o： 在下面新建一行插入； O： 在上面新建一行插入； c[n]w: 改写光标后1(n)个词。 c[n]l: 改写光标后n个字母。 c[n]h: 改写光标前n个字母。 [n]cc: 修改当前[n]行。 [n]s: 以输入的文本替代光标之后1(n)个字符，相当于c[n]l。 [n]S: 删除指定数目的行，并以所输入文本代替之。 r: 替换光标处的字符，同样支持汉字。 R: 进入替换模式，按esc回到正常模式。 ~: 反转光标所在字符的大小写注意，类似 cnw,dnw,ynw 的形式同样可以写为 ncw,ndw,nyw删除 [n]x: 剪切光标右边n个字符，相当于 d[n]l。 [n]X: 剪切光标左边n个字符，相当于 d[n]h。 d: 删除（剪切）在可视模式下选中的文本。 d$ or D: 删除（剪切）当前位置到行尾的内容。 d[n]w: 删除（剪切）1(n)个单词（注意，大写W规定以空格分割的词，而小写可以为其他） d[n]l: 删除（剪切）光标右边1(n)个字符。 d[n]h: 删除（剪切）光标左边1(n)个字符。 d0: 删除（剪切）当前位置到行首的内容 [n] dd: 删除（剪切）1(n)行。 :m,nd 剪切m行到n行的内容。 d1G 或 dgg: 剪切光标以上的所有行。 dG: 剪切光标以下的所有行。 daw 和 das：剪切一个词和剪切一个句子，即使光标不在词首和句首也没关系。 d/f&lt;cr&gt;：这是一个比较高级的组合命令，它将删除当前位置 到下一个 f 之间的内容。 dt+定位符：一直删除到该行的定位符处 Ctrl+r：撤销 有时候可以把诸如空格替换成制表符，借助 Excel 删除不需要的列选择 shift+v：行选模式： i{：选中光标所在中括号之间所有内容，不包括中括号 i： 选中分词符（一般为空格，除非特别指明）内的所有内容 a： 选中包括分词符（一般为空格，除非特别指明）在内的所有内容 a{：选中光标所在中括号之间所有内容，包括中括号 ib / i(：选中光标所在小括号之间所有内容，不包括小括号 ab / a(：选中光标所在小括号之间所有内容，包括小括号以上可以和 y、c、d 等结合实现快速复制、修改、删除功能复制 y: 复制在可视模式下选中的文本。 yy or Y: 复制整行文本。 y[n]w: 复制一(n)个词。y[n]l: 复制光标右边 1(n) 个字符。y[n]h: 复制光标左边1(n)个字符。 y$: 从光标当前位置复制到行尾。 y0: 从光标当前位置复制到行首。 :m,ny&lt;cr&gt; 复制m行到n行的内容。 ygg: 复制光标以上的所有行。 yG: 复制光标以下的所有行。 yaw 和 yas：复制一个词和复制一个句子，即使光标不在词首和句首也没关系。粘贴 p: 在光标之后粘贴。 P: 在光标之前粘贴。 \"+y: 复制到系统剪切板 \"+p: 从系统剪切板中粘贴， 命令行或插入模式下 Ctrl+r+寄存器符号 可粘贴相应寄存器中的内容：如可以使用 yiw 复制内容，然后在命令行中使用 Ctrl+r+0 粘贴移动 ctrl+f： 下翻一屏。 ctrl+b： 上翻一屏。 ctrl+d： 下翻半屏。 ctrl+u： 上翻半屏。 M： 移动到屏幕的中间行 H： 移动到屏幕首行 L： 移动到屏幕的末行 nH： 移动到屏幕首行下面的第n行 nL： 移动到屏幕末上上面的第n行 0nl： 表示先用命令 0 将光标移动到行首，nl 表示执行 n 次向右移动光标操作 n|： 表示使用 | 命令跳转到当前行的第 n 列 ta/fa： 移动到光标所之后第一个字符a处 Ta/Fa： 移动到光标所之前最后一个字符a处 zz： 将当前行移动到屏幕中央。 zt： 将当前行移动到屏幕顶端。 zb： 将当前行移动到屏幕底端。 gg： 移动到文件首行 G： 移动到文末 $: 从光标当前位置到行尾。 0: 从光标当前位置到行首。 w和W: 从光标当前位置到词尾 gg： 从光标当前位置到页首 G： 从光标当前位置到页尾 H： 移动到起始点—-屏幕首行 M： 移动到屏幕的中间行 L： 移动到屏幕的末行 nH： 移动到屏幕首行下面的第n行 nL： 移动到屏幕末上上面的第n行 m{a-z}: 标记光标所在位置，局部标记，只用于当前文件。 m{A-Z}: 标记光标所在位置，全局标记。标记之后，退出 Vim， 重新启动，标记仍然有效。 '{a-z}: 移动到标记位置。 '{A-Z}: 移动到标记位置。以上可以通过插件简单管理实现。 ''： 移动到上次修改或编辑的地方 '.： 移动到最后修改的地方 Ctrl+i 或 Ctrl+o 或 Ctrl+t：快进或快退 ta： 移动到所在行之后第一个字符a前一字符 fa： 移动到所在行之后第一个字符a处 Ta： 移动到所在行之前最后一个字符a的后一个字符 Fa： 移动到所在行之前最后一个字符a处 0nl 或 n|： 跳转到当前行的第 n 列 Ctrl+o 和 Ctrl+i： 很像浏览器上的 后退 和 前进 gd: 跳转到局部变量的定义处； gD: 跳转到全局变量的定义处，从当前文件开头开始搜索； g;: 上一个修改过的地方； g,: 下一个修改过的地方； [[: 跳转到上一个函数块开始，需要有单独一行的{。 ]]: 跳转到下一个函数块开始，需要有单独一行的{。 []: 跳转到上一个函数块结束，需要有单独一行的}。 ][: 跳转到下一个函数块结束，需要有单独一行的}。 [{: 跳转到当前块开始处； ]}: 跳转到当前块结束处； [/: 跳转到当前注释块开始处； ]/: 跳转到当前注释块结束处； %: 不仅能移动到匹配的 (), {} 或 [] 上，而且能在 #if，#else， #endif 之间跳跃。查找 /something: 在后面的文本中查找something。 ?something: 在前面的文本中查找something。 /pattern/+number: 将光标停在包含pattern的行后面第number行上。 /pattern/-number: 将光标停在包含pattern的行前面第number行上。 f(或者F，t，T)： 后面跟需要查找的字符。 % 可以搜索与之匹配的对应的()[]{}。这个功能对于书写程序特别有用。 n: 向后查找下一个。 N: 向前查找下一个。 \\*：buffer 内查找当前词 在搜索命令中， .*[]^%/?~$这10个字符有着特殊意义，所以在使用这些字符的时候要在前面加上一个反斜杠/。而/e表示&lt;esc&gt;；/t表示&lt;tab&gt;；/r表示&lt;cr&gt;；/b表示&lt;bs&gt;折叠 zf – 创建折叠的命令，可以在一个可视区域上使用该命令； zf ap – 折叠光标所在的段； zf % – 折叠光标配对括号的部分，例如光标在{处，则折叠{}间的部分，对折叠函数很有用； zd – 删除当前行的折叠； zD – 删除当前行的折叠； zo – 打开折叠的文本； zc – 收起折叠； za – 打开/关闭当前折叠； zr – 打开嵌套的折行； zm – 收起嵌套的折行； zR (zO) – 打开所有折行； zM (zC) – 收起所有折行； zj – 跳到下一个折叠处； zk – 跳到上一个折叠处； [z 到当前打开的折叠的开始处。 ]z 到当前打开的折叠的末尾处。 zi – enable/disable fold;缩进 &lt;&lt; 向左缩进一个 shiftwidth &gt;&gt; 向右缩进一个 shiftwidth CTRL-T 插入模式下向右缩进 CTRL-D 插入模式下向左缩进 J 拼接当前行和下一行 gJ 同 J ，不过合并后不留空格撤销或重做 [n]u: 取消一(n)个改动。 :undolist – 你的撤销历史。 ctrl + r: 重做最后的改动。 g+:\t转到较新的文本状态 U: 取消当前行中所有的改动。v 模式（块模式 Ctrl+v 或 字符模式 v） i{、（、&lt;、[：选中括号中的所有内容 iw：选中一个单词 is：选中一个句子 ip：选中一个段落 o\t光标移动到选中文本的另一结尾 O\t光标移动到选中文本的另一角落 U 或 u：把选中的文本变为大写或小写。 gu(U) 接范围（如$，或G），可以把从光标当前位置到指定位置之间字母全部 转换成小写或大写。命令模式（Esc+:） :r filename 在当前位置插入另一个文件的内容。 :[n]r filename 在第n行插入另一个文件的内容。 :r !date 在光标处插入当前日期与时间。同理，:r !command可以将其它shell命令的输出插入当前文档。 在普通模式下使用 yiw 复制，然后在命令模式下 Ctrl+r 然后输入 0 即可复制文本到 vim 命令行中 Ctrl-w： 向前删除一个单词。 Ctrl-h： 向前删除一个字符，等同于Backspace。 Ctrl-u： 从当前位置移动到命令行开头。 Ctrl-b： 移动到命令行开头。 Ctrl-e： 移动到命令行末尾。 Shift-Left： 左移一个单词。 Shift-Right： 右移一个单词。 @： 重复上一次的冒号命令。 :m,ny&lt;cr&gt; 复制m行到n行的内容。 :s/old/new - 用new（如果没有/new，则视为删除）替换当前行第一个old。 :s/old/new/g - 用new替换当前行所有的old。 :n1,n2s/old/new/g - 用new替换文件n1行到n2行所有的old。 :%s/old/new/g - 用new替换文件中所有的old。 :%s/^/xxx/g - 在每一行的行首插入xxx，^表示行首。 :%s/$/xxx/g - 在每一行的行尾插入xxx，$表示行尾。 所有替换命令末尾加上c，每个替换都将需要用户确认。 加上i则忽略大小写 [range]g/pattern/command：例如 :%g/^ xyz/normal dd :pwd 显示vim的工作目录。 :cd path 改变vim的工作目录。插入模式（Esc+i） Ctrl-h, Ctrl+w, Ctrl-u 具有删除功能 Ctrl-R {0-9a-z\"%#\\*+:.~=}插入寄存器内容补全菜单 Ctrl-p 向前切换成员； Ctrl-n 向后切换成员； Ctrl-e 退出下拉菜单，并退回到原来录入的文字； Ctrl-y 退出下拉菜单，并接受当前选项。行选模式（shift+v） i{ ：选中光标所在中括号之间所有内容，不包括中括号 a{ ：选中光标所在中括号之间所有内容，包括中括号 ib / i(：选中光标所在小括号之间所有内容，不包括小括号 ab / a(：选中光标所在小括号之间所有内容，包括小括号多文件或缓冲区多缓冲区 :buffers 或 :ls 或 :files – 显示缓冲区列表。 ctrl+6：在最近两个缓冲区间切换。 :bn – 下一个缓冲区。 :bp – 上一个缓冲区。 :bl – 最后一个缓冲区。 :b[n] 或 :[n]b – 切换到第n个缓冲区。 :nbw(ipeout) – 彻底删除第n个缓冲区。 :nbd(elete) – 删除第n个缓冲区，并未真正删除，还在unlisted列表中。 :ba[ll] – 把所有的缓冲区在当前页中打开，每个缓冲区占一个窗口。 :ls – //列出打开的文件，带编号多标签页 终端中 vim -p files: 打开多个文件，每个文件占用一个标签页。 :tabe, tabnew – 如果加文件名，就在新的标签中打开这个文件， 否则打开一个空缓冲区。 ^w gf – 在新的标签页里打开光标下路径指定的文件。 :tabn – 切换到下一个标签。Control + PageDown，也可以。 :tabp – 切换到上一个标签。Control + PageUp，也可以。 [n] gt – 切换到下一个标签。如果前面加了 n ， 就切换到第n个标签。第一个标签的序号就是1。 :tab split – 将当前缓冲区的内容在新页签中打开。 :tabc[lose] – 关闭当前的标签页。 :tabo[nly] – 关闭其它的标签页。 :tabs – 列出所有的标签页和它们包含的窗口。 :tabm[ove] [N] – 移动标签页，移动到第N个标签页之后。 如 tabm 0 当前标签页，就会变成第一个标签页。 :q、 :close（暂时关闭窗口，其内容还存在缓存中） 标准模式下：gt（可能被其他插件或映射占用） , gT 可以直接在 tab 之间切换。更多可以查看帮助 :help table ， help -p窗格分割 :split(:sp) – 把当前窗水平分割成两个窗口（两个窗口内容一致）。(CTRL-W s 或 CTRL-W CTRL-S) —注意如果在终端下，CTRL-S可能会冻结终端，请按CTRL-Q继续。 :split filename – 水平分割窗口，并在新窗口中显示另一个文件。 ctrl+w f –水平分割出一个窗口，并在新窗口打开名称为光标所在词的文件 。 C-w C-^ – 水平分割一个窗口，打开刚才编辑的文件。 :vsplit(:vsp) – 把当前窗口分割成水平分布的两个窗口。 (CTRL-W v或CTRL CTRL-V) ctrl+w o – 只保留当前窗口窗格关闭 :qall – 关闭所有窗口，退出vim。 :wall – 保存所有修改过的窗口。 :only – 只保留当前窗口，关闭其它窗口。(CTRL-W o) :close – 关闭当前窗口，CTRL-W c/q 能实现同样的功能。 (象 :q :x同样工作 )调整窗口大小 ctrl+w + –当前窗口增高一行。也可以用n增高n行。 ctrl+w - –当前窗口减小一行。也可以用n减小n行。 ctrl+w \\_–当前窗口扩展到尽可能的大。也可以用n设定行数。 :resize n – 当前窗口n行高。 ctrl+w = – 所有窗口同样高度。 n ctrl+w \\_ – 当前窗口的高度设定为n行。 ctrl+w &lt; –当前窗口减少一列。也可以用n减少n列。 ctrl+w &gt; –当前窗口增宽一列。也可以用n增宽n列。 ctrl+w | –当前窗口尽可能的宽。也可以用n设定列数。切换和移动窗口 ctrl+w ctrl+w: 切换到下一个窗口。或者是ctrl+w w。 ctrl+w p: 切换到前一个窗口。 ctrl+w h(l,j,k):切换到左（右，下，上）的窗口。 ctrl+w t(b):切换到最上（下）面的窗口。 ctrl+w H(L,K,J): 将当前窗口移动到最左（右、上、下）面。 ctrl+w r：顺时针旋转窗口的位置。 ctrl+w R：逆时针旋转窗口的位置。 ctrl+w x：交换同列或同行的窗口的位置 ctrl+w T: 将当前的窗口移动到新的标签页上。简便操作重复操作（.）We saw how the . command can be used to repeat the lasi changed. But the dot command won’t replay changes madefrom Vim’s command line. Instead, we can repeat the last Ex command by pressing @:数字的增减在编程中常常会为变量进行编号，通常很多行代码只是变量的编号不一样，而且这些编号一般是递增或递减或有相同间距等，那么我们就可以使用yyp类似的命令进行复制，然后单独修改数字编号即可。对于修改编号有快速方法：定位到该编号，然后使用”数字+\"(比如定位到0px处，nomal下输入180(注意指的是Ctrl+x)，则0px就变成了-180px);命令配合数字使用vim 大部分命令都可以配合数字使用，但是为了充分利用.和u命令提高效率，建议：Don’t Count if you can repeat!(因为数字表示重复命令多少次，这数字是多少呢，会增加思考点数时间，同时不易使用u命令)，所以更好的选择是使用一次命令然后用.重复该命令，这样选择余地更大，使用u命令恢复更有选择性（比如你只需要恢复一个词语，但是你使用了 d2w 命令删除了 2 个，那么你使用u命令则恢复了2个词语，那么你还得删除一个词语）。" }, { "title": "redis 杂谈", "url": "/2016/07/redis.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2016-07-06 11:26:51 +0800", "snippet": " 本文主要介绍 Redis 相关的一些理论知识、实践经验和验证实验。它的全称是 REmote Dictionary Service, 直接翻译过来是远程字典服务。 redis 架构 应用架构演化 Redis 自身架构演化 redis 模块 线程模型 单线程模型 多线程模型 ...", "content": " 本文主要介绍 Redis 相关的一些理论知识、实践经验和验证实验。它的全称是 REmote Dictionary Service, 直接翻译过来是远程字典服务。 redis 架构 应用架构演化 Redis 自身架构演化 redis 模块 线程模型 单线程模型 多线程模型 redis 应用 典型应用场景 数据类型及相关命令 redis 实现原理 底层数据结构 底层数据结构概述 SDS(简单动态字符串存储结构) 链表 压缩列表 哈希表 哈希表结构设计 哈希冲突 整数集合 整数集合结构设计 整数集合的升级操作 跳表 跳表结构设计 跳表节点查询过程 跳表节点层数设置 quicklist listpack rax(前缀树) stream 添加消息 删除消息 参考文档 redis 源码导读 redis 通信协议 RESP2 简单字符串 错误 整型 批量字符串 数组 数组中的空元素 多命令和管道 内联命令 高性能 Redis 协议解析器 参考文档 RESP3 与RESP2兼容 请求格式 Simple string Simple error Number Blob string Array RESP3中新的类型 Null Double Boolean Blob error Verbatim string Big number Aggregate data types Map Set Attribute Push Stream HELLO 参考文档 gossip redis 集群 集群部署方案 主从复制模式 Sentinel（哨兵）模式 Cluster模式 Redis集群的数据分布算法：哈希槽算法 集群的请求重定向 集群扩容和缩容 集群的故障检测与故障转恢复机制 集群故障检测 集群的故障恢复 集群的运维 数据迁移问题 带宽消耗问题 Pub/Sub广播问题 集群倾斜 集群读写分离 参考文档 redis 故障及调优 redis 综合redis 架构Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。Redis 是一种KV存储的非关系数据库，类似的数据库组件可参考此网站nosql-database。能不能把SQL和NoSQL的特性结合在一起呢？当然可以。所以现在又有了所谓的NewSQL数据库。NewSQL是指这样一类新式的关系型数据库管理系统，针对OLTP（读-写）工作负载，追求提供和NoSQL系统相同的扩展性能，且仍然保持ACID和SQL等特性（scalable and ACID and (relational and/or sql -access)）。NewSQL 结合了 SQL和 NoSQL 的特性。例如 TiDB (PingCAP)、VoltDB、ScaleDB等。redis 架构从单机版不断演化成如今的分片集群版。应用架构演化 单机版：作为热数据的内存KV数据库，分担Mysql非内存式的持久化数据库的压力 Redis 持久化($DB/AOF)：减少数据丢失 主从复制：多副本 缩短不可用时间：master 宕机，手动把slave提升为master 分摊读压力，提升读性能：让 slave 分担一部分读请求，提升应用整体性能 单哨兵：单哨兵可能因网络问题，对master存活造成误判 哨兵集群：故障节点自动切换，加快切换时间（相对于故障手动切换而言） 分片集群：分摊写压力，提升集群整体性能 proxy方案(非官方)：多个主从集群分担根据路由规则写压力，一个哨兵集群监测状态。其中路由规则可以在客户端实现（客户端分片），也可以在服务端实现。对于在服务端实现路由的方案，即为这里所说的proxy方案 gossip协议方案(官方)：Redis 节点之间通过 Gossip 协议通信，无需部署哨兵集群，可横向扩容 proxy加官方集群方案：由各公司自研的proxy，来屏蔽业务迁移至官方集群的复杂性，降低升级成本 更复杂和详细的应用演化之旅可以参考以下文章： 阿里云Redis技术架构演进 一文搞懂Redis架构演化之路Redis 自身架构演化Redis 自身架构演化大体和其应用架构演化类似。 单机版：Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。 集群架构 redis 模块线程模型Redis 6.0 之前为什么使用单线程。虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解 Redis 有多线程同时执行命令。Redis 官方表示，Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上。Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据，并不会以多线程的方式处理读请求。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。//读请求也使用io多线程io-threads-do-reads yes // io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）io-threads 4关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会创建 6 个线程： Redis-server ： Redis的主线程，主要负责执行命令； bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务； io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。单线程模型Redis 6.0 版本之前的单线模式如下图：Redis 初始化的时候，会做下面这几件事情： 调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务器套接字 socket； 调用 bind() 绑定端口和调用 listen() 设置监听该套接字； 将调用 epoll_ctl() 将该监听套接字listen socket 加入到 epoll红黑树柄，同时注册「连接请求」处理函数。初始化完后，主线程就进入到一个事件循环函数，主要会做以下事情： 先调用处理发送队列函数，每一次进入 epoll_wait 前都调用 beforesleep看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写事件触发后再处理 。 接着，调用 epoll_wait 函数等待事件的到来： 如果是连接事件到来，则会调用连接事件处理函数，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数； 如果是读事件到来，则会调用读事件处理函数，该函数会做这些事情：调用 read 获的取客户端发送数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存送区等待发； 如果是写事件到来，则会调用写事件处理函数，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。 在 aeMain 函数中，每次在进入 aeProcessEvents 前都需要先进行 beforesleep 处理。该函数处理了许多工作，其中一项便是： 遍历发送任务队列，并将 client 发送缓存区中的处理结果通过 write 发送到客户端手中； 值得注意的是，发送 write 并不总是能一次性发送完的。假如要发送的结果太大，而系统为每个 socket 设置的发送缓存区又是有限的； 在这种情况下， 判断仍然有未发送完的数据的话，就需要注册一个写事件处理函数到 epoll 上。等待 epoll 发现该 socket 可写的时候再次调用 sendReplyToClient进行发送。其他详细解读请参考以下文章： Redis源码剖析——线程模型 从架构图及源码分析redis单体服务架构之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因： 内存操作 高效数据结构 I/O多路复用 协议简单 无多线程切换和资源争用开销 处理流程简单高效多线程模型Redis6.0版本的多线程处理模型：主线程工作流程如下： 主线程负责接收建立连接请求，将epoll_wait等待的读事件加入全局待处理列表中； 将等待列表中的读事件平均分给IO线程； 主线程处理其中一部分读事件； 阻塞等待IO线程将分配到的读事件进行命令解析； 当所有IO线程将分配到的读事件都命令解析完毕，主线程负责执行命令，并将回复信息写入客户端对应的回复缓冲区。 将等待等待列表中写事件平均分给IO线程； 主线程处理其中一部分写事件；从上面的实现机制可以看出，Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行。所以我们不需要去考虑控制 key、lua、事务，LPUSH/LPOP 等等的并发及线程安全问题。 Redis多线程模型缺陷随着互联网的飞速发展，互联网业务系统所要处理的线上流量越来越大，Redis 的程单线模式会导致系统消耗很多 CPU 时间在网络 I/O 上从而降低吞吐量，于是诞生了Redis6.0多线程模型。但是 Redis 多线程网络模型实际上并不是一个标准的 Multi-Reactors/Master-Workers模型。Redis 的多线程方案中，I/O 线程任务仅仅是通过 socket 读取客户端请求命令并解析，却没有真正去执行命令。所有客户端命令最后还需要回到主线程去执行，因此对多核的利用率并不算高，而且每次主线程都必须在分配完任务之后忙轮询等待所有 I/O 线程完成任务之后才能继续执行其他逻辑。在我看来，Redis 目前的多线程方案更像是一个折中的选择：既保持了原系统的兼容性，又能利用多核提升 I/O 性能redis 应用有时候应用一个组件不需要事先知道其原理，只有在深度使用时遇到比较棘手的场景或问题时才会去深度了解。基于这个观点，我们首先从应用的角度来了解redis。典型应用场景 Redis 16种常见应用场景 Redis在项目中的地位及使用场景剖析 关于redis的应用场景 细说 Redis 九种数据类型和应用场景 Redis的应用场景数据类型及相关命令数据类型有哪些可以参考官方文档、中文文档 redis架构 Redis命令 或者 Redis命令 在学习命令或者验证所学的时候，图简便可以参考在线Redis 一文读懂Redis数据类型redis 实现原理了解了基本的应用之后，会遇到对性能和匹配度要求更高的场景，甚至为了自身特殊需要来改造redis，这就需要了解redis的底层原理及其相关理论。 Redis单机版全面讲解 浅谈redis(一)——单机版redis特性记录底层数据结构Redis 目前共有 9 种数据结构：SDS、双向链表、压缩列表(新版本已废弃)、哈希表、跳表、整数集合、quicklist、listpack。底层数据结构是 redis 高性能的一个重要支撑。我们也可以借鉴这些结构，用到其他项目中，或者在它的基础上进行改良。本章节参考了： 为了拿捏 Redis 数据结构，我画了 40 张图（完整版） Redis设计与实现 第一部分的数据结构与对象 《Redis 源码剖析与实战》底层数据结构概述Redis 是一种k-v数据库，那这种键值对是怎么实现的呢？Redis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。哈希桶存放的是指向键值对数据的指针（dictEntry*），这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void * value 指针找到。上图中涉及到的数据结构的名字和用途： redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针； dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用，具体什么是 rehash，我在本文的哈希表数据结构会讲； ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针； dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void * key 和 void * value 指针， key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。特别说明下，void * key 和 void * value 指针指向的是 Redis 对象，Redis 中的每个对象都由 redisObject 结构表示，如下图：// redis 6.0.6typedef struct redisObject { unsigned type:4; // 4位=0.5字节 unsigned encoding:4; // 4位=0.5字节 unsigned lru:LRU_BITS; // 24位=3字节, 对象最后一次访问时间（秒） int refcount; // 32位=4字节，引用计数。0：可被垃圾回收 void *ptr; // 64位=8字节} robj;对象结构里包含的成员变量： type： 显式类型，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）； encoding：隐式类型，标识该对象使用了哪种底层的数据结构； ptr：指向底层数据结构的指针。每种显式类型，会根据不同的阈值在不同的隐式类型中切换。 序号 类型 描述 1 int 整数 2 embstr embstr编码的简单动态字符串（SDS） 3 raw 简单动态字符串 4 ht 字典 5 linkedlist 双端链表 5 ziplist 压缩列表 5 intset 整数集合 5 skiplist 跳跃链表和字典 type和encoding之间的对应关系大致如下(可能存在版本差异)，数据使用不同类型存储是有限制条件的，不同条件下，使用不同的存储格式。 type encoding string （1）int：值为整型，取值[-2^63-1, 2^63-1]   （2）embstr：值不为整型或者整型值不在上述int范围内，且值长度小于等于44个字节   （3）raw：值超过44个字节(64-16-3-1=44) list quicklist(3.2版本前对应ziplist   linkedlist)3.2版本后，list使用quicklist(ziplist和linkedlist组合) hash （1）ziplist：值个数在hash-max-ziplist-entries范围内或者值长度在hash-max-ziplist-value范围内   （2）hashtable：超过上述范围 set （1）intset：值为整型，取值[-2^63-1, 2^63-1]   （2）hashtable：其他情况 zset （1）ziplist：值个数在zset-max-ziplist-entries范围内或者值长度在zset-max-ziplist-value范围内   （2）skiplist：超过上述情况 我画了一张 Redis 键值对数据库的全景图，你就能清晰知道 Redis 对象和数据结构的关系了： redis会采用dict来保存全局hash，会有2个dict，dict0和dict1，其中dict1用于扩容用。redis有扩容和缩容，缩容流程与扩容基本一致。除了什么时候扩会有差异：扩容是负载因子&gt;=1或负载因子&gt;=5；缩容是负载因子小于等于0.1。扩容时，采用的是渐进式hash。这种思路可以借鉴。 对于增删改查都会将一个元素从dict0放到dict1 对于没有变动的使用定时任务迁移 对于增加只会往dict1放 迁移完成后将dict0置为dict1，同时清空dict1整体redis的渐近式hash细节步骤可以用到数据库扩容上SDS(简单动态字符串存储结构)字符串在 Redis 中是很常用的，键值对中的键是字符串类型，值有时也是字符串类型。Redis 是用 C 语言实现的，但是它没有直接使用 C 语言的 char* 字符数组来实现字符串，而是自己封装了一个名为简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串，也就是 Redis 的 String 数据类型的底层数据结构是 SDS。既然 Redis 设计了 SDS 结构来表示字符串，肯定是 C 语言的 char* 字符数组存在一些缺陷。要了解这一点，得先来看看 char* 字符数组的结构。C 语言的字符串其实就是一个字符数组，即数组中每个元素是字符串中的一个字符。在 C 语言里，对字符串操作时，char * 指针只是指向字符数组的起始位置，而字符数组的结尾位置就用“\\0”表示，意思是指字符串的结束。这种字符数组结构有以下不便： 求字符串长度需要遍历计数 不能存放二进制数据(比如音视频数据、压缩编码数据)或者含有”\\0”的数据，否则会被截断，无法读取真实完整的字符串 修改字符串时带来的内存重分配次数较多 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；Redis 实现的 SDS 的结构就把上面这些问题解决了，接下来我们一起看看 Redis 是如何解决的。下图就是 Redis 5.0 的 SDS 的数据结构：总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷。当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容），以满足修改所需的大小。在扩展 SDS 空间之前，SDS API 会优先检查未使用空间是否足够，如果不够的话，API 不仅会为 SDS 分配修改所必须要的空间，还会给 SDS 分配额外的「未使用空间」。这样的好处是，下次在操作 SDS 时，如果 SDS 空间够的话，API 就会直接使用「未使用空间」，而无须执行内存分配，有效的减少内存分配次数。所以，使用 SDS 即不需要手动修改 SDS 的空间大小，也不会出现缓冲区溢出的问题。SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。Redos 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。这 5 种类型的主要区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间。比如，在保存小字符串时，结构头占用空间也比较少。除了设计不同类型的结构体，Redis 在编程上还使用了专门的编译优化来节省内存空间，即在 struct 声明了 __attribute__ ((packed)) ，它的作用是：告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐。比如，sdshdr16 类型的 SDS，默认情况下，编译器会按照 16 字节对齐的方式给变量分配内存，这意味着，即使一个变量的大小不到 16 个字节，编译器也会给它分配 16 个字节。链表Redis 的 List 对象的底层实现之一就是链表。C 语言本身没有链表这个数据结构的，所以 Redis 自己设计了一个链表数据结构。实际上就是双链表。Redis 在双链表的基础上封装了 List 结构(把操作和数据绑定，类似面向对象)。typedef struct list { //链表头节点 listNode *head; //链表尾节点 listNode *tail; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值比较函数 int (*match)(void *ptr, void *key); //链表节点数量 unsigned long len;} list;list 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup、free、match 函数。Redis 的链表实现优点如下： listNode 链表节点的结构里带有 prev 和 next 指针，获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表； list 结构因为提供了表头指针 head 和表尾节点 tail，所以获取链表的表头节点和表尾节点的时间复杂度只需O(1)； list 结构因为提供了链表节点数量 len，所以获取链表中的节点数量的时间复杂度只需O(1)； listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此链表节点可以保存各种不同类型的值；链表的缺陷也是有的： 链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。 还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，内存开销较大。因此，Redis 3.0 的 List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。不过，压缩列表存在性能问题（具体什么问题，下面会说），所以 Redis 在 3.2 版本设计了新的数据结构 quicklist，并将 List 对象的底层数据结构改由 quicklist 实现。然后在 Redis 5.0 设计了新的数据结构 listpack，沿用了压缩列表紧凑型的内存布局，最终在最新的 Redis 版本，将 Hash 对象和 Zset 对象的底层数据结构实现之一的压缩列表，替换成由 listpack 实现。压缩列表压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。但是，压缩列表的缺陷也是有的：不能保存过多的元素，否则查询效率就会降低；新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题。因此，Redis 对象（List 对象、Hash 对象、Zset 对象）包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。压缩列表是 Redis 为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组。 zlbytes，记录整个压缩列表占用对内存字节数； zltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素。压缩列表节点（entry）的构成如下： prevlen，记录了「前一个节点」的长度； encoding，记录了当前节点实际数据的类型以及长度； data，记录了当前节点的实际数据；当我们往压缩列表中插入数据时，压缩列表就会根据数据是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的。分别说下，prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配。压缩列表里的每个节点中的 prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如： 如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用 1 字节的空间来保存这个长度值； 如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用 5 字节的空间来保存这个长度值；encoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关： 如果当前节点的数据是整数，则 encoding 会使用 1 字节的空间进行编码。 如果当前节点的数据是字符串，根据字符串的长度大小，encoding 会使用 1 字节/2字节/5字节的空间进行编码。压缩列表除了查找复杂度较高之外，还有一个连续更新的问题。压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。前面提到，压缩列表节点的 prevlen 属性会根据前一个节点的长度进行不同的空间大小分配 如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用 1 字节的空间来保存这个长度值； 如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用 5 字节的空间来保存这个长度值；现在假设一个压缩列表中有多个连续的、长度在 250～253 之间的节点，如下图：因为这些节点长度值小于 254 字节，所以 prevlen 属性需要用 1 字节的空间来保存这个长度值。这时，如果将一个长度大于等于 254 字节的新节点加入到压缩列表的表头节点，即新节点将成为 e1 的前置节点，如下图因为 e1 节点的 prevlen 属性只有 1 个字节大小，无法保存新节点的长度，此时就需要对压缩列表的空间重分配操作，并将 e1 节点的 prevlen 属性从原来的 1 字节大小扩展为 5 字节大小。多米诺牌的效应就此开始。e1 原本的长度在 250～253 之间，因为刚才的扩展空间，此时 e1 的长度就大于等于 254 了，因此原本 e2 保存 e1 的 prevlen 属性也必须从 1 字节扩展至 5 字节大小。正如扩展 e1 引发了对 e2 扩展一样，扩展 e2 也会引发对 e3 的扩展，而扩展 e3 又会引发对 e4 的扩展… 一直持续到结尾。这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」，就像多米诺牌的效应一样，第一张牌倒下了，推动了第二张牌倒下；第二张牌倒下，又推动了第三张牌倒下……空间扩展操作也就是重新分配内存，因此连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。所以说，虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题。因此，压缩列表只会用于保存的节点数量不多的场景，只要节点数量足够小，即使发生连锁更新，也是能接受的。虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。哈希表哈希表是一种保存键值对（key-value）的数据结构。哈希表中的每一个 key 都是独一无二的，程序可以根据 key 查找到与之关联的 value，或者通过 key 来更新 value，又或者根据 key 来删除整个 key-value等等。在讲压缩列表的时候，提到过 Redis 的 Hash 对象的底层实现之一是压缩列表（最新 Redis 代码已将压缩列表替换成 listpack）。Hash 对象的另外一个底层实现就是哈希表。哈希表优点在于，它能以 O(1) 的复杂度快速查询数据。怎么做到的呢？将 key 通过 Hash 函数的计算，就能定位数据在表中的位置，因为哈希表实际上是数组，所以可以通过索引值快速查询到数据。但是存在的风险也是有，在哈希表大小固定的情况下，随着数据不断增多，那么哈希冲突的可能性也会越高。解决哈希冲突的方式，有很多种。Redis 采用了「链式哈希」来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接起，以便这些数据在表中仍然可以被查询到。哈希表结构设计Redis 的哈希表结构如下：typedef struct dictht { //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 unsigned long sizemask; //该哈希表已有的节点数量 unsigned long used;} dictht;可以看到，哈希表是一个数组（dictEntry **table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针。哈希表节点的结构如下：typedef struct dictEntry { //键值对中的键 void *key; //键值对中的值 union { void *val; uint64_t u64; int64_t s64; double d; } v; //指向下一个哈希表节点，形成链表 struct dictEntry *next;} dictEntry;dictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。另外，这里还跟你提一下，dictEntry 结构里键值对中的值是一个「联合体 v」定义的，因此，键值对中的值可以是一个指向实际值的指针，或者是一个无符号的 64 位整数或有符号的 64 位整数或double 类的值。这么做的好处是可以节省内存空间，因为当「值」是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。哈希冲突哈希表实际上是一个数组，数组里多每一个元素就是一个哈希桶。当一个键值对的键经过 Hash 函数计算后得到哈希值，再将(哈希值 % 哈希表大小)取模计算，得到的结果值就是该 key-value 对应的数组元素位置，也就是第几个哈希桶。什么是哈希冲突呢？举个例子，有一个可以存放 8 个哈希桶的哈希表。key1 经过哈希函数计算后，再将「哈希值 % 8 」进行取模计算，结果值为 1，那么就对应哈希桶 1，类似的，key9 和 key10 分别对应哈希桶 1 和桶 6。此时，key1 和 key9 对应到了相同的哈希桶中，这就发生了哈希冲突。因此，当有两个以上数量的 kay 被分配到了哈希表中同一个哈希桶上时，此时称这些 key 发生了冲突。Redis 采用了「链式哈希」的方法来解决哈希冲突。链式哈希是怎么实现的？实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来，这样就解决了哈希冲突。还是用前面的哈希冲突例子，key1 和 key9 经过哈希计算后，都落在同一个哈希桶，链式哈希的话，key1 就会通过 next 指针指向 key9，形成一个单向链表。不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)。要想解决这一问题，就需要进行 rehash，也就是对哈希表的大小进行扩展。接下来，看看 Redis 是如何实现的 rehash 的。哈希表结构设计的这一小节，我给大家介绍了 Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了两个哈希表（ht[2]）。typedef struct dict { … //两个Hash表，交替使用，用于rehash操作 dictht ht[2]; …} dict;之所以定义了 2 个哈希表，是因为进行 rehash 的时候，需要用上 2 个哈希表了。在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。随着数据逐步增多，触发了 rehash 操作，这个过程分为三步： 给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍； 将「哈希表 1 」的数据迁移到「哈希表 2」 中； 迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。为了方便你理解，我把 rehash 这三个过程画在了下面这张图。这个过程看起来简单，但是其实第二步很有问题，如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求。为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。渐进式 rehash 步骤如下： 给「哈希表 2」 分配空间； 在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上； 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间嗲呢，会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。rehash 的触发条件跟 负载因子（load factor） 有关系。负载因子可以通过下面这个公式计算：触发 rehash 操作的条件，主要有两个： 当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。 当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。整数集合整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不时，就会使用整数集这个数据结构作为底层实现。整数集合结构设计整数集合本质上是一块连续内存空间，它的结构定义如下：typedef struct intset { //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];} intset;可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。比如： 如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t； 如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t； 如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t；不同类型的 contents 数组，意味着数组的大小也会不同。整数集合的升级操作整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割，如果 encoding 属性值为 INTSET_ENC_INT16，则每个元素的间隔就是 16 位。举个例子，假设有一个整数集合里有 3 个类型为 int16_t 的元素。现在，往这个整数集合中加入一个新元素 65535，这个新元素需要用 int32_t 类型来保存，所以整数集合要进行升级操作，首先需要为 contents 数组扩容，在原本空间的大小之上再扩容多 80 位（4x32-3x16=80），这样就能保存下 4 个类型为 int32_t 的元素。扩容完 contents 数组空间大小后，需要将之前的三个元素转换为 int32_t 类型，并将转换后的元素放置到正确的位上面，并且需要维持底层数组的有序性不变，整个转换过程如下：整数集合升级有什么好处呢？如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成内存浪费的情况。整数集合升级就能避免这种情况，如果一直向整数集合添加 int16_t 类型的元素，那么整数集合的底层实现就一直是用 int16_t 类型的数组，只有在我们要将 int32_t 类型或 int64_t 类型的元素添加到集合时，才会对数组进行升级操作。因此，整数集合升级的好处是节省内存资源。整数集合支持降级操作吗？不支持降级操作，一旦对数组进行了升级，就会一直保持升级后的状态。比如前面的升级操作的例子，如果删除了 65535 元素，整数集合的数组还是 int32_t 类型的，并不会因此降级为 int16_t 类型。跳表Redis 只有在 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。Zset 对象是唯一一个同时使用了两个数据结构来实现的 Redis 对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。typedef struct zset { dict *dict; zskiplist *zsl;} zset;Zset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了跳表，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时采用了哈希表进行索引。跳表结构设计链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，这样的好处是能快读定位数据。那跳表长什么样呢？我这里举个例子，下图展示了一个层级为 3 的跳表。图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来： L0 层级共有 5 个节点，分别是节点1、2、3、4、5； L1 层级共有 3 个节点，分别是节点 2、3、5； L2 层级只有 1 个节点，也就是节点 3 。如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。那跳表节点是怎么实现多层级的呢？这就需要看「跳表节点」的数据结构了，如下：typedef struct zskiplistNode { //Zset 对象的元素值 sds ele; //元素权重值 double score; //后向指针 struct zskiplistNode *backward; //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; } level[];} zskiplistNode;Zset 对象要同时保存元素和元素的权重，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel 结构体类型的 level 数组。level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。比如，下面这张图，展示了各个节点的跨度。图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来： L0 层级共有 5 个节点，分别是节点1、2、3、4、5； L1 层级共有 3 个节点，分别是节点 2、3、5； L2 层级只有 1 个节点，也就是节点 3 。如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。那跳表节点是怎么实现多层级的呢？这就需要看「跳表节点」的数据结构了，如下：typedef struct zskiplistNode { //Zset 对象的元素值 sds ele; //元素权重值 double score; //后向指针 struct zskiplistNode *backward; //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; } level[];} zskiplistNode;Zset 对象要同时保存元素和元素的权重，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel 结构体类型的 level 数组。level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。比如，下面这张图，展示了各个节点的跨度。第一眼看到跨度的时候，以为是遍历操作有关，实际上并没有任何关系，遍历操作只需要用前向指针就可以完成了。跨度实际上是为了计算这个节点在跳表中的排位。具体怎么做的呢？因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。举个例子，查找图中节点 3 在跳表中的排位，从头节点开始查找节点 3，查找的过程只经过了一个层（L3），并且层的跨度是 3，所以节点 3 在跳表中的排位是 3。另外，图中的头节点其实也是 zskiplistNode 跳表节点，只不过头节点的后向指针、权重、元素值都会被用到，所以图中省略了这部分。问题来了，由谁定义哪个跳表节点是头节点呢？这就介绍「跳表」结构体了，如下所示： 跳表的头尾节点，便于在O(1)时间复杂度内访问跳表的头节点和尾节点； 跳表的长度，便于在O(1)时间复杂度获取跳表节点的数量； 跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level;} zskiplist;跳表节点查询过程查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件： 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。举个例子，下图有个 3 层级的跳表。如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的： 先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点； 但是该层上的下一个节点是空节点，于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1]; 「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，但是当前节点的 SDS 类型数据「大于」要查找的数据，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]； 「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束。跳表节点层数设置跳表的相邻两层的节点数量的比例会影响跳表的查询性能。举个例子，下图的跳表，第二层的节点数量只有 1 个，而第一层的节点数量有 6 个。这时，如果想要查询节点 6，那基本就跟链表的查询复杂度一样，就需要在第一层的节点中依次顺序查找，复杂度就是 O(N) 了。所以，为了降低查询复杂度，我们就需要维持相邻层结点数间的关系。跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)。下图的跳表就是，相邻两层的节点数量的比例是 2 : 1。那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。Redis 则采用一种巧妙的方法是，跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。quicklist在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。quicklist 解决办法，通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。typedef struct quicklist { //quicklist的链表头 quicklistNode *head; //quicklist的链表头 //quicklist的链表头 quicklistNode *tail; //所有压缩列表中的总元素个数 unsigned long count; //quicklistNodes的个数 unsigned long len; ...} quicklist;quicklistNode 的结构定义：typedef struct quicklistNode { //前一个quicklistNode struct quicklistNode *prev; //前一个quicklistNode //下一个quicklistNode struct quicklistNode *next; //后一个quicklistNode //quicklistNode指向的压缩列表 unsigned char *zl; //压缩列表的的字节大小 unsigned int sz; //压缩列表的元素个数 unsigned int count : 16; //ziplist中的元素个数 ....} quicklistNode;可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。我画了一张图，方便你理解 quicklist 数据结构。在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。listpackquicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。我看了 Redis 的 Github，在最新 6.2 发行版本中，Redis Hash 对象、Set 对象的底层数据结构的压缩列表还未被替换成 listpack，而 Redis 的最新代码（还未发布版本）已经将所有用到压缩列表底层数据结构的 Redis 对象替换成 listpack 数据结构来实现，估计不久将来，Redis 就会发布一个将压缩列表为 listpack 的发行版本。listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。我们先看看 listpack 结构：listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。每个 listpack 节点结构如下：主要包含三个方面内容： encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码； data，实际存放的数据； len，encoding+data的总长度；可以看到，listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。rax(前缀树)rax 是 redis 自己实现的基数树, 它是一种基于存储空间优化的前缀树数据结构, 在 redis 的许多地方都有使用到，比如：streams这个类型里面的 consumer group(消费者组) 的名称还有集群名称；集群状态下clusterState中的slots_to_keys用rax保存了从槽到key之间的关系。通常来讲, 一个基数树(前缀树) 看起来如下所示： * (f) \"\" * \\ * (o) \"f\" * \\ * (o) \"fo\" * \\ * [t b] \"foo\" * / \\ * \"foot\" (e) (a) \"foob\" * / \\ * \"foote\" (r) (r) \"fooba\" * / \\ * \"footer\" [] [] \"foobar\"然而, 当前的代码实现使用了一种非常常见的优化策略, 把只有单个子的节点连续几个节点压缩成一个节点, 这个节点有一个字符串, 不再是只存储单个字符, 上述的结构可以优化成如下结构： * [\"foo\"] \"\" * | * [t b] \"foo\" * / \\ * \"foot\" (\"er\") (\"ar\") \"foob\" * / \\ * \"footer\" [] [] \"foobar\"字符串 mygroup1 在 rax 中也是以压缩节点的方式存储的, 可以用如下表示: * [\"mygroup1\"] \"\" * | * [] \"mygroup1\"第一个节点存储了压缩过的整个字符串 mygroup1, 第二个节点是一个空的叶子节点, 他是一个 key 值, 表示到这个节点之前合起来的字符串存储在了当前的 raxNode中。rax结构代表一个Rax树：typedef struct rax {　　raxNode *head;　　uint64_t numele;　　uint64_t numnodes;} rax; head：指向rax的头节点； numele：rax元素的个数，即key的个数； numnodes：节点个数。typedef struct raxNode { //节点是否包含key uint32_t iskey:1; /* Does this node contain a key? */ //节点的值是否为NULL uint32_t isnull:1; /* Associated value is NULL (don't store it). */ //节点是否被压缩 uint32_t iscompr:1; /* Node is compressed. */ //节点大小 uint32_t size:29; /* Number of children, or compressed string len. */ //节点的实际存储数据 unsigned char data[];} raxNode; iskey 表示当前的节点是否为 key 节点，即表示从 Radix Tree 的根节点到当前节点路径上的字符组成的字符串，是否表示了一个完整的 key。这里需要注意的是，当前节点所表示的 key，并不包含该节点自身的内容 isnull 表示当前节点是否有存储额外的值(data的指针是否为空) iscompr 表示当前节点是否为压缩的节点 size 是子节点数量或者压缩的字符串长度，如果当前节点是压缩节点，该值表示压缩数据的长度；如果是非压缩节点，该值表示该节点指向的子节点个数。 data存储数据在 Radix Tree 中存在两类节点： 第一类节点是非压缩节点，这类节点会包含多个指向不同子节点的指针，以及多个子节点所对应的字符。data 数组包括子节点对应的字符、指向子节点的指针，以及节点表示 key 时对应的 value 指针； 第二类节点是压缩节点，这类节点会包含一个指向子节点的指针，以及子节点所代表的合并的字符串。data 数组包括子节点对应的合并字符串、指向子节点的指针，以及节点为 key 时的 value 指针。在 raxNode 的实现中，无论是非压缩节点还是压缩节点，其实具有两个特点： 它们所代表的 key，是从根节点到当前节点路径上的字符串，但并不包含当前节点； 它们本身就已经包含了子节点代表的字符或合并字符串。而对于它们的子节点来说，也都属于非压缩或压缩节点，所以，子节点本身又会保存，子节点的子节点所代表的字符或合并字符串。可以简单看下这个例子：这张图上显示了 Radix Tree 最右侧分支的 4 个节点 r、e、d、is 和它们各自的 raxNode 内容。其中，节点 r、e 和 d 都不代表 key，所以它们的 iskey 值为 0，isnull 值为 1，没有为 value 指针分配空间。节点 r 和 e 指向的子节点都是单字符节点，所以它们不是压缩节点，iscompr 值为 0。而节点 d 的子节点包含了合并字符串“is”，所以该节点是压缩节点，iscompr 值为 1。最后的叶子节点 is，它的 raxNode 的 size 为 0，没有子节点指针。不过，因为从根节点到节点 is 路径上的字符串代表了 key“redis”，所以，节点 is 的 value 指针指向了“redis”对应的 value 数据。这里，你需要注意的是，为了满足内存对齐的需要，raxNode 会根据保存的字符串长度，在字符串后面填充一些字节，也就是图中的 padding 部分。下图是字符串 mygroup1 当前所在的 rax 的实际图示：第一个节点的 iscompr 值为 1, 并且整个字符串 mygroup1 存储在了当前这一个节点中, size 为 8 表示当前节点存储了 8 个 char 字符, iskey为 0, 表示当前的节点不是 key 节点, 我们需要继续往下搜索。第二个节点的 iskey 为 1, 表示当前的节点为 key 节点, 它表示在到这个节点之前的所有字符串连起来(也就是mygroup1) 存在当前的前缀树中, 也就是说当前的前缀树有包含 mygroup1 这个字符串, isnull 为 0 表示在当前这个 key 节点的 data 尾部存储了一个指针, 这个指针是函数调用者进行存储的, 在当前的情况它是一个指向 streamCG 的指针, 但是实际上他可以是指向任意对象的指针, 比如集群名称或者其他对象。我们再来插入一个 consumer group 名称到当前的前缀树中：比如执行 XGROUP CREATE mystream mygroup2 $从上图可知, 第一个节点被裁剪了, 并且它后面插入了一个新的节点, 左下角的节点是原先存在的节点, 右下角的节点也是一个新插入的节点: * [\"mygroup\"] \"\" * | * [1 2] \"mygroup\" * / \\ * \"mygroup1\" [] [] \"mygroup2\"中间的节点未被压缩(iscompr 这个位没有被设置), data 字段中存储了 size 个字符, 在这些字符之后, 同样会存储 size 个指向与之前字符一一对应的 raxNode 的结构的指针。底下两个节点的 iskey = 1 并 isnull = 0, 表示当到达任意一个这样的节点时, 当前的字符串是存储在这个前缀树中的, 并且在 data 字段最尾部存储了一个辅助的指针, 这个指针具体指向什么对象取决于调用者。streamStream 会使用 Radix Tree 来保存消息 ID，然后将消息内容保存在 listpack 中，并作为消息 ID 的 value，用 raxNode 的 value 指针指向对应的 listpack。typedef struct stream {　　rax *rax; /* 存储生产者生产的具体消息，以消息ID为键，消息内容为值存储在rax中，值得注意的是，rax中的一个节点可能存储多个消息*/　　uint64_t length; /*当前stream中的消息个数（不包括已经删除的消息）。*/　　streamID last_id; /* 当前stream中最后插入的消息的ID，stream空时，设置为0。. */　　rax *cgroups; /* 存储了当前stream相关的消费组，rax中: name -&gt; streamCG */} stream; rax：指向rax的的头节点，存储生产者生产的具体消息，以消息ID为键，消息内容为值存储在rax中； length：stream中消息的个数，不包括已经删除的消息； last_id： 当前stream中最后插入的消息的ID，stream空时，设置为0； cgoups：指向rax的头节点，存储了当前stream相关的消费组。每个Stream会有多个消费组，每个消费组通过组名称进行唯一标识，同时关联一个streamCG结构，该结构定义如下：typedef struct streamCG {　　streamID last_id; // 该消费组已经确认的最后一个消息的ID　　rax *pel; // 该消费组尚未确认的消息，消息ID为键，streamNACK（一个尚未确认的消息）为值；　　rax *consumers; // 该消费组中所有的消费者，消费者的名称为键，streamConsumer（代表一个消费者）为值。} streamCG;每个消费者通过streamConsumer唯一标识，该结构如下：typedef struct streamConsumer {　　mstime_t seen_time; /* 该消费者最后一次活跃的时间； */　　sds name; /* 消费者的名称*/　　rax *pel; /* 消费者尚未确认的消息，以消息ID为键，streamNACK为值。 */} streamConsumer;未确认消息（streamNACK）维护了消费组或者消费者尚未确认的消息，值得注意的是，消费组中的pel的元素与每个消费者的pel中的元素是共享的，即该消费组消费了某个消息，这个消息会同时放到消费组以及该消费者的pel队列中，并且二者是同一个streamNACK结构。/* Pending (yet not acknowledged) message in a consumer group. */typedef struct streamNACK { mstime_t delivery_time; /* 该消息最后发送给消费方的时间 */ uint64_t delivery_count; /*为该消息已经发送的次数（组内的成员可以通过xclaim命令获取某个消息的处理权，该消息已经分给组内另一个消费者但其并没有确认该消息）。*/ streamConsumer *consumer; /* 该消息当前归属的消费者 */} streamNACK;此外，还可以看下迭代器：typedef struct streamIterator { stream *stream; /*当前迭代器正在遍历的消息流 */ streamID master_id; /* 消息内容实际存储在listpack中，每个listpack都有一个masterentry（也就是第一个插入的消息），master_id为该消息id */ uint64_t master_fields_count; /* master entry中field域的个数. */ unsigned char *master_fields_start; /*master entry field域存储的首地址*/ unsigned char *master_fields_ptr; /*当listpack中消息的field域与master entry的field域完全相同时，该消息会复用master entry的field域，在我们遍历该消息时，需要记录当前所在的field域的具体位置，master_fields_ptr就是实现这个功能的。 */ int entry_flags; /* 当前遍历的消息的标志位 */ int rev; /*当前迭代器的方向 */ uint64_t start_key[2]; /* 该迭代器处理的消息ID的范围 */ uint64_t end_key[2]; /* End key as 128 bit big endian. */ raxIterator ri; /*rax迭代器，用于遍历rax中所有的key. */ unsigned char *lp; /* 当前listpack指针*/ unsigned char *lp_ele; /* 当前正在遍历的listpack中的元素, cursor. */ unsigned char *lp_flags; /* Current entry flags pointer.指向当前消息的flag域 */ //用于从listpack读取数据时的缓存 unsigned char field_buf[LP_INTBUF_SIZE]; unsigned char value_buf[LP_INTBUF_SIZE];} streamIterator;存储方式如下图示：stream 结构体中的 rax 指针，指向了 Radix Tree 的头节点，也就是 rax 结构体。rax 结构体中的头指针进一步指向了第一个 raxNode。因为我们假设就只有一个 streamID，暂时没有其他 streamID 和该 streamID 共享前缀，所以，当前这个 streamID 就可以用压缩节点保存。然后，第一个 raxNode 指向了下一个 raxNode，也是 Radix Tree 的叶子节点。这个节点的 size 为 0，它的 value 指针指向了实际的消息内容。streamID可以自己指定，也可以由redis生成，即由每个消息创建时的时间（1970年1月1号至今的毫秒数）以及序号组成，共128位：typedef struct streamID {　　uint64_t ms; /* Unix time in milliseconds. */　　uint64_t seq; /* Sequence number. */} streamID;而在消息内容这里，是使用了 listpack 进行保存的。一个listpack可以存储多个消息，也就是说多个raxNode可能会指向同一个listpack。每个listpack都有一个master entry，该结构中存储了创建这个listpack时待插入消息的所有field，这主要是考虑同一个消息流，消息内容通常具有相似性，如果后续消息的field与master entry内容相同，则不需要再存储其field。master entry中每一个元素都是一个单独的entry（下图省略了listpack每个元素存储时的encoding以及backlen字段） count 为当前listpack中的所有未删除的消息个数； deleted 为当前listpack中所有已经删除的消息个数； num-fields 为下面的field的个数； field-1,…,filed-N 为当前listpack中第一个插入的消息的所有field域； 0 为标识位，在从后向前遍历该listpack的所有消息时使用。存储一个消息时，如果该消息的field域与master entry的域完全相同，则不需要再次存储field域： flags字段为消息标志位，STREAM_ITEM_FLAG_NONE代表无特殊标识， STREAM_ITEM_FLAG_DELETED代表该消息已经被删除， STREAM_ITEM_FLAG_SAMEFIELDS代表该消息的field域与master entry完全相同； streamID.ms以及streamID.seq为该消息ID减去master entry id之后的值； value域存储了该消息的每个field域对应的内容； lp-count为该消息占用listpack的元素个数，也就是3+N。消息的field域与master entry不完全相同，存储如下： flags为消息标志位，与上面一致； streamID.ms，streamID.seq为该消息ID减去master entry id之后的值； num-fields为该消息field域的个数； field-value存储了消息的域值对，也就是消息的具体内容； lp-count为该消息占用的listpack的元素个数，也就是4+2N。添加消息Redis提供了streamAppendItem函数，用于向stream中添加一个新的消息：int streamAppendItem(stream *s, robj **argv, int64_t numfields, streamID *added_id, streamID *use_id) s 为待插入的数据流； argv 为待插入的消息内容，argv[0]为field_1，argv[1]为value_1，依此类推； numfields 为待插入的消息的field的总数； added_id 不为空，并且插入成功时，将新插入的消息id写入added_id以供调用方使用； use_id 为调用方为该消息定义的消息id，该消息id应该大于s中任意一个消息的id。大概流程如下： 获取rax的最后一个key所在的节点，由于Rax树是按照消息id的顺序存储的，所以最后一个key节点存储了上一次插入的消息； 查看该节点是否可以插入这条新的消息； 如果该节点已经不能再插入新的消息（listpack为空或者已经达到设定的存储最大值），在rax中插入新的节点（以消息id为key，新建listpack为value），并初始化新建的listpack； 如果仍然可以插入消息，则对比插入的消息与listpack中的master消息对应的fields是否完全一致，完全一致则表明该消息可以复用master的field； 将待插入的消息内容插入到新建的listpack中或者原来的rax的最后一个key节点对应的listpack中，这一步主要取决于前2步的结果。删除消息streamIteratorRemoveEntry函数用于移除某个消息，值得注意的是，该函数通常只是设置待移除消息的标志位为已删除，并修改master entry的统计信息，而不会将该消息从所在的listpack中删除。当消息所在的整个listpack的所有消息都已删除时，则会从rax中释放该节点。void streamIteratorRemoveEntry(streamIterator *si, streamID *current) { unsigned char *lp = si-&gt;lp; int64_t aux; int flags = lpGetInteger(si-&gt;lp_flags); flags |= STREAM_ITEM_FLAG_DELETED; lp = lpReplaceInteger(lp,&amp;si-&gt;lp_flags,flags); // 设置消息的标志位 /* Change the valid/deleted entries count in the master entry. */ unsigned char *p = lpFirst(lp); aux = lpGetInteger(p); if (aux == 1) { /* 当前Listpack只有待删除消息，可以直接删除节点. */ lpFree(lp); raxRemove(si-&gt;stream-&gt;rax,si-&gt;ri.key,si-&gt;ri.key_len,NULL); } else { /* 修改listpack master enty中的统计信息 */ lp = lpReplaceInteger(lp,&amp;p,aux-1); p = lpNext(lp,p); /* Seek deleted field. */ aux = lpGetInteger(p); lp = lpReplaceInteger(lp,&amp;p,aux+1); /* 查看listpack是否有变化(listpack中元素变化导致的扩容缩容) . */ if (si-&gt;lp != lp) raxInsert(si-&gt;stream-&gt;rax,si-&gt;ri.key,si-&gt;ri.key_len,lp,NULL); } .....}参考文档 图文讲解Redis底层数据结构之embstr,raw,ziplist,quicklist和hashtable （带源码讲解） redis各数据类型的编码格式和数据结构SDS、list、dict、zskiplist、intset、ziplist、quicklist、listpack、rax、streamredis 源码导读数据结构除了抽象描述之外，如何实现也是很有参考价值的。了解Redis原理时看C语言代码有困难，或者想了解Go语言是如何实现Redis功能的，可参考Godis。 Redis 源码阅读篇 Redis源码解析-全览 深入了解Redis（底层实现）源码 （第一篇） 深入了解Redis（底层实现）源码 （第二篇） 深入了解Redis（底层实现）源码 （第三篇） 深入了解Redis（底层实现）源码 （第四篇） Redis核心设计原理（深入底层C源码） 如何去高效阅读源码 Redis源码注解 Redis源码 阅读源码应从低版本开始，毕竟代码量比较少 Redis 源码日志redis 通信协议所谓 协议，本质是一种约定，需要使用者双方来准守，常见于 C/S 通信模式中，比如在浏览器中最常用的 HTTP 应用层通信协议。通信两端需要某种约定，才能保持正常通信。一端通过约定的格式发送数据，另一端通过约定的格式解析数据，这种约定，取了一个好听的名字 —- 协议。典型的 HTTP 协议，最本质的原理也是如此。redis 作为一款高性能内存组件，要尽可能将精力花在数据的组织形式上，因此，没有采用开源的一些复杂协议，比如 HTTP，而是简单的自定义一套应用层通信协议。Redis 客户端 - 服务端通信协议称之为 RESP 协议，全称叫 Redis Serialization Protocol，即 redis 序列化协议。人类易读，相当精巧！RESP 是一种二进制安全协议，因为编码后的每一个字符串都有前缀来表明其长度，通过长度就能知道数据边界，从而避免越界访问的问题。值得注意的是，RESP 协议只用于 客户端 - 服务端 之间的交流，redis cluster 各节点之间采用不同的二进制协议（采用 Gossip 协议）进行交流。我们知道，在传统计算机网络模型中，传输层（TCP / UDP）的上一层便是应用层。应用层协议一般专注于数据的编解码等约定，比如经典的 HTTP 协议。RESP 协议本质和 HTTP 是一个级别，都属于应用层协议。在 redis 中，传输层协议使用的是 TCP，服务端从 TCP socket 缓冲区中读取数据，然后经过 RESP 协议解码得到我们的指令。而写入数据则是相反，服务器先将响应数据使用 RESP 编码，然后将编码后的数据写入 TCP Socket 缓冲区发送给客户端。RESP2在 RESP 协议中，第一个字节决定了具体数据类型： 简单字符串：Simple Strings，第一个字节响应 + 错误：Errors，第一个字节响应 - 整型：Integers，第一个字节响应 : 批量字符串：Bulk Strings，第一个字节响应 $ 数组：Arrays，第一个字节响应 *我们来看看一具体的例子，我们一条正常指令PSETEX test_redisson_batch_key8 120000 test_redisson_batch_key=&gt;value:8，经 RESP 协议编码后长这样：*4$6PSETEX$24test_redisson_batch_key8$6120000$32test_redisson_batch_key=&gt;value:8值得注意的是，在 RESP 协议中的每一部分都是以 \\R\\N 结尾。简单字符串Simple Strings。以 + 为前缀的响应数据，例如：\"+OK\\r\\n\"。以上是字符串 OK，被编码后的格式，总共 5 字节。这是一种非二进制安全的编码方式，因为， 我们无法确切的知道字符串的长度，只能以 \\r\\n 来判断，所以编码的字符串中，不能包含 \\r 或者 \\n 字符。当然，如果你想要二进制安全字符串，可以选择 Bulk Strings 方式，我们后面会介绍。错误RESP 提供了错误类型，和简单字符串非常类似，不过是以 - 开头，基本格式如下：\"-Error message\\r\\n\"。与简单字符串真正不同的之处在于客户端的处理上，对 - 开头的响应，客户端直接以异常情况处理。我们来看一个是实际例子，当我们的指令或者参数错误，redis 服务端会直接返回异常，如下：-ERR unknown command 'helloworld'-WRONGTYPE Operation against a key holding the wrong kind of value其中 - 后面的第一个单词，直到第一个空格或换行符，表示返回的错误类型。这只是 Redis 使用的一个惯例，并不是 RESP 错误格式的一部分。ERR 是通用错误，而 WRONGTYPE 是一个更具体的错误，表示客户端尝试执行错误的数据类型，通常作为一个错误的前缀，它允许客户端在不检查确切错误消息的情况下理解服务器返回的错误类型。我们在客户端实现的时候，可以针对不同的错误返回不同类型的异常，或者提供一种捕获错误的通用方法，比如，直接将错误名称作为字符串提供给调用者。然而，这样的特性不应该被认为是至关重要的，因为它很少有用，而且有限的客户端实现可能只是返回一个通用的错误条件，比如 false。整型RESP Integers。表示响应的是整数，以 : 开头，比如 :0\\r\\n 和 :1000\\r\\nredis 中很多命令的响应都是整数，比如 INCR, LLEN, 及 LASTSAVE。另外，响应值是一个 64 位的整数。当然，整形也可以表示 true 或者 false 语义，比如 EXISTS 或者 SISMEMBER 返回 1 表示 true，0 表示 false。还有其他命令，比如 SADD, SREM, 和 SETNX 返回 1 表示实际执行，反之为 0。以下命令会响应结果为整数：SETNX, DEL, EXISTS, INCR, INCRBY, DECR, DECRBY, DBSIZE, LASTSAVE, RENAMENX, MOVE, LLEN, SADD, SREM, SISMEMBER, SCARD.批量字符串RESP Bulk Strings。批量回复，是一个大小在 512 Mb 的二进制安全字符串，被编码成： 以 $ 开头，紧跟一个整数代表回复字符串的大小，以 \\r\\n 结束 随后是实际的字符串数据 最后以 “\\r\\n” 结尾以下是示例： 比如 hello 被编码为：”$5\\r\\nhello\\r\\n” 一个空字符串被编码为：”$0\\r\\n\\r\\n”另外，对于一些不存在的 value 可以返回 -1 表示 null，也被称为 NULL 批量回复。客户端库进行实现时，可以将此 -1 处理成空对象，比如 Ruby 将返回 nil，而 C 则返回 NULL数组RESP Arrays。数组，对于响应的集合元素，比如 LRANGE 命令，返回的是元素列表，也就是数组形式。编码格式： 以 * 开头表示，紧接着是一个整数，表示数组元素个数，并以 \\r\\n 结尾。 数组的每个元素的都是 RESP 提供的类型。以下是示例： 例如，空数组：\"*0\\r\\n\" 包含 “hello” 和 “world” 的响应数组（也叫多批量字符串，每一个元素是批量字符串）：\"*2\\r\\n$5\\r\\nhello\\r\\n$5\\r\\nworld\\r\\n\" 3个整数的数组是这样的：\"*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\" 另外，数组也可以混合类型的。比如以下5个元素中，有4个是整形，一个是 批量字符串：*5\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n:4\\r\\n$5\\r\\nhello\\r\\n以上结果为了更加清晰的展示，进行了手动换行。当然，也同样支持空数组（一般情况下，更习惯使用 Null Bulk String，但由于历史原因，两种方式都存在）例如，当使用 BLPOP 命令 timeout 时，将返回空数组：\"*-1\\r\\n\"当 redis 返回 NULL 数组时，客户端实现库最好也返回一个空对象，有助于区别到底是 empty 数组还是产生了其他问题内置数组，如下：*2\\r\\n*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n*2\\r\\n+Hello\\r\\n-World\\r\\n同样，为了展示更加清晰，进行了手动换行该响应结果表示，外层数组包含两个元素，每个元素都是数组。第一个子数组包含 3 个整型数字，第二个子数组包含 1 个简单字符串和一个错误。数组中的空元素Null elements in Arrays。数组出现 NULL 元素，这种场景也是很常见的，比如我们使用 MGET 批量获取 key，当其中一些 key 不存在时，返回的就是 NULL 元素。例如响应结果：*3\\r\\n$5\\r\\nhello\\r\\n$-1\\r\\n$5\\r\\nworld\\r\\n如上响应编码，客户端库解析之后应该是这样：[\"hello\",nil,\"world\"]多命令和管道Multiple commands and pipelining。多命令和管道，redis 中提供了一次发送多条指令的操作，比如 MGET、MSET、pipline，服务端接收并处理后一次性响应。这种形式就是上面提到的数组，数组里面可以是批量字符串、整数，甚至是 NULL 都可以。我们先使用 telnet 看看原生响应结果：[root@VM-20-17-centos ~]# telnet 127.0.0.1 6379MGET key1 key2 key3*3$6value1$6value2$-1我们再使用 redis-cli 看看被客户端解码后的结果：127.0.0.1:6379&gt; MGET key1 key2 key31) \"value1\"2) \"value2\"3) (nil)内联命令Inline commands。是这样的，一般情况下我们和 redis 服务端通信都需要一个客户端（比如redis-cli），因为双方都遵循 RESP 协议，数据可以正常编码和解析。考虑这样一种情况，当你没有任何客户端工具可用时，是否也能正常和服务端通信呢？比如 telnet。也是可以的，redis 正式通过 内联指令 支持的，咱们来看看例子： 例1，通过 RESP 协议发送指令（由于没有客户端，这里我们手动编码）：[root@VM-20-17-centos ~]# telnet 127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.*3 $3set$4 key1$5 world+OK我们正常的指令是 set key1 word，经过 RESP 编码之后 *3\\r\\n$3\\r\\nset\\r\\n$4\\r\\nkey1\\r\\r$5\\r\\nworld，redis 服务端解码之后便可得到正常指令。 例2，通过内联操作发送指令：[root@VM-20-17-centos ~]# telnet 127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.exists key1:1get key1$11set key1 hello +OKget key1$5hello这里我们直接发送 内联指令 比如 EXISTS key1、GET key1、SET key1 hello 等，无需 RESP 协议编码，服务端仍可正常处理。值得注意的是，因为没有了统一请求协议中的 * 项来声明参数的数量，所以在 telnet 会话输入命令的时候，必须使用空格来分割各个参数，服务器在接收到数据之后，会按空格对用户的输入进行解析，并获取其中的命令参数。高性能 Redis 协议解析器High performance parser for the Redis protocol，即，高性能 Redis 协议分析器。RESP 是一款人类易读、简单实现的通信协议，它可以类似于二进制协议的性能实现。RESP 使用前缀长度来传输批量数据，因此不需要像 JSON 那样，为了查找某个特殊字符而扫描整个数据，也无须对发送至服务器的数据进行转义。程序可以在对协议文本中的各个字符进行处理的同时， 查找 CR 字符， 并计算出批量回复或多条批量回复的长度， 就像这样：#include &lt;stdio.h&gt;int main(void) { unsigned char *p = \"$123\\r\\n\"; int len = 0; p++; while(*p != '\\r') { len = (len*10)+(*p - '0'); p++; } /* Now p points at '\\r', and the len is in bulk_len. */ printf(\"%d\\n\", len); return 0;}得到了批量回复或多条批量回复的长度之后， 程序只需调用一次 read 函数， 就可以将回复的正文数据全部读入到内存中， 而无须对这些数据做任何的处理。在回复最末尾的 CR 和 LF 不作处理，丢弃它们。Redis 协议的实现性能可以和二进制协议的实现性能相媲美，并且由于 Redis 协议的简单性，大部分高级语言都可以轻易地实现这个协议，这使得客户端软件的 bug 数量大大减少。参考文档 redis 通信协议（RESP），最简单的应用层协议，没有之一 redis 通信协议 redis-cli，Redis命令行工具RESP3为了照顾老用户，Redis6在兼容 RESP2 的基础上，开始支持 RESP3，但未来会全面切换到RESP3之上。今天的客户端缓存在基于RESP3才能有更好的实现，可以在同一个连接中运行数据的查询和接收失效消息。而目前在RESP2上实现的客户端缓存，需要两个客户端连接以转发重定向的形式实现在Redis6中我们可以使用HELLO命令在RESP2和RESP3协议之间进行切换：#使用RESP2协议HELLO 2#使用RESP3协议HELLO 3与RESP2兼容随着Redis版本的不断更新以及功能迭代，RESP V2协议开始渐渐无法满足新的需求，为了适配在Redis6.0中出现的一些新功能，在它的基础上发展出了全新的下一代RESP3协议。下面我们先来回顾一下继承自RESP V2的5种数据返回类型，在了解这些类型的局限性后，再来看看RESP3中新的数据返回类型都在什么地方做出了改进。请求格式协议中数据的请求格式与RESP V2完全相同，请求的格式如下：*&lt;参数数量&gt; CRLF$&lt;参数1的字节长度&gt; CRLF&lt;参数1的数据&gt; CRLF$&lt;参数2的字节长度&gt; CRLF&lt;参数2的数据&gt; CRLF...$&lt;参数N的字节长度&gt; CRLF&lt;参数N的数据&gt; CRLF每行末尾的CRLF转换成程序语言是\\r\\n，也就是回车加换行。以set name hydra这条命令为例，转换过程及转换后的结果如下：在了解了发送的协议后，下面对不同类型的回复进行测试。这一过程如何进行模拟呢？直接在命令行下使用telnet进行连接就可以了，以我本机启动的redis为例，直接输入telnet 127.0.0.1 6379就可以连接到redis服务了。之后再将包含换行的指令一次性拷贝到命令行，然后回车，就能够收到来自Redis服务的回复了：下面先来看看继承自RESP V2的5种返回格式，为了统一命名规范，介绍中均采用RESP3官方文档中的新的名称来替代RESP V2中的旧命名，例如不再使用旧的批量回复、多条批量回复等类型名称。Simple string表示简单字符串回复，它只有一行回复，回复的内容以+作为开头，不允许换行，并以\\r\\n结束。有很多指令在执行成功后只会回复一个OK，使用的就是这种格式，能够有效地将传输、解析的开销降到最低。还是以上面的set指令为例，发送请求*3$3set$4name$5hydra收到回复：+OK\\r\\nSimple error错误回复，它可以看做简单字符串回复的变种形式，它们之间的格式也非常类似，区别只有第一个字符是以-作为开头，错误回复的内容通常是错误类型及对错误描述的字符串。错误回复出现在一些异常的场景，例如当发送了错误的指令、操作数的数量不对时，都会进行错误回复。发送一条错误的指令：*1$8Dr.Hydra收到回复，提示错误信息：-ERR unknown command `Dr.Hydra`, with args beginning with:\\r\\nNumber整数回复，它的应用也非常广泛，它以:作为开头，以\\r\\n结束，用于返回一个整数。例如当执行incr后返回自增后的值，执行llen返回数组的长度，或者使用exists命令返回的0或1作为判断一个key是否存在的依据，这些都使用了整数回复。发送一条查看数组长度的指令：*2$4llen$7myarray收到回复：:4\\r\\nBlob string多行字符串的回复，也被叫做批量回复，在RESP V2中将它称为Bulk String。以$作为开头，后面是发送的字节长度，然后是\\r\\n，然后发送实际的数据，最终以\\r\\n结束。如果要回复的数据不存在，那么回复长度为-1。发送一条get命令请求：*2$3get$4name收到回复：$5\\r\\nhydra\\r\\nArray可以理解为RESP V2中的多条批量回复，当服务端要返回多个值时，例如返回一些元素的集合时，就会使用Array。它以*作为开头，后面是返回元素的个数，之后再跟随多个上面的Blob String。*4$6lrange$7myarray$10$2-1收到回复，包含了集合中的4个元素：*4$11$12$12$232RESP3中新的类型目前在Redis6.0.X版本中，仍然是默认使用的RESP V2协议，并且在兼容RESP V2的基础上，也同时也支持开启RESP3。估计在未来的某个版本，Redis可能会全面切换到RESP3，不过这么做的话对目前的Redis客户端连接工具会有不小的冲击，都需要根据协议内容进行底层通信的改造。在使用telnet连接到redis服务后，先输入下面的命令来切换到RESP3版本的协议，至于hello命令的具体返回数据以及数据表示的意义，这里暂且略过，后面会具体来看。下面我们就来详细看看在RESP3中，除了保留上面的5种旧回复类型外，新增的13种通信返回数据类型，部分数据类型会配合示例进行演示。为了看起来更加简洁，下面的演示例子发送命令均使用原始命令，不再转化为协议格式，并且省略数据返回结果中每行结束的\\r\\n！Null新协议中使用下划线字符后跟CR和LF字符来表示空值，也就是用_\\r\\n来替代原先的单个空值的返回$-1。例如在使用get命令查找一个不存在的key时，get keyNotExist，不同版本的回包协议返回如下： RESP V2 返回 $-1 RESP3 返回 _\\r\\nDouble浮点数返回时以逗号开头，格式为 ,\\r\\n，使用zset score key member获取分数的命令来进行测试。如执行 zscore fruit apple，返回如下： RESP V2返回时使用的是Bulk String的格式：$185.6600000000000001 RESP3返回格式：,5.6600000000000001\\r\\nBoolean布尔类型的数据返回值，其中true被表示为#t\\r\\n，而false被表示为#f\\r\\n。Blob error与字符串类型比较相似，它的格式为!\\r\\n\\r\\n，但是与简单错误类型一样，开头使用!表示返回的是一段错误信息描述。例如错误SYNTAX invalid syntax会按照下面的格式返回：!21SYNTAX invalid syntaxVerbatim stringVerbatim string也表示一个字符串格式，与Blob String非常相似，但是使用=开头替换了$，另外之后的三个字节提供了有关字符串格式的信息，例如txt表示纯文本，mkd表示markdown格式，第四个字节则固定为 :。这种格式适用于在没有任何转义或过滤的情况下显示给用户。使用延时事件统计与分析指令进行测试，发送：latency doctor RESP2返回的数据还是Blob String格式：$196Dave, no latency spike was observed during the lifetime of this Redis instance, not in the slightest bit. I honestly think you ought to sit down calmly, take a stress pill, and think things over. RESP V3返回的数据采用了新的格式：=200txt:Dave, no latency spike was observed during the lifetime of this Redis instance, not in the slightest bit. I honestly think you ought to sit down calmly, take a stress pill, and think things over.Big numberBig number类型用于返回非常大的整数数字，可以表示在有符号64位数字范围内的整数，包括正数或负数，但是需要注意不能含有小数部分。数据格式为(&lt;big number&gt;\\r\\n，以左括号开头，示例如下：(3492890328409238509324850943850943825024385注意，当Big number不可用时，客户端会返回一个字符串格式的数据。Aggregate data types与前面我们介绍的给定数据类型的单个值不同，Aggregate data types可以理解为聚合数据类型。这也是RESP3的一个核心思想，要能够从协议和类型的角度，来描述不同语义的聚合数据类型。聚合数据类型的格式如下，通常由聚合类型、元素个数以及具体的单一元素构成：&lt;aggregate-type-char&gt;&lt;numelements&gt;&lt;CR&gt;&lt;LF&gt;... numelements other types ...例如一个包含三个数字的数组[1,2,3]可以表示为：*3:1:2:3当然聚合数据类型中的元素可以是其他聚合数据类型，例如在数组中也可以嵌套包含其他数组（下面的内容包含了缩进方便理解）：*2 *3 :1 $5 hello :2 #f上面的聚合数据类型所表示的数据为[[1,”hello”,2],false]。MapMap数据类型与数组比较类似，但是以%作为起始，后面是Map中键值对的数量，而不再是单个数据项的数量。它的数据内容是一个有序的键值对的数组，之后分行显示键值对的key和value，因此后面的数据行一定是偶数行。先看一下官方文档给出的例子，以下面的Json字符串为例：{ \"first\":1, \"second\":2}转换为Map类型后格式为下面的形式：%2+first:1+second:2但是通过实验，Hydra发现了点有意思的东西，当我们发送一条hgetall的命令来请求哈希类型的数据时，如 hgetall user RESP V2返回的数据仍然使用老的Array格式，符合我们的预期：*4$4name$5Hydra$3age$218 但是下面RESP3的数据返回却出乎我们的意料，可以看到虽然前面的%2表示使用了Map格式，但是后面并没有遵循官方文档给出的规范，除了开头的%2以外，其余部分与Array完全相同（）。%2$4name$5Hydra$3age$218关于实际传输数据与文档中给出示例的出入，Hydra有一点自己的猜测，放在最后总结部分。SetSet与Array类型非常相似，但是它的第一个字节使用~替代了*，它是一个无序的数据集合。还是先看一下官方文档中给出的示例，下面是一个包含了5个元素的集合类型数据，并且其中具体的数据类型可以不同：~5&lt;CR&gt;&lt;LF&gt;+orange&lt;CR&gt;&lt;LF&gt;+apple&lt;CR&gt;&lt;LF&gt;#t&lt;CR&gt;&lt;LF&gt;:100&lt;CR&gt;&lt;LF&gt;:999&lt;CR&gt;&lt;LF&gt;下面使用SMEMBERS命令获取集合中的所有元素进行测试，如 MEMBERS myset RESP V2返回时仍然使用Array格式：*3$1a$1c$1b RESP3的数据返回情况和Map比较类似，使用~开头，但是没有完全遵从协议中的格式：~3$1a$1c$1bAttributeAttribute类型与Map类型非常相似，但是头一个字节使用|来代替了%，Attribute描述的数据内容比较像Map中的字典映射。客户端不应该将这个字典内容看做数据回复的一部分，而是当做增强回复内容的辅助数据。在文档中提到，在未来某个版本的Redis中可能会出现这样一个功能，每次执行指令时都会打印访问的key的请求频率，这个值可能使用一个浮点数表示，那么在执行MGET a b时就可能会收到回复：|1 +key-popularity %2 $1 a ,0.1923 $1 b ,0.0012*2 :2039123 :9543892在上面的数据回复中，实际中回复的数据应该是[2039123,9543892]，但是在前面附加了它们请求的属性，当读到这个Attribute类型数据后，应当继续读取后面的实际数据。PushPush数据类型是一种服务器向客户端发送的异步数据，它的格式与Array类型比较类似，但是以&gt;开头，接下来的数组中的第一个数据为字符串类型，表示服务器发送给客户端的推送数据是何种类型。数组中其他的数据也都包含自己的类型，需要按照协议中类型规范进行解析。简单看一下文档中给出的示例，在执行get key命令后，可能会得到两个有效回复：&gt;4+pubsub+message+somechannel+this is the message$9Get-Reply在上面的这段回复中需要注意，收到的两个回复中第一个是推送数据的类型，第二个才是真正回复的数据内容。注意！这里在文档中有一句提示：虽然下面的演示使用的是Simple string格式，但是在实际数据传输中使用的是Blob string格式。所以盲猜一波，上面的Map和Set也是同样的情况？这里先简单铺垫一下Push回复类型在redis6中非常重要的一个使用场景客户端缓存client-side caching，它允许将数据存储在本地应用中，当访问时不再需要访问redis服务端，但是其他客户端修改数据时需要通知当前客户端作废掉本地应用的客户端缓存，这时候就会用到Push类型的消息。client tracking onget key1在客户端B中执行： set key1 newValue这时就会在客户端A中收到Push类型的消息，通知客户端缓存失效。在下面收到的消息中就包含了两部分，第一部分表示收到的消息类型为invalidate，第二部分则是需要作废的缓存key1：&gt;2$10invalidate*1$4key1Stream在前面介绍的类型中，返回的数据字符串一般都具有指定的长度，例如下面这样：$1234&lt;CR&gt;&lt;LF&gt;.... 1234 bytes of data here ...&lt;CR&gt;&lt;LF&gt;但是有时候需要将一段不知道长度的字符串数据从客户端传给服务器（或者反向传输）时，很明显这种格式无法使用，因此需要一种新的格式用来传送不确定长度的数据。文档中提到，过去在服务端有一个私有扩展的数据格式，规范如下：$EOF:&lt;40 bytes marker&gt;&lt;CR&gt;&lt;LF&gt;... any number of bytes of data here not containing the marker ...&lt;40 bytes marker&gt;它以$EOF:作为起始字节，然后是40字节的marker标识符，在\\r\\n后跟随的是真正的数据，结束后也是40字节的标识符。标识符以伪随机的方式生成，基本上不会与正常的数据发生冲突。但是这种格式存在一定的局限性，主要问题就在于生成标识符以及解析标识符上，由于一些原因使得上面这种格式在实际使用中非常脆弱。因此最终在规范中提出了一种分块编码格式，举一个简单的例子，当需要发送事先不知道长度的字符串Hello world时：$?;4Hell;5o wor;2ld;0这种格式以$?开头，表示是一个不知道长度的分块编码格式，后面传输的数据数量没有限制，在最后以零长度的;0作为结束传输的标识。文档中提到，目前还没有命令会以这个格式来进行数据回复，但是会在后面的功能模块中实装这个协议。HELLO在介绍RESP3的最开始，我们就在telnet中通过hello 3的命令来切换协议到V3版本。这个特殊的命令完成了两件事： 它允许服务器与RESP V2版本向后兼容，也方便以后更加轻松的切换到RESP3 hello命令可以返回有关服务器和协议的信息，以供客户端使用hello命令的格式如下，可以看到除了协议版本号外，还可以指定用户名和密码：HELLO &lt;protocol-version&gt; [AUTH &lt;username&gt; &lt;password&gt;]hello命令的返回结果是前面介绍过的Map类型，仅仅在客户端和服务器建立连接的时候发送。%7$6server$5redis$7version$66.0.16$5proto:3$2id:18$4mode$10standalone$4role$6master$7modules*0转换为我们可读的Map格式后，可以看到它返回的Redis服务端的一些信息：{ \"server\":\"redis\", \"version\":\"6.0.16\", \"proto\":3, \"id\":18, \"mode\":\"standalone\", \"role\":\"master\", \"modules\":[]}参考文档 redis-doc RESP3 redis-parser go-redis客户端gossipCluster中的每个节点都维护一份在自己看来当前整个集群的状态，主要包括： 当前集群状态 集群中各节点所负责的slots信息，及其migrate状态 集群中各节点的master-slave状态 集群中各节点的存活状态及不可达投票redis集群的哈希槽算法解决的是数据的存取问题，不同的哈希槽位于不同的节点上，而不同的节点维护着一份它所认为的当前集群的状态，同时，Redis集群是去中心化的架构。那么，当集群的状态发生变化时，比如新节点加入、slot迁移、节点宕机、slave提升为新Master等等，我们希望这些变化尽快被其他节点发现，Redis是如何进行处理的呢？也就是说，Redis不同节点之间是如何进行通信进行维护集群的同步状态呢？在Redis集群中，不同的节点之间采用gossip协议进行通信，节点之间通讯的目的是为了维护节点之间的元数据信息。这些元数据就是每个节点包含哪些数据，是否出现故障，通过gossip协议，达到最终数据的一致性。gossip协议，是基于流行病传播方式的节点或者进程之间信息交换的协议。原理就是在不同的节点间不断地通信交换信息，一段时间后，所有的节点就都有了整个集群的完整信息，并且所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，但只要这些节可以通过网络连通，最终他们的状态就会是一致的。Gossip协议最大的好处在于，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。Redis集群中节点的通信过程如下： 集群中每个节点都会单独开一个TCP通道，用于节点间彼此通信。 每个节点在固定周期内通过待定的规则选择几个节点发送ping消息 接收到ping消息的节点用pong消息作为响应使用gossip协议的优点在于将元数据的更新分散在不同的节点上面，降低了压力；但是缺点就是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。另外，由于 gossip 协议对服务器时间的要求较高，时间戳不准确会影响节点判断消息的有效性。而且节点数量增多后的网络开销也会对服务器产生压力，同时结点数太多，意味着达到最终一致性的时间也相对变长，因此官方推荐最大节点数为1000左右。redis cluster架构下的每个redis都要开放两个端口号，比如一个是6379，另一个就是加1w的端口号16379。 6379端口号就是redis服务器入口。 16379端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用的是一种叫gossip 协议的二进制协议gossip协议常见的消息类型包含： ping、pong、meet、fail等等。 meet：主要用于通知新节点加入到集群中，通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。 ping：用于交换节点的元数据。每个节点每秒会向集群中其他节点发送 ping 消息，消息中封装了自身节点状态还有其他部分节点的状态数据，也包括自身所管理的槽信息等等。 因为发送ping命令时要携带一些元数据，如果很频繁，可能会加重网络负担。因此，一般每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。 如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长导致信息严重滞后。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。 每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 （总节点数 - 2）个其它节点的信息。 pong：ping和meet消息的响应，同样包含了自身节点的状态和集群元数据信息。 fail：某个节点判断另一个节点 fail 之后，向集群所有节点广播该节点挂掉的消息，其他节点收到消息后标记已下线。由于Redis集群的去中心化以及gossip通信机制，Redis集群中的节点只能保证最终一致性。例如当加入新节点时(meet)，只有邀请节点和被邀请节点知道这件事，其余节点要等待 ping 消息一层一层扩散。除了 Fail 是立即全网通知的，其他诸如新节点、节点重上线、从节点选举成为主节点、槽变化等，都需要等待被通知到，也就是Gossip协议是最终一致性的协议。redis 集群集群部署方案在开发测试环境中，我们一般搭建Redis的单实例来应对开发测试需求，但是在生产环境，如果对可用性、可靠性要求较高，则需要引入Redis的集群方案。虽然现在各大云平台有提供缓存服务可以直接使用，但了解一下其背后的实现与原理总还是有些必要（比如面试）， 本文就一起来学习一下Redis的几种集群方案主从复制模式原理：主从复制模式中包含一个主数据库实例（master）与一个或多个从数据库实例（slave），如下图客户端可对主数据库进行读写操作，对从数据库进行读操作，主数据库写入的数据会实时自动同步给从数据库。具体工作机制为： slave启动后，向master发送SYNC命令，master接收到SYNC命令后通过bgsave保存快照（即上文所介绍的RDB持久化），并使用缓冲区记录保存快照这段时间内执行的写命令 master将保存的快照文件发送给slave，并继续记录执行的写命令 slave接收到快照文件后，加载快照文件，载入数据 master快照发送完后开始向slave发送缓冲区的写命令，slave接收命令并执行，完成复制初始化 此后master每次执行一个写命令都会同步发送给slave，保持master与slave之间数据的一致性本示例基于Redis 5.0.3版。redis.conf的主要配置，部署示例如下：###网络相关#### bind 127.0.0.1 # 绑定监听的网卡IP，注释掉或配置成0.0.0.0可使任意IP均可访问protected-mode no # 关闭保护模式，使用密码访问port 6379 # 设置监听端口，建议生产环境均使用自定义端口timeout 30 # 客户端连接空闲多久后断开连接，单位秒，0表示禁用###通用配置###daemonize yes # 在后台运行pidfile /var/run/redis_6379.pid # pid进程文件名logfile /usr/local/redis/logs/redis.log # 日志文件的位置###RDB持久化配置###save 900 1 # 900s内至少一次写操作则执行bgsave进行RDB持久化save 300 10save 60 10000# 如果禁用RDB持久化，可在这里添加 save \"\"rdbcompression yes #是否对RDB文件进行压缩，建议设置为no，以（磁盘）空间换（CPU）时间dbfilename dump.rdb # RDB文件名称dir /usr/local/redis/datas # RDB文件保存路径，AOF文件也保存在这里###AOF配置###appendonly yes # 默认值是no，表示不使用AOF增量持久化的方式，使用RDB全量持久化的方式appendfsync everysec # 可选值 always， everysec，no，建议设置为everysec###设置密码###requirepass 123456 # 设置复杂一点的密码部署主从复制模式只需稍微调整slave的配置，在redis.conf中添加replicaof 127.0.0.1 6379 # master的ip，portmasterauth 123456 # master的密码replica-serve-stale-data no # 如果slave无法与master同步，设置成slave不可读，方便监控脚本发现问题本示例在单台服务器上配置master端口6379，两个slave端口分别为7001,7002，启动master，再启动两个slave[root@dev-server-1 master-slave]# redis-server master.conf[root@dev-server-1 master-slave]# redis-server slave1.conf[root@dev-server-1 master-slave]# redis-server slave2.conf进入master数据库，写入一个数据，再进入一个slave数据库，立即便可访问刚才写入master数据库的数据。如下所示[root@dev-server-1 master-slave]# redis-cli127.0.0.1:6379&gt; auth 123456OK127.0.0.1:6379&gt; set site blog.jboost.cnOK127.0.0.1:6379&gt; get site\"blog.jboost.cn\"127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=7001,state=online,offset=13364738,lag=1slave1:ip=127.0.0.1,port=7002,state=online,offset=13364738,lag=0...127.0.0.1:6379&gt; exit[root@dev-server-1 master-slave]# redis-cli -p 7001127.0.0.1:7001&gt; auth 123456OK127.0.0.1:7001&gt; get site\"blog.jboost.cn\"执行info replication命令可以查看连接该数据库的其它库的信息，如上可看到有两个slave连接到master主从复制的优缺点： 优点： master能自动将数据同步到slave，可以进行读写分离，分担master的读压力 master、slave之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求 缺点： 不具备自动容错与恢复功能，master或slave的宕机都可能导致客户端请求失败，需要等待机器重启或手动切换客户端IP才能恢复 master宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题 难以支持在线扩容，Redis的容量受限于单机配置 Sentinel（哨兵）模式哨兵模式基于主从复制模式，只是引入了哨兵来监控与自动处理故障。如图哨兵顾名思义，就是来为Redis集群站哨的，一旦发现问题能做出相应的应对处理。其功能包括 监控master、slave是否正常运行 当master出现故障时，能自动将一个slave转换为master（大哥挂了，选一个小弟上位） 多个哨兵可以监控同一个Redis，哨兵之间也会自动监控在配置文件中通过 sentinel monitor 来定位master的IP、端口，一个哨兵可以监控多个master数据库，只需要提供多个该配置项即可。哨兵启动后，会与要监控的master建立两条连接： 一条连接用来订阅master的_sentinel_:hello频道与获取其他监控该master的哨兵节点信息 另一条连接定期向master发送INFO等命令获取master本身的信息与master建立连接后，哨兵会执行三个操作： 定期（一般10s一次，当master被标记为主观下线时，改为1s一次）向master和slave发送INFO命令 定期向master和slave的_sentinel_:hello频道发送自己的信息 定期（1s一次）向master、slave和其他哨兵发送PING命令发送INFO命令可以获取当前数据库的相关信息从而实现新节点的自动发现。所以说哨兵只需要配置master数据库信息就可以自动发现其slave信息。获取到slave信息后，哨兵也会与slave建立两条连接执行监控。通过INFO命令，哨兵可以获取主从数据库的最新信息，并进行相应的操作，比如角色变更等。接下来哨兵向主从数据库的_sentinel_:hello频道发送信息与同样监控这些数据库的哨兵共享自己的信息，发送内容为哨兵的ip端口、运行id、配置版本、master名字、master的ip端口还有master的配置版本。这些信息有以下用处： 其他哨兵可以通过该信息判断发送者是否是新发现的哨兵，如果是的话会创建一个到该哨兵的连接用于发送PING命令。 其他哨兵通过该信息可以判断master的版本，如果该版本高于直接记录的版本，将会更新 当实现了自动发现slave和其他哨兵节点后，哨兵就可以通过定期发送PING命令定时监控这些数据库和节点有没有停止服务。如果被PING的数据库或者节点超时（通过 sentinel down-after-milliseconds master-name milliseconds 配置）未回复，哨兵认为其主观下线（sdown，s就是Subjectively —— 主观地）。如果下线的是master，哨兵会向其它哨兵发送命令询问它们是否也认为该master主观下线，如果达到一定数目（即配置文件中的quorum）投票，哨兵会认为该master已经客观下线（odown，o就是Objectively —— 客观地），并选举领头的哨兵节点对主从系统发起故障恢复。若没有足够的sentinel进程同意master下线，master的客观下线状态会被移除，若master重新向sentinel进程发送的PING命令返回有效回复，master的主观下线状态就会被移除哨兵认为master客观下线后，故障恢复的操作需要由选举的领头哨兵来执行，选举采用Raft算法： 发现master下线的哨兵节点（我们称他为A）向每个哨兵发送命令，要求对方选自己为领头哨兵 如果目标哨兵节点没有选过其他人，则会同意选举A为领头哨兵 如果有超过一半的哨兵同意选举A为领头，则A当选 如果有多个哨兵节点同时参选领头，此时有可能存在一轮投票无竞选者胜出，此时每个参选的节点等待一个随机时间后再次发起参选请求，进行下一轮投票竞选，直至选举出领头哨兵选出领头哨兵后，领头者开始对系统进行故障恢复，从出现故障的master的从数据库中挑选一个来当选新的master,选择规则如下： 所有在线的slave中选择优先级最高的，优先级可以通过slave-priority配置 如果有多个最高优先级的slave，则选取复制偏移量最大（即复制越完整）的当选 如果以上条件都一样，选取id最小的slave挑选出需要继任的slave后，领头哨兵向该数据库发送命令使其升格为master，然后再向其他slave发送命令接受新的master，最后更新数据。将已经停止的旧的master更新为新的master的从数据库，使其恢复服务后以slave的身份继续运行。哨兵模式基于前文的主从复制模式。哨兵的配置文件为sentinel.conf，在文件中添加sentinel monitor mymaster 127.0.0.1 6379 1 # mymaster定义一个master数据库的名称，后面是master的ip， port，1表示至少需要一个Sentinel进程同意才能将master判断为失效，如果不满足这个条件，则自动故障转移（failover）不会执行sentinel auth-pass mymaster 123456 # master的密码sentinel down-after-milliseconds mymaster 5000 # 5s未回复PING，则认为master主观下线，默认为30ssentinel parallel-syncs mymaster 2 # 指定在执行故障转移时，最多可以有多少个slave实例在同步新的master实例，在slave实例较多的情况下这个数字越小，同步的时间越长，完成故障转移所需的时间就越长sentinel failover-timeout mymaster 300000 # 如果在该时间（ms）内未能完成故障转移操作，则认为故障转移失败，生产环境需要根据数据量设置该值一个哨兵可以监控多个master数据库，只需按上述配置添加多套。分别以26379,36379,46379端口启动三个sentinel[root@dev-server-1 sentinel]# redis-server sentinel1.conf --sentinel[root@dev-server-1 sentinel]# redis-server sentinel2.conf --sentinel[root@dev-server-1 sentinel]# redis-server sentinel3.conf --sentinel也可以使用redis-sentinel sentinel1.conf 命令启动。此时集群包含一个master、两个slave、三个sentinel，如图，我们来模拟master挂掉的场景，执行 kill -9 3017 将master进程干掉，进入slave中执行 info replication查看，[root@dev-server-1 sentinel]# redis-cli -p 7001127.0.0.1:7001&gt; auth 123456OK127.0.0.1:7001&gt; info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:7002master_link_status:upmaster_last_io_seconds_ago:1master_sync_in_progress:0# 省略127.0.0.1:7001&gt; exit[root@dev-server-1 sentinel]# redis-cli -p 7002127.0.0.1:7002&gt; auth 123456OK127.0.0.1:7002&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=7001,state=online,offset=13642721,lag=1# 省略可以看到slave 7002已经成功上位晋升为master（role：master），接收一个slave 7001的连接。此时查看slave2.conf配置文件，发现replicaof的配置已经被移除了，slave1.conf的配置文件里replicaof 127.0.0.1 6379 被改为 replicaof 127.0.0.1 7002。重新启动master，也可以看到master.conf配置文件中添加了replicaof 127.0.0.1 7002的配置项，可见大哥（master）下位后，再出来混就只能当当小弟（slave）了，三十年河东三十年河西。哨兵模式的优缺点： 优点： 哨兵模式基于主从复制模式，所以主从复制模式有的优点，哨兵模式也有 哨兵模式下，master挂掉可以自动进行切换，系统可用性更高 缺点： 同样也继承了主从模式难以在线扩容的缺点，Redis的容量受限于单机配置 需要额外的资源来启动sentinel进程，实现相对复杂一点，同时slave节点作为备份节点不提供服务 Cluster模式哨兵模式解决了主从复制不能自动故障转移，达不到高可用的问题，但还是存在难以在线扩容，Redis容量受限于单机配置的问题。Cluster模式实现了Redis的分布式存储，即每台节点存储不同的内容，来解决在线扩容的问题。如图 Cluster采用无中心结构,它的特点如下： 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽 节点的fail是通过集群中超过半数的节点检测失效时才生效 客户端与redis节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可Cluster模式的具体工作机制： 在Redis的每个节点上，都有一个插槽（slot），取值范围为0-16383 当我们存取key的时候，Redis会根据CRC16的算法得出一个结果，然后把结果对16384求余数，这样每个key都会对应一个编号在0-16383之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作 为了保证高可用，Cluster模式也引入主从复制模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点 当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。如果主节点A和它的从节点都宕机了，那么该集群就无法再提供服务了Cluster模式集群节点最小配置6个节点(3主3从，因为需要半数以上)，其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。本示例基于Redis 5.0.3版。部署步骤如下所述。Cluster模式的部署比较简单，首先在redis.conf中port 7100 # 本示例6个节点端口分别为7100,7200,7300,7400,7500,7600daemonize yes # r后台运行pidfile /var/run/redis_7100.pid # pidfile文件对应7100,7200,7300,7400,7500,7600cluster-enabled yes # 开启集群模式masterauth passw0rd # 如果设置了密码，需要指定master密码cluster-config-file nodes_7100.conf # 集群的配置文件，同样对应7100,7200等六个节点cluster-node-timeout 15000 # 请求超时 默认15秒，可自行设置分别以端口7100,7200,7300,7400,7500,7600 启动六个实例(如果是每个服务器一个实例则配置可一样)[root@dev-server-1 cluster]# redis-server redis_7100.conf[root@dev-server-1 cluster]# redis-server redis_7200.conf...然后通过命令将这个6个实例组成一个3主节点3从节点的集群，redis-cli --cluster create --cluster-replicas 1 127.0.0.1:7100 127.0.0.1:7200 127.0.0.1:7300 127.0.0.1:7400 127.0.0.1:7500 127.0.0.1:7600 -a passw0rd执行结果如图可以看到 7100， 7200， 7300 作为3个主节点，分配的slot分别为 0-5460，5461-10922，10923-16383，7600作为7100的slave，7500作为7300的slave，7400作为7200的slave。 我们连接7100设置一个值[root@dev-server-1 cluster]# redis-cli -p 7100 -c -a passw0rdWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.127.0.0.1:7100&gt; set site blog.jboost.cn-&gt; Redirected to slot [9421] located at 127.0.0.1:7200OK127.0.0.1:7200&gt; get site\"blog.jboost.cn\"127.0.0.1:7200&gt;注意添加 -c 参数表示以集群模式，否则报 (error) MOVED 9421 127.0.0.1:7200 错误， 以 -a 参数指定密码，否则报(error) NOAUTH Authentication required错误。从上面命令看到key为site算出的slot为9421，落在7200节点上，所以有Redirected to slot [9421] located at 127.0.0.1:7200，集群会自动进行跳转。因此客户端可以连接任何一个节点来进行数据的存取。通过cluster nodes可查看集群的节点信息127.0.0.1:7200&gt; cluster nodeseb28aaf090ed1b6b05033335e3d90a202b422d6c 127.0.0.1:7500@17500 slave c1047de2a1b5d5fa4666d554376ca8960895a955 0 1584165266071 5 connected4cc0463878ae00e5dcf0b36c4345182e021932bc 127.0.0.1:7400@17400 slave 5544aa5ff20f14c4c3665476de6e537d76316b4a 0 1584165267074 4 connecteddbbb6420d64db22f35a9b6fa460b0878c172a2fb 127.0.0.1:7100@17100 master - 0 1584165266000 1 connected 0-5460d4b434f5829e73e7e779147e905eea6247ffa5a2 127.0.0.1:7600@17600 slave dbbb6420d64db22f35a9b6fa460b0878c172a2fb 0 1584165265000 6 connected5544aa5ff20f14c4c3665476de6e537d76316b4a 127.0.0.1:7200@17200 myself,master - 0 1584165267000 2 connected 5461-10922c1047de2a1b5d5fa4666d554376ca8960895a955 127.0.0.1:7300@17300 master - 0 1584165268076 3 connected 10923-16383我们将7200通过 kill -9 pid杀死进程来验证集群的高可用，重新进入集群执行cluster nodes可以看到7200 fail了，但是7400成了master，重新启动7200，可以看到此时7200已经变成了slave。Cluster模式的优缺点： 优点： 无中心架构，数据按照slot分布在多个节点。 集群中的每个节点都是平等的关系，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。 可线性扩展到1000多个节点，节点可动态添加或删除 能够实现自动故障转移，节点之间通过gossip协议交换状态信息，用投票机制完成slave到master的角色转换 缺点： 客户端实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度。目前仅JedisCluster相对成熟，异常处理还不完善，比如常见的“max redirect exception” 节点会因为某些原因发生阻塞（阻塞时间大于 cluster-node-timeout）被判断下线，这种failover是没有必要的 数据通过异步复制，不保证数据的强一致性 slave充当“冷备”，不能缓解读压力 批量操作限制，目前只支持具有相同slot值的key执行批量操作，对mset、mget、sunion等操作支持不友好 key事务操作支持有线，只支持多key在同一节点的事务操作，多key分布不同节点时无法使用事务功能 不支持多数据库空间，单机redis可以支持16个db，集群模式下只能使用一个，即db 0 Redis Cluster模式不建议使用pipeline和multi-keys操作，减少max redirect产生的场景。Redis集群的数据分布算法：哈希槽算法Redis集群通过分布式存储的方式解决了单节点的海量数据存储的问题，对于分布式存储，需要考虑的重点就是如何将数据进行拆分到不同的Redis服务器上。常见的分区算法有hash算法、一致性hash算法 普通hash算法：将key使用hash算法计算之后，按照节点数量来取余，即hash(key)%N。优点就是比较简单，但是扩容或者摘除节点时需要重新根据映射关系计算，会导致数据重新迁移。 一致性hash算法：为每一个节点分配一个token，构成一个哈希环；查找时先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。优点是在加入和删除节点时只影响相邻的两个节点，缺点是加减节点会造成部分数据无法命中，所以一般用于缓存，而且用于节点量大的情况下，扩容一般增加一倍节点保障数据负载均衡。Redis集群采用的算法是哈希槽分区算法。Redis集群中有16384个哈希槽（槽的范围是 0 -16383，哈希槽），将不同的哈希槽分布在不同的Redis节点上面进行管理，也就是说每个Redis节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会对使用CRC16算法对key进行计算并对16384取模（slot = CRC16(key)%16383），得到的结果就是 Key-Value 所放入的槽，通过这个值，去找到对应的槽所对应的Redis节点，然后直接到这个对应的节点上进行存取操作。使用哈希槽的好处就在于可以方便的添加或者移除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；哈希槽数据分区算法具有以下几种特点： 解耦数据和节点之间的关系，简化了扩容和收缩难度； 节点自身维护槽的映射关系，不需要客户端代理服务维护槽分区元数据 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景槽的迁移与指派命令：CLUSTER ADDSLOTS 0 1 2 3 4 ... 5000。默认情况下，redis集群的读和写都是到master上去执行的，不支持slave节点读和写，跟Redis主从复制下读写分离不一样，因为redis集群的核心的理念，主要是使用slave做数据的热备，以及master故障时的主备切换，实现高可用的。Redis的读写分离，是为了横向任意扩展slave节点去支撑更大的读吞吐量。而redis集群架构下，本身master就是可以任意扩展的，如果想要支撑更大的读或写的吞吐量，都可以直接对master进行横向扩展。代码实现中，clusterNode数据结构的slots属性和numslot属性记录了节点负责处理那些槽：slots属性是一个二进制位数组(bit array)，这个数组的长度为16384/8=2048个字节，共包含16384个二进制位。Master节点用bit来标识对于某个槽自己是否拥有，时间复杂度为O(1)。当收到集群中其他节点发送的信息时，通过将节点槽的指派信息保存在本地的clusterState.slots数组里面，程序要检查槽i是否已经被指派，又或者取得负责处理槽i的节点，只需要访问clusterState.slots[i]的值即可，时间复杂度仅为O(1)。 集群的请求重定向Redis集群在客户端层面没有采用代理，并且无论Redis 的客户端访问集群中的哪个节点都可以路由到对应的节点上，下面来看看 Redis 客户端是如何通过路由来调用缓存节点的： MOVED请求如上图所示，Redis 客户端通过 CRC16(key)%16383 计算出 Slot 的值，发现需要找“缓存节点1”进行数据操作，但是由于缓存数据迁移或者其他原因导致这个对应的 Slot 的数据被迁移到了“缓存节点2”上面。那么这个时候 Redis 客户端就无法从“缓存节点1”中获取数据了。但是由于“缓存节点1”中保存了所有集群中缓存节点的信息，因此它知道这个 Slot 的数据在“缓存节点2”中保存，因此向 Redis 客户端发送了一个 MOVED 的重定向请求。这个请求告诉其应该访问的“缓存节点2”的地址。Redis 客户端拿到这个地址，继续访问“缓存节点2”并且拿到数据。 ASK请求：上面的例子说明了，数据 Slot 从“缓存节点1”已经迁移到“缓存节点2”了，那么客户端可以直接找“缓存节点2”要数据。那么如果两个缓存节点正在做节点的数据迁移，此时客户端请求会如何处理呢？Redis 客户端向“缓存节点1”发出请求，此时“缓存节点1”正向“缓存节点 2”迁移数据，如果没有命中对应的 Slot，它会返回客户端一个 ASK 重定向请求并且告诉“缓存节点2”的地址。客户端向“缓存节点2”发送 Asking 命令，询问需要的数据是否在“缓存节点2”上，“缓存节点2”接到消息以后返回数据是否存在的结果。 频繁重定向造成的网络开销的处理：smart客户端在大部分情况下，可能都会出现一次请求重定向才能找到正确的节点，这个重定向过程显然会增加集群的网络负担和单次请求耗时。所以大部分的客户端都是smart的。所谓 smart客户端，就是指客户端本地维护一份hashslot =&gt; node的映射表缓存，大部分情况下，直接走本地缓存就可以找到hashslot =&gt; node，不需要通过节点进行moved重定向，虽然ASK与MOVED都是对客户端的重定向控制，但是有本质区别。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道迁移什么时候完成，因此只能是临时性的重定向，客户端不会更新slots缓存。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，客户端需要更新slots缓存。集群扩容和缩容作为分布式部署的缓存节点总会遇到缓存扩容和缓存故障的问题。这就会导致缓存节点的上线和下线的问题。由于每个节点中保存着槽数据，因此当缓存节点数出现变动时，这些槽数据会根据对应的虚拟槽算法被迁移到其他的缓存节点上。所以对于redis集群，集群伸缩主要在于槽和数据在节点之间移动。 扩容 （1）启动新节点 （2）使用cluster meet命令将新节点加入到集群 （3）迁移槽和数据：添加新节点后，需要将一些槽和数据从旧节点迁移到新节点如上图所示，集群中本来存在“缓存节点1”和“缓存节点2”，此时“缓存节点3”上线了并且加入到集群中。此时根据虚拟槽的算法，“缓存节点1”和“缓存节点2”中对应槽的数据会应该新节点的加入被迁移到“缓存节点3”上面。新节点加入到集群的时候，作为孤儿节点是没有和其他节点进行通讯的。因此需要在集群中任意节点执行 cluster meet 命令让新节点加入进来。假设新节点是 192.168.1.1 5002，老节点是 192.168.1.1 5003，那么运行以下命令将新节点加入到集群中。192.168.1.1 5003&gt; cluster meet 192.168.1.1 5002这个是由老节点发起的，有点老成员欢迎新成员加入的意思。新节点刚刚建立没有建立槽对应的数据，也就是说没有缓存任何数据。如果这个节点是主节点，需要对其进行槽数据的扩容；如果这个节点是从节点，就需要同步主节点上的数据。总之就是要同步数据。如上图所示，由客户端发起节点之间的槽数据迁移，数据从源节点往目标节点迁移。 （1）客户端对目标节点发起准备导入槽数据的命令，让目标节点准备好导入槽数据。使用命令：cluster setslot {slot} importing {sourceNodeId} （2）之后对源节点发起送命令，让源节点准备迁出对应的槽数据。使用命令：cluster setslot {slot} migrating {targetNodeId} （3）此时源节点准备迁移数据了，在迁移之前把要迁移的数据获取出来。通过命令 cluster getkeysinslot {slot} {count}。Count 表示迁移的 Slot 的个数。 （4）然后在源节点上执行，migrate {targetIP} {targetPort} “” 0 {timeout} keys {keys} 命令，把获取的键通过流水线批量迁移到目标节点。 （5）重复 3 和 4 两步不断将数据迁移到目标节点。 （6）完成数据迁移到目标节点以后，通过 cluster setslot {slot} node {targetNodeId} 命令通知对应的槽被分配到目标节点，并且广播这个信息给全网的其他主节点，更新自身的槽节点对应表。 缩容 迁移槽。 忘记节点。通过命令 cluster forget {downNodeId} 通知其他的节点为了安全删除节点，Redis集群只能下线没有负责槽的节点。因此如果要下线有负责槽的master节点，则需要先将它负责的槽迁移到其他节点。迁移的过程也与上线操作类似，不同的是下线的时候需要通知全网的其他节点忘记自己，此时通过命令 cluster forget {downNodeId} 通知其他的节点。集群的故障检测与故障转恢复机制Redis集群的搭建可以分为以下几个部分： 启动节点：将节点以集群模式启动，读取或者生成集群配置文件，此时节点是独立的。 节点握手：节点通过gossip协议通信，将独立的节点连成网络，主要使用meet命令。 槽指派：将16384个槽位分配给主节点，以达到分片保存数据库键值对的效果。集群搭建好之后，其是如何保证可靠性的呢？集群故障检测Redis集群的故障检测是基于gossip协议的，集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此交换各个节点状态信息，检测各个节点状态：在线状态、疑似下线状态PFAIL、已下线状态FAIL。 主观下线（pfail）：当节点A检测到与节点B的通讯时间超过了cluster-node-timeout 的时候，就会更新本地节点状态，把节点B更新为主观下线。主观下线并不能代表某个节点真的下线了，有可能是节点A与节点B之间的网络断开了，但是其他的节点依旧可以和节点B进行通讯。 客观下线：由于集群内的节点会不断地与其他节点进行通讯，下线信息也会通过 Gossip 消息传遍所有节点，因此集群内的节点会不断收到下线报告。当半数以上的主节点标记了节点B是主观下线时，便会触发客观下线的流程（该流程只针对主节点，如果是从节点就会忽略）。将主观下线的报告保存到本地的 ClusterNode 的结构fail_reports链表中，并且对主观下线报告的时效性进行检查，如果超过 cluster-node-timeout*2 的时间，就忽略这个报告，否则就记录报告内容，将其标记为客观下线。接着向集群广播一条主节点B的Fail 消息，所有收到消息的节点都会标记节点B为客观下线。集群的故障恢复当故障节点下线后，如果是持有槽的主节点则需要在其从节点中找出一个替换它，从而保证高可用。此时下线主节点的所有从节点都担负着恢复义务，这些从节点会定时监测主节点是否进入客观下线状态，如果是，则触发故障恢复流程。故障恢复也就是选举一个节点充当新的master，选举的过程是基于Raft协议选举方式来实现的。 从节点过滤：检查每个slave节点与master节点断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master 投票选举 节点排序：对通过过滤条件的所有从节点进行排序，按照priority、offset、run id排序，排序越靠前的节点，越优先进行选举。 priority的值越低，优先级越高 offset越大，表示从master节点复制的数据越多，选举时间越靠前，优先进行选举 如果offset相同，run id越小，优先级越高 更新配置纪元：每个主节点会去更新配置纪元（clusterNode.configEpoch），这个值是不断增加的整数。这个值记录了每个节点的版本和整个集群的版本。每当发生重要事情的时候（例如：出现新节点，从节点精选）都会增加全局的配置纪元并且赋给相关的主节点，用来记录这个事件。更新这个值目的是，保证所有主节点对这件“大事”保持一致，大家都统一成一个配置纪元，表示大家都知道这个“大事”了。 选举投票： 如果一个主节点具有投票权，并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点。每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。 如果超过(N/2 + 1)数量的master节点都投票给了某个从节点，那么选举通过，这个从节点可以切换成master，如果在 cluster-node-timeout*2 的时间内从节点没有获得足够数量的票数，本次选举作废，更新配置纪元，并进行第二轮选举，直到选出新的主节点为止。 在节点排序环节领先的从节点通常会获得更多的票，因为它触发选举的时间更早一些，获得票的机会更大 替换主节点：当满足投票条件的从节点被选出来以后，会触发替换主节点的操作。删除原主节点负责的槽数据，把这些槽数据添加到自己节点上，并且广播让其他的节点都知道这件事情，新的主节点诞生了。 被选中的从节点执行SLAVEOF NO ONE命令，使其成为新的主节点 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己 新的主节点对集群进行广播PONG消息，告知其他节点已经成为新的主节点 新的主节点开始接收和处理槽相关的请求 如果集群中某个节点的master和slave节点都宕机了，那么集群就会进入fail状态，因为集群的slot映射不完整。如果集群超过半数以上的master挂掉，无论是否有slave，集群都会进入fail状态。集群的运维集群什么时候不可用？ 无主从备份,某一节点宕机 某一节点主从全部宕机 超半数主节点宕机为什么需要集群? 并发量：通常来说，单台Redis能够执行10万/秒的命令，这个并发基本上能够满足我们所有需求了。但有时候比如做离线计算，为了更快的得出结果，有时候我们希望超过这个并发，那这个时候单机就不满足我们需求了，就需要集群了。 数据量：通常来说，单台服务器的内存大概在16G-256G之间，前面我们说Redis数据量都是存在内存中的，那如果实际业务要保存在Redis的数据量超过了单台机器的内存，这个时候最简单的方法是增加服务器内存。但是单台服务器内存不可能无限制的增加，纵向扩展不了了，便想到如何进行横向扩展。这时候我们就会想将这些业务数据分散存储在多台Redis服务器中，但是要保证多台Redis服务器能够无障碍的进行内存数据沟通，这也就是Redis集群。Redis cluster集群模式功能限制 key批量操作支持有限。如：MSET``MGET，目前只支持具有相同slot值的key执行批量操作。 key事务操作支持有限。支持多key在同一节点上的事务操作，不支持分布在多个节点的事务功能。 key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点。如：hash、list。 不支持多数据库空间。单机下Redis支持16个数据库，集群模式下只能使用一个数据库空间，即db 0。 复制结构只支持一层，不支持嵌套树状复制结构。数据迁移问题Redis集群可以进行节点的动态扩容缩容，这一过程目前还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。而 Redis为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis均会进入时长不等的阻塞状态，对于小Key，该时间可以忽略不计，但如果一旦Key的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。带宽消耗问题Redis集群是无中心节点的集群架构，依靠Gossip协议协同自动化修复集群的状态，但goosip有消息延时和消息冗余的问题，在集群节点数量过多的时候，goosip协议通信会消耗大量的带宽，主要体现在以下几个方面： 消息发送频率：跟cluster-node-timeout密切相关，当节点发现与其他节点的最后通信时间超过 cluster-node-timeout/2时会直接发送ping消息 消息数据量：每个消息主要的数据占用包含：slots槽数组（2kb）和整个集群1/10的状态数据 节点部署的机器规模：机器的带宽上限是固定的，因此相同规模的集群分布的机器越多，每台机器划分的节点越均匀，则整个集群内整体的可用带宽越高集群带宽消耗主要分为：读写命令消耗+Gossip消息消耗，因此搭建Redis集群需要根据业务数据规模和消息通信成本做出合理规划： 在满足业务需求的情况下尽量避免大集群，同一个系统可以针对不同业务场景拆分使用若干个集群。 适度提供cluster-node-timeout降低消息发送频率，但是cluster-node-timeout还影响故障转移的速度，因此需要根据自身业务场景兼顾二者平衡 如果条件允许尽量均匀部署在更多机器上，避免集中部署。如果有60个节点的集群部署在3台机器上每台20个节点，这是机器的带宽消耗将非常严重Pub/Sub广播问题集群模式下内部对所有publish命令都会向所有节点进行广播，加重带宽负担，所以集群应该避免频繁使用Pub/sub功能集群倾斜集群倾斜是指不同节点之间数据量和请求量出现明显差异，这种情况将加大负载均衡和开发运维的难度。因此需要理解集群倾斜的原因 数据倾斜： 节点和槽分配不均 不同槽对应键数量差异过大 集合对象包含大量元素 内存相关配置不一致 请求倾斜：合理设计键，热点大集合对象做拆分或者使用hmget代替hgetall避免整体读取集群读写分离集群模式下读写分离成本比较高，直接扩展主节点数量来提高集群性能是更好的选择。参考文档 一文掌握Redis的三种集群方案 深入分析Cluster 集群模式 你必须知道的4种 Redis 集群方案及优缺点对比 Redis Cluster数据分片实现原理、及请求路由实现 Redis集群Gosisp协议与节点通信 集群通信 Redis高可用架构—Redis集群（Redis Cluster）详细介绍redis 故障及调优 Redis 故障诊断及常用运维命令—内存篇 3大问题！Redis缓存异常及处理方案总结 Redis的三大缓存异常原因分析和解决方案 Redis常见的故障以及发生场景 Redis中常见的问题以及解决方案 redis线上环境挂机导致的服务崩溃的故障记录 redis故障修复 Redis的性能问题总结、排查及调优 Redis性能优化redis 综合可参见以下系列文章 一文让你彻底了解Redis(进阶)，史上最全,不看后悔！！！【建议收藏】、 Redis 整理 一文全、 用Redis实现分布式锁的血泪史" }, { "title": "kafka 杂谈", "url": "/2016/07/kafka.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2016-07-06 08:36:51 +0800", "snippet": " 本文主要介绍 kafka 相关的一些理论知识、实践经验和验证实验。 架构简介 kafka 应用 典型应用场景 常用工具和命令 kafka 实现原理 通讯协议 kafka 集群 kafka 故障及调优 kafka 综合 kafka 常见面试题架构简介 Kafka系列3-Kafka架构 Kafka的基本架构和组成部分 Kafka体...", "content": " 本文主要介绍 kafka 相关的一些理论知识、实践经验和验证实验。 架构简介 kafka 应用 典型应用场景 常用工具和命令 kafka 实现原理 通讯协议 kafka 集群 kafka 故障及调优 kafka 综合 kafka 常见面试题架构简介 Kafka系列3-Kafka架构 Kafka的基本架构和组成部分 Kafka体系架构详细分解 Kafka基本架构和概述 Apache Kafka 集群架构 Kafka的简介与架构 Kafka技术架构那些事儿 Kafka 架构分析 Kafka架构图 一文带你搞懂 Kafka 的系统架构（深度好文，值得收藏） Kafka 架构设计 Kafka 架构设计kafka 应用有时候应用一个组件不需要事先知道其原理，只有在深度使用时遇到比较棘手的场景或问题时才会去深度了解。基于这个观点，我们首先从应用的角度来了解 kafka。典型应用场景 kafka介绍及使用场景 kafka学习（六）：kafka应用场景 Kafka的应用场景有哪些 应用场景 解开Kafka神秘的面纱(一)：kafka架构与应用场景 解开Kafka神秘的面纱(二)：Kafka的高效读写与消息安全常用工具和命令 Kafka的命令行工具 Kafka全网最全最详细运维命令合集 Kafka监控工具汇总 Kafka可视化工具详解(3种主流可视化工具) kafkactl Kafka 命令行工具 kcat/kafkacatkafka 实现原理 Kafka基本原理详解 讲真！Kafka 的原理竟是这样的，一看就明白！ Kafka 的原理有哪些？ Kafka的核心原理 一文读懂Kafka的工作原理 Kafka事务「原理剖析」 一文读懂 kafka 的事务机制 【十二】kafka事务机制 kafka的幂等及事务 Kafka的底层高性能实现解读 再过半小时，你就能明白kafka的工作原理了 搞透Kafka的存储架构，看这篇就够了 kafka原理讲解 kafka的底层结构原理 深入浅出kafka原理-3-高效文件存储设计特点 深入浅出kafka原理-2-Kafka为何那么快（高效） kafka 数据可靠性深度解读 22.神说：Kafka其实是个数据库(此话不要当真) Kafka核心原理的秘密，藏在这19张图里！ Kafka核心原理的秘密，藏在这19张图里！ kafka核心工作原理 kafka内核原理通讯协议 kafka协议 Kafka通讯协议指南 吃透Kafka底层通信机制后，我把系统网络性能提升了10倍以上！ 面试系列-kafka内部通信协议kafka 集群 Kafka集群原理 Kafka之集群架构原理 Kafka集群原理讲解及分区机制 浅析 Apache Kafka 分区重分配的实现原理 Kafka分区分配策略 Kafka分区分配策略详解 【总结】Kafka消费者——分区分配策略 Kafka 原理以及分区分配策略剖析 Kafka提升–内部工作原理 无需zookeeper，kafka3.0版本集群安装实战 kafka集群搭建过程 Kafka 跨集群同步方案 为什么说基于 Kafka 的数据集成方案很难走得更远kafka 故障及调优 Kafka 容错及高可用原理 | 运维进阶 kafka常见的问题（具体详细） kafka常见问题汇总 kafka容灾机制 Kafka常见问题整理 Kafka | 记一次修复Kafka分区所在broker宕机故障-引发当前分区不可用的思考过程 通过一个Kafka故障解决过程阐述架构师必须具备的架构思维 Kafka突然宕机了？稳住，莫慌！ kafka故障排查-consumer处理超时导致的异常 Topic 配置 ACL 策略后导致其他产品联动能力失效 配置 ACL 策略 美团1.5万台Kafka，怎么抗下每秒数亿消息量的挑战？ Kafka 万亿级消息实践之资源组流量掉零故障排查分析 Kafka 数据丢失问题总结 线上kafka消息堆积，consumer掉线，怎么办？ 公司内部一次关于kafka消息队列消费积压故障复盘分享kafka 综合 「查缺补漏」 Kafka 核心知识梳理 【Kafka从入门到放弃系列 零】Kafka看这一篇就够了、 kafka系统设计开篇， 想完全弄懂kafka？看这篇就够了 真的，搞懂 Kafka 看这一篇就够了 Kafka全面学习 Kafka详解(包括kafka集群搭建)kafka 常见面试题 Kafka的面试知识，都在这儿了 八年面试生涯，整理了一套Kafka面试题、 2019年这50个Kafka面试题，你知道答案么？、 Kafka面试题、 面试问：Kafka 为什么速度那么快？、 Kafka 常见问题 大数据面试题知识点分析之 Kafka 面试真题及答案有哪些？ kafka面试总结（全面） Kafka面试题系列(进阶篇)、 常见Kafka面试题及答案总汇、" }, { "title": "MySQL 杂谈", "url": "/2016/07/mysql.html", "categories": "计算机综合", "tags": "IT_Basic", "date": "2016-07-04 08:25:45 +0800", "snippet": " 本文主要介绍 MySQL 相关的一些理论知识、实践经验和验证实验。 基本概念 MySQL 基本框架图 SQL 语句 数据库连接 语句执行流程 查询语句执行流程 查询状态 查询优化 ...", "content": " 本文主要介绍 MySQL 相关的一些理论知识、实践经验和验证实验。 基本概念 MySQL 基本框架图 SQL 语句 数据库连接 语句执行流程 查询语句执行流程 查询状态 查询优化 update 语句执行流程 insert 语句执行流程 delete 语句执行流程 语句实现原理 select 工作原理 关联查询（join） order by 工作原理 group by 工作原理 where 和 having 的区别 事务机制 衡量事务的四个特性（ACID） undo log 实现原子性 redo log 实现持久性 锁和 MVCC 机制实现隔离性 日志文件 日志落盘策略 数据丢失的场景 主从同步 存储过程 视图 索引 不走索引的情况 存储引擎基本概念MySQL 是一个开源免费的关系数据库软件。数据库相关的基础可以参考博文数据库基础。MySQL 基本框架图框架图可以帮助我们从宏观上了解 MySQL 的大致全貌，有助于我们从关联的角度理解其如此设计的背后逻辑。同时也可以帮助我们从外部寻找线索窥探其中的设计原理和实现细节。以下几张架构图试图从不同的详略角度刻画 MySQL 的基本架构。 其中较为底层的原理可参见一篇文章让你搞懂MYSQL底层原理， 更详细的文档可参考官方文档 操作手册 mysql组成部分总览 mysql组件间的协同流程 源码方面的解读MySQL源码探索02SQL命令总体执行流程 有人总结的面试经典 《深入精通Mysql（一）》Mysql整体架构和sql执行过程（面试高频题 《深入精通Mysql（二）》深入底层剖析Mysql索引（面试必问） 《深入精通Mysql（三）》深入底层剖析Mysql各种锁机制（面试必问） 《深入精通Mysql（四）》MySQL 事务机制，中高级开发面试必问！ 深入了解MySQL主从复制的原理 《深入精通Mysql（六）》系列之如何通过慢查询日志进行SQL分析和优化 《深入精通Mysql（七）》系列之如何通过EXPLAIN 执行计划分析SQL语句的性能瓶颈 配置可能引发一些问题：MySQL部署和运维、mysql配置和问题、mysql配置参数详解 SQL 语句MySQL 语句可以分为以下几类，详细的可参考标准SQL。 mysql支持的数据类型可参考官方文档 mysql与标准的SQL的关系可参考标准SQL扩展、与标准SQL的差异 mysql操作可参考官方文档 类型 包含的指令 DDL((Data Definition Language，数据定义语言)) create: 创建数据库及其对象(包括新建表，索引，视图，存储过程，用户等)   alter: 改变现有数据库或表的结构 (包括修改索引，修改字段类型，删除索引)   truncate: 删除表中所有记录，并删除已分配的空间   comment: 添加注释   rename: 重命名，其中包括索引、表名等。   use: 切换数据库。   show: 查看所有的数据库或表或建表语句，后面可接 databases，tables，或者 show create databases或table 库名或表名。   desc: 查看表结构 desc 表名   drop: 删除数据库或表或用户，drop database或table 库名或表名 DML (Data Manipulation Language，数据操作语句) select: 从数据库中检索数据   insert: 新增数据到数据库中   update: 更新表格中现有数据   delete: 删除现有数据   explain: 查看语句的执行计划   lock table: 锁表操作 DCL (Data Control Language，数据控制语句) grant: 允许用户访问数据库的权限   revoke: 撤销用户访问数据库的权限 TCL (Transactional Control Language，事务控制语言) commit: 提交事务   rollback: 回滚事务   set transaction: 设置事务隔离级别 这里以存储过程的操作为例：-- 创建存储过程CREATE PROCEDURE proname() BEGINselect * from table;END;-- 执行存储过程CALL proname();-- 删除存储过程DROP PROCEDURE proname;数据库连接当你在终端敲下该命令 mysql -h 主机名(ip) -u 用户名 -P 端口 -p密码 数据库名 --default-character-set=编码类型 （详细参数说明可参考官方文档 回车之后发生了什么？ TCP 三次握手 mysql 客户端与服务端握手认证（三次握手） 服务器 -&gt; 客户端：握手初始化消息 客户端 -&gt; 服务器：登陆认证消息 服务器 -&gt; 客户端：认证结果消息 命令执行阶段（上述阶段完成之后） 客户端 -&gt; 服务器：执行命令消息 服务器 -&gt; 客户端：命令执行结果 退出命令 TCP 四次挥手 参考文章 具体的协议包分析可参考mysql通信协议抓包分析、Mysql 通讯协议分析、通信方式类别。mysql 客户端与服务端的通信协议可参考官方文档。 对于 TCP 的连接和断开分析可参考 4个实验，彻底搞懂TCP连接的断开。 不用的版本或配置，可能会导致相同的语句的执行结果或报错不一样，配置可参考Mysql数据库配置参数详解大全、mysql配置参数详解语句执行流程了解 MySQL 语句执行流程有助于我们优化和选择恰当的语句，以提供性能。每个具体执行流程中执行的操作不相同，所涉及到的数据量不同，有的可能使用临时表等，针对这些特点可以采取更换顺序、减少数据量等手段进行优化。查询语句执行流程 DML语句首先进行语法分析，对使用sql表示的查询进行语法分析，生成查询语法分析树。 语义检查：检查sql中所涉及的对象以及是否在数据库中存在，用户是否具有操作权限等 视图转换：将语法分析树转换成关系代数表达式，称为逻辑查询计划； 查询优化：在选择逻辑查询计划时，会有多个不同的表达式，选择最佳的逻辑查询计划； 代码生成：必须将逻辑查询计划转换成物理查询计划，物理查询计划不仅能指明要执行的操作，也给出了这些操作的执行顺序，每步所用的算法，存储数据的方式以及从一个操作传递给另一个操作的方式。 将DML转换成一串可执行的存取操作的过程称为束缚过程，--查询组合字段(6)select (6-2) distinct(6-3) top(&lt;top_specification&gt;)(6-1)&lt;select_list&gt;--连表(1)from (1-J)&lt;left_table&gt;&lt;join_type&gt; join &lt;right_table&gt; on &lt;on_predicate&gt; (1-A)&lt;left_table&gt;&lt;apply_type&gt; apply &lt;right_table_expression&gt; as &lt;alias&gt; (1-P)&lt;left_table&gt; pivot (&lt;pivot_specification&gt;) as &lt;alias&gt; (1-U)&lt;left_table&gt; unpivot (&lt;unpivot_specification&gt;) as &lt;alias&gt;--查询条件(2)where &lt;where_pridicate&gt;--分组(3)group by &lt;group_by_specification&gt;--是否对分类聚合后的结果进行再汇总(4)with &lt;cube|rollup&gt;--分组条件(5)having&lt;having_predicate&gt;--排序(7)union(all)(8)order by&lt;order_by_list&gt;(9)limit &lt;limit_number&gt;--说明：--1、顺序为有1-6，6个大步骤，然后细分，6-1，6-2，6-3，由小变大顺序，1-J，1-A，1-P，1-U，为并行次序。如果不够明白，接下来我在来个流程图看看。--2、执行过程中也会相应的产生多个虚拟表（下面会有提到），以配合最终的正确查询。--参考自博客：https://blog.csdn.net/bitcarmanlee/article/details/51004767?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-6.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-6.control查询状态对于 MySQL 连接，任何时刻都有一个状态，该状态表示了MySQL当前正在做什么。使用 show full processlist 命令查看当前状态。在一个查询生命周期中，状态会变化很多次，下面是这些状态的解释： sleep：线程正在等待客户端发送新的请求； query：线程正在执行查询或者正在将结果发送给客户端； locked：在MySQL服务器层，该线程正在等待表锁。在存储引擎级别实现的锁，例如InnoDB的行锁，并不会体现在线程状态中。对于MyISAM来说这是一个比较典型的状态； analyzing and statistics：线程正在收集存储引擎的统计信息，并生成查询的执行计划； copying to tmp table：线程在执行查询，并且将其结果集复制到一个临时表中，这种状态一般要么是做group by操作，要么是文件排序操作，或者union操作。如果这个状态后面还有on disk标记，那表示MySQL正在将一个内存临时表放到磁盘上； sorting result：线程正在对结果集进行排序； sending data：线程可能在多个状态间传送数据，或者在生成结果集，或者在想客户端返回数据。查询优化MySQL Query Optimizer 通过执行explain命令来获取一个 Query 在当前状态的数据库中的执行计划。expain 出来的信息有10列，分别是 id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra。可以通过这个线上实验网站进行 expain 实验。 示例可参见官方文档 Mysql Explain 详解。 万字SQL优化大全 MySQL的SQL优化常用30种方法、21个SQL语句优化规范方法、MySQL数据库优化技巧大全 MySql基础知识总结（SQL优化篇）、MySQL数据库优化总结 MySQL定位并优化慢查询sql的详细实例 字段名 描述 值 id SELECT 识别符。这是 SELECT 的查询序列号 id 相同时，执行顺序由上至下     如果是子查询，id 的序号会递增，id 值越大优先级越高，越先被执行     id 如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id 值越大，优先级越高，越先执行 select_type 示查询中每个 select 子句的类型 SIMPLE(简单SELECT,不使用UNION或子查询等)；     PRIMARY(查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY)；     UNION(UNION中的第二个或后面的SELECT语句)；     DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)；     UNION RESULT(UNION的结果)；     SUBQUERY(子查询中的第一个SELECT)；     DEPENDENT SUBQUERY(子查询中的第一个SELECT，取决于外面的查询)；     DERIVED(派生表的SELECT, FROM子句的子查询)；     UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行)。 table 表示 explain 的一行正在访问哪个表 有时不是真实的表名字，可能是简称，例如上面的e，d，也可能是第几步执行的结果的简称 type 表示MySQL在表中找到所需行的方式 常用的类型有：ALL, index, range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）     ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行     index: Full Index Scan，index 与 ALL 区别为 index 类型只遍历索引树     range:只检索给定范围的行，使用一个索引来选择行     ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行     eq_ref: 类似 ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件     const、system: 当 MySQL 对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system     NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 possible_keys 显示查询可能使用哪些索引来查找 explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，MySQL认为索引对此查询帮助不大，选择了全表查询。     如果该列是 NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果 key 显示 MySQL 实际决定使用的键（索引） 如果没有选择索引，键是 NULL。要想强制 MySQL 使用或忽视 possible_keys 列中的索引，在查询中使用 FORCE INDEX、USE INDEX 或者 IGNORE INDEX。 key_len 表示索引中使用的字节数 可通过该列计算查询中使用的索引的长度（key_len 显示的值为索引字段的最大可能长度，并非实际使用长度，即 key_len 是根据表定义计算而得，不是通过表内检索出的）     不损失精确性的情况下，长度越短越好。 ref 这一列显示了在 key 列记录的索引中，表查找值所用到的列或常量 常见的有：const（常量），func，NULL，字段名（例：film.id） rows 估计要读取并检测的行数 这个不是结果集里的行数 filtered 返回结果的行数占读取行数的百分比 值越大越好 Extra 额外信息 distinct: 一旦mysql找到了与行相联合匹配的行，就不再搜索了     Using index: 所有列都覆盖索引时， 不需要返回表中的行记录     Using where: 在存储引擎检索行后再进行过滤     Using temporary: 表示MySQL需要使用临时表来存储结果集，常见于 distinct、排序和分组查询。这个需要优化，比如是否有必要使用该语句、新建索引等     Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序”，对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时 mysql 会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。     Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。     Impossible where：这个值强调了 where 语句会导致没有符合条件的行。 offset limit 优化mysql查询使用select命令，配合limit，offset参数可以读取指定范围的记录,但是offset过大影响查询性能 通过二级索引查到主键值（找出所有gender=1的id)。 再根据查到的主键值通过主键索引找到相应的数据块（根据id找出对应的数据块内容）。 根据offset的值，查询300001次主键索引的数据，最后将之前的300000条丢弃，取出最后1条。所以，mysql 查询时，offset 过大影响性能的原因是多次通过主键索引访问数据块的I/O操作。优化方法有以下几种： 自增 ID 范围： 如 select * from table_name where (id &gt;= 10000) limit 10 in 主键： 如 Select * From table_name Where id in (Select id From table_name where ( user = xxx )) limit 10000, 10; inner join: 如 select * from table_name inner join ( select id from table_name where (user = xxx) limit 10000,10) b using (id) 提前算出边界，使用 between and 代替update 语句执行流程以语句 UPDATE test SET c = c + 1 WHERE id = 1; 为例简单绘制成下图（详见mysql update语句的执行过程详解）当事务提交的时候，innodb不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已)delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。update分为两种情况：update的列是否是主键列。 如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。 如果是主键列，update分两部执行：先删除该行，再插入一行目标行。insert 语句执行流程这里只给出简约的流程图（详见MySQL insert 语句的磁盘写入之旅）：delete 语句执行流程这里只给出简约的流程图： 删除优化根据不同的需求选择恰当的删除数据的方式： drop： 是直接将表格删除（包括表结构），无法找回 truncate： 是删除表中所有数据（保留表结构） delete： 也是删除表中数据，但可以与 where 连用，删除特定行； 逻辑珊瑚：使用标记位 当待删除的数据比要保留的数据量大得多时：可以先转移要保留的数据，truncate 之后再转回 delete 和 truncate 的区别 DELETE 是可以带 WHERE 的，所以支持条件删除；而 TRUNCATE 只能删除整个表 由于 DELETE 是数据操作语言（DML - Data Manipulation Language），操作时原数据会被放到 rollback segment中，可以被回滚；而 TRUNCATE 是数据定义语言（DDL - Data Definition Language)，操作时不会进行存储，不能进行回滚 在数据量比较小的情况下，DELETE 和 TRUNCATE 的清理速度差别不是很大。但是数据量很大的时候就能看出区别。由于第二项中说的，TRUNCATE 不需要支持回滚，所以使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项，固然会慢，但是相对来说也较安全 随着不断地进行表记录的 DML 操作，会不断提高表的高水位线（HWM），DELETE操作之后虽然表的数据删除了，但是并没有降低表的高水位，随着 DML 操作数据库容量也只会上升，不会下降。所以如果使用 DELETE，就算将表中的数据减少了很多，在查询时还是很和 DELETE 操作前速度一样。 而 TRUNCATE 操作会重置高水位线，数据库容量也会被重置，之后再进行 DML 操作速度也会有提升。语句实现原理select 工作原理可参见 MySQL select实现原理关联查询（join）join 实现原理可参见 MySQL 的Join及底层实现原理、数据库基础（七）Mysql Join算法原理，各种join可参见 图解MySQL里的各种 JOIN，看完不懂来找我！order by 工作原理可参见 MySQL order by、group by底层实现及优化（非常详细）、MySQL order by实现原理分析和Filesort优化、Mysql学习之order by的工作原理、mysql ORDER BY,GROUP BY 和DISTINCT原理group by 工作原理可参见 MySQL分组查询Group By实现原理详解where 和 having 的区别可参见 mysql having和where的区别、mysql where和having的区别、Mysql-where子句与having子句的区别事务机制我们可以把事务理解为一组sql语句的集合，事务可以只包含一条sql语句，也能包含多条复杂的SQL语句，事务中的所有SQL语句被当作一个操作单元，也就是说，事务中的SQL语句要么都执行成功，要么全部执行失败，事务内的SQL语句被当做一个整体，被当做一个原子进行操作。MySQL 典型的事务语句使用方法可参见mysql事务（二）——控制语句使用，详细用法见 MySQL事务控制语句（学习笔记），事务处理实例可参考 mysql事务处理语句及使用 事务（transaction）指一组SQL语句； 回退（rollback）指撤销指定SQL语句的过程； 提交（commit）指将未存储的SQL语句结果写入数据库表； 保留点（savepoint）指事务处理中设置的临时占位符（place-holder），你可以对它发布回退（与回退整个事务处理不同）-- 使用回退START TRANSACTIONdelete from table where id=123; --删除的数据 ROLLBACK 后将会还原ROLLBACK;-- 使用提交START TRANSACTIONdelete from table where id=123;delete from table where id=123;COMMIT; -- COMMIT语句仅在不出错时写出更改，只要有一条语句错误 ，所有语句将会回退。-- 使用保留点-- 使用保留点处理部分提交或回退SAVEPOINT pointName; -- 定义一个保留点ROLLBACK TO pointName; -- 回退到指定保留点RELEASE SAVEPOINT pointName; --明确地释放保留点衡量事务的四个特性（ACID）按照严格的标准，只有同时满足ACID特性才是事务；但是在各大数据库厂商的实现中，真正满足 ACID 的事务少之又少。例如 MySQL 的 NDB Cluster 事务不满足持久性和隔离性；InnoDB 默认事务隔离级别是可重复读，不满足隔离性；Oracle 默认的事务隔离级别为 READ COMMITTED，不满足隔离性……因此与其说 ACID 是事务必须满足的条件，不如说它们是衡量事务的四个维度 事务特性 描述 实现原理 原子性（Atomicity，或称不可分割性） 原子性是指一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做； 如果事务中一个sql语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态。 undo log保证了事务的原子性 一致性（Consistency） 一致性是指事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。 原子性、持久性和隔离性都是为了实现事务的一致性 隔离性（Isolation） 事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰 (一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性；(一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性。InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView） 持久性（Durability） 持久性是指事务一旦提交，它对数据库的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响 MySQL的innoDB存储引擎，使用Redo log保证了事务的持久性 数据库中的一致性可以分为数据库外部的一致性和数据库内部的一致性。前者由外部应用的编码来保证，即某个应用在执行转帐的数据库操作时，必须在同一个事务内部调用对帐户A和帐户B的操作。如果在这个层次出现错误，这不是数据库本身能够解决的，也不属于我们需要讨论的范围。后者由数据库来保证，即在同一个事务内部的一组操作必须全部执行成功(或者全部失败)。这就是事务处理的原子性。如果在事务中第一次读取采用非加锁读，第二次读取采用加锁读，则如果在两次读取之间数据发生了变化，两次读取到的结果不一样，因为加锁读时不会采用 MVCCundo log 实现原子性MySQL 的日志有很多种，如二进制日志、错误日志、查询日志、慢查询日志等，此外 InnoDB 存储引擎还提供了两种事务日志：redo log(重做日志)和undo log(回滚日志)。其中 redo log用于保证事务持久性；undo log则是事务原子性和隔离性实现的基础。实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的 sql 语句。InnoDB 实现回滚，靠的是 undo log：当事务对数据库进行修改时，InnoDB 会生成对应的 undo log；如果事务执行失败或调用了 rollback，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。undo log 属于逻辑日志，它记录的是 sql 执行相关的信息。当发生回滚时，InnoDB 会根据 undo log的内容做与之前相反的工作：对于每个 insert，回滚时会执行 delete；对于每个 delete，回滚时会执行 insert；对于每个 update，回滚时会执行一个相反的 update，把数据改回去。redo log 实现持久性InnoDB 作为 MySQL 的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘 IO，效率会很低。为此，InnoDB 提供了缓存(Buffer Pool)，Buffer Pool 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，则从磁盘读取后放入 Buffer Pool；当向数据库写入数据时，会首先写入 Buffer Pool，Buffer Pool 中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。Buffer Pool 的使用大大提高了读写数据的效率，但是也带了新的问题：如果 MySQL 宕机，而此时 Buffer Pool 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。于是，redo log 被引入来解决这个问题：当数据修改时，除了修改 Buffer Pool 中的数据，还会在 redo log 记录这次操作；当事务提交时，会调用 fsync 接口对 redo log 进行刷盘。如果 MySQL 宕机，重启时可以读取 redo log 中的数据，对数据库进行恢复。redo log 采用的是 WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。在这个事务提交前，将 redo log 的写入拆成了两个步骤，prepare 和 commit，这就是”两阶段提交”。 为什么要采用两阶段提交呢？实际上，两阶段提交是分布式系统常用的机制。MySQL 使用了两阶段提交后，也是为了保证事务的持久性。redo log 和 bingo 有一个共同的数据字段叫 XID, 崩溃恢复的时候，会按顺序扫描 redo log。 假设在写入 binlog 前系统崩溃，那么数据库恢复后顺序扫描 redo log，碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务，而且 binlog 也没写入，所以事务就直接回滚了。 假设在写入 binlog 之后，事务提交前数据库崩溃，那么数据库恢复后顺序扫描 redo log，碰到既有 prepare、又有 commit 的 redo log，就直接提交，保证数据不丢失。插入数据的过程中，生成的日志都得先写入 redo log buffer ，等到 commit 的时候，才真正把日志写到 redo log 文件。（当然，这里不绝对，因为redo log buffer可能因为其他原因被迫刷新到redo log）。而为了确保每次日志都能写入日志文件，在每次将 重做日志缓冲 写入 重做日志文件 后，InnoDB 存储引擎都需要调用一次 fsync 操作，确保写入了磁盘。而为了确保每次日志都能写入日志文件，在每次将重做日志缓冲 写入 重做日志文件 后，InnoDB存储引擎都需要调用一次fsync操作，确保写入了磁盘。锁和 MVCC 机制实现隔离性MySQL 的锁机制可以参见MySQL锁总结，结合案例分析可参见MySQL锁详解。MVCC 可参见正确的理解MySQL的MVCC及实现原理，其案例分析可参见MYSQL MVCC实现原理，版本链形象化描述可参见mvcc原理详解MVCC 具象化描述可参见 MySQL MVCC底层原理详解MySQL MVCC底层原理详解日志文件 日志文件的类型可参见 MySQL不会丢失数据的秘密，就藏在它的 7种日志里、MySQL系列之十一 日志记录 、MySQL中的日志文件 你全都了解吗？ 或 详细分析MySQL的日志(一) binlog、undo log、redo log 参见彻底搞懂mysql日志系统binlog,redolog,undolog、必须了解的mysql三大日志,你知道几个？ binlog 详解可参见 MySQL 数据库之Binlog日志使用总结 事务日志详解可参见 详细分析MySQL事务日志(redo log和undo log)、说说MySQL中的Redo log Undo log都在干啥 、Redo与Undo的理解 redo 和 bin 日志区别(联系见该文) 产生位置不同： redo log是属于innoDB层面，binlog属于MySQL Server层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。 记录内容不同： redo log是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑 生成方式不同： redo log是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。 使用目的不同： binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。 写入时间不同： binlog仅仅在事务提交前，只写磁盘⼀次，不论这时该事务多⼤；重做⽇志，在事务进⾏过程中，会发⽣不断地写⼊ redolog 和 undolog的区别 作用不同： redolog即重做⽇志，⽤来保证事务的原⼦性和持久性。正常情况⽤不到，只有 mysql 实例所在的主机断电了，Innodb存储引擎会使⽤redolog恢复到掉电前的时刻，保证数据完整性；undolog⽤来保证事务的⼀致性，当事务需要回滚时，就会⽤到undolog 位置不同： redolog存储在重做⽇志⽂件中， undo放在数据库内部的⼀个特殊的段，这个段被称 为undo段。 undo段位于共享表空间内 类型不同： redo是物理⽇志，记录的是⻚的物理修改操作。undo是逻辑⽇志，根据每⾏记录进⾏记录。当事务回滚时， undolog回滚⾏记录到某个特定版本。只是将数据库逻辑地恢复到原来的样⼦，⽽不是完整的将数据库回滚到事务开始前的样⼦。 事务回滚可能有各种原因，⽐如死锁回滚，⽐如⽤⽤户主动rollback等.日志落盘策略Mysql 普通落盘策略可参见 MySQL InnoDB的磁盘文件及落盘机制 和 mysql数据落盘详解_MySQL的Flush-List和脏页的落盘机制redo 日志刷盘策略可参见 redo日志的刷盘策略数据丢失的场景可参见 MySQL数据库丢失数据场景分析、[MySQL] 如何做到不丢数据主从同步可参见 Mysql主从同步的原理、小白都能懂的Mysql主从复制原理（原理+实操）、深度探索MySQL主从复制原理、主从存在的疑问 MySQL主备、主从、读写分离详解存储过程存储过程是⼀个预编译的SQL语句，优点是允许模块化的设计，就是说只需要创建⼀次，以后在该程序中就可以调⽤多次。如果某次操作需要执⾏多次SQL，使⽤存储过程⽐单纯SQL 语句执⾏要快。-- 创建存储过程CREATE PROCEDURE proname() BEGINselect * from table;END;-- 执行存储过程CALL proname();-- 删除存储过程DROP PROCEDURE proname; 优点 1）存储过程是预编译过的，执⾏效率⾼。 2）存储过程的代码直接存放于数据库中，通过存储过程名直接调⽤，减少⽹络通讯。 3）安全性⾼，执⾏存储过程需要有⼀定权限的⽤户。 4）存储过程可以重复使⽤，减少数据库开发⼈员的⼯作量。 缺点 1）调试麻烦，但是⽤ PL/SQL Developer 调试很⽅便！弥补这个缺点。 2）移植问题，数据库端代码当然是与数据库相关的。但是如果是做⼯程型项⽬，基本不存在移植问题。 3）重新编译问题，因为后端代码是运⾏前编译的，如果带有引⽤关系的对象发⽣改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运⾏时刻⾃动编译）存储过程的具体细节可参见 mysql存储过程详细教程视图所谓视图，本质上是⼀种虚拟表，在物理上是不存在的，其内容与真实的表相似，包含⼀系列带有名称的列和⾏数据。但是，视图并不在数据库中以储存的数据值形式存在。⾏和列数据来⾃定义视图的查询所引⽤基本表，并且在具体引⽤视图时动态⽣成。为了提⾼复杂SQL语句的复⽤性和表操作的安全性， MySQL数据库管理系统提供了视图特性。视图使开发者只关⼼感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，⽽不是视图所引⽤表中的数据，从⽽提⾼了数据库中数据的安全性。视图相关的一些具体细节可参见 MySQL视图详解索引可参见 彻底搞懂MySQL的索引、彻底搞懂MySQL的索引、MySQL索引到底怎么回事、mysql 索引是怎么实现的？、MySQL索引完全解读彻底理解 MySQL 的索引机制，终于不再因为 MySQL 优化而被面试官鄙视了不走索引的情况可参见 mysql中的索引使用以及索引失效及索引常见面试题、详解mysql什么时候不走索引、总结mysql索引失效的N种情况、MySQL中有哪些情况下数据库索引会失效详析、mysql什么时候需要建索引，什么是后不要建索引？存储引擎MyISAM 和 InnoDB 对比可参见 MySQL存储引擎详解，各大存储引擎简介可参见 MySQL 常用存储引擎详解和区别、MySQL 各种存储引擎详解，各大引擎的适用场景可参见 mysql的存储引擎详解_Mysql存储引擎详解" } ]
